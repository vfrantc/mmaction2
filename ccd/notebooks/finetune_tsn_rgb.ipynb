{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vfrantc/mmaction2/blob/main/ccd/notebooks/finetune_tsn_rgb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eetlQsC7Gz2U",
        "outputId": "2d95c22a-c16c-43f6-fad1-f0e5ce43fce2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vfrantc/mmaction2.git\n",
        "%cd mmaction2\n",
        "!pip install timm\n",
        "!pip install -v -e .\n",
        "!pip install -U openmim\n",
        "!mim install mmengine\n",
        "!mim install mmcv\n",
        "!mim install mmdet\n",
        "!mim install mmpose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IE0AXWotcaUb",
        "outputId": "0f2e4b3b-251d-4b74-af19-8ffa0eb62b10"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmaction2'...\n",
            "remote: Enumerating objects: 22287, done.\u001b[K\n",
            "remote: Counting objects: 100% (201/201), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 22287 (delta 113), reused 152 (delta 83), pack-reused 22086\u001b[K\n",
            "Receiving objects: 100% (22287/22287), 65.36 MiB | 30.26 MiB/s, done.\n",
            "Resolving deltas: 100% (15676/15676), done.\n",
            "/content/mmaction2\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.12\n",
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Obtaining file:///content/mmaction2\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-8rliwwgt/mmaction2.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-8rliwwgt/mmaction2.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-8rliwwgt/mmaction2.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-8rliwwgt/mmaction2.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-8rliwwgt/mmaction2.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-8rliwwgt/mmaction2.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-8rliwwgt/mmaction2.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no files found matching 'mmaction/.mim/model-index.yml'\n",
            "  warning: no files found matching 'mmaction/.mim/dataset-index.yml'\n",
            "  warning: no files found matching '*.py' under directory 'mmaction/.mim/configs'\n",
            "  warning: no files found matching '*.yml' under directory 'mmaction/.mim/configs'\n",
            "  warning: no files found matching '*.sh' under directory 'mmaction/.mim/tools'\n",
            "  warning: no files found matching '*.py' under directory 'mmaction/.mim/tools'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-8rliwwgt/mmaction2.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting decord>=0.4.1 (from mmaction2==1.2.0)\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from mmaction2==1.2.0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmaction2==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->mmaction2==1.2.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->mmaction2==1.2.0) (1.3.0)\n",
            "Installing collected packages: einops, decord, mmaction2\n",
            "  Running setup.py develop for mmaction2\n",
            "    Running command python setup.py develop\n",
            "    running develop\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "    !!\n",
            "\n",
            "            ********************************************************************************\n",
            "            Please avoid running ``setup.py`` and ``easy_install``.\n",
            "            Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "            other standards-based tools.\n",
            "\n",
            "            See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "            ********************************************************************************\n",
            "\n",
            "    !!\n",
            "      easy_install.initialize_options(self)\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "    !!\n",
            "\n",
            "            ********************************************************************************\n",
            "            Please avoid running ``setup.py`` directly.\n",
            "            Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "            other standards-based tools.\n",
            "\n",
            "            See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "            ********************************************************************************\n",
            "\n",
            "    !!\n",
            "      self.initialize_options()\n",
            "    running egg_info\n",
            "    creating mmaction2.egg-info\n",
            "    writing mmaction2.egg-info/PKG-INFO\n",
            "    writing dependency_links to mmaction2.egg-info/dependency_links.txt\n",
            "    writing requirements to mmaction2.egg-info/requires.txt\n",
            "    writing top-level names to mmaction2.egg-info/top_level.txt\n",
            "    writing manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    reading manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    Creating /usr/local/lib/python3.10/dist-packages/mmaction2.egg-link (link to .)\n",
            "    Adding mmaction2 1.2.0 to easy-install.pth file\n",
            "\n",
            "    Installed /content/mmaction2\n",
            "Successfully installed decord-0.6.0 einops-0.7.0 mmaction2-1.2.0\n",
            "Collecting openmim\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.7)\n",
            "Collecting colorama (from openmim)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.31.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.7.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.5.1)\n",
            "Collecting ordered-set (from model-index->openmim)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (4.66.1)\n",
            "Collecting openxlab (from opendatalab->openmim)\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.23.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests (from openmim)\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich (from openmim)\n",
            "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm (from opendatalab->openmim)\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun-python-sdk-core-2.14.0.tar.gz (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m41.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (41.0.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\n",
            "Building wheels for collected packages: oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=0bf31e0116d76e136561b02c16c4de1323dd1dc257ccd9becde0c38a64d34fc1\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.14.0-py3-none-any.whl size=535289 sha256=ee5de932af2e2b3bcb93dc52750a2a801d6292675871364c5b08e4dff7c2e386\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/3c/68/b7eab618d9f1d5e7d386296f1e07e2cf36aaa1eb5161885038\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31405 sha256=58befbb66984c3f2bdf360864e105cd58bfc9220bb45daf1b2940209b3d1856d\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: crcmod, urllib3, tqdm, setuptools, pycryptodome, ordered-set, jmespath, colorama, rich, requests, model-index, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.0\n",
            "    Uninstalling rich-13.7.0:\n",
            "      Successfully uninstalled rich-13.7.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.32 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.14.0 aliyun-python-sdk-kms-2.16.2 colorama-0.4.6 crcmod-1.7 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.29 ordered-set-4.1.0 oss2-2.17.0 pycryptodome-3.19.0 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2 urllib3-1.26.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\n",
            "Collecting mmengine\n",
            "  Downloading mmengine-0.10.1-py3-none-any.whl (450 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.3/450.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmengine)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine) (1.23.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine) (6.0.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.3.0)\n",
            "Collecting yapf (from mmengine)\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (4.0.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\n",
            "Installing collected packages: addict, yapf, mmengine\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mmaction2 1.2.0 requires mmcv<2.2.0,>=2.0.0rc4, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed addict-2.4.0 mmengine-0.10.1 yapf-0.40.2\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\n",
            "Collecting mmcv\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/mmcv-2.1.0-cp310-cp310-manylinux1_x86_64.whl (99.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from mmcv) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv) (23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv) (0.40.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv) (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv) (2.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv) (4.0.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv) (3.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv) (1.16.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.1.0\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\n",
            "Collecting mmdet\n",
            "  Downloading mmdet-3.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet) (1.23.5)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet) (2.0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet) (1.11.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet) (1.16.0)\n",
            "Collecting terminaltables (from mmdet)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mmdet) (4.65.2)\n",
            "Requirement already satisfied: mmcv<2.2.0,>=2.0.0rc4 in /usr/local/lib/python3.10/dist-packages (from mmdet) (2.1.0)\n",
            "Requirement already satisfied: mmengine<1.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from mmdet) (0.10.1)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (2.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (0.40.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (4.8.0.76)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.7.1->mmdet) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.7.1->mmdet) (2.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.0.0,>=0.7.1->mmdet) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.0.0,>=0.7.1->mmdet) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0rc4->mmdet) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0rc4->mmdet) (4.0.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0rc4->mmdet) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv<2.2.0,>=2.0.0rc4->mmdet) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine<1.0.0,>=0.7.1->mmdet) (0.1.2)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "Successfully installed mmdet-3.2.0 terminaltables-3.1.10\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\n",
            "Collecting mmpose\n",
            "  Downloading mmpose-1.2.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chumpy (from mmpose)\n",
            "  Downloading chumpy-0.70.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting json-tricks (from mmpose)\n",
            "  Downloading json_tricks-3.17.3-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmpose) (3.7.1)\n",
            "Collecting munkres (from mmpose)\n",
            "  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmpose) (1.23.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mmpose) (4.8.0.76)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from mmpose) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmpose) (1.11.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from mmpose) (0.16.0+cu118)\n",
            "Collecting xtcocotools>=1.12 (from mmpose)\n",
            "  Downloading xtcocotools-1.14.3-cp310-cp310-manylinux1_x86_64.whl (436 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.0/436.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mmcv<2.2.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mmpose) (2.1.0)\n",
            "Requirement already satisfied: mmdet<3.3.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from mmpose) (3.2.0)\n",
            "Requirement already satisfied: mmengine<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mmpose) (0.10.1)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0->mmpose) (2.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0->mmpose) (23.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0->mmpose) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0->mmpose) (0.40.2)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet<3.3.0,>=3.0.0->mmpose) (2.0.7)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet<3.3.0,>=3.0.0->mmpose) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet<3.3.0,>=3.0.0->mmpose) (1.16.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from mmdet<3.3.0,>=3.0.0->mmpose) (3.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mmdet<3.3.0,>=3.0.0->mmpose) (4.65.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.4.0->mmpose) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.4.0->mmpose) (2.3.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.10/dist-packages (from xtcocotools>=1.12->mmpose) (60.2.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.10/dist-packages (from xtcocotools>=1.12->mmpose) (3.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmpose) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmpose) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmpose) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmpose) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmpose) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmpose) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->mmpose) (2.28.2)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->mmpose) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->mmpose) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->mmpose) (3.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->mmpose) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->mmpose) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.0.0,>=0.4.0->mmpose) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.0.0,>=0.4.0->mmpose) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0->mmpose) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0->mmpose) (4.0.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0->mmpose) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv<2.2.0,>=2.0.0->mmpose) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine<1.0.0,>=0.4.0->mmpose) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision->mmpose) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision->mmpose) (1.3.0)\n",
            "Building wheels for collected packages: chumpy\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chumpy: filename=chumpy-0.70-py3-none-any.whl size=58281 sha256=fddc463ffe0447630f86523b467393e8e923d9d7479c1ef4e921976661aad851\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/c1/ef/29ba7be03653a29ef6f2c3e1956d6c4d8877f2b243af411db1\n",
            "Successfully built chumpy\n",
            "Installing collected packages: munkres, json-tricks, chumpy, xtcocotools, mmpose\n",
            "Successfully installed chumpy-0.70 json-tricks-3.17.3 mmpose-1.2.0 munkres-1.1.4 xtcocotools-1.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/accident-detection/ccd_rgb_flow.zip .\n",
        "!unzip -q ccd_rgb_flow.zip"
      ],
      "metadata": {
        "id": "4U4R9DfkcLi6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Of7pZwnj2vXm",
        "outputId": "6a67bf87-acd4-4042-987a-d0dfd2dfd228"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "remote: Enumerating objects: 18, done.\u001b[K\n",
            "remote: Counting objects:   7% (1/14)\u001b[K\rremote: Counting objects:  14% (2/14)\u001b[K\rremote: Counting objects:  21% (3/14)\u001b[K\rremote: Counting objects:  28% (4/14)\u001b[K\rremote: Counting objects:  35% (5/14)\u001b[K\rremote: Counting objects:  42% (6/14)\u001b[K\rremote: Counting objects:  50% (7/14)\u001b[K\rremote: Counting objects:  57% (8/14)\u001b[K\rremote: Counting objects:  64% (9/14)\u001b[K\rremote: Counting objects:  71% (10/14)\u001b[K\rremote: Counting objects:  78% (11/14)\u001b[K\rremote: Counting objects:  85% (12/14)\u001b[K\rremote: Counting objects:  92% (13/14)\u001b[K\rremote: Counting objects: 100% (14/14)\u001b[K\rremote: Counting objects: 100% (14/14), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 8 (delta 6), reused 8 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects:  12% (1/8)\rUnpacking objects:  25% (2/8)\rUnpacking objects:  37% (3/8)\rUnpacking objects:  50% (4/8)\rUnpacking objects:  62% (5/8)\rUnpacking objects:  75% (6/8)\rUnpacking objects:  87% (7/8)\rUnpacking objects: 100% (8/8)\rUnpacking objects: 100% (8/8), 775 bytes | 258.00 KiB/s, done.\n",
            "From https://github.com/vfrantc/mmaction2\n",
            "   555bbb75..5cf3c036  main       -> origin/main\n",
            "Updating 555bbb75..5cf3c036\n",
            "Fast-forward\n",
            " tools/data/activitynet/generate_rawframes_filelist.py | 4 \u001b[32m++\u001b[m\u001b[31m--\u001b[m\n",
            " 1 file changed, 2 insertions(+), 2 deletions(-)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/ActivityNet/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZdhjItj29D1",
        "outputId": "78b1a5bc-1281-4884-da13-d44bb2c3fce1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "action_name.csv\t\tanet_anno_action.json  rawframes       videos\n",
            "activity_net.v1-3.json\tlabel_map.txt\t       video_info.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./tools/data/activitynet/generate_rawframes_filelist.py"
      ],
      "metadata": {
        "id": "oVSAobzuOYlz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat data/ActivityNet/anet_train_video.txt | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nBSzhLJ407Q",
        "outputId": "51a606db-927b-409b-cc22-f3a200aff143"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Finetune"
      ],
      "metadata": {
        "id": "qndRn6d7vcIr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py ccd/configs/tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55TLXf0tTAM3",
        "outputId": "4837e89a-a8e3-408b-a29c-4afd55e0fadb"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/02 20:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 345519763\n",
            "    GPU 0: Tesla V100-SXM2-16GB\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.1.0+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.0+cu118\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 345519763\n",
            "    diff_rank_seed: False\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/02 20:13:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "ann_file_test = './data/ActivityNet/anet_val_video.txt'\n",
            "ann_file_train = './data/ActivityNet/anet_train_video.txt'\n",
            "ann_file_val = './data/ActivityNet/anet_val_video.txt'\n",
            "data_root = './data/ActivityNet/rawframes'\n",
            "data_root_val = './data/ActivityNet/rawframes'\n",
            "dataset_type = 'RawframeDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(interval=1, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'),\n",
            "    timer=dict(type='IterTimerHook'))\n",
            "default_scope = 'mmaction'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "img_norm_cfg = dict(\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ], std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ])\n",
            "launcher = 'none'\n",
            "load_from = 'https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_320p_1x1x8_100e_kinetics400_rgb/tsn_r50_320p_1x1x8_100e_kinetics400_rgb_20200702-ef80e3d7.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        depth=50,\n",
            "        norm_eval=False,\n",
            "        pretrained='https://download.pytorch.org/models/resnet50-11ad3fa6.pth',\n",
            "        type='ResNet'),\n",
            "    cls_head=dict(\n",
            "        average_clips='prob',\n",
            "        consensus=dict(dim=1, type='AvgConsensus'),\n",
            "        dropout_ratio=0.8,\n",
            "        in_channels=2048,\n",
            "        init_std=0.01,\n",
            "        num_classes=2,\n",
            "        spatial_type='avg',\n",
            "        type='TSNHead'),\n",
            "    data_preprocessor=dict(\n",
            "        format_shape='NCHW',\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='ActionDataPreprocessor'),\n",
            "    test_cfg=None,\n",
            "    train_cfg=None,\n",
            "    type='Recognizer2D')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=dict(max_norm=40, norm_type=2),\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0001))\n",
            "optimizer = dict(lr=0.001, momentum=0.9, type='SGD', weight_decay=0.0001)\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        end=50,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            20,\n",
            "            40,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "randomness = dict(deterministic=False, diff_rank_seed=False, seed=None)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='./data/ActivityNet/anet_val_video.txt',\n",
            "        data_prefix=dict(img='./data/ActivityNet/rawframes'),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=25,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='RawFrameDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=256, type='ThreeCrop'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='RawframeDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "test_pipeline = [\n",
            "    dict(\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=25,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='RawFrameDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=256, type='ThreeCrop'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "train_cfg = dict(\n",
            "    max_epochs=50, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_size=8,\n",
            "    dataset=dict(\n",
            "        ann_file='./data/ActivityNet/anet_train_video.txt',\n",
            "        data_prefix=dict(img='./data/ActivityNet/rawframes'),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                clip_len=1, frame_interval=1, num_clips=8,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='RawFrameDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(type='RandomResizedCrop'),\n",
            "            dict(keep_ratio=False, scale=(\n",
            "                224,\n",
            "                224,\n",
            "            ), type='Resize'),\n",
            "            dict(flip_ratio=0.5, type='Flip'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        type='RawframeDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(clip_len=1, frame_interval=1, num_clips=8, type='SampleFrames'),\n",
            "    dict(type='RawFrameDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(type='RandomResizedCrop'),\n",
            "    dict(keep_ratio=False, scale=(\n",
            "        224,\n",
            "        224,\n",
            "    ), type='Resize'),\n",
            "    dict(flip_ratio=0.5, type='Flip'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=8,\n",
            "    dataset=dict(\n",
            "        ann_file='./data/ActivityNet/anet_val_video.txt',\n",
            "        data_prefix=dict(img='./data/ActivityNet/rawframes'),\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=8,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='RawFrameDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=256, type='CenterCrop'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='RawframeDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "val_pipeline = [\n",
            "    dict(\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=8,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='RawFrameDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=256, type='CenterCrop'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './rgb_checkpoints/'\n",
            "\n",
            "12/02 20:13:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/02 20:13:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "Loads checkpoint by http backend from path: https://download.pytorch.org/models/resnet50-11ad3fa6.pth\n",
            "12/02 20:13:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - These parameters in pretrained checkpoint are not loaded: {'fc.bias', 'fc.weight'}\n",
            "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_320p_1x1x8_100e_kinetics400_rgb/tsn_r50_320p_1x1x8_100e_kinetics400_rgb_20200702-ef80e3d7.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([2, 2048]).\n",
            "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "12/02 20:13:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_320p_1x1x8_100e_kinetics400_rgb/tsn_r50_320p_1x1x8_100e_kinetics400_rgb_20200702-ef80e3d7.pth\n",
            "12/02 20:13:20 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/02 20:13:20 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "12/02 20:13:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmaction2/rgb_checkpoints.\n",
            "12/02 20:13:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 20/332]  lr: 1.0000e-02  eta: 2:59:49  time: 0.6507  data_time: 0.0569  memory: 5586  grad_norm: 33.6465  loss: 2.2350  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 2.2350\n",
            "12/02 20:13:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 40/332]  lr: 1.0000e-02  eta: 2:08:52  time: 0.2831  data_time: 0.0669  memory: 5586  grad_norm: 17.7045  loss: 2.0022  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 2.0022\n",
            "12/02 20:13:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 60/332]  lr: 1.0000e-02  eta: 1:45:18  time: 0.2121  data_time: 0.0206  memory: 5586  grad_norm: 16.8050  loss: 1.1805  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1805\n",
            "12/02 20:13:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 80/332]  lr: 1.0000e-02  eta: 1:33:46  time: 0.2163  data_time: 0.0221  memory: 5586  grad_norm: 30.7340  loss: 1.4791  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4791\n",
            "12/02 20:13:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][100/332]  lr: 1.0000e-02  eta: 1:30:51  time: 0.2895  data_time: 0.0717  memory: 5586  grad_norm: 14.5603  loss: 1.6222  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.6222\n",
            "12/02 20:13:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][120/332]  lr: 1.0000e-02  eta: 1:27:45  time: 0.2653  data_time: 0.0594  memory: 5586  grad_norm: 16.0039  loss: 1.0751  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0751\n",
            "12/02 20:14:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][140/332]  lr: 1.0000e-02  eta: 1:23:40  time: 0.2179  data_time: 0.0246  memory: 5586  grad_norm: 17.4988  loss: 1.1530  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 1.1530\n",
            "12/02 20:14:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][160/332]  lr: 1.0000e-02  eta: 1:20:47  time: 0.2239  data_time: 0.0263  memory: 5586  grad_norm: 8.5797  loss: 1.2257  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 1.2257\n",
            "12/02 20:14:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][180/332]  lr: 1.0000e-02  eta: 1:20:49  time: 0.2990  data_time: 0.0805  memory: 5586  grad_norm: 15.5874  loss: 1.5598  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 1.5598\n",
            "12/02 20:14:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][200/332]  lr: 1.0000e-02  eta: 1:19:30  time: 0.2510  data_time: 0.0490  memory: 5586  grad_norm: 9.4451  loss: 1.3307  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 1.3307\n",
            "12/02 20:14:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][220/332]  lr: 1.0000e-02  eta: 1:17:31  time: 0.2149  data_time: 0.0225  memory: 5586  grad_norm: 16.6964  loss: 1.7756  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.7756\n",
            "12/02 20:14:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][240/332]  lr: 1.0000e-02  eta: 1:16:30  time: 0.2430  data_time: 0.0385  memory: 5586  grad_norm: 10.0523  loss: 0.9381  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.9381\n",
            "12/02 20:14:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][260/332]  lr: 1.0000e-02  eta: 1:17:01  time: 0.3104  data_time: 0.0892  memory: 5586  grad_norm: 9.5171  loss: 1.3119  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3119\n",
            "12/02 20:14:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][280/332]  lr: 1.0000e-02  eta: 1:15:52  time: 0.2278  data_time: 0.0325  memory: 5586  grad_norm: 11.8008  loss: 1.3809  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3809\n",
            "12/02 20:14:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][300/332]  lr: 1.0000e-02  eta: 1:14:38  time: 0.2166  data_time: 0.0232  memory: 5586  grad_norm: 7.7013  loss: 1.0885  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.0885\n",
            "12/02 20:14:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][320/332]  lr: 1.0000e-02  eta: 1:14:26  time: 0.2680  data_time: 0.0585  memory: 5586  grad_norm: 5.5217  loss: 0.9883  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9883\n",
            "12/02 20:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][332/332]  lr: 1.0000e-02  eta: 1:14:40  time: 0.2996  data_time: 0.0865  memory: 5586  grad_norm: 8.4651  loss: 1.0042  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0042\n",
            "12/02 20:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
            "12/02 20:14:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][20/42]    eta: 0:00:03  time: 0.1602  data_time: 0.0671  memory: 1141  \n",
            "12/02 20:14:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][40/42]    eta: 0:00:00  time: 0.1424  data_time: 0.0509  memory: 1141  \n",
            "12/02 20:14:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0571  time: 0.1479\n",
            "12/02 20:15:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.5559 acc/top1 at 1 epoch is saved to best_acc_top1_epoch_1.pth.\n",
            "12/02 20:15:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 20/332]  lr: 1.0000e-02  eta: 1:14:24  time: 0.2642  data_time: 0.0583  memory: 5586  grad_norm: 8.3202  loss: 1.3285  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 1.3285\n",
            "12/02 20:15:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 40/332]  lr: 1.0000e-02  eta: 1:14:39  time: 0.2980  data_time: 0.0845  memory: 5586  grad_norm: 6.2442  loss: 1.1689  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 1.1689\n",
            "12/02 20:15:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 60/332]  lr: 1.0000e-02  eta: 1:13:50  time: 0.2236  data_time: 0.0283  memory: 5586  grad_norm: 6.5724  loss: 0.9834  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9834\n",
            "12/02 20:15:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 80/332]  lr: 1.0000e-02  eta: 1:13:00  time: 0.2165  data_time: 0.0232  memory: 5586  grad_norm: 4.3300  loss: 1.1052  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 1.1052\n",
            "12/02 20:15:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][100/332]  lr: 1.0000e-02  eta: 1:12:41  time: 0.2527  data_time: 0.0454  memory: 5586  grad_norm: 10.5610  loss: 1.0994  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 1.0994\n",
            "12/02 20:15:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][120/332]  lr: 1.0000e-02  eta: 1:12:57  time: 0.3000  data_time: 0.0812  memory: 5586  grad_norm: 8.6628  loss: 0.7541  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7541\n",
            "12/02 20:15:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][140/332]  lr: 1.0000e-02  eta: 1:12:10  time: 0.2099  data_time: 0.0175  memory: 5586  grad_norm: 8.2043  loss: 0.9095  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9095\n",
            "12/02 20:15:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][160/332]  lr: 1.0000e-02  eta: 1:11:27  time: 0.2108  data_time: 0.0178  memory: 5586  grad_norm: 8.3454  loss: 1.0028  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 1.0028\n",
            "12/02 20:15:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][180/332]  lr: 1.0000e-02  eta: 1:11:20  time: 0.2631  data_time: 0.0473  memory: 5586  grad_norm: 5.2045  loss: 1.0692  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.0692\n",
            "12/02 20:15:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][200/332]  lr: 1.0000e-02  eta: 1:11:28  time: 0.2880  data_time: 0.0685  memory: 5586  grad_norm: 7.3935  loss: 1.3214  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.3214\n",
            "12/02 20:15:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][220/332]  lr: 1.0000e-02  eta: 1:10:49  time: 0.2102  data_time: 0.0174  memory: 5586  grad_norm: 4.1938  loss: 1.0197  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.0197\n",
            "12/02 20:16:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][240/332]  lr: 1.0000e-02  eta: 1:10:16  time: 0.2145  data_time: 0.0223  memory: 5586  grad_norm: 12.9242  loss: 1.0196  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 1.0196\n",
            "12/02 20:16:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][260/332]  lr: 1.0000e-02  eta: 1:10:09  time: 0.2602  data_time: 0.0479  memory: 5586  grad_norm: 9.5274  loss: 0.9760  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.9760\n",
            "12/02 20:16:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][280/332]  lr: 1.0000e-02  eta: 1:10:22  time: 0.2978  data_time: 0.0825  memory: 5586  grad_norm: 6.8451  loss: 0.8789  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8789\n",
            "12/02 20:16:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][300/332]  lr: 1.0000e-02  eta: 1:09:50  time: 0.2106  data_time: 0.0184  memory: 5586  grad_norm: 4.9956  loss: 1.0274  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 1.0274\n",
            "12/02 20:16:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][320/332]  lr: 1.0000e-02  eta: 1:09:21  time: 0.2140  data_time: 0.0184  memory: 5586  grad_norm: 5.6900  loss: 0.9890  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9890\n",
            "12/02 20:16:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:16:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][332/332]  lr: 1.0000e-02  eta: 1:09:04  time: 0.2125  data_time: 0.0195  memory: 5586  grad_norm: 5.2699  loss: 0.8499  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8499\n",
            "12/02 20:16:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
            "12/02 20:16:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][20/42]    eta: 0:00:04  time: 0.2233  data_time: 0.1189  memory: 1141  \n",
            "12/02 20:16:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][40/42]    eta: 0:00:00  time: 0.1945  data_time: 0.0978  memory: 1141  \n",
            "12/02 20:16:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.1018  time: 0.1989\n",
            "12/02 20:16:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 20/332]  lr: 1.0000e-02  eta: 1:08:42  time: 0.2251  data_time: 0.0320  memory: 5586  grad_norm: 3.5589  loss: 0.9440  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.9440\n",
            "12/02 20:16:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 40/332]  lr: 1.0000e-02  eta: 1:08:15  time: 0.2097  data_time: 0.0173  memory: 5586  grad_norm: 4.6729  loss: 1.0259  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 1.0259\n",
            "12/02 20:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 60/332]  lr: 1.0000e-02  eta: 1:08:19  time: 0.2800  data_time: 0.0631  memory: 5586  grad_norm: 4.1134  loss: 0.7866  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7866\n",
            "12/02 20:16:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 80/332]  lr: 1.0000e-02  eta: 1:08:18  time: 0.2682  data_time: 0.0532  memory: 5586  grad_norm: 25.0852  loss: 1.0237  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0237\n",
            "12/02 20:16:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][100/332]  lr: 1.0000e-02  eta: 1:07:52  time: 0.2071  data_time: 0.0161  memory: 5586  grad_norm: 6.2909  loss: 0.8668  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8668\n",
            "12/02 20:16:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][120/332]  lr: 1.0000e-02  eta: 1:07:28  time: 0.2097  data_time: 0.0162  memory: 5586  grad_norm: 6.5980  loss: 0.8810  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8810\n",
            "12/02 20:17:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][140/332]  lr: 1.0000e-02  eta: 1:07:37  time: 0.2932  data_time: 0.0732  memory: 5586  grad_norm: 4.7344  loss: 0.8980  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8980\n",
            "12/02 20:17:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][160/332]  lr: 1.0000e-02  eta: 1:07:35  time: 0.2654  data_time: 0.0550  memory: 5586  grad_norm: 4.6144  loss: 0.9510  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9510\n",
            "12/02 20:17:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][180/332]  lr: 1.0000e-02  eta: 1:07:14  time: 0.2125  data_time: 0.0188  memory: 5586  grad_norm: 4.4277  loss: 0.8551  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8551\n",
            "12/02 20:17:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][200/332]  lr: 1.0000e-02  eta: 1:06:53  time: 0.2144  data_time: 0.0191  memory: 5586  grad_norm: 4.3974  loss: 0.9043  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9043\n",
            "12/02 20:17:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][220/332]  lr: 1.0000e-02  eta: 1:07:02  time: 0.2937  data_time: 0.0727  memory: 5586  grad_norm: 4.0277  loss: 0.7865  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7865\n",
            "12/02 20:17:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][240/332]  lr: 1.0000e-02  eta: 1:06:57  time: 0.2564  data_time: 0.0472  memory: 5586  grad_norm: 4.5964  loss: 0.9095  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9095\n",
            "12/02 20:17:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][260/332]  lr: 1.0000e-02  eta: 1:06:37  time: 0.2116  data_time: 0.0175  memory: 5586  grad_norm: 4.1932  loss: 0.8175  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8175\n",
            "12/02 20:17:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][280/332]  lr: 1.0000e-02  eta: 1:06:19  time: 0.2178  data_time: 0.0190  memory: 5586  grad_norm: 4.7074  loss: 0.8455  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8455\n",
            "12/02 20:17:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][300/332]  lr: 1.0000e-02  eta: 1:06:29  time: 0.2991  data_time: 0.0772  memory: 5586  grad_norm: 8.0912  loss: 1.0919  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0919\n",
            "12/02 20:17:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][320/332]  lr: 1.0000e-02  eta: 1:06:24  time: 0.2544  data_time: 0.0464  memory: 5586  grad_norm: 3.4351  loss: 0.9955  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.9955\n",
            "12/02 20:17:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:17:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][332/332]  lr: 1.0000e-02  eta: 1:06:11  time: 0.2064  data_time: 0.0186  memory: 5586  grad_norm: 3.2429  loss: 0.9143  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.9143\n",
            "12/02 20:17:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
            "12/02 20:17:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][20/42]    eta: 0:00:03  time: 0.1430  data_time: 0.0512  memory: 1141  \n",
            "12/02 20:17:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][40/42]    eta: 0:00:00  time: 0.1804  data_time: 0.0871  memory: 1141  \n",
            "12/02 20:18:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0678  time: 0.1574\n",
            "12/02 20:18:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:18:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 20/332]  lr: 1.0000e-02  eta: 1:06:23  time: 0.3109  data_time: 0.0967  memory: 5586  grad_norm: 3.6878  loss: 1.0392  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.0392\n",
            "12/02 20:18:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 40/332]  lr: 1.0000e-02  eta: 1:06:08  time: 0.2244  data_time: 0.0280  memory: 5586  grad_norm: 3.1713  loss: 1.0229  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.0229\n",
            "12/02 20:18:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 60/332]  lr: 1.0000e-02  eta: 1:05:51  time: 0.2119  data_time: 0.0183  memory: 5586  grad_norm: 2.6554  loss: 0.8690  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8690\n",
            "12/02 20:18:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 80/332]  lr: 1.0000e-02  eta: 1:05:43  time: 0.2452  data_time: 0.0336  memory: 5586  grad_norm: 2.1267  loss: 0.8785  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8785\n",
            "12/02 20:18:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][100/332]  lr: 1.0000e-02  eta: 1:05:48  time: 0.2895  data_time: 0.0658  memory: 5586  grad_norm: 4.2428  loss: 1.0325  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 1.0325\n",
            "12/02 20:18:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][120/332]  lr: 1.0000e-02  eta: 1:05:33  time: 0.2214  data_time: 0.0238  memory: 5586  grad_norm: 2.7249  loss: 0.8449  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8449\n",
            "12/02 20:18:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][140/332]  lr: 1.0000e-02  eta: 1:05:17  time: 0.2115  data_time: 0.0191  memory: 5586  grad_norm: 11.9714  loss: 1.0882  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0882\n",
            "12/02 20:18:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][160/332]  lr: 1.0000e-02  eta: 1:05:09  time: 0.2412  data_time: 0.0310  memory: 5586  grad_norm: 2.7480  loss: 0.8799  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8799\n",
            "12/02 20:18:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][180/332]  lr: 1.0000e-02  eta: 1:05:15  time: 0.2955  data_time: 0.0725  memory: 5586  grad_norm: 2.8129  loss: 0.9511  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.9511\n",
            "12/02 20:18:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][200/332]  lr: 1.0000e-02  eta: 1:05:01  time: 0.2192  data_time: 0.0218  memory: 5586  grad_norm: 4.8511  loss: 0.9948  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.9948\n",
            "12/02 20:18:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][220/332]  lr: 1.0000e-02  eta: 1:04:45  time: 0.2119  data_time: 0.0180  memory: 5586  grad_norm: 3.0095  loss: 0.9163  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9163\n",
            "12/02 20:18:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][240/332]  lr: 1.0000e-02  eta: 1:04:38  time: 0.2435  data_time: 0.0320  memory: 5586  grad_norm: 3.6171  loss: 0.8626  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8626\n",
            "12/02 20:19:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][260/332]  lr: 1.0000e-02  eta: 1:04:44  time: 0.2970  data_time: 0.0792  memory: 5586  grad_norm: 2.0050  loss: 0.7570  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7570\n",
            "12/02 20:19:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][280/332]  lr: 1.0000e-02  eta: 1:04:30  time: 0.2164  data_time: 0.0218  memory: 5586  grad_norm: 3.7568  loss: 0.9712  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9712\n",
            "12/02 20:19:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][300/332]  lr: 1.0000e-02  eta: 1:04:15  time: 0.2122  data_time: 0.0195  memory: 5586  grad_norm: 2.6767  loss: 0.8214  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8214\n",
            "12/02 20:19:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][320/332]  lr: 1.0000e-02  eta: 1:04:11  time: 0.2547  data_time: 0.0432  memory: 5586  grad_norm: 2.5886  loss: 0.8491  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8491\n",
            "12/02 20:19:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:19:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][332/332]  lr: 1.0000e-02  eta: 1:04:10  time: 0.2759  data_time: 0.0634  memory: 5586  grad_norm: 2.2847  loss: 0.7938  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7938\n",
            "12/02 20:19:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
            "12/02 20:19:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][20/42]    eta: 0:00:03  time: 0.1691  data_time: 0.0745  memory: 1141  \n",
            "12/02 20:19:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][40/42]    eta: 0:00:00  time: 0.1440  data_time: 0.0528  memory: 1141  \n",
            "12/02 20:19:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][42/42]    acc/top1: 0.5408  acc/top5: 1.0000  acc/mean1: 0.4871  data_time: 0.0597  time: 0.1496\n",
            "12/02 20:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 20/332]  lr: 1.0000e-02  eta: 1:03:59  time: 0.2238  data_time: 0.0324  memory: 5586  grad_norm: 10.6143  loss: 1.0137  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0137\n",
            "12/02 20:19:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 40/332]  lr: 1.0000e-02  eta: 1:03:56  time: 0.2638  data_time: 0.0512  memory: 5586  grad_norm: 2.1296  loss: 0.7734  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7734\n",
            "12/02 20:19:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 60/332]  lr: 1.0000e-02  eta: 1:03:58  time: 0.2826  data_time: 0.0648  memory: 5586  grad_norm: 2.8964  loss: 0.8646  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8646\n",
            "12/02 20:19:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 80/332]  lr: 1.0000e-02  eta: 1:03:45  time: 0.2160  data_time: 0.0201  memory: 5586  grad_norm: 3.3290  loss: 0.9745  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.9745\n",
            "12/02 20:19:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][100/332]  lr: 1.0000e-02  eta: 1:03:32  time: 0.2136  data_time: 0.0203  memory: 5586  grad_norm: 4.1050  loss: 1.0364  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0364\n",
            "12/02 20:19:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][120/332]  lr: 1.0000e-02  eta: 1:03:32  time: 0.2739  data_time: 0.0567  memory: 5586  grad_norm: 2.9476  loss: 0.8709  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8709\n",
            "12/02 20:20:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][140/332]  lr: 1.0000e-02  eta: 1:03:32  time: 0.2782  data_time: 0.0628  memory: 5586  grad_norm: 2.7036  loss: 0.8950  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8950\n",
            "12/02 20:20:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][160/332]  lr: 1.0000e-02  eta: 1:03:19  time: 0.2138  data_time: 0.0192  memory: 5586  grad_norm: 2.1362  loss: 0.7220  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7220\n",
            "12/02 20:20:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][180/332]  lr: 1.0000e-02  eta: 1:03:06  time: 0.2106  data_time: 0.0184  memory: 5586  grad_norm: 2.3520  loss: 0.8221  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8221\n",
            "12/02 20:20:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][200/332]  lr: 1.0000e-02  eta: 1:03:07  time: 0.2809  data_time: 0.0560  memory: 5586  grad_norm: 4.3578  loss: 0.8614  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8614\n",
            "12/02 20:20:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][220/332]  lr: 1.0000e-02  eta: 1:03:06  time: 0.2706  data_time: 0.0574  memory: 5586  grad_norm: 10.2096  loss: 0.7682  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7682\n",
            "12/02 20:20:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][240/332]  lr: 1.0000e-02  eta: 1:02:53  time: 0.2107  data_time: 0.0176  memory: 5586  grad_norm: 3.4028  loss: 0.7781  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7781\n",
            "12/02 20:20:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][260/332]  lr: 1.0000e-02  eta: 1:02:41  time: 0.2136  data_time: 0.0188  memory: 5586  grad_norm: 3.5150  loss: 0.9069  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9069\n",
            "12/02 20:20:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][280/332]  lr: 1.0000e-02  eta: 1:02:40  time: 0.2736  data_time: 0.0542  memory: 5586  grad_norm: 4.3276  loss: 0.9006  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.9006\n",
            "12/02 20:20:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][300/332]  lr: 1.0000e-02  eta: 1:02:38  time: 0.2699  data_time: 0.0568  memory: 5586  grad_norm: 3.2587  loss: 0.9263  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9263\n",
            "12/02 20:20:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][320/332]  lr: 1.0000e-02  eta: 1:02:27  time: 0.2129  data_time: 0.0201  memory: 5586  grad_norm: 2.4610  loss: 0.8133  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8133\n",
            "12/02 20:20:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:20:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][332/332]  lr: 1.0000e-02  eta: 1:02:18  time: 0.2046  data_time: 0.0176  memory: 5586  grad_norm: 2.1242  loss: 0.7223  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7223\n",
            "12/02 20:20:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
            "12/02 20:20:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][20/42]    eta: 0:00:04  time: 0.2038  data_time: 0.1033  memory: 1141  \n",
            "12/02 20:20:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][40/42]    eta: 0:00:00  time: 0.2283  data_time: 0.1297  memory: 1141  \n",
            "12/02 20:20:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][42/42]    acc/top1: 0.5801  acc/top5: 1.0000  acc/mean1: 0.5299  data_time: 0.1091  time: 0.2051\n",
            "12/02 20:20:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/rgb_checkpoints/best_acc_top1_epoch_1.pth is removed\n",
            "12/02 20:21:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.5801 acc/top1 at 5 epoch is saved to best_acc_top1_epoch_5.pth.\n",
            "12/02 20:21:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 20/332]  lr: 1.0000e-02  eta: 1:02:10  time: 0.2319  data_time: 0.0363  memory: 5586  grad_norm: 3.5861  loss: 0.9298  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9298\n",
            "12/02 20:21:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 40/332]  lr: 1.0000e-02  eta: 1:01:58  time: 0.2111  data_time: 0.0178  memory: 5586  grad_norm: 2.3389  loss: 0.7583  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7583\n",
            "12/02 20:21:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 60/332]  lr: 1.0000e-02  eta: 1:01:52  time: 0.2462  data_time: 0.0360  memory: 5586  grad_norm: 4.2346  loss: 0.9812  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.9812\n",
            "12/02 20:21:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 80/332]  lr: 1.0000e-02  eta: 1:01:54  time: 0.2899  data_time: 0.0683  memory: 5586  grad_norm: 1.9918  loss: 0.7260  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7260\n",
            "12/02 20:21:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][100/332]  lr: 1.0000e-02  eta: 1:01:43  time: 0.2098  data_time: 0.0177  memory: 5586  grad_norm: 4.7066  loss: 0.8998  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8998\n",
            "12/02 20:21:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][120/332]  lr: 1.0000e-02  eta: 1:01:32  time: 0.2136  data_time: 0.0196  memory: 5586  grad_norm: 4.1481  loss: 0.8399  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8399\n",
            "12/02 20:21:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][140/332]  lr: 1.0000e-02  eta: 1:01:27  time: 0.2542  data_time: 0.0439  memory: 5586  grad_norm: 3.5700  loss: 1.0507  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 1.0507\n",
            "12/02 20:21:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][160/332]  lr: 1.0000e-02  eta: 1:01:30  time: 0.2970  data_time: 0.0756  memory: 5586  grad_norm: 4.9642  loss: 1.1269  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 1.1269\n",
            "12/02 20:21:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][180/332]  lr: 1.0000e-02  eta: 1:01:19  time: 0.2106  data_time: 0.0179  memory: 5586  grad_norm: 4.4598  loss: 0.9974  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.9974\n",
            "12/02 20:21:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][200/332]  lr: 1.0000e-02  eta: 1:01:08  time: 0.2137  data_time: 0.0209  memory: 5586  grad_norm: 3.7769  loss: 0.8814  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8814\n",
            "12/02 20:21:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][220/332]  lr: 1.0000e-02  eta: 1:01:06  time: 0.2636  data_time: 0.0490  memory: 5586  grad_norm: 4.4201  loss: 0.9275  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.9275\n",
            "12/02 20:21:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][240/332]  lr: 1.0000e-02  eta: 1:01:06  time: 0.2853  data_time: 0.0685  memory: 5586  grad_norm: 4.0812  loss: 0.7695  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7695\n",
            "12/02 20:22:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][260/332]  lr: 1.0000e-02  eta: 1:00:56  time: 0.2143  data_time: 0.0206  memory: 5586  grad_norm: 2.7705  loss: 0.9546  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.9546\n",
            "12/02 20:22:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][280/332]  lr: 1.0000e-02  eta: 1:00:45  time: 0.2114  data_time: 0.0181  memory: 5586  grad_norm: 3.9226  loss: 0.8340  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8340\n",
            "12/02 20:22:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][300/332]  lr: 1.0000e-02  eta: 1:00:47  time: 0.2936  data_time: 0.0769  memory: 5586  grad_norm: 4.7028  loss: 0.9920  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.9920\n",
            "12/02 20:22:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][320/332]  lr: 1.0000e-02  eta: 1:00:46  time: 0.2738  data_time: 0.0608  memory: 5586  grad_norm: 7.2138  loss: 0.8922  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8922\n",
            "12/02 20:22:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:22:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][332/332]  lr: 1.0000e-02  eta: 1:00:38  time: 0.2061  data_time: 0.0176  memory: 5586  grad_norm: 6.5469  loss: 0.7796  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7796\n",
            "12/02 20:22:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
            "12/02 20:22:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][20/42]    eta: 0:00:03  time: 0.1425  data_time: 0.0496  memory: 1141  \n",
            "12/02 20:22:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][40/42]    eta: 0:00:00  time: 0.1559  data_time: 0.0630  memory: 1141  \n",
            "12/02 20:22:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0528  time: 0.1429\n",
            "12/02 20:22:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:22:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 20/332]  lr: 1.0000e-02  eta: 1:00:42  time: 0.3095  data_time: 0.0901  memory: 5586  grad_norm: 4.4372  loss: 0.9761  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9761\n",
            "12/02 20:22:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 40/332]  lr: 1.0000e-02  eta: 1:00:35  time: 0.2402  data_time: 0.0367  memory: 5586  grad_norm: 3.5668  loss: 0.7560  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7560\n",
            "12/02 20:22:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 60/332]  lr: 1.0000e-02  eta: 1:00:25  time: 0.2104  data_time: 0.0171  memory: 5586  grad_norm: 3.7258  loss: 0.9859  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.9859\n",
            "12/02 20:22:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 80/332]  lr: 1.0000e-02  eta: 1:00:17  time: 0.2269  data_time: 0.0234  memory: 5586  grad_norm: 3.6574  loss: 0.9056  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9056\n",
            "12/02 20:22:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][100/332]  lr: 1.0000e-02  eta: 1:00:16  time: 0.2767  data_time: 0.0535  memory: 5586  grad_norm: 2.5154  loss: 0.7445  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7445\n",
            "12/02 20:22:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][120/332]  lr: 1.0000e-02  eta: 1:00:10  time: 0.2423  data_time: 0.0360  memory: 5586  grad_norm: 2.5412  loss: 0.7644  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7644\n",
            "12/02 20:23:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][140/332]  lr: 1.0000e-02  eta: 1:00:00  time: 0.2165  data_time: 0.0216  memory: 5586  grad_norm: 3.2979  loss: 0.8993  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8993\n",
            "12/02 20:23:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][160/332]  lr: 1.0000e-02  eta: 0:59:52  time: 0.2246  data_time: 0.0241  memory: 5586  grad_norm: 2.9062  loss: 0.8905  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.8905\n",
            "12/02 20:23:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][180/332]  lr: 1.0000e-02  eta: 0:59:52  time: 0.2889  data_time: 0.0673  memory: 5586  grad_norm: 4.7139  loss: 0.9245  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9245\n",
            "12/02 20:23:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][200/332]  lr: 1.0000e-02  eta: 0:59:46  time: 0.2392  data_time: 0.0409  memory: 5586  grad_norm: 3.2151  loss: 0.7446  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7446\n",
            "12/02 20:23:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][220/332]  lr: 1.0000e-02  eta: 0:59:36  time: 0.2086  data_time: 0.0162  memory: 5586  grad_norm: 3.3807  loss: 0.7916  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7916\n",
            "12/02 20:23:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][240/332]  lr: 1.0000e-02  eta: 0:59:29  time: 0.2323  data_time: 0.0273  memory: 5586  grad_norm: 1.4546  loss: 0.7144  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7144\n",
            "12/02 20:23:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][260/332]  lr: 1.0000e-02  eta: 0:59:29  time: 0.2882  data_time: 0.0720  memory: 5586  grad_norm: 2.0372  loss: 0.7165  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7165\n",
            "12/02 20:23:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][280/332]  lr: 1.0000e-02  eta: 0:59:22  time: 0.2367  data_time: 0.0355  memory: 5586  grad_norm: 2.6854  loss: 0.7559  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7559\n",
            "12/02 20:23:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][300/332]  lr: 1.0000e-02  eta: 0:59:13  time: 0.2148  data_time: 0.0190  memory: 5586  grad_norm: 2.9808  loss: 0.8720  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8720\n",
            "12/02 20:23:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][320/332]  lr: 1.0000e-02  eta: 0:59:07  time: 0.2345  data_time: 0.0259  memory: 5586  grad_norm: 1.9623  loss: 0.7730  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7730\n",
            "12/02 20:23:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:23:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][332/332]  lr: 1.0000e-02  eta: 0:59:06  time: 0.2704  data_time: 0.0569  memory: 5586  grad_norm: 2.5926  loss: 0.8708  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8708\n",
            "12/02 20:23:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 7 epochs\n",
            "12/02 20:23:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][20/42]    eta: 0:00:04  time: 0.1869  data_time: 0.0908  memory: 1141  \n",
            "12/02 20:23:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][40/42]    eta: 0:00:00  time: 0.1363  data_time: 0.0442  memory: 1141  \n",
            "12/02 20:23:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [7][42/42]    acc/top1: 0.4834  acc/top5: 1.0000  acc/mean1: 0.5210  data_time: 0.0640  time: 0.1549\n",
            "12/02 20:24:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 20/332]  lr: 1.0000e-02  eta: 0:58:58  time: 0.2255  data_time: 0.0326  memory: 5586  grad_norm: 3.4410  loss: 0.8959  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8959\n",
            "12/02 20:24:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 40/332]  lr: 1.0000e-02  eta: 0:58:52  time: 0.2454  data_time: 0.0330  memory: 5586  grad_norm: 2.1650  loss: 0.8516  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8516\n",
            "12/02 20:24:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 60/332]  lr: 1.0000e-02  eta: 0:58:53  time: 0.2920  data_time: 0.0698  memory: 5586  grad_norm: 2.8908  loss: 0.8996  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8996\n",
            "12/02 20:24:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 80/332]  lr: 1.0000e-02  eta: 0:58:43  time: 0.2089  data_time: 0.0174  memory: 5586  grad_norm: 1.4289  loss: 0.6849  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6849\n",
            "12/02 20:24:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][100/332]  lr: 1.0000e-02  eta: 0:58:34  time: 0.2097  data_time: 0.0180  memory: 5586  grad_norm: 3.4522  loss: 0.7569  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7569\n",
            "12/02 20:24:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][120/332]  lr: 1.0000e-02  eta: 0:58:30  time: 0.2585  data_time: 0.0448  memory: 5586  grad_norm: 2.6952  loss: 0.8467  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8467\n",
            "12/02 20:24:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][140/332]  lr: 1.0000e-02  eta: 0:58:28  time: 0.2776  data_time: 0.0598  memory: 5586  grad_norm: 2.0341  loss: 0.8143  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8143\n",
            "12/02 20:24:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][160/332]  lr: 1.0000e-02  eta: 0:58:20  time: 0.2144  data_time: 0.0213  memory: 5586  grad_norm: 3.3659  loss: 0.9175  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.9175\n",
            "12/02 20:24:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][180/332]  lr: 1.0000e-02  eta: 0:58:10  time: 0.2078  data_time: 0.0159  memory: 5586  grad_norm: 3.0855  loss: 0.7386  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7386\n",
            "12/02 20:24:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][200/332]  lr: 1.0000e-02  eta: 0:58:05  time: 0.2478  data_time: 0.0310  memory: 5586  grad_norm: 1.9732  loss: 0.7583  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7583\n",
            "12/02 20:24:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][220/332]  lr: 1.0000e-02  eta: 0:58:04  time: 0.2843  data_time: 0.0626  memory: 5586  grad_norm: 2.5892  loss: 0.7733  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7733\n",
            "12/02 20:24:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][240/332]  lr: 1.0000e-02  eta: 0:57:56  time: 0.2136  data_time: 0.0206  memory: 5586  grad_norm: 1.4540  loss: 0.6718  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6718\n",
            "12/02 20:24:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][260/332]  lr: 1.0000e-02  eta: 0:57:47  time: 0.2106  data_time: 0.0188  memory: 5586  grad_norm: 3.1557  loss: 0.8532  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.8532\n",
            "12/02 20:25:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][280/332]  lr: 1.0000e-02  eta: 0:57:43  time: 0.2646  data_time: 0.0512  memory: 5586  grad_norm: 2.5178  loss: 0.8037  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8037\n",
            "12/02 20:25:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][300/332]  lr: 1.0000e-02  eta: 0:57:42  time: 0.2839  data_time: 0.0645  memory: 5586  grad_norm: 1.6420  loss: 0.7292  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7292\n",
            "12/02 20:25:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][320/332]  lr: 1.0000e-02  eta: 0:57:34  time: 0.2172  data_time: 0.0216  memory: 5586  grad_norm: 1.5803  loss: 0.8403  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8403\n",
            "12/02 20:25:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:25:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][332/332]  lr: 1.0000e-02  eta: 0:57:28  time: 0.2072  data_time: 0.0182  memory: 5586  grad_norm: 1.2904  loss: 0.7046  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7046\n",
            "12/02 20:25:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 8 epochs\n",
            "12/02 20:25:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][20/42]    eta: 0:00:03  time: 0.1595  data_time: 0.0639  memory: 1141  \n",
            "12/02 20:25:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][40/42]    eta: 0:00:00  time: 0.2255  data_time: 0.1294  memory: 1141  \n",
            "12/02 20:25:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][42/42]    acc/top1: 0.5468  acc/top5: 1.0000  acc/mean1: 0.4918  data_time: 0.0931  time: 0.1857\n",
            "12/02 20:25:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 20/332]  lr: 1.0000e-02  eta: 0:57:27  time: 0.2792  data_time: 0.0716  memory: 5586  grad_norm: 1.4408  loss: 0.7845  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7845\n",
            "12/02 20:25:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 40/332]  lr: 1.0000e-02  eta: 0:57:18  time: 0.2101  data_time: 0.0184  memory: 5586  grad_norm: 2.2519  loss: 0.8167  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8167\n",
            "12/02 20:25:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 60/332]  lr: 1.0000e-02  eta: 0:57:09  time: 0.2093  data_time: 0.0158  memory: 5586  grad_norm: 3.0546  loss: 0.7752  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7752\n",
            "12/02 20:25:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 80/332]  lr: 1.0000e-02  eta: 0:57:07  time: 0.2727  data_time: 0.0512  memory: 5586  grad_norm: 1.5530  loss: 0.6954  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6954\n",
            "12/02 20:25:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][100/332]  lr: 1.0000e-02  eta: 0:57:03  time: 0.2660  data_time: 0.0487  memory: 5586  grad_norm: 1.2653  loss: 0.7058  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7058\n",
            "12/02 20:25:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][120/332]  lr: 1.0000e-02  eta: 0:56:55  time: 0.2111  data_time: 0.0189  memory: 5586  grad_norm: 2.6969  loss: 0.7892  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7892\n",
            "12/02 20:25:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][140/332]  lr: 1.0000e-02  eta: 0:56:46  time: 0.2118  data_time: 0.0179  memory: 5586  grad_norm: 2.3366  loss: 0.8476  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8476\n",
            "12/02 20:26:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][160/332]  lr: 1.0000e-02  eta: 0:56:44  time: 0.2738  data_time: 0.0578  memory: 5586  grad_norm: 1.3861  loss: 0.7530  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7530\n",
            "12/02 20:26:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][180/332]  lr: 1.0000e-02  eta: 0:56:41  time: 0.2691  data_time: 0.0573  memory: 5586  grad_norm: 2.4440  loss: 0.7649  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7649\n",
            "12/02 20:26:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][200/332]  lr: 1.0000e-02  eta: 0:56:33  time: 0.2097  data_time: 0.0170  memory: 5586  grad_norm: 1.7020  loss: 0.7809  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7809\n",
            "12/02 20:26:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][220/332]  lr: 1.0000e-02  eta: 0:56:24  time: 0.2094  data_time: 0.0165  memory: 5586  grad_norm: 2.3588  loss: 0.7382  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7382\n",
            "12/02 20:26:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][240/332]  lr: 1.0000e-02  eta: 0:56:22  time: 0.2746  data_time: 0.0526  memory: 5586  grad_norm: 3.4273  loss: 0.7250  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7250\n",
            "12/02 20:26:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][260/332]  lr: 1.0000e-02  eta: 0:56:19  time: 0.2664  data_time: 0.0585  memory: 5586  grad_norm: 3.1670  loss: 0.8290  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8290\n",
            "12/02 20:26:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][280/332]  lr: 1.0000e-02  eta: 0:56:11  time: 0.2105  data_time: 0.0168  memory: 5586  grad_norm: 3.8743  loss: 0.7857  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7857\n",
            "12/02 20:26:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][300/332]  lr: 1.0000e-02  eta: 0:56:03  time: 0.2134  data_time: 0.0192  memory: 5586  grad_norm: 3.7129  loss: 0.7142  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7142\n",
            "12/02 20:26:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][320/332]  lr: 1.0000e-02  eta: 0:56:00  time: 0.2719  data_time: 0.0526  memory: 5586  grad_norm: 3.7311  loss: 0.7722  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7722\n",
            "12/02 20:26:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:26:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][332/332]  lr: 1.0000e-02  eta: 0:55:58  time: 0.2773  data_time: 0.0635  memory: 5586  grad_norm: 6.3324  loss: 0.7877  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7877\n",
            "12/02 20:26:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
            "12/02 20:26:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][20/42]    eta: 0:00:03  time: 0.1442  data_time: 0.0538  memory: 1141  \n",
            "12/02 20:26:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][40/42]    eta: 0:00:00  time: 0.1379  data_time: 0.0475  memory: 1141  \n",
            "12/02 20:26:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0474  time: 0.1349\n",
            "12/02 20:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:26:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 20/332]  lr: 1.0000e-02  eta: 0:55:52  time: 0.2341  data_time: 0.0353  memory: 5586  grad_norm: 2.9426  loss: 0.7497  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7497\n",
            "12/02 20:27:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 40/332]  lr: 1.0000e-02  eta: 0:55:51  time: 0.2819  data_time: 0.0601  memory: 5586  grad_norm: 5.5878  loss: 0.8604  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8604\n",
            "12/02 20:27:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 60/332]  lr: 1.0000e-02  eta: 0:55:46  time: 0.2547  data_time: 0.0484  memory: 5586  grad_norm: 5.0760  loss: 0.9203  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.9203\n",
            "12/02 20:27:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 80/332]  lr: 1.0000e-02  eta: 0:55:38  time: 0.2096  data_time: 0.0176  memory: 5586  grad_norm: 3.3784  loss: 0.8256  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8256\n",
            "12/02 20:27:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][100/332]  lr: 1.0000e-02  eta: 0:55:31  time: 0.2179  data_time: 0.0198  memory: 5586  grad_norm: 3.4765  loss: 0.8972  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.8972\n",
            "12/02 20:27:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][120/332]  lr: 1.0000e-02  eta: 0:55:28  time: 0.2780  data_time: 0.0516  memory: 5586  grad_norm: 3.2238  loss: 0.8929  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8929\n",
            "12/02 20:27:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][140/332]  lr: 1.0000e-02  eta: 0:55:23  time: 0.2462  data_time: 0.0415  memory: 5586  grad_norm: 3.1675  loss: 0.9666  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.9666\n",
            "12/02 20:27:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][160/332]  lr: 1.0000e-02  eta: 0:55:15  time: 0.2099  data_time: 0.0174  memory: 5586  grad_norm: 2.8807  loss: 0.8669  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8669\n",
            "12/02 20:27:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][180/332]  lr: 1.0000e-02  eta: 0:55:08  time: 0.2144  data_time: 0.0171  memory: 5586  grad_norm: 2.2118  loss: 0.8092  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8092\n",
            "12/02 20:27:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][200/332]  lr: 1.0000e-02  eta: 0:55:05  time: 0.2728  data_time: 0.0507  memory: 5586  grad_norm: 5.3317  loss: 0.7428  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7428\n",
            "12/02 20:27:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][220/332]  lr: 1.0000e-02  eta: 0:55:01  time: 0.2563  data_time: 0.0486  memory: 5586  grad_norm: 2.2631  loss: 0.7388  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7388\n",
            "12/02 20:27:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][240/332]  lr: 1.0000e-02  eta: 0:54:53  time: 0.2162  data_time: 0.0224  memory: 5586  grad_norm: 3.1674  loss: 0.8402  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8402\n",
            "12/02 20:27:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][260/332]  lr: 1.0000e-02  eta: 0:54:46  time: 0.2128  data_time: 0.0176  memory: 5586  grad_norm: 1.9911  loss: 0.7201  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7201\n",
            "12/02 20:28:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][280/332]  lr: 1.0000e-02  eta: 0:54:43  time: 0.2732  data_time: 0.0520  memory: 5586  grad_norm: 2.2410  loss: 0.9029  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9029\n",
            "12/02 20:28:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][300/332]  lr: 1.0000e-02  eta: 0:54:39  time: 0.2624  data_time: 0.0573  memory: 5586  grad_norm: 2.1853  loss: 0.7757  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7757\n",
            "12/02 20:28:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][320/332]  lr: 1.0000e-02  eta: 0:54:32  time: 0.2149  data_time: 0.0207  memory: 5586  grad_norm: 2.7260  loss: 0.8260  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8260\n",
            "12/02 20:28:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:28:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][332/332]  lr: 1.0000e-02  eta: 0:54:27  time: 0.2051  data_time: 0.0178  memory: 5586  grad_norm: 3.2046  loss: 0.8991  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8991\n",
            "12/02 20:28:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n",
            "12/02 20:28:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][20/42]    eta: 0:00:04  time: 0.2168  data_time: 0.1192  memory: 1141  \n",
            "12/02 20:28:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][40/42]    eta: 0:00:00  time: 0.2176  data_time: 0.1189  memory: 1141  \n",
            "12/02 20:28:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][42/42]    acc/top1: 0.5317  acc/top5: 1.0000  acc/mean1: 0.4940  data_time: 0.1133  time: 0.2081\n",
            "12/02 20:28:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 20/332]  lr: 1.0000e-02  eta: 0:54:21  time: 0.2406  data_time: 0.0431  memory: 5586  grad_norm: 2.1600  loss: 0.8693  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8693\n",
            "12/02 20:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 40/332]  lr: 1.0000e-02  eta: 0:54:14  time: 0.2092  data_time: 0.0167  memory: 5586  grad_norm: 6.0800  loss: 0.9556  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9556\n",
            "12/02 20:28:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 60/332]  lr: 1.0000e-02  eta: 0:54:08  time: 0.2333  data_time: 0.0287  memory: 5586  grad_norm: 2.8883  loss: 0.7722  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7722\n",
            "12/02 20:28:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 80/332]  lr: 1.0000e-02  eta: 0:54:06  time: 0.2821  data_time: 0.0623  memory: 5586  grad_norm: 2.4992  loss: 0.8434  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8434\n",
            "12/02 20:28:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][100/332]  lr: 1.0000e-02  eta: 0:53:59  time: 0.2274  data_time: 0.0291  memory: 5586  grad_norm: 2.7157  loss: 0.8801  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8801\n",
            "12/02 20:28:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][120/332]  lr: 1.0000e-02  eta: 0:53:51  time: 0.2081  data_time: 0.0169  memory: 5586  grad_norm: 4.6313  loss: 0.9690  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.9690\n",
            "12/02 20:28:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][140/332]  lr: 1.0000e-02  eta: 0:53:46  time: 0.2348  data_time: 0.0271  memory: 5586  grad_norm: 3.1764  loss: 0.7976  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7976\n",
            "12/02 20:29:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][160/332]  lr: 1.0000e-02  eta: 0:53:44  time: 0.2876  data_time: 0.0676  memory: 5586  grad_norm: 2.6282  loss: 0.8001  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8001\n",
            "12/02 20:29:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][180/332]  lr: 1.0000e-02  eta: 0:53:38  time: 0.2277  data_time: 0.0286  memory: 5586  grad_norm: 2.8626  loss: 0.7904  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7904\n",
            "12/02 20:29:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][200/332]  lr: 1.0000e-02  eta: 0:53:30  time: 0.2128  data_time: 0.0191  memory: 5586  grad_norm: 1.9905  loss: 0.7329  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7329\n",
            "12/02 20:29:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][220/332]  lr: 1.0000e-02  eta: 0:53:24  time: 0.2316  data_time: 0.0230  memory: 5586  grad_norm: 5.0912  loss: 0.8777  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8777\n",
            "12/02 20:29:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][240/332]  lr: 1.0000e-02  eta: 0:53:22  time: 0.2824  data_time: 0.0619  memory: 5586  grad_norm: 2.8900  loss: 0.8406  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8406\n",
            "12/02 20:29:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][260/332]  lr: 1.0000e-02  eta: 0:53:17  time: 0.2345  data_time: 0.0340  memory: 5586  grad_norm: 3.6317  loss: 0.9264  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9264\n",
            "12/02 20:29:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][280/332]  lr: 1.0000e-02  eta: 0:53:09  time: 0.2076  data_time: 0.0146  memory: 5586  grad_norm: 3.3473  loss: 0.9155  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.9155\n",
            "12/02 20:29:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][300/332]  lr: 1.0000e-02  eta: 0:53:03  time: 0.2295  data_time: 0.0241  memory: 5586  grad_norm: 3.0277  loss: 0.8312  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8312\n",
            "12/02 20:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][320/332]  lr: 1.0000e-02  eta: 0:53:01  time: 0.2930  data_time: 0.0730  memory: 5586  grad_norm: 2.7590  loss: 0.7937  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7937\n",
            "12/02 20:29:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:29:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][332/332]  lr: 1.0000e-02  eta: 0:52:58  time: 0.2573  data_time: 0.0495  memory: 5586  grad_norm: 2.7155  loss: 0.8623  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8623\n",
            "12/02 20:29:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 11 epochs\n",
            "12/02 20:29:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][20/42]    eta: 0:00:03  time: 0.1436  data_time: 0.0511  memory: 1141  \n",
            "12/02 20:29:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][40/42]    eta: 0:00:00  time: 0.1425  data_time: 0.0518  memory: 1141  \n",
            "12/02 20:29:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][42/42]    acc/top1: 0.5196  acc/top5: 1.0000  acc/mean1: 0.4811  data_time: 0.0488  time: 0.1375\n",
            "12/02 20:29:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 20/332]  lr: 1.0000e-02  eta: 0:52:54  time: 0.2611  data_time: 0.0507  memory: 5586  grad_norm: 2.9794  loss: 0.9989  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9989\n",
            "12/02 20:30:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 40/332]  lr: 1.0000e-02  eta: 0:52:53  time: 0.2945  data_time: 0.0738  memory: 5586  grad_norm: 2.8094  loss: 0.7925  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7925\n",
            "12/02 20:30:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 60/332]  lr: 1.0000e-02  eta: 0:52:45  time: 0.2124  data_time: 0.0201  memory: 5586  grad_norm: 2.1840  loss: 0.7882  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7882\n",
            "12/02 20:30:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 80/332]  lr: 1.0000e-02  eta: 0:52:38  time: 0.2135  data_time: 0.0197  memory: 5586  grad_norm: 1.9386  loss: 0.7247  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7247\n",
            "12/02 20:30:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][100/332]  lr: 1.0000e-02  eta: 0:52:33  time: 0.2417  data_time: 0.0315  memory: 5586  grad_norm: 2.1300  loss: 0.9037  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.9037\n",
            "12/02 20:30:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][120/332]  lr: 1.0000e-02  eta: 0:52:32  time: 0.2948  data_time: 0.0689  memory: 5586  grad_norm: 2.1993  loss: 0.8274  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8274\n",
            "12/02 20:30:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][140/332]  lr: 1.0000e-02  eta: 0:52:25  time: 0.2221  data_time: 0.0250  memory: 5586  grad_norm: 1.6754  loss: 0.7600  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7600\n",
            "12/02 20:30:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][160/332]  lr: 1.0000e-02  eta: 0:52:18  time: 0.2108  data_time: 0.0173  memory: 5586  grad_norm: 2.3853  loss: 0.8734  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8734\n",
            "12/02 20:30:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][180/332]  lr: 1.0000e-02  eta: 0:52:13  time: 0.2391  data_time: 0.0265  memory: 5586  grad_norm: 1.9916  loss: 0.7675  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7675\n",
            "12/02 20:30:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][200/332]  lr: 1.0000e-02  eta: 0:52:10  time: 0.2867  data_time: 0.0688  memory: 5586  grad_norm: 1.4178  loss: 0.6730  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6730\n",
            "12/02 20:30:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][220/332]  lr: 1.0000e-02  eta: 0:52:04  time: 0.2243  data_time: 0.0288  memory: 5586  grad_norm: 1.6953  loss: 0.7512  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7512\n",
            "12/02 20:30:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][240/332]  lr: 1.0000e-02  eta: 0:51:57  time: 0.2115  data_time: 0.0172  memory: 5586  grad_norm: 1.7989  loss: 0.7124  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7124\n",
            "12/02 20:30:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][260/332]  lr: 1.0000e-02  eta: 0:51:52  time: 0.2382  data_time: 0.0276  memory: 5586  grad_norm: 2.3251  loss: 0.7963  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7963\n",
            "12/02 20:30:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][280/332]  lr: 1.0000e-02  eta: 0:51:50  time: 0.2904  data_time: 0.0751  memory: 5586  grad_norm: 2.7934  loss: 0.8191  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8191\n",
            "12/02 20:31:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][300/332]  lr: 1.0000e-02  eta: 0:51:43  time: 0.2184  data_time: 0.0222  memory: 5586  grad_norm: 3.2243  loss: 0.7333  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7333\n",
            "12/02 20:31:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][320/332]  lr: 1.0000e-02  eta: 0:51:36  time: 0.2132  data_time: 0.0189  memory: 5586  grad_norm: 1.7413  loss: 0.7654  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7654\n",
            "12/02 20:31:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:31:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][332/332]  lr: 1.0000e-02  eta: 0:51:31  time: 0.2042  data_time: 0.0166  memory: 5586  grad_norm: 2.4938  loss: 0.8189  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8189\n",
            "12/02 20:31:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n",
            "12/02 20:31:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][20/42]    eta: 0:00:05  time: 0.2293  data_time: 0.1298  memory: 1141  \n",
            "12/02 20:31:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][40/42]    eta: 0:00:00  time: 0.2133  data_time: 0.1123  memory: 1141  \n",
            "12/02 20:31:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.1131  time: 0.2098\n",
            "12/02 20:31:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:31:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 20/332]  lr: 1.0000e-02  eta: 0:51:25  time: 0.2245  data_time: 0.0301  memory: 5586  grad_norm: 2.2611  loss: 0.7867  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7867\n",
            "12/02 20:31:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 40/332]  lr: 1.0000e-02  eta: 0:51:18  time: 0.2093  data_time: 0.0175  memory: 5586  grad_norm: 2.1030  loss: 0.8145  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8145\n",
            "12/02 20:31:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 60/332]  lr: 1.0000e-02  eta: 0:51:14  time: 0.2666  data_time: 0.0446  memory: 5586  grad_norm: 1.8256  loss: 0.7458  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7458\n",
            "12/02 20:31:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 80/332]  lr: 1.0000e-02  eta: 0:51:12  time: 0.2770  data_time: 0.0621  memory: 5586  grad_norm: 2.6129  loss: 0.7523  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7523\n",
            "12/02 20:31:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][100/332]  lr: 1.0000e-02  eta: 0:51:05  time: 0.2137  data_time: 0.0176  memory: 5586  grad_norm: 1.5778  loss: 0.8551  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8551\n",
            "12/02 20:31:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][120/332]  lr: 1.0000e-02  eta: 0:50:58  time: 0.2097  data_time: 0.0155  memory: 5586  grad_norm: 1.3059  loss: 0.6964  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6964\n",
            "12/02 20:31:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][140/332]  lr: 1.0000e-02  eta: 0:50:54  time: 0.2668  data_time: 0.0449  memory: 5586  grad_norm: 2.1983  loss: 0.8036  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8036\n",
            "12/02 20:31:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][160/332]  lr: 1.0000e-02  eta: 0:50:51  time: 0.2795  data_time: 0.0582  memory: 5586  grad_norm: 1.5335  loss: 0.7851  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7851\n",
            "12/02 20:32:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][180/332]  lr: 1.0000e-02  eta: 0:50:44  time: 0.2118  data_time: 0.0190  memory: 5586  grad_norm: 1.8480  loss: 0.8615  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8615\n",
            "12/02 20:32:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][200/332]  lr: 1.0000e-02  eta: 0:50:37  time: 0.2078  data_time: 0.0154  memory: 5586  grad_norm: 1.1949  loss: 0.6888  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6888\n",
            "12/02 20:32:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][220/332]  lr: 1.0000e-02  eta: 0:50:34  time: 0.2726  data_time: 0.0559  memory: 5586  grad_norm: 1.3410  loss: 0.6919  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6919\n",
            "12/02 20:32:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][240/332]  lr: 1.0000e-02  eta: 0:50:31  time: 0.2751  data_time: 0.0628  memory: 5586  grad_norm: 1.6773  loss: 0.7193  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7193\n",
            "12/02 20:32:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][260/332]  lr: 1.0000e-02  eta: 0:50:24  time: 0.2076  data_time: 0.0166  memory: 5586  grad_norm: 1.6009  loss: 0.7660  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7660\n",
            "12/02 20:32:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][280/332]  lr: 1.0000e-02  eta: 0:50:17  time: 0.2113  data_time: 0.0177  memory: 5586  grad_norm: 1.6002  loss: 0.8297  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8297\n",
            "12/02 20:32:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][300/332]  lr: 1.0000e-02  eta: 0:50:13  time: 0.2610  data_time: 0.0405  memory: 5586  grad_norm: 1.7778  loss: 0.7814  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7814\n",
            "12/02 20:32:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][320/332]  lr: 1.0000e-02  eta: 0:50:10  time: 0.2824  data_time: 0.0651  memory: 5586  grad_norm: 1.2618  loss: 0.6804  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6804\n",
            "12/02 20:32:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:32:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][332/332]  lr: 1.0000e-02  eta: 0:50:06  time: 0.2211  data_time: 0.0289  memory: 5586  grad_norm: 1.5389  loss: 0.6972  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6972\n",
            "12/02 20:32:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 13 epochs\n",
            "12/02 20:32:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][20/42]    eta: 0:00:03  time: 0.1488  data_time: 0.0554  memory: 1141  \n",
            "12/02 20:32:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][40/42]    eta: 0:00:00  time: 0.1415  data_time: 0.0523  memory: 1141  \n",
            "12/02 20:32:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][42/42]    acc/top1: 0.5438  acc/top5: 1.0000  acc/mean1: 0.4898  data_time: 0.0516  time: 0.1399\n",
            "12/02 20:32:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 20/332]  lr: 1.0000e-02  eta: 0:50:05  time: 0.3153  data_time: 0.0978  memory: 5586  grad_norm: 1.3583  loss: 0.7547  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7547\n",
            "12/02 20:32:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 40/332]  lr: 1.0000e-02  eta: 0:50:00  time: 0.2453  data_time: 0.0402  memory: 5586  grad_norm: 1.5208  loss: 0.8022  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8022\n",
            "12/02 20:33:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 60/332]  lr: 1.0000e-02  eta: 0:49:53  time: 0.2085  data_time: 0.0161  memory: 5586  grad_norm: 1.6449  loss: 0.7875  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7875\n",
            "12/02 20:33:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 80/332]  lr: 1.0000e-02  eta: 0:49:47  time: 0.2170  data_time: 0.0182  memory: 5586  grad_norm: 3.0842  loss: 0.7260  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7260\n",
            "12/02 20:33:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][100/332]  lr: 1.0000e-02  eta: 0:49:44  time: 0.2836  data_time: 0.0620  memory: 5586  grad_norm: 2.3575  loss: 0.7413  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7413\n",
            "12/02 20:33:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][120/332]  lr: 1.0000e-02  eta: 0:49:39  time: 0.2514  data_time: 0.0439  memory: 5586  grad_norm: 1.9972  loss: 0.7687  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7687\n",
            "12/02 20:33:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][140/332]  lr: 1.0000e-02  eta: 0:49:33  time: 0.2109  data_time: 0.0176  memory: 5586  grad_norm: 1.6311  loss: 0.7209  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7209\n",
            "12/02 20:33:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][160/332]  lr: 1.0000e-02  eta: 0:49:26  time: 0.2178  data_time: 0.0213  memory: 5586  grad_norm: 1.3833  loss: 0.7584  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7584\n",
            "12/02 20:33:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][180/332]  lr: 1.0000e-02  eta: 0:49:23  time: 0.2731  data_time: 0.0524  memory: 5586  grad_norm: 1.2588  loss: 0.7260  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7260\n",
            "12/02 20:33:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][200/332]  lr: 1.0000e-02  eta: 0:49:18  time: 0.2535  data_time: 0.0439  memory: 5586  grad_norm: 1.4187  loss: 0.7355  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7355\n",
            "12/02 20:33:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][220/332]  lr: 1.0000e-02  eta: 0:49:12  time: 0.2127  data_time: 0.0188  memory: 5586  grad_norm: 1.2762  loss: 0.7461  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7461\n",
            "12/02 20:33:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][240/332]  lr: 1.0000e-02  eta: 0:49:06  time: 0.2199  data_time: 0.0226  memory: 5586  grad_norm: 1.4160  loss: 0.7173  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7173\n",
            "12/02 20:33:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][260/332]  lr: 1.0000e-02  eta: 0:49:02  time: 0.2676  data_time: 0.0483  memory: 5586  grad_norm: 1.3099  loss: 0.7153  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7153\n",
            "12/02 20:33:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][280/332]  lr: 1.0000e-02  eta: 0:48:58  time: 0.2606  data_time: 0.0491  memory: 5586  grad_norm: 1.1403  loss: 0.7165  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7165\n",
            "12/02 20:33:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][300/332]  lr: 1.0000e-02  eta: 0:48:51  time: 0.2100  data_time: 0.0183  memory: 5586  grad_norm: 1.2294  loss: 0.7604  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7604\n",
            "12/02 20:34:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][320/332]  lr: 1.0000e-02  eta: 0:48:45  time: 0.2207  data_time: 0.0214  memory: 5586  grad_norm: 1.2976  loss: 0.7730  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7730\n",
            "12/02 20:34:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:34:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][332/332]  lr: 1.0000e-02  eta: 0:48:42  time: 0.2439  data_time: 0.0391  memory: 5586  grad_norm: 1.4171  loss: 0.7561  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7561\n",
            "12/02 20:34:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 14 epochs\n",
            "12/02 20:34:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][20/42]    eta: 0:00:04  time: 0.2253  data_time: 0.1245  memory: 1141  \n",
            "12/02 20:34:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][40/42]    eta: 0:00:00  time: 0.1441  data_time: 0.0541  memory: 1141  \n",
            "12/02 20:34:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0834  time: 0.1755\n",
            "12/02 20:34:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 20/332]  lr: 1.0000e-02  eta: 0:48:37  time: 0.2262  data_time: 0.0314  memory: 5586  grad_norm: 1.0369  loss: 0.7060  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7060\n",
            "12/02 20:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 40/332]  lr: 1.0000e-02  eta: 0:48:31  time: 0.2295  data_time: 0.0236  memory: 5586  grad_norm: 1.0777  loss: 0.6919  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6919\n",
            "12/02 20:34:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 60/332]  lr: 1.0000e-02  eta: 0:48:28  time: 0.2853  data_time: 0.0678  memory: 5586  grad_norm: 1.3372  loss: 0.7181  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7181\n",
            "12/02 20:34:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 80/332]  lr: 1.0000e-02  eta: 0:48:22  time: 0.2279  data_time: 0.0275  memory: 5586  grad_norm: 0.9833  loss: 0.7014  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7014\n",
            "12/02 20:34:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][100/332]  lr: 1.0000e-02  eta: 0:48:16  time: 0.2095  data_time: 0.0157  memory: 5586  grad_norm: 1.0217  loss: 0.7064  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7064\n",
            "12/02 20:34:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][120/332]  lr: 1.0000e-02  eta: 0:48:10  time: 0.2351  data_time: 0.0272  memory: 5586  grad_norm: 1.3802  loss: 0.7245  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7245\n",
            "12/02 20:34:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][140/332]  lr: 1.0000e-02  eta: 0:48:08  time: 0.2861  data_time: 0.0628  memory: 5586  grad_norm: 1.4620  loss: 0.6847  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6847\n",
            "12/02 20:34:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][160/332]  lr: 1.0000e-02  eta: 0:48:02  time: 0.2294  data_time: 0.0292  memory: 5586  grad_norm: 0.9129  loss: 0.6835  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6835\n",
            "12/02 20:34:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][180/332]  lr: 1.0000e-02  eta: 0:47:56  time: 0.2140  data_time: 0.0196  memory: 5586  grad_norm: 1.2450  loss: 0.7299  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7299\n",
            "12/02 20:35:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][200/332]  lr: 1.0000e-02  eta: 0:47:50  time: 0.2400  data_time: 0.0310  memory: 5586  grad_norm: 1.1247  loss: 0.7115  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7115\n",
            "12/02 20:35:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][220/332]  lr: 1.0000e-02  eta: 0:47:47  time: 0.2783  data_time: 0.0580  memory: 5586  grad_norm: 1.1298  loss: 0.7151  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7151\n",
            "12/02 20:35:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][240/332]  lr: 1.0000e-02  eta: 0:47:42  time: 0.2433  data_time: 0.0421  memory: 5586  grad_norm: 1.1678  loss: 0.7078  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7078\n",
            "12/02 20:35:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][260/332]  lr: 1.0000e-02  eta: 0:47:36  time: 0.2114  data_time: 0.0181  memory: 5586  grad_norm: 0.8921  loss: 0.6599  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6599\n",
            "12/02 20:35:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][280/332]  lr: 1.0000e-02  eta: 0:47:30  time: 0.2325  data_time: 0.0241  memory: 5586  grad_norm: 1.1442  loss: 0.7331  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7331\n",
            "12/02 20:35:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][300/332]  lr: 1.0000e-02  eta: 0:47:28  time: 0.2892  data_time: 0.0680  memory: 5586  grad_norm: 2.9555  loss: 0.7312  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7312\n",
            "12/02 20:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][320/332]  lr: 1.0000e-02  eta: 0:47:22  time: 0.2293  data_time: 0.0291  memory: 5586  grad_norm: 3.1997  loss: 0.7564  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7564\n",
            "12/02 20:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][332/332]  lr: 1.0000e-02  eta: 0:47:18  time: 0.2062  data_time: 0.0174  memory: 5586  grad_norm: 3.1778  loss: 0.8042  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8042\n",
            "12/02 20:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 15 epochs\n",
            "12/02 20:35:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][20/42]    eta: 0:00:03  time: 0.1435  data_time: 0.0527  memory: 1141  \n",
            "12/02 20:35:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][40/42]    eta: 0:00:00  time: 0.2137  data_time: 0.1129  memory: 1141  \n",
            "12/02 20:35:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][42/42]    acc/top1: 0.5347  acc/top5: 1.0000  acc/mean1: 0.4830  data_time: 0.0790  time: 0.1716\n",
            "12/02 20:35:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:35:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 20/332]  lr: 1.0000e-02  eta: 0:47:16  time: 0.3025  data_time: 0.0836  memory: 5586  grad_norm: 2.0130  loss: 0.7479  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7479\n",
            "12/02 20:35:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 40/332]  lr: 1.0000e-02  eta: 0:47:09  time: 0.2125  data_time: 0.0191  memory: 5586  grad_norm: 1.3928  loss: 0.7189  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7189\n",
            "12/02 20:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 60/332]  lr: 1.0000e-02  eta: 0:47:03  time: 0.2107  data_time: 0.0174  memory: 5586  grad_norm: 4.3984  loss: 0.7522  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7522\n",
            "12/02 20:36:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 80/332]  lr: 1.0000e-02  eta: 0:46:59  time: 0.2639  data_time: 0.0466  memory: 5586  grad_norm: 1.6299  loss: 0.7364  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7364\n",
            "12/02 20:36:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][100/332]  lr: 1.0000e-02  eta: 0:46:56  time: 0.2798  data_time: 0.0635  memory: 5586  grad_norm: 1.3173  loss: 0.7125  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7125\n",
            "12/02 20:36:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][120/332]  lr: 1.0000e-02  eta: 0:46:49  time: 0.2123  data_time: 0.0178  memory: 5586  grad_norm: 1.3544  loss: 0.7191  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7191\n",
            "12/02 20:36:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][140/332]  lr: 1.0000e-02  eta: 0:46:43  time: 0.2078  data_time: 0.0164  memory: 5586  grad_norm: 1.7241  loss: 0.7135  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7135\n",
            "12/02 20:36:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][160/332]  lr: 1.0000e-02  eta: 0:46:39  time: 0.2660  data_time: 0.0455  memory: 5586  grad_norm: 1.5033  loss: 0.7283  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7283\n",
            "12/02 20:36:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][180/332]  lr: 1.0000e-02  eta: 0:46:35  time: 0.2717  data_time: 0.0570  memory: 5586  grad_norm: 1.5379  loss: 0.7290  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7290\n",
            "12/02 20:36:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][200/332]  lr: 1.0000e-02  eta: 0:46:29  time: 0.2116  data_time: 0.0182  memory: 5586  grad_norm: 1.5903  loss: 0.7602  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7602\n",
            "12/02 20:36:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][220/332]  lr: 1.0000e-02  eta: 0:46:22  time: 0.2093  data_time: 0.0164  memory: 5586  grad_norm: 1.4073  loss: 0.7570  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7570\n",
            "12/02 20:36:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][240/332]  lr: 1.0000e-02  eta: 0:46:19  time: 0.2680  data_time: 0.0471  memory: 5586  grad_norm: 1.3033  loss: 0.7512  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7512\n",
            "12/02 20:36:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][260/332]  lr: 1.0000e-02  eta: 0:46:15  time: 0.2696  data_time: 0.0516  memory: 5586  grad_norm: 0.9998  loss: 0.6856  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6856\n",
            "12/02 20:36:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][280/332]  lr: 1.0000e-02  eta: 0:46:09  time: 0.2126  data_time: 0.0187  memory: 5586  grad_norm: 2.2619  loss: 0.7509  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7509\n",
            "12/02 20:36:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][300/332]  lr: 1.0000e-02  eta: 0:46:02  time: 0.2105  data_time: 0.0172  memory: 5586  grad_norm: 1.4562  loss: 0.7049  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7049\n",
            "12/02 20:37:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][320/332]  lr: 1.0000e-02  eta: 0:45:58  time: 0.2614  data_time: 0.0404  memory: 5586  grad_norm: 1.4281  loss: 0.7249  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7249\n",
            "12/02 20:37:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:37:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][332/332]  lr: 1.0000e-02  eta: 0:45:56  time: 0.2766  data_time: 0.0589  memory: 5586  grad_norm: 1.2181  loss: 0.7257  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7257\n",
            "12/02 20:37:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 16 epochs\n",
            "12/02 20:37:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][20/42]    eta: 0:00:03  time: 0.1448  data_time: 0.0553  memory: 1141  \n",
            "12/02 20:37:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][40/42]    eta: 0:00:00  time: 0.1382  data_time: 0.0464  memory: 1141  \n",
            "12/02 20:37:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][42/42]    acc/top1: 0.5347  acc/top5: 1.0000  acc/mean1: 0.4953  data_time: 0.0479  time: 0.1356\n",
            "12/02 20:37:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 20/332]  lr: 1.0000e-02  eta: 0:45:50  time: 0.2275  data_time: 0.0315  memory: 5586  grad_norm: 1.6645  loss: 0.7878  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7878\n",
            "12/02 20:37:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 40/332]  lr: 1.0000e-02  eta: 0:45:47  time: 0.2776  data_time: 0.0500  memory: 5586  grad_norm: 2.0888  loss: 0.7298  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7298\n",
            "12/02 20:37:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 60/332]  lr: 1.0000e-02  eta: 0:45:43  time: 0.2569  data_time: 0.0470  memory: 5586  grad_norm: 2.0350  loss: 0.7381  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7381\n",
            "12/02 20:37:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 80/332]  lr: 1.0000e-02  eta: 0:45:36  time: 0.2090  data_time: 0.0163  memory: 5586  grad_norm: 1.7619  loss: 0.7441  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7441\n",
            "12/02 20:37:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][100/332]  lr: 1.0000e-02  eta: 0:45:30  time: 0.2175  data_time: 0.0213  memory: 5586  grad_norm: 0.8813  loss: 0.6973  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6973\n",
            "12/02 20:37:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][120/332]  lr: 1.0000e-02  eta: 0:45:27  time: 0.2799  data_time: 0.0638  memory: 5586  grad_norm: 1.3219  loss: 0.7305  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7305\n",
            "12/02 20:37:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][140/332]  lr: 1.0000e-02  eta: 0:45:23  time: 0.2626  data_time: 0.0504  memory: 5586  grad_norm: 2.3273  loss: 0.8053  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8053\n",
            "12/02 20:37:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][160/332]  lr: 1.0000e-02  eta: 0:45:17  time: 0.2144  data_time: 0.0186  memory: 5586  grad_norm: 1.2748  loss: 0.7396  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7396\n",
            "12/02 20:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][180/332]  lr: 1.0000e-02  eta: 0:45:11  time: 0.2160  data_time: 0.0197  memory: 5586  grad_norm: 1.3255  loss: 0.7637  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7637\n",
            "12/02 20:37:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][200/332]  lr: 1.0000e-02  eta: 0:45:07  time: 0.2801  data_time: 0.0573  memory: 5586  grad_norm: 1.6496  loss: 0.8201  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8201\n",
            "12/02 20:38:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][220/332]  lr: 1.0000e-02  eta: 0:45:03  time: 0.2572  data_time: 0.0455  memory: 5586  grad_norm: 1.2713  loss: 0.7097  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7097\n",
            "12/02 20:38:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][240/332]  lr: 1.0000e-02  eta: 0:44:57  time: 0.2101  data_time: 0.0160  memory: 5586  grad_norm: 0.9687  loss: 0.6707  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6707\n",
            "12/02 20:38:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][260/332]  lr: 1.0000e-02  eta: 0:44:50  time: 0.2126  data_time: 0.0194  memory: 5586  grad_norm: 1.0932  loss: 0.7063  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7063\n",
            "12/02 20:38:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][280/332]  lr: 1.0000e-02  eta: 0:44:47  time: 0.2784  data_time: 0.0533  memory: 5586  grad_norm: 1.2779  loss: 0.7723  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7723\n",
            "12/02 20:38:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][300/332]  lr: 1.0000e-02  eta: 0:44:43  time: 0.2622  data_time: 0.0494  memory: 5586  grad_norm: 1.4132  loss: 0.7644  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7644\n",
            "12/02 20:38:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][320/332]  lr: 1.0000e-02  eta: 0:44:37  time: 0.2141  data_time: 0.0190  memory: 5586  grad_norm: 0.9912  loss: 0.7023  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7023\n",
            "12/02 20:38:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:38:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][332/332]  lr: 1.0000e-02  eta: 0:44:33  time: 0.2063  data_time: 0.0183  memory: 5586  grad_norm: 0.9494  loss: 0.7030  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7030\n",
            "12/02 20:38:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 17 epochs\n",
            "12/02 20:38:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][20/42]    eta: 0:00:05  time: 0.2283  data_time: 0.1263  memory: 1141  \n",
            "12/02 20:38:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][40/42]    eta: 0:00:00  time: 0.2196  data_time: 0.1183  memory: 1141  \n",
            "12/02 20:38:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.1142  time: 0.2125\n",
            "12/02 20:38:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 20/332]  lr: 1.0000e-02  eta: 0:44:28  time: 0.2381  data_time: 0.0428  memory: 5586  grad_norm: 1.6740  loss: 0.7554  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7554\n",
            "12/02 20:38:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 40/332]  lr: 1.0000e-02  eta: 0:44:21  time: 0.2107  data_time: 0.0179  memory: 5586  grad_norm: 2.0457  loss: 0.7170  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7170\n",
            "12/02 20:38:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 60/332]  lr: 1.0000e-02  eta: 0:44:17  time: 0.2436  data_time: 0.0306  memory: 5586  grad_norm: 1.5733  loss: 0.7594  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7594\n",
            "12/02 20:39:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 80/332]  lr: 1.0000e-02  eta: 0:44:13  time: 0.2894  data_time: 0.0654  memory: 5586  grad_norm: 1.3633  loss: 0.6855  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6855\n",
            "12/02 20:39:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][100/332]  lr: 1.0000e-02  eta: 0:44:08  time: 0.2372  data_time: 0.0250  memory: 5586  grad_norm: 2.0705  loss: 0.7673  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7673\n",
            "12/02 20:39:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][120/332]  lr: 1.0000e-02  eta: 0:44:02  time: 0.2091  data_time: 0.0160  memory: 5586  grad_norm: 1.1955  loss: 0.7160  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.7160\n",
            "12/02 20:39:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][140/332]  lr: 1.0000e-02  eta: 0:43:57  time: 0.2429  data_time: 0.0270  memory: 5586  grad_norm: 1.7303  loss: 0.7672  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7672\n",
            "12/02 20:39:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][160/332]  lr: 1.0000e-02  eta: 0:43:54  time: 0.2956  data_time: 0.0762  memory: 5586  grad_norm: 2.4637  loss: 0.7492  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7492\n",
            "12/02 20:39:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][180/332]  lr: 1.0000e-02  eta: 0:43:48  time: 0.2105  data_time: 0.0177  memory: 5586  grad_norm: 1.7557  loss: 0.7308  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7308\n",
            "12/02 20:39:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][200/332]  lr: 1.0000e-02  eta: 0:43:42  time: 0.2091  data_time: 0.0154  memory: 5586  grad_norm: 1.3143  loss: 0.7069  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7069\n",
            "12/02 20:39:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][220/332]  lr: 1.0000e-02  eta: 0:43:37  time: 0.2536  data_time: 0.0411  memory: 5586  grad_norm: 1.2746  loss: 0.7078  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7078\n",
            "12/02 20:39:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][240/332]  lr: 1.0000e-02  eta: 0:43:34  time: 0.2907  data_time: 0.0695  memory: 5586  grad_norm: 1.3979  loss: 0.7793  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7793\n",
            "12/02 20:39:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][260/332]  lr: 1.0000e-02  eta: 0:43:28  time: 0.2115  data_time: 0.0186  memory: 5586  grad_norm: 1.4203  loss: 0.7118  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7118\n",
            "12/02 20:39:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][280/332]  lr: 1.0000e-02  eta: 0:43:22  time: 0.2107  data_time: 0.0163  memory: 5586  grad_norm: 0.9802  loss: 0.7394  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7394\n",
            "12/02 20:39:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][300/332]  lr: 1.0000e-02  eta: 0:43:17  time: 0.2499  data_time: 0.0330  memory: 5586  grad_norm: 1.4354  loss: 0.6434  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6434\n",
            "12/02 20:39:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][320/332]  lr: 1.0000e-02  eta: 0:43:15  time: 0.2974  data_time: 0.0779  memory: 5586  grad_norm: 1.5353  loss: 0.7051  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7051\n",
            "12/02 20:40:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:40:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][332/332]  lr: 1.0000e-02  eta: 0:43:11  time: 0.2380  data_time: 0.0397  memory: 5586  grad_norm: 1.2359  loss: 0.7073  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7073\n",
            "12/02 20:40:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 18 epochs\n",
            "12/02 20:40:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][20/42]    eta: 0:00:03  time: 0.1497  data_time: 0.0549  memory: 1141  \n",
            "12/02 20:40:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][40/42]    eta: 0:00:00  time: 0.1391  data_time: 0.0483  memory: 1141  \n",
            "12/02 20:40:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][42/42]    acc/top1: 0.5408  acc/top5: 1.0000  acc/mean1: 0.4871  data_time: 0.0484  time: 0.1381\n",
            "12/02 20:40:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 20/332]  lr: 1.0000e-02  eta: 0:43:08  time: 0.2981  data_time: 0.0791  memory: 5586  grad_norm: 1.3759  loss: 0.6942  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6942\n",
            "12/02 20:40:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:40:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 40/332]  lr: 1.0000e-02  eta: 0:43:04  time: 0.2640  data_time: 0.0484  memory: 5586  grad_norm: 1.5952  loss: 0.7271  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7271\n",
            "12/02 20:40:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 60/332]  lr: 1.0000e-02  eta: 0:42:58  time: 0.2172  data_time: 0.0209  memory: 5586  grad_norm: 1.2660  loss: 0.7179  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7179\n",
            "12/02 20:40:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 80/332]  lr: 1.0000e-02  eta: 0:42:52  time: 0.2100  data_time: 0.0169  memory: 5586  grad_norm: 1.4714  loss: 0.7368  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7368\n",
            "12/02 20:40:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][100/332]  lr: 1.0000e-02  eta: 0:42:48  time: 0.2809  data_time: 0.0574  memory: 5586  grad_norm: 1.8326  loss: 0.7259  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7259\n",
            "12/02 20:40:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][120/332]  lr: 1.0000e-02  eta: 0:42:44  time: 0.2676  data_time: 0.0560  memory: 5586  grad_norm: 2.9200  loss: 0.8048  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8048\n",
            "12/02 20:40:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][140/332]  lr: 1.0000e-02  eta: 0:42:38  time: 0.2106  data_time: 0.0179  memory: 5586  grad_norm: 2.5381  loss: 0.7284  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7284\n",
            "12/02 20:40:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][160/332]  lr: 1.0000e-02  eta: 0:42:32  time: 0.2199  data_time: 0.0212  memory: 5586  grad_norm: 1.4420  loss: 0.7225  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7225\n",
            "12/02 20:40:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][180/332]  lr: 1.0000e-02  eta: 0:42:29  time: 0.2800  data_time: 0.0619  memory: 5586  grad_norm: 2.6541  loss: 0.7533  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7533\n",
            "12/02 20:40:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][200/332]  lr: 1.0000e-02  eta: 0:42:24  time: 0.2598  data_time: 0.0472  memory: 5586  grad_norm: 1.7137  loss: 0.7093  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7093\n",
            "12/02 20:41:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][220/332]  lr: 1.0000e-02  eta: 0:42:18  time: 0.2120  data_time: 0.0188  memory: 5586  grad_norm: 1.4108  loss: 0.7460  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7460\n",
            "12/02 20:41:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][240/332]  lr: 1.0000e-02  eta: 0:42:12  time: 0.2107  data_time: 0.0175  memory: 5586  grad_norm: 1.5278  loss: 0.7147  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7147\n",
            "12/02 20:41:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][260/332]  lr: 1.0000e-02  eta: 0:42:08  time: 0.2719  data_time: 0.0484  memory: 5586  grad_norm: 1.0345  loss: 0.6961  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6961\n",
            "12/02 20:41:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][280/332]  lr: 1.0000e-02  eta: 0:42:05  time: 0.2751  data_time: 0.0638  memory: 5586  grad_norm: 1.0730  loss: 0.6841  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6841\n",
            "12/02 20:41:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][300/332]  lr: 1.0000e-02  eta: 0:41:59  time: 0.2150  data_time: 0.0193  memory: 5586  grad_norm: 1.0618  loss: 0.7270  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7270\n",
            "12/02 20:41:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][320/332]  lr: 1.0000e-02  eta: 0:41:53  time: 0.2112  data_time: 0.0181  memory: 5586  grad_norm: 1.2446  loss: 0.7059  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7059\n",
            "12/02 20:41:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:41:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][332/332]  lr: 1.0000e-02  eta: 0:41:50  time: 0.2373  data_time: 0.0324  memory: 5586  grad_norm: 1.2816  loss: 0.7195  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7195\n",
            "12/02 20:41:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 19 epochs\n",
            "12/02 20:41:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][20/42]    eta: 0:00:05  time: 0.2282  data_time: 0.1281  memory: 1141  \n",
            "12/02 20:41:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][40/42]    eta: 0:00:00  time: 0.1552  data_time: 0.0639  memory: 1141  \n",
            "12/02 20:41:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0899  time: 0.1823\n",
            "12/02 20:41:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 20/332]  lr: 1.0000e-02  eta: 0:41:44  time: 0.2252  data_time: 0.0323  memory: 5586  grad_norm: 1.0366  loss: 0.6742  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6742\n",
            "12/02 20:41:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 40/332]  lr: 1.0000e-02  eta: 0:41:39  time: 0.2265  data_time: 0.0249  memory: 5586  grad_norm: 1.2893  loss: 0.7041  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7041\n",
            "12/02 20:41:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 60/332]  lr: 1.0000e-02  eta: 0:41:35  time: 0.2838  data_time: 0.0575  memory: 5586  grad_norm: 1.0236  loss: 0.7159  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7159\n",
            "12/02 20:41:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 80/332]  lr: 1.0000e-02  eta: 0:41:31  time: 0.2442  data_time: 0.0387  memory: 5586  grad_norm: 1.0729  loss: 0.6540  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6540\n",
            "12/02 20:42:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][100/332]  lr: 1.0000e-02  eta: 0:41:25  time: 0.2148  data_time: 0.0200  memory: 5586  grad_norm: 2.1065  loss: 0.8235  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8235\n",
            "12/02 20:42:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][120/332]  lr: 1.0000e-02  eta: 0:41:19  time: 0.2300  data_time: 0.0273  memory: 5586  grad_norm: 1.1504  loss: 0.7159  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7159\n",
            "12/02 20:42:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][140/332]  lr: 1.0000e-02  eta: 0:41:16  time: 0.2753  data_time: 0.0527  memory: 5586  grad_norm: 1.6774  loss: 0.7224  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7224\n",
            "12/02 20:42:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][160/332]  lr: 1.0000e-02  eta: 0:41:11  time: 0.2501  data_time: 0.0432  memory: 5586  grad_norm: 1.0950  loss: 0.7023  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7023\n",
            "12/02 20:42:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][180/332]  lr: 1.0000e-02  eta: 0:41:05  time: 0.2132  data_time: 0.0188  memory: 5586  grad_norm: 0.7018  loss: 0.6499  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6499\n",
            "12/02 20:42:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][200/332]  lr: 1.0000e-02  eta: 0:41:00  time: 0.2278  data_time: 0.0254  memory: 5586  grad_norm: 1.4418  loss: 0.7540  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7540\n",
            "12/02 20:42:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][220/332]  lr: 1.0000e-02  eta: 0:40:56  time: 0.2817  data_time: 0.0624  memory: 5586  grad_norm: 1.6000  loss: 0.7897  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7897\n",
            "12/02 20:42:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][240/332]  lr: 1.0000e-02  eta: 0:40:51  time: 0.2395  data_time: 0.0340  memory: 5586  grad_norm: 1.2784  loss: 0.7265  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7265\n",
            "12/02 20:42:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][260/332]  lr: 1.0000e-02  eta: 0:40:45  time: 0.2154  data_time: 0.0207  memory: 5586  grad_norm: 1.0893  loss: 0.6747  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6747\n",
            "12/02 20:42:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][280/332]  lr: 1.0000e-02  eta: 0:40:40  time: 0.2296  data_time: 0.0240  memory: 5586  grad_norm: 1.2820  loss: 0.7295  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7295\n",
            "12/02 20:42:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][300/332]  lr: 1.0000e-02  eta: 0:40:37  time: 0.2969  data_time: 0.0731  memory: 5586  grad_norm: 1.6679  loss: 0.6994  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6994\n",
            "12/02 20:42:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][320/332]  lr: 1.0000e-02  eta: 0:40:31  time: 0.2352  data_time: 0.0306  memory: 5586  grad_norm: 1.1912  loss: 0.7050  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7050\n",
            "12/02 20:42:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:42:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][332/332]  lr: 1.0000e-02  eta: 0:40:28  time: 0.2045  data_time: 0.0165  memory: 5586  grad_norm: 0.8899  loss: 0.6918  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6918\n",
            "12/02 20:42:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 20 epochs\n",
            "12/02 20:43:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][20/42]    eta: 0:00:03  time: 0.1454  data_time: 0.0553  memory: 1141  \n",
            "12/02 20:43:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][40/42]    eta: 0:00:00  time: 0.2088  data_time: 0.1132  memory: 1141  \n",
            "12/02 20:43:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0826  time: 0.1724\n",
            "12/02 20:43:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 20/332]  lr: 1.0000e-03  eta: 0:40:25  time: 0.3007  data_time: 0.0772  memory: 5586  grad_norm: 1.1509  loss: 0.6651  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6651\n",
            "12/02 20:43:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 40/332]  lr: 1.0000e-03  eta: 0:40:19  time: 0.2115  data_time: 0.0170  memory: 5586  grad_norm: 4.0946  loss: 0.7317  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7317\n",
            "12/02 20:43:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 60/332]  lr: 1.0000e-03  eta: 0:40:13  time: 0.2149  data_time: 0.0187  memory: 5586  grad_norm: 0.8661  loss: 0.6638  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6638\n",
            "12/02 20:43:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 80/332]  lr: 1.0000e-03  eta: 0:40:08  time: 0.2519  data_time: 0.0357  memory: 5586  grad_norm: 1.0549  loss: 0.7245  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7245\n",
            "12/02 20:43:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][100/332]  lr: 1.0000e-03  eta: 0:40:05  time: 0.2867  data_time: 0.0675  memory: 5586  grad_norm: 1.1407  loss: 0.7125  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7125\n",
            "12/02 20:43:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][120/332]  lr: 1.0000e-03  eta: 0:39:59  time: 0.2127  data_time: 0.0190  memory: 5586  grad_norm: 0.9685  loss: 0.6965  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6965\n",
            "12/02 20:43:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][140/332]  lr: 1.0000e-03  eta: 0:39:53  time: 0.2093  data_time: 0.0161  memory: 5586  grad_norm: 0.7499  loss: 0.7082  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7082\n",
            "12/02 20:43:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][160/332]  lr: 1.0000e-03  eta: 0:39:49  time: 0.2600  data_time: 0.0386  memory: 5586  grad_norm: 1.2570  loss: 0.7174  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7174\n",
            "12/02 20:43:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][180/332]  lr: 1.0000e-03  eta: 0:39:45  time: 0.2808  data_time: 0.0606  memory: 5586  grad_norm: 2.9496  loss: 0.6521  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6521\n",
            "12/02 20:43:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][200/332]  lr: 1.0000e-03  eta: 0:39:39  time: 0.2152  data_time: 0.0202  memory: 5586  grad_norm: 1.5372  loss: 0.7756  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7756\n",
            "12/02 20:43:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][220/332]  lr: 1.0000e-03  eta: 0:39:33  time: 0.2124  data_time: 0.0187  memory: 5586  grad_norm: 1.1393  loss: 0.7046  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7046\n",
            "12/02 20:44:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][240/332]  lr: 1.0000e-03  eta: 0:39:29  time: 0.2594  data_time: 0.0434  memory: 5586  grad_norm: 1.0382  loss: 0.6739  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6739\n",
            "12/02 20:44:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][260/332]  lr: 1.0000e-03  eta: 0:39:25  time: 0.2814  data_time: 0.0660  memory: 5586  grad_norm: 1.1243  loss: 0.6953  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6953\n",
            "12/02 20:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][280/332]  lr: 1.0000e-03  eta: 0:39:19  time: 0.2111  data_time: 0.0176  memory: 5586  grad_norm: 1.2357  loss: 0.6923  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6923\n",
            "12/02 20:44:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][300/332]  lr: 1.0000e-03  eta: 0:39:14  time: 0.2101  data_time: 0.0183  memory: 5586  grad_norm: 2.3509  loss: 0.7236  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7236\n",
            "12/02 20:44:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][320/332]  lr: 1.0000e-03  eta: 0:39:09  time: 0.2651  data_time: 0.0472  memory: 5586  grad_norm: 2.0487  loss: 0.6916  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6916\n",
            "12/02 20:44:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:44:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][332/332]  lr: 1.0000e-03  eta: 0:39:07  time: 0.2761  data_time: 0.0636  memory: 5586  grad_norm: 1.8227  loss: 0.7245  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7245\n",
            "12/02 20:44:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 21 epochs\n",
            "12/02 20:44:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][20/42]    eta: 0:00:03  time: 0.1528  data_time: 0.0616  memory: 1141  \n",
            "12/02 20:44:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][40/42]    eta: 0:00:00  time: 0.1404  data_time: 0.0482  memory: 1141  \n",
            "12/02 20:44:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0519  time: 0.1406\n",
            "12/02 20:44:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 20/332]  lr: 1.0000e-03  eta: 0:39:01  time: 0.2233  data_time: 0.0291  memory: 5586  grad_norm: 1.1733  loss: 0.7176  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7176\n",
            "12/02 20:44:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:44:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 40/332]  lr: 1.0000e-03  eta: 0:38:57  time: 0.2699  data_time: 0.0465  memory: 5586  grad_norm: 1.5003  loss: 0.7066  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7066\n",
            "12/02 20:44:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 60/332]  lr: 1.0000e-03  eta: 0:38:53  time: 0.2687  data_time: 0.0565  memory: 5586  grad_norm: 1.4106  loss: 0.7457  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7457\n",
            "12/02 20:44:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 80/332]  lr: 1.0000e-03  eta: 0:38:47  time: 0.2094  data_time: 0.0175  memory: 5586  grad_norm: 1.1251  loss: 0.7157  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7157\n",
            "12/02 20:44:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][100/332]  lr: 1.0000e-03  eta: 0:38:41  time: 0.2112  data_time: 0.0179  memory: 5586  grad_norm: 1.0118  loss: 0.6867  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6867\n",
            "12/02 20:45:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][120/332]  lr: 1.0000e-03  eta: 0:38:37  time: 0.2837  data_time: 0.0623  memory: 5586  grad_norm: 1.3942  loss: 0.6902  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6902\n",
            "12/02 20:45:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][140/332]  lr: 1.0000e-03  eta: 0:38:33  time: 0.2603  data_time: 0.0451  memory: 5586  grad_norm: 2.5161  loss: 0.8008  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8008\n",
            "12/02 20:45:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][160/332]  lr: 1.0000e-03  eta: 0:38:27  time: 0.2162  data_time: 0.0215  memory: 5586  grad_norm: 1.1571  loss: 0.6920  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6920\n",
            "12/02 20:45:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][180/332]  lr: 1.0000e-03  eta: 0:38:22  time: 0.2174  data_time: 0.0177  memory: 5586  grad_norm: 1.6460  loss: 0.7620  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7620\n",
            "12/02 20:45:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][200/332]  lr: 1.0000e-03  eta: 0:38:18  time: 0.2744  data_time: 0.0515  memory: 5586  grad_norm: 1.0974  loss: 0.6581  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6581\n",
            "12/02 20:45:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][220/332]  lr: 1.0000e-03  eta: 0:38:13  time: 0.2600  data_time: 0.0518  memory: 5586  grad_norm: 1.1833  loss: 0.7012  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7012\n",
            "12/02 20:45:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][240/332]  lr: 1.0000e-03  eta: 0:38:08  time: 0.2125  data_time: 0.0185  memory: 5586  grad_norm: 1.0301  loss: 0.6850  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6850\n",
            "12/02 20:45:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][260/332]  lr: 1.0000e-03  eta: 0:38:02  time: 0.2181  data_time: 0.0189  memory: 5586  grad_norm: 0.7855  loss: 0.6498  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6498\n",
            "12/02 20:45:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][280/332]  lr: 1.0000e-03  eta: 0:37:58  time: 0.2848  data_time: 0.0622  memory: 5586  grad_norm: 1.0691  loss: 0.6969  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6969\n",
            "12/02 20:45:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][300/332]  lr: 1.0000e-03  eta: 0:37:54  time: 0.2556  data_time: 0.0502  memory: 5586  grad_norm: 3.1844  loss: 0.7021  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7021\n",
            "12/02 20:45:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][320/332]  lr: 1.0000e-03  eta: 0:37:48  time: 0.2109  data_time: 0.0177  memory: 5586  grad_norm: 1.3075  loss: 0.6812  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6812\n",
            "12/02 20:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][332/332]  lr: 1.0000e-03  eta: 0:37:44  time: 0.2058  data_time: 0.0164  memory: 5586  grad_norm: 1.5966  loss: 0.6904  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6904\n",
            "12/02 20:45:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 22 epochs\n",
            "12/02 20:45:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][20/42]    eta: 0:00:04  time: 0.2181  data_time: 0.1142  memory: 1141  \n",
            "12/02 20:46:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][40/42]    eta: 0:00:00  time: 0.2222  data_time: 0.1218  memory: 1141  \n",
            "12/02 20:46:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.1129  time: 0.2114\n",
            "12/02 20:46:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 20/332]  lr: 1.0000e-03  eta: 0:37:39  time: 0.2400  data_time: 0.0450  memory: 5586  grad_norm: 0.9619  loss: 0.7243  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7243\n",
            "12/02 20:46:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 40/332]  lr: 1.0000e-03  eta: 0:37:34  time: 0.2088  data_time: 0.0165  memory: 5586  grad_norm: 2.9321  loss: 0.6897  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6897\n",
            "12/02 20:46:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 60/332]  lr: 1.0000e-03  eta: 0:37:29  time: 0.2427  data_time: 0.0294  memory: 5586  grad_norm: 1.1478  loss: 0.6613  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6613\n",
            "12/02 20:46:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 80/332]  lr: 1.0000e-03  eta: 0:37:25  time: 0.2873  data_time: 0.0639  memory: 5586  grad_norm: 1.4775  loss: 0.7167  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7167\n",
            "12/02 20:46:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][100/332]  lr: 1.0000e-03  eta: 0:37:20  time: 0.2227  data_time: 0.0252  memory: 5586  grad_norm: 1.9328  loss: 0.6963  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6963\n",
            "12/02 20:46:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][120/332]  lr: 1.0000e-03  eta: 0:37:14  time: 0.2103  data_time: 0.0170  memory: 5586  grad_norm: 1.2351  loss: 0.7069  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7069\n",
            "12/02 20:46:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][140/332]  lr: 1.0000e-03  eta: 0:37:09  time: 0.2383  data_time: 0.0282  memory: 5586  grad_norm: 0.7852  loss: 0.6552  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6552\n",
            "12/02 20:46:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][160/332]  lr: 1.0000e-03  eta: 0:37:05  time: 0.2796  data_time: 0.0543  memory: 5586  grad_norm: 1.1271  loss: 0.6956  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6956\n",
            "12/02 20:46:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][180/332]  lr: 1.0000e-03  eta: 0:37:00  time: 0.2387  data_time: 0.0361  memory: 5586  grad_norm: 1.5864  loss: 0.7115  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7115\n",
            "12/02 20:46:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][200/332]  lr: 1.0000e-03  eta: 0:36:54  time: 0.2118  data_time: 0.0168  memory: 5586  grad_norm: 1.1908  loss: 0.7105  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7105\n",
            "12/02 20:46:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][220/332]  lr: 1.0000e-03  eta: 0:36:49  time: 0.2352  data_time: 0.0259  memory: 5586  grad_norm: 4.1512  loss: 0.6640  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6640\n",
            "12/02 20:47:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][240/332]  lr: 1.0000e-03  eta: 0:36:46  time: 0.2948  data_time: 0.0783  memory: 5586  grad_norm: 2.6867  loss: 0.7092  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7092\n",
            "12/02 20:47:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][260/332]  lr: 1.0000e-03  eta: 0:36:40  time: 0.2327  data_time: 0.0345  memory: 5586  grad_norm: 2.6799  loss: 0.7080  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7080\n",
            "12/02 20:47:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][280/332]  lr: 1.0000e-03  eta: 0:36:35  time: 0.2108  data_time: 0.0163  memory: 5586  grad_norm: 2.9855  loss: 0.7191  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7191\n",
            "12/02 20:47:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][300/332]  lr: 1.0000e-03  eta: 0:36:30  time: 0.2358  data_time: 0.0279  memory: 5586  grad_norm: 2.6793  loss: 0.7315  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7315\n",
            "12/02 20:47:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][320/332]  lr: 1.0000e-03  eta: 0:36:26  time: 0.2855  data_time: 0.0651  memory: 5586  grad_norm: 2.2191  loss: 0.7689  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7689\n",
            "12/02 20:47:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:47:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][332/332]  lr: 1.0000e-03  eta: 0:36:23  time: 0.2541  data_time: 0.0462  memory: 5586  grad_norm: 1.5841  loss: 0.7108  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7108\n",
            "12/02 20:47:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 23 epochs\n",
            "12/02 20:47:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][20/42]    eta: 0:00:03  time: 0.1495  data_time: 0.0575  memory: 1141  \n",
            "12/02 20:47:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][40/42]    eta: 0:00:00  time: 0.1460  data_time: 0.0570  memory: 1141  \n",
            "12/02 20:47:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0538  time: 0.1414\n",
            "12/02 20:47:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 20/332]  lr: 1.0000e-03  eta: 0:36:19  time: 0.2771  data_time: 0.0649  memory: 5586  grad_norm: 2.6659  loss: 0.7021  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7021\n",
            "12/02 20:47:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 40/332]  lr: 1.0000e-03  eta: 0:36:15  time: 0.2879  data_time: 0.0690  memory: 5586  grad_norm: 2.0877  loss: 0.7110  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7110\n",
            "12/02 20:47:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 60/332]  lr: 1.0000e-03  eta: 0:36:09  time: 0.2122  data_time: 0.0181  memory: 5586  grad_norm: 1.1470  loss: 0.6999  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6999\n",
            "12/02 20:47:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 80/332]  lr: 1.0000e-03  eta: 0:36:04  time: 0.2128  data_time: 0.0191  memory: 5586  grad_norm: 1.1451  loss: 0.6998  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6998\n",
            "12/02 20:47:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][100/332]  lr: 1.0000e-03  eta: 0:35:59  time: 0.2555  data_time: 0.0361  memory: 5586  grad_norm: 1.4390  loss: 0.7316  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7316\n",
            "12/02 20:48:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][120/332]  lr: 1.0000e-03  eta: 0:35:55  time: 0.2857  data_time: 0.0591  memory: 5586  grad_norm: 1.3838  loss: 0.6993  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6993\n",
            "12/02 20:48:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][140/332]  lr: 1.0000e-03  eta: 0:35:50  time: 0.2147  data_time: 0.0186  memory: 5586  grad_norm: 1.1698  loss: 0.6983  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6983\n",
            "12/02 20:48:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][160/332]  lr: 1.0000e-03  eta: 0:35:44  time: 0.2085  data_time: 0.0158  memory: 5586  grad_norm: 1.2869  loss: 0.6872  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6872\n",
            "12/02 20:48:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][180/332]  lr: 1.0000e-03  eta: 0:35:40  time: 0.2583  data_time: 0.0391  memory: 5586  grad_norm: 1.2292  loss: 0.7381  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7381\n",
            "12/02 20:48:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][200/332]  lr: 1.0000e-03  eta: 0:35:36  time: 0.2915  data_time: 0.0738  memory: 5586  grad_norm: 1.6401  loss: 0.6910  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6910\n",
            "12/02 20:48:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][220/332]  lr: 1.0000e-03  eta: 0:35:30  time: 0.2136  data_time: 0.0195  memory: 5586  grad_norm: 1.1101  loss: 0.6796  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6796\n",
            "12/02 20:48:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][240/332]  lr: 1.0000e-03  eta: 0:35:25  time: 0.2125  data_time: 0.0192  memory: 5586  grad_norm: 1.5780  loss: 0.7256  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7256\n",
            "12/02 20:48:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][260/332]  lr: 1.0000e-03  eta: 0:35:20  time: 0.2526  data_time: 0.0367  memory: 5586  grad_norm: 1.5148  loss: 0.6964  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6964\n",
            "12/02 20:48:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][280/332]  lr: 1.0000e-03  eta: 0:35:16  time: 0.2930  data_time: 0.0730  memory: 5586  grad_norm: 1.0468  loss: 0.6667  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6667\n",
            "12/02 20:48:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][300/332]  lr: 1.0000e-03  eta: 0:35:11  time: 0.2122  data_time: 0.0186  memory: 5586  grad_norm: 1.2971  loss: 0.7004  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7004\n",
            "12/02 20:48:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][320/332]  lr: 1.0000e-03  eta: 0:35:05  time: 0.2109  data_time: 0.0171  memory: 5586  grad_norm: 1.4813  loss: 0.6705  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6705\n",
            "12/02 20:48:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:48:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][332/332]  lr: 1.0000e-03  eta: 0:35:02  time: 0.2166  data_time: 0.0212  memory: 5586  grad_norm: 1.7326  loss: 0.6908  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6908\n",
            "12/02 20:48:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 24 epochs\n",
            "12/02 20:48:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][20/42]    eta: 0:00:04  time: 0.2197  data_time: 0.1183  memory: 1141  \n",
            "12/02 20:49:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][40/42]    eta: 0:00:00  time: 0.1967  data_time: 0.0989  memory: 1141  \n",
            "12/02 20:49:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][42/42]    acc/top1: 0.5438  acc/top5: 1.0000  acc/mean1: 0.4912  data_time: 0.1016  time: 0.1977\n",
            "12/02 20:49:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 20/332]  lr: 1.0000e-03  eta: 0:34:57  time: 0.2276  data_time: 0.0337  memory: 5586  grad_norm: 1.1295  loss: 0.6925  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6925\n",
            "12/02 20:49:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:49:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 40/332]  lr: 1.0000e-03  eta: 0:34:51  time: 0.2110  data_time: 0.0174  memory: 5586  grad_norm: 1.5340  loss: 0.7084  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7084\n",
            "12/02 20:49:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 60/332]  lr: 1.0000e-03  eta: 0:34:47  time: 0.2760  data_time: 0.0481  memory: 5586  grad_norm: 0.8942  loss: 0.6718  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6718\n",
            "12/02 20:49:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 80/332]  lr: 1.0000e-03  eta: 0:34:42  time: 0.2556  data_time: 0.0444  memory: 5586  grad_norm: 1.2155  loss: 0.7209  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7209\n",
            "12/02 20:49:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][100/332]  lr: 1.0000e-03  eta: 0:34:37  time: 0.2133  data_time: 0.0180  memory: 5586  grad_norm: 0.9964  loss: 0.6852  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6852\n",
            "12/02 20:49:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][120/332]  lr: 1.0000e-03  eta: 0:34:31  time: 0.2116  data_time: 0.0166  memory: 5586  grad_norm: 1.8679  loss: 0.6778  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6778\n",
            "12/02 20:49:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][140/332]  lr: 1.0000e-03  eta: 0:34:27  time: 0.2677  data_time: 0.0420  memory: 5586  grad_norm: 1.3092  loss: 0.6962  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6962\n",
            "12/02 20:49:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][160/332]  lr: 1.0000e-03  eta: 0:34:23  time: 0.2728  data_time: 0.0549  memory: 5586  grad_norm: 1.1387  loss: 0.7298  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7298\n",
            "12/02 20:49:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][180/332]  lr: 1.0000e-03  eta: 0:34:17  time: 0.2125  data_time: 0.0198  memory: 5586  grad_norm: 1.0536  loss: 0.6801  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6801\n",
            "12/02 20:49:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][200/332]  lr: 1.0000e-03  eta: 0:34:12  time: 0.2125  data_time: 0.0183  memory: 5586  grad_norm: 0.9735  loss: 0.6879  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6879\n",
            "12/02 20:49:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][220/332]  lr: 1.0000e-03  eta: 0:34:07  time: 0.2695  data_time: 0.0467  memory: 5586  grad_norm: 0.8694  loss: 0.6684  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6684\n",
            "12/02 20:49:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][240/332]  lr: 1.0000e-03  eta: 0:34:03  time: 0.2754  data_time: 0.0630  memory: 5586  grad_norm: 0.7656  loss: 0.6865  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6865\n",
            "12/02 20:50:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][260/332]  lr: 1.0000e-03  eta: 0:33:58  time: 0.2142  data_time: 0.0202  memory: 5586  grad_norm: 1.3051  loss: 0.7131  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7131\n",
            "12/02 20:50:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][280/332]  lr: 1.0000e-03  eta: 0:33:52  time: 0.2114  data_time: 0.0189  memory: 5586  grad_norm: 1.1311  loss: 0.6626  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6626\n",
            "12/02 20:50:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][300/332]  lr: 1.0000e-03  eta: 0:33:48  time: 0.2742  data_time: 0.0476  memory: 5586  grad_norm: 1.0955  loss: 0.7065  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7065\n",
            "12/02 20:50:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][320/332]  lr: 1.0000e-03  eta: 0:33:43  time: 0.2637  data_time: 0.0473  memory: 5586  grad_norm: 2.0005  loss: 0.7080  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7080\n",
            "12/02 20:50:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:50:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][332/332]  lr: 1.0000e-03  eta: 0:33:40  time: 0.2151  data_time: 0.0240  memory: 5586  grad_norm: 1.2231  loss: 0.6969  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6969\n",
            "12/02 20:50:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 25 epochs\n",
            "12/02 20:50:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][20/42]    eta: 0:00:03  time: 0.1457  data_time: 0.0566  memory: 1141  \n",
            "12/02 20:50:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][40/42]    eta: 0:00:00  time: 0.1573  data_time: 0.0646  memory: 1141  \n",
            "12/02 20:50:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5007  data_time: 0.0595  time: 0.1475\n",
            "12/02 20:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][ 20/332]  lr: 1.0000e-03  eta: 0:33:36  time: 0.3036  data_time: 0.0831  memory: 5586  grad_norm: 1.3761  loss: 0.7496  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7496\n",
            "12/02 20:50:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][ 40/332]  lr: 1.0000e-03  eta: 0:33:31  time: 0.2388  data_time: 0.0381  memory: 5586  grad_norm: 1.1177  loss: 0.6931  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6931\n",
            "12/02 20:50:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][ 60/332]  lr: 1.0000e-03  eta: 0:33:26  time: 0.2076  data_time: 0.0152  memory: 5586  grad_norm: 1.1225  loss: 0.7014  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7014\n",
            "12/02 20:50:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][ 80/332]  lr: 1.0000e-03  eta: 0:33:20  time: 0.2259  data_time: 0.0233  memory: 5586  grad_norm: 1.6708  loss: 0.7239  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7239\n",
            "12/02 20:50:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][100/332]  lr: 1.0000e-03  eta: 0:33:17  time: 0.2924  data_time: 0.0667  memory: 5586  grad_norm: 1.5821  loss: 0.7219  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7219\n",
            "12/02 20:50:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][120/332]  lr: 1.0000e-03  eta: 0:33:12  time: 0.2398  data_time: 0.0323  memory: 5586  grad_norm: 1.0349  loss: 0.6682  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6682\n",
            "12/02 20:51:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][140/332]  lr: 1.0000e-03  eta: 0:33:06  time: 0.2120  data_time: 0.0187  memory: 5586  grad_norm: 1.3684  loss: 0.6673  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6673\n",
            "12/02 20:51:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][160/332]  lr: 1.0000e-03  eta: 0:33:01  time: 0.2269  data_time: 0.0242  memory: 5586  grad_norm: 2.4531  loss: 0.7081  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7081\n",
            "12/02 20:51:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][180/332]  lr: 1.0000e-03  eta: 0:32:57  time: 0.2816  data_time: 0.0600  memory: 5586  grad_norm: 2.8647  loss: 0.7153  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7153\n",
            "12/02 20:51:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][200/332]  lr: 1.0000e-03  eta: 0:32:52  time: 0.2479  data_time: 0.0394  memory: 5586  grad_norm: 2.4872  loss: 0.7189  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7189\n",
            "12/02 20:51:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][220/332]  lr: 1.0000e-03  eta: 0:32:47  time: 0.2140  data_time: 0.0191  memory: 5586  grad_norm: 2.3005  loss: 0.7071  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7071\n",
            "12/02 20:51:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][240/332]  lr: 1.0000e-03  eta: 0:32:41  time: 0.2225  data_time: 0.0206  memory: 5586  grad_norm: 1.4856  loss: 0.6982  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6982\n",
            "12/02 20:51:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][260/332]  lr: 1.0000e-03  eta: 0:32:37  time: 0.2937  data_time: 0.0672  memory: 5586  grad_norm: 1.8429  loss: 0.7071  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7071\n",
            "12/02 20:51:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][280/332]  lr: 1.0000e-03  eta: 0:32:32  time: 0.2393  data_time: 0.0367  memory: 5586  grad_norm: 0.9479  loss: 0.6861  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6861\n",
            "12/02 20:51:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][300/332]  lr: 1.0000e-03  eta: 0:32:27  time: 0.2102  data_time: 0.0171  memory: 5586  grad_norm: 1.4863  loss: 0.6759  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6759\n",
            "12/02 20:51:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][320/332]  lr: 1.0000e-03  eta: 0:32:22  time: 0.2305  data_time: 0.0270  memory: 5586  grad_norm: 1.0112  loss: 0.6737  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6737\n",
            "12/02 20:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][332/332]  lr: 1.0000e-03  eta: 0:32:19  time: 0.2605  data_time: 0.0464  memory: 5586  grad_norm: 1.0031  loss: 0.6592  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6592\n",
            "12/02 20:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 26 epochs\n",
            "12/02 20:51:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [26][20/42]    eta: 0:00:04  time: 0.2192  data_time: 0.1175  memory: 1141  \n",
            "12/02 20:51:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [26][40/42]    eta: 0:00:00  time: 0.1331  data_time: 0.0403  memory: 1141  \n",
            "12/02 20:51:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [26][42/42]    acc/top1: 0.5589  acc/top5: 1.0000  acc/mean1: 0.5041  data_time: 0.0743  time: 0.1682\n",
            "12/02 20:52:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][ 20/332]  lr: 1.0000e-03  eta: 0:32:14  time: 0.2242  data_time: 0.0316  memory: 5586  grad_norm: 1.1019  loss: 0.6710  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6710\n",
            "12/02 20:52:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][ 40/332]  lr: 1.0000e-03  eta: 0:32:09  time: 0.2361  data_time: 0.0261  memory: 5586  grad_norm: 1.6142  loss: 0.7012  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7012\n",
            "12/02 20:52:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][ 60/332]  lr: 1.0000e-03  eta: 0:32:05  time: 0.2845  data_time: 0.0621  memory: 5586  grad_norm: 1.7415  loss: 0.7172  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7172\n",
            "12/02 20:52:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][ 80/332]  lr: 1.0000e-03  eta: 0:32:00  time: 0.2253  data_time: 0.0234  memory: 5586  grad_norm: 1.1846  loss: 0.6956  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6956\n",
            "12/02 20:52:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][100/332]  lr: 1.0000e-03  eta: 0:31:54  time: 0.2127  data_time: 0.0177  memory: 5586  grad_norm: 1.2549  loss: 0.6801  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6801\n",
            "12/02 20:52:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][120/332]  lr: 1.0000e-03  eta: 0:31:49  time: 0.2455  data_time: 0.0352  memory: 5586  grad_norm: 1.3224  loss: 0.7056  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7056\n",
            "12/02 20:52:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][140/332]  lr: 1.0000e-03  eta: 0:31:45  time: 0.2852  data_time: 0.0586  memory: 5586  grad_norm: 1.5989  loss: 0.7331  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7331\n",
            "12/02 20:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][160/332]  lr: 1.0000e-03  eta: 0:31:40  time: 0.2236  data_time: 0.0263  memory: 5586  grad_norm: 1.2625  loss: 0.6975  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6975\n",
            "12/02 20:52:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][180/332]  lr: 1.0000e-03  eta: 0:31:35  time: 0.2129  data_time: 0.0192  memory: 5586  grad_norm: 2.5432  loss: 0.7116  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7116\n",
            "12/02 20:52:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][200/332]  lr: 1.0000e-03  eta: 0:31:30  time: 0.2438  data_time: 0.0301  memory: 5586  grad_norm: 1.9980  loss: 0.7029  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7029\n",
            "12/02 20:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][220/332]  lr: 1.0000e-03  eta: 0:31:26  time: 0.2930  data_time: 0.0683  memory: 5586  grad_norm: 3.5983  loss: 0.6931  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6931\n",
            "12/02 20:52:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][240/332]  lr: 1.0000e-03  eta: 0:31:20  time: 0.2192  data_time: 0.0278  memory: 5586  grad_norm: 3.2081  loss: 0.7496  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7496\n",
            "12/02 20:53:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][260/332]  lr: 1.0000e-03  eta: 0:31:15  time: 0.2085  data_time: 0.0167  memory: 5586  grad_norm: 2.6965  loss: 0.7221  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7221\n",
            "12/02 20:53:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][280/332]  lr: 1.0000e-03  eta: 0:31:10  time: 0.2453  data_time: 0.0340  memory: 5586  grad_norm: 1.6951  loss: 0.6741  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6741\n",
            "12/02 20:53:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][300/332]  lr: 1.0000e-03  eta: 0:31:06  time: 0.3041  data_time: 0.0830  memory: 5586  grad_norm: 1.5045  loss: 0.6839  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6839\n",
            "12/02 20:53:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][320/332]  lr: 1.0000e-03  eta: 0:31:01  time: 0.2112  data_time: 0.0169  memory: 5586  grad_norm: 1.6093  loss: 0.6918  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6918\n",
            "12/02 20:53:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:53:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][332/332]  lr: 1.0000e-03  eta: 0:30:58  time: 0.2034  data_time: 0.0162  memory: 5586  grad_norm: 1.1709  loss: 0.6697  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6697\n",
            "12/02 20:53:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 27 epochs\n",
            "12/02 20:53:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [27][20/42]    eta: 0:00:03  time: 0.1511  data_time: 0.0569  memory: 1141  \n",
            "12/02 20:53:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [27][40/42]    eta: 0:00:00  time: 0.2110  data_time: 0.1127  memory: 1141  \n",
            "12/02 20:53:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [27][42/42]    acc/top1: 0.5529  acc/top5: 1.0000  acc/mean1: 0.4973  data_time: 0.0831  time: 0.1761\n",
            "12/02 20:53:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][ 20/332]  lr: 1.0000e-03  eta: 0:30:53  time: 0.2907  data_time: 0.0748  memory: 5586  grad_norm: 1.2134  loss: 0.6988  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6988\n",
            "12/02 20:53:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:53:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][ 40/332]  lr: 1.0000e-03  eta: 0:30:48  time: 0.2117  data_time: 0.0174  memory: 5586  grad_norm: 1.4727  loss: 0.6918  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6918\n",
            "12/02 20:53:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][ 60/332]  lr: 1.0000e-03  eta: 0:30:43  time: 0.2090  data_time: 0.0163  memory: 5586  grad_norm: 1.6773  loss: 0.7146  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7146\n",
            "12/02 20:53:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][ 80/332]  lr: 1.0000e-03  eta: 0:30:38  time: 0.2573  data_time: 0.0398  memory: 5586  grad_norm: 0.7254  loss: 0.6814  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6814\n",
            "12/02 20:53:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][100/332]  lr: 1.0000e-03  eta: 0:30:34  time: 0.2845  data_time: 0.0653  memory: 5586  grad_norm: 0.9995  loss: 0.6973  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6973\n",
            "12/02 20:53:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][120/332]  lr: 1.0000e-03  eta: 0:30:28  time: 0.2124  data_time: 0.0193  memory: 5586  grad_norm: 1.3568  loss: 0.7024  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7024\n",
            "12/02 20:53:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][140/332]  lr: 1.0000e-03  eta: 0:30:23  time: 0.2097  data_time: 0.0158  memory: 5586  grad_norm: 2.5959  loss: 0.6869  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6869\n",
            "12/02 20:54:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][160/332]  lr: 1.0000e-03  eta: 0:30:18  time: 0.2594  data_time: 0.0351  memory: 5586  grad_norm: 1.5066  loss: 0.6698  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6698\n",
            "12/02 20:54:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][180/332]  lr: 1.0000e-03  eta: 0:30:14  time: 0.2842  data_time: 0.0660  memory: 5586  grad_norm: 0.8658  loss: 0.6720  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6720\n",
            "12/02 20:54:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][200/332]  lr: 1.0000e-03  eta: 0:30:09  time: 0.2154  data_time: 0.0219  memory: 5586  grad_norm: 1.5785  loss: 0.6971  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6971\n",
            "12/02 20:54:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][220/332]  lr: 1.0000e-03  eta: 0:30:04  time: 0.2145  data_time: 0.0199  memory: 5586  grad_norm: 1.6020  loss: 0.6545  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6545\n",
            "12/02 20:54:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][240/332]  lr: 1.0000e-03  eta: 0:29:59  time: 0.2658  data_time: 0.0459  memory: 5586  grad_norm: 1.5824  loss: 0.6949  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6949\n",
            "12/02 20:54:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][260/332]  lr: 1.0000e-03  eta: 0:29:55  time: 0.2727  data_time: 0.0583  memory: 5586  grad_norm: 1.1884  loss: 0.6724  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6724\n",
            "12/02 20:54:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][280/332]  lr: 1.0000e-03  eta: 0:29:49  time: 0.2123  data_time: 0.0189  memory: 5586  grad_norm: 1.1627  loss: 0.7150  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7150\n",
            "12/02 20:54:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][300/332]  lr: 1.0000e-03  eta: 0:29:44  time: 0.2127  data_time: 0.0198  memory: 5586  grad_norm: 1.1520  loss: 0.6719  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6719\n",
            "12/02 20:54:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][320/332]  lr: 1.0000e-03  eta: 0:29:39  time: 0.2663  data_time: 0.0424  memory: 5586  grad_norm: 1.7270  loss: 0.7063  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7063\n",
            "12/02 20:54:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:54:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][332/332]  lr: 1.0000e-03  eta: 0:29:37  time: 0.2794  data_time: 0.0602  memory: 5586  grad_norm: 1.3270  loss: 0.7037  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.7037\n",
            "12/02 20:54:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 28 epochs\n",
            "12/02 20:54:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [28][20/42]    eta: 0:00:03  time: 0.1492  data_time: 0.0594  memory: 1141  \n",
            "12/02 20:54:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [28][40/42]    eta: 0:00:00  time: 0.1383  data_time: 0.0487  memory: 1141  \n",
            "12/02 20:54:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [28][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0511  time: 0.1380\n",
            "12/02 20:54:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][ 20/332]  lr: 1.0000e-03  eta: 0:29:32  time: 0.2294  data_time: 0.0349  memory: 5586  grad_norm: 1.2602  loss: 0.6904  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6904\n",
            "12/02 20:55:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][ 40/332]  lr: 1.0000e-03  eta: 0:29:27  time: 0.2716  data_time: 0.0507  memory: 5586  grad_norm: 1.2877  loss: 0.6870  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6870\n",
            "12/02 20:55:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][ 60/332]  lr: 1.0000e-03  eta: 0:29:23  time: 0.2628  data_time: 0.0486  memory: 5586  grad_norm: 1.2305  loss: 0.6844  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6844\n",
            "12/02 20:55:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][ 80/332]  lr: 1.0000e-03  eta: 0:29:17  time: 0.2140  data_time: 0.0190  memory: 5586  grad_norm: 1.0586  loss: 0.6670  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6670\n",
            "12/02 20:55:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][100/332]  lr: 1.0000e-03  eta: 0:29:12  time: 0.2154  data_time: 0.0195  memory: 5586  grad_norm: 1.0562  loss: 0.6862  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6862\n",
            "12/02 20:55:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][120/332]  lr: 1.0000e-03  eta: 0:29:08  time: 0.2887  data_time: 0.0613  memory: 5586  grad_norm: 1.1764  loss: 0.7237  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7237\n",
            "12/02 20:55:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][140/332]  lr: 1.0000e-03  eta: 0:29:03  time: 0.2546  data_time: 0.0463  memory: 5586  grad_norm: 1.0623  loss: 0.6886  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6886\n",
            "12/02 20:55:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][160/332]  lr: 1.0000e-03  eta: 0:28:58  time: 0.2101  data_time: 0.0177  memory: 5586  grad_norm: 1.1759  loss: 0.7346  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7346\n",
            "12/02 20:55:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][180/332]  lr: 1.0000e-03  eta: 0:28:53  time: 0.2250  data_time: 0.0229  memory: 5586  grad_norm: 1.7341  loss: 0.7067  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7067\n",
            "12/02 20:55:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][200/332]  lr: 1.0000e-03  eta: 0:28:48  time: 0.2825  data_time: 0.0607  memory: 5586  grad_norm: 1.1555  loss: 0.7008  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7008\n",
            "12/02 20:55:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][220/332]  lr: 1.0000e-03  eta: 0:28:44  time: 0.2514  data_time: 0.0449  memory: 5586  grad_norm: 1.3176  loss: 0.6641  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6641\n",
            "12/02 20:55:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][240/332]  lr: 1.0000e-03  eta: 0:28:38  time: 0.2136  data_time: 0.0199  memory: 5586  grad_norm: 2.4712  loss: 0.7075  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7075\n",
            "12/02 20:55:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][260/332]  lr: 1.0000e-03  eta: 0:28:33  time: 0.2208  data_time: 0.0207  memory: 5586  grad_norm: 1.8818  loss: 0.6902  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6902\n",
            "12/02 20:56:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][280/332]  lr: 1.0000e-03  eta: 0:28:29  time: 0.2779  data_time: 0.0558  memory: 5586  grad_norm: 1.0786  loss: 0.6862  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6862\n",
            "12/02 20:56:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][300/332]  lr: 1.0000e-03  eta: 0:28:24  time: 0.2551  data_time: 0.0457  memory: 5586  grad_norm: 1.3036  loss: 0.7036  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7036\n",
            "12/02 20:56:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][320/332]  lr: 1.0000e-03  eta: 0:28:19  time: 0.2134  data_time: 0.0184  memory: 5586  grad_norm: 1.3178  loss: 0.6907  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6907\n",
            "12/02 20:56:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:56:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][332/332]  lr: 1.0000e-03  eta: 0:28:15  time: 0.2022  data_time: 0.0158  memory: 5586  grad_norm: 1.1114  loss: 0.7280  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7280\n",
            "12/02 20:56:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 29 epochs\n",
            "12/02 20:56:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [29][20/42]    eta: 0:00:04  time: 0.2129  data_time: 0.1129  memory: 1141  \n",
            "12/02 20:56:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [29][40/42]    eta: 0:00:00  time: 0.2321  data_time: 0.1339  memory: 1141  \n",
            "12/02 20:56:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [29][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.1173  time: 0.2129\n",
            "12/02 20:56:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][ 20/332]  lr: 1.0000e-03  eta: 0:28:11  time: 0.2403  data_time: 0.0422  memory: 5586  grad_norm: 1.1823  loss: 0.7166  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7166\n",
            "12/02 20:56:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][ 40/332]  lr: 1.0000e-03  eta: 0:28:05  time: 0.2090  data_time: 0.0163  memory: 5586  grad_norm: 1.6836  loss: 0.7181  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7181\n",
            "12/02 20:56:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][ 60/332]  lr: 1.0000e-03  eta: 0:28:00  time: 0.2412  data_time: 0.0322  memory: 5586  grad_norm: 0.9450  loss: 0.6636  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6636\n",
            "12/02 20:56:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][ 80/332]  lr: 1.0000e-03  eta: 0:27:56  time: 0.2835  data_time: 0.0667  memory: 5586  grad_norm: 0.8436  loss: 0.6779  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6779\n",
            "12/02 20:56:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][100/332]  lr: 1.0000e-03  eta: 0:27:51  time: 0.2219  data_time: 0.0260  memory: 5586  grad_norm: 1.0070  loss: 0.6777  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6777\n",
            "12/02 20:56:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][120/332]  lr: 1.0000e-03  eta: 0:27:46  time: 0.2112  data_time: 0.0173  memory: 5586  grad_norm: 1.1500  loss: 0.7084  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7084\n",
            "12/02 20:56:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][140/332]  lr: 1.0000e-03  eta: 0:27:41  time: 0.2445  data_time: 0.0328  memory: 5586  grad_norm: 1.4283  loss: 0.6871  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6871\n",
            "12/02 20:57:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][160/332]  lr: 1.0000e-03  eta: 0:27:36  time: 0.2842  data_time: 0.0640  memory: 5586  grad_norm: 1.8202  loss: 0.7081  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7081\n",
            "12/02 20:57:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][180/332]  lr: 1.0000e-03  eta: 0:27:31  time: 0.2284  data_time: 0.0306  memory: 5586  grad_norm: 1.2652  loss: 0.7028  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7028\n",
            "12/02 20:57:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][200/332]  lr: 1.0000e-03  eta: 0:27:26  time: 0.2124  data_time: 0.0187  memory: 5586  grad_norm: 1.8271  loss: 0.7045  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7045\n",
            "12/02 20:57:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][220/332]  lr: 1.0000e-03  eta: 0:27:21  time: 0.2299  data_time: 0.0235  memory: 5586  grad_norm: 2.4598  loss: 0.6872  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6872\n",
            "12/02 20:57:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][240/332]  lr: 1.0000e-03  eta: 0:27:17  time: 0.2960  data_time: 0.0783  memory: 5586  grad_norm: 2.4386  loss: 0.6905  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6905\n",
            "12/02 20:57:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][260/332]  lr: 1.0000e-03  eta: 0:27:12  time: 0.2352  data_time: 0.0326  memory: 5586  grad_norm: 3.0716  loss: 0.7176  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7176\n",
            "12/02 20:57:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][280/332]  lr: 1.0000e-03  eta: 0:27:07  time: 0.2127  data_time: 0.0175  memory: 5586  grad_norm: 1.8884  loss: 0.6739  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6739\n",
            "12/02 20:57:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][300/332]  lr: 1.0000e-03  eta: 0:27:02  time: 0.2406  data_time: 0.0310  memory: 5586  grad_norm: 1.8502  loss: 0.6634  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6634\n",
            "12/02 20:57:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][320/332]  lr: 1.0000e-03  eta: 0:26:57  time: 0.2886  data_time: 0.0672  memory: 5586  grad_norm: 2.6249  loss: 0.7052  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7052\n",
            "12/02 20:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][332/332]  lr: 1.0000e-03  eta: 0:26:54  time: 0.2516  data_time: 0.0497  memory: 5586  grad_norm: 2.2624  loss: 0.6995  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6995\n",
            "12/02 20:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 30 epochs\n",
            "12/02 20:57:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][20/42]    eta: 0:00:03  time: 0.1459  data_time: 0.0545  memory: 1141  \n",
            "12/02 20:57:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][40/42]    eta: 0:00:00  time: 0.1428  data_time: 0.0512  memory: 1141  \n",
            "12/02 20:57:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0498  time: 0.1383\n",
            "12/02 20:57:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][ 20/332]  lr: 1.0000e-03  eta: 0:26:50  time: 0.2798  data_time: 0.0619  memory: 5586  grad_norm: 2.8178  loss: 0.7057  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7057\n",
            "12/02 20:58:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:58:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][ 40/332]  lr: 1.0000e-03  eta: 0:26:46  time: 0.2777  data_time: 0.0571  memory: 5586  grad_norm: 3.3958  loss: 0.6972  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6972\n",
            "12/02 20:58:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][ 60/332]  lr: 1.0000e-03  eta: 0:26:40  time: 0.2124  data_time: 0.0180  memory: 5586  grad_norm: 2.4088  loss: 0.7299  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7299\n",
            "12/02 20:58:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][ 80/332]  lr: 1.0000e-03  eta: 0:26:35  time: 0.2084  data_time: 0.0164  memory: 5586  grad_norm: 2.1683  loss: 0.6954  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6954\n",
            "12/02 20:58:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][100/332]  lr: 1.0000e-03  eta: 0:26:30  time: 0.2551  data_time: 0.0367  memory: 5586  grad_norm: 1.6496  loss: 0.6826  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6826\n",
            "12/02 20:58:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][120/332]  lr: 1.0000e-03  eta: 0:26:26  time: 0.2816  data_time: 0.0649  memory: 5586  grad_norm: 2.1258  loss: 0.7136  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7136\n",
            "12/02 20:58:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][140/332]  lr: 1.0000e-03  eta: 0:26:21  time: 0.2078  data_time: 0.0164  memory: 5586  grad_norm: 1.7117  loss: 0.6606  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6606\n",
            "12/02 20:58:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][160/332]  lr: 1.0000e-03  eta: 0:26:15  time: 0.2136  data_time: 0.0191  memory: 5586  grad_norm: 1.6112  loss: 0.7010  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.7010\n",
            "12/02 20:58:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][180/332]  lr: 1.0000e-03  eta: 0:26:11  time: 0.2461  data_time: 0.0301  memory: 5586  grad_norm: 3.0517  loss: 0.7066  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7066\n",
            "12/02 20:58:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][200/332]  lr: 1.0000e-03  eta: 0:26:06  time: 0.2989  data_time: 0.0774  memory: 5586  grad_norm: 1.8083  loss: 0.6963  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6963\n",
            "12/02 20:58:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][220/332]  lr: 1.0000e-03  eta: 0:26:01  time: 0.2131  data_time: 0.0170  memory: 5586  grad_norm: 1.5270  loss: 0.6872  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6872\n",
            "12/02 20:58:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][240/332]  lr: 1.0000e-03  eta: 0:25:56  time: 0.2105  data_time: 0.0182  memory: 5586  grad_norm: 1.1993  loss: 0.6729  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6729\n",
            "12/02 20:58:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][260/332]  lr: 1.0000e-03  eta: 0:25:51  time: 0.2495  data_time: 0.0329  memory: 5586  grad_norm: 1.5975  loss: 0.6954  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6954\n",
            "12/02 20:58:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][280/332]  lr: 1.0000e-03  eta: 0:25:47  time: 0.2911  data_time: 0.0676  memory: 5586  grad_norm: 1.4538  loss: 0.6705  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6705\n",
            "12/02 20:59:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][300/332]  lr: 1.0000e-03  eta: 0:25:42  time: 0.2118  data_time: 0.0178  memory: 5586  grad_norm: 1.2147  loss: 0.6876  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6876\n",
            "12/02 20:59:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][320/332]  lr: 1.0000e-03  eta: 0:25:36  time: 0.2127  data_time: 0.0176  memory: 5586  grad_norm: 1.3601  loss: 0.6930  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6930\n",
            "12/02 20:59:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 20:59:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][332/332]  lr: 1.0000e-03  eta: 0:25:33  time: 0.2130  data_time: 0.0205  memory: 5586  grad_norm: 1.9955  loss: 0.7067  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7067\n",
            "12/02 20:59:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 31 epochs\n",
            "12/02 20:59:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [31][20/42]    eta: 0:00:04  time: 0.2249  data_time: 0.1233  memory: 1141  \n",
            "12/02 20:59:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [31][40/42]    eta: 0:00:00  time: 0.1896  data_time: 0.0935  memory: 1141  \n",
            "12/02 20:59:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [31][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.1011  time: 0.1965\n",
            "12/02 20:59:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][ 20/332]  lr: 1.0000e-03  eta: 0:25:28  time: 0.2246  data_time: 0.0319  memory: 5586  grad_norm: 3.8913  loss: 0.6623  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6623\n",
            "12/02 20:59:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][ 40/332]  lr: 1.0000e-03  eta: 0:25:23  time: 0.2081  data_time: 0.0156  memory: 5586  grad_norm: 3.2789  loss: 0.6761  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6761\n",
            "12/02 20:59:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][ 60/332]  lr: 1.0000e-03  eta: 0:25:18  time: 0.2658  data_time: 0.0408  memory: 5586  grad_norm: 1.0874  loss: 0.6904  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6904\n",
            "12/02 20:59:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][ 80/332]  lr: 1.0000e-03  eta: 0:25:14  time: 0.2671  data_time: 0.0532  memory: 5586  grad_norm: 1.5332  loss: 0.6906  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6906\n",
            "12/02 20:59:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][100/332]  lr: 1.0000e-03  eta: 0:25:08  time: 0.2140  data_time: 0.0198  memory: 5586  grad_norm: 1.2175  loss: 0.6998  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6998\n",
            "12/02 20:59:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][120/332]  lr: 1.0000e-03  eta: 0:25:03  time: 0.2119  data_time: 0.0171  memory: 5586  grad_norm: 1.1013  loss: 0.6845  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6845\n",
            "12/02 20:59:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][140/332]  lr: 1.0000e-03  eta: 0:24:59  time: 0.2724  data_time: 0.0508  memory: 5586  grad_norm: 1.0368  loss: 0.7027  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7027\n",
            "12/02 20:59:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][160/332]  lr: 1.0000e-03  eta: 0:24:54  time: 0.2704  data_time: 0.0577  memory: 5586  grad_norm: 0.9842  loss: 0.6840  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6840\n",
            "12/02 21:00:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][180/332]  lr: 1.0000e-03  eta: 0:24:49  time: 0.2129  data_time: 0.0186  memory: 5586  grad_norm: 0.9949  loss: 0.6827  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6827\n",
            "12/02 21:00:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][200/332]  lr: 1.0000e-03  eta: 0:24:44  time: 0.2118  data_time: 0.0186  memory: 5586  grad_norm: 0.9681  loss: 0.6898  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6898\n",
            "12/02 21:00:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][220/332]  lr: 1.0000e-03  eta: 0:24:39  time: 0.2887  data_time: 0.0610  memory: 5586  grad_norm: 1.0856  loss: 0.6820  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6820\n",
            "12/02 21:00:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][240/332]  lr: 1.0000e-03  eta: 0:24:35  time: 0.2549  data_time: 0.0454  memory: 5586  grad_norm: 0.8638  loss: 0.6856  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6856\n",
            "12/02 21:00:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][260/332]  lr: 1.0000e-03  eta: 0:24:29  time: 0.2154  data_time: 0.0198  memory: 5586  grad_norm: 0.9487  loss: 0.6813  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6813\n",
            "12/02 21:00:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][280/332]  lr: 1.0000e-03  eta: 0:24:24  time: 0.2158  data_time: 0.0187  memory: 5586  grad_norm: 1.2595  loss: 0.6932  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6932\n",
            "12/02 21:00:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][300/332]  lr: 1.0000e-03  eta: 0:24:20  time: 0.2835  data_time: 0.0578  memory: 5586  grad_norm: 1.4021  loss: 0.7100  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7100\n",
            "12/02 21:00:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][320/332]  lr: 1.0000e-03  eta: 0:24:15  time: 0.2608  data_time: 0.0466  memory: 5586  grad_norm: 1.9461  loss: 0.6761  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6761\n",
            "12/02 21:00:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:00:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][332/332]  lr: 1.0000e-03  eta: 0:24:12  time: 0.2076  data_time: 0.0194  memory: 5586  grad_norm: 1.9767  loss: 0.6873  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6873\n",
            "12/02 21:00:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 32 epochs\n",
            "12/02 21:00:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [32][20/42]    eta: 0:00:03  time: 0.1437  data_time: 0.0515  memory: 1141  \n",
            "12/02 21:00:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [32][40/42]    eta: 0:00:00  time: 0.1811  data_time: 0.0842  memory: 1141  \n",
            "12/02 21:00:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [32][42/42]    acc/top1: 0.5619  acc/top5: 1.0000  acc/mean1: 0.5075  data_time: 0.0667  time: 0.1581\n",
            "12/02 21:00:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][ 20/332]  lr: 1.0000e-03  eta: 0:24:08  time: 0.3043  data_time: 0.0833  memory: 5586  grad_norm: 1.0361  loss: 0.7303  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7303\n",
            "12/02 21:00:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][ 40/332]  lr: 1.0000e-03  eta: 0:24:03  time: 0.2259  data_time: 0.0285  memory: 5586  grad_norm: 0.8930  loss: 0.6948  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6948\n",
            "12/02 21:01:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][ 60/332]  lr: 1.0000e-03  eta: 0:23:58  time: 0.2127  data_time: 0.0189  memory: 5586  grad_norm: 0.9761  loss: 0.6909  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6909\n",
            "12/02 21:01:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][ 80/332]  lr: 1.0000e-03  eta: 0:23:53  time: 0.2353  data_time: 0.0237  memory: 5586  grad_norm: 1.3921  loss: 0.6711  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6711\n",
            "12/02 21:01:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][100/332]  lr: 1.0000e-03  eta: 0:23:48  time: 0.2926  data_time: 0.0715  memory: 5586  grad_norm: 0.8545  loss: 0.6715  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6715\n",
            "12/02 21:01:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][120/332]  lr: 1.0000e-03  eta: 0:23:43  time: 0.2267  data_time: 0.0285  memory: 5586  grad_norm: 0.9908  loss: 0.6756  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6756\n",
            "12/02 21:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][140/332]  lr: 1.0000e-03  eta: 0:23:38  time: 0.2125  data_time: 0.0193  memory: 5586  grad_norm: 1.0202  loss: 0.7030  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7030\n",
            "12/02 21:01:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][160/332]  lr: 1.0000e-03  eta: 0:23:33  time: 0.2369  data_time: 0.0265  memory: 5586  grad_norm: 0.7610  loss: 0.6919  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6919\n",
            "12/02 21:01:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][180/332]  lr: 1.0000e-03  eta: 0:23:29  time: 0.2883  data_time: 0.0625  memory: 5586  grad_norm: 0.8766  loss: 0.6734  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6734\n",
            "12/02 21:01:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][200/332]  lr: 1.0000e-03  eta: 0:23:24  time: 0.2247  data_time: 0.0256  memory: 5586  grad_norm: 1.0449  loss: 0.6871  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6871\n",
            "12/02 21:01:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][220/332]  lr: 1.0000e-03  eta: 0:23:19  time: 0.2128  data_time: 0.0182  memory: 5586  grad_norm: 0.9175  loss: 0.6697  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6697\n",
            "12/02 21:01:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][240/332]  lr: 1.0000e-03  eta: 0:23:14  time: 0.2394  data_time: 0.0286  memory: 5586  grad_norm: 1.2478  loss: 0.7058  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7058\n",
            "12/02 21:01:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][260/332]  lr: 1.0000e-03  eta: 0:23:09  time: 0.2947  data_time: 0.0722  memory: 5586  grad_norm: 1.5908  loss: 0.6884  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6884\n",
            "12/02 21:01:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][280/332]  lr: 1.0000e-03  eta: 0:23:04  time: 0.2194  data_time: 0.0233  memory: 5586  grad_norm: 0.9039  loss: 0.6942  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6942\n",
            "12/02 21:02:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][300/332]  lr: 1.0000e-03  eta: 0:22:59  time: 0.2080  data_time: 0.0150  memory: 5586  grad_norm: 0.8181  loss: 0.6974  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6974\n",
            "12/02 21:02:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][320/332]  lr: 1.0000e-03  eta: 0:22:54  time: 0.2340  data_time: 0.0271  memory: 5586  grad_norm: 1.0380  loss: 0.6783  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6783\n",
            "12/02 21:02:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:02:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][332/332]  lr: 1.0000e-03  eta: 0:22:51  time: 0.2603  data_time: 0.0465  memory: 5586  grad_norm: 0.7579  loss: 0.6667  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6667\n",
            "12/02 21:02:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 33 epochs\n",
            "12/02 21:02:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [33][20/42]    eta: 0:00:04  time: 0.1929  data_time: 0.0947  memory: 1141  \n",
            "12/02 21:02:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [33][40/42]    eta: 0:00:00  time: 0.1467  data_time: 0.0604  memory: 1141  \n",
            "12/02 21:02:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [33][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5027  data_time: 0.0724  time: 0.1617\n",
            "12/02 21:02:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][ 20/332]  lr: 1.0000e-03  eta: 0:22:46  time: 0.2238  data_time: 0.0313  memory: 5586  grad_norm: 1.1221  loss: 0.7064  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7064\n",
            "12/02 21:02:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][ 40/332]  lr: 1.0000e-03  eta: 0:22:41  time: 0.2458  data_time: 0.0347  memory: 5586  grad_norm: 1.3532  loss: 0.7007  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7007\n",
            "12/02 21:02:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:02:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][ 60/332]  lr: 1.0000e-03  eta: 0:22:37  time: 0.2841  data_time: 0.0603  memory: 5586  grad_norm: 1.1323  loss: 0.6879  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6879\n",
            "12/02 21:02:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][ 80/332]  lr: 1.0000e-03  eta: 0:22:32  time: 0.2150  data_time: 0.0187  memory: 5586  grad_norm: 0.6523  loss: 0.6717  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6717\n",
            "12/02 21:02:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][100/332]  lr: 1.0000e-03  eta: 0:22:27  time: 0.2108  data_time: 0.0169  memory: 5586  grad_norm: 0.7480  loss: 0.6781  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6781\n",
            "12/02 21:02:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][120/332]  lr: 1.0000e-03  eta: 0:22:22  time: 0.2417  data_time: 0.0320  memory: 5586  grad_norm: 1.0549  loss: 0.7137  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7137\n",
            "12/02 21:02:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][140/332]  lr: 1.0000e-03  eta: 0:22:17  time: 0.2811  data_time: 0.0547  memory: 5586  grad_norm: 1.0022  loss: 0.6866  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6866\n",
            "12/02 21:02:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][160/332]  lr: 1.0000e-03  eta: 0:22:12  time: 0.2261  data_time: 0.0292  memory: 5586  grad_norm: 0.8429  loss: 0.6773  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6773\n",
            "12/02 21:03:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][180/332]  lr: 1.0000e-03  eta: 0:22:07  time: 0.2130  data_time: 0.0183  memory: 5586  grad_norm: 0.8424  loss: 0.6872  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6872\n",
            "12/02 21:03:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][200/332]  lr: 1.0000e-03  eta: 0:22:02  time: 0.2422  data_time: 0.0285  memory: 5586  grad_norm: 0.9601  loss: 0.6801  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6801\n",
            "12/02 21:03:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][220/332]  lr: 1.0000e-03  eta: 0:21:58  time: 0.3012  data_time: 0.0777  memory: 5586  grad_norm: 1.1294  loss: 0.7031  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7031\n",
            "12/02 21:03:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][240/332]  lr: 1.0000e-03  eta: 0:21:53  time: 0.2184  data_time: 0.0219  memory: 5586  grad_norm: 1.2532  loss: 0.7187  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7187\n",
            "12/02 21:03:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][260/332]  lr: 1.0000e-03  eta: 0:21:48  time: 0.2096  data_time: 0.0173  memory: 5586  grad_norm: 0.9258  loss: 0.6751  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6751\n",
            "12/02 21:03:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][280/332]  lr: 1.0000e-03  eta: 0:21:43  time: 0.2332  data_time: 0.0262  memory: 5586  grad_norm: 0.8657  loss: 0.6873  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6873\n",
            "12/02 21:03:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][300/332]  lr: 1.0000e-03  eta: 0:21:38  time: 0.2945  data_time: 0.0750  memory: 5586  grad_norm: 1.4387  loss: 0.6961  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6961\n",
            "12/02 21:03:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][320/332]  lr: 1.0000e-03  eta: 0:21:33  time: 0.2271  data_time: 0.0285  memory: 5586  grad_norm: 0.6988  loss: 0.6605  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6605\n",
            "12/02 21:03:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:03:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][332/332]  lr: 1.0000e-03  eta: 0:21:30  time: 0.2058  data_time: 0.0173  memory: 5586  grad_norm: 0.7327  loss: 0.6756  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6756\n",
            "12/02 21:03:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 34 epochs\n",
            "12/02 21:03:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [34][20/42]    eta: 0:00:03  time: 0.1429  data_time: 0.0520  memory: 1141  \n",
            "12/02 21:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [34][40/42]    eta: 0:00:00  time: 0.2226  data_time: 0.1212  memory: 1141  \n",
            "12/02 21:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [34][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0834  time: 0.1763\n",
            "12/02 21:03:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][ 20/332]  lr: 1.0000e-03  eta: 0:21:26  time: 0.2894  data_time: 0.0717  memory: 5586  grad_norm: 0.7559  loss: 0.6795  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6795\n",
            "12/02 21:03:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][ 40/332]  lr: 1.0000e-03  eta: 0:21:21  time: 0.2108  data_time: 0.0175  memory: 5586  grad_norm: 1.0078  loss: 0.6774  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6774\n",
            "12/02 21:03:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][ 60/332]  lr: 1.0000e-03  eta: 0:21:15  time: 0.2090  data_time: 0.0155  memory: 5586  grad_norm: 0.7302  loss: 0.6781  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6781\n",
            "12/02 21:04:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][ 80/332]  lr: 1.0000e-03  eta: 0:21:11  time: 0.2778  data_time: 0.0483  memory: 5586  grad_norm: 0.7150  loss: 0.6705  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6705\n",
            "12/02 21:04:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][100/332]  lr: 1.0000e-03  eta: 0:21:06  time: 0.2688  data_time: 0.0541  memory: 5586  grad_norm: 0.7658  loss: 0.6889  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6889\n",
            "12/02 21:04:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][120/332]  lr: 1.0000e-03  eta: 0:21:01  time: 0.2127  data_time: 0.0181  memory: 5586  grad_norm: 0.7527  loss: 0.6684  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6684\n",
            "12/02 21:04:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][140/332]  lr: 1.0000e-03  eta: 0:20:56  time: 0.2142  data_time: 0.0185  memory: 5586  grad_norm: 2.1657  loss: 0.6977  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6977\n",
            "12/02 21:04:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][160/332]  lr: 1.0000e-03  eta: 0:20:51  time: 0.2849  data_time: 0.0625  memory: 5586  grad_norm: 1.6635  loss: 0.7030  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7030\n",
            "12/02 21:04:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][180/332]  lr: 1.0000e-03  eta: 0:20:47  time: 0.2601  data_time: 0.0459  memory: 5586  grad_norm: 2.2263  loss: 0.6920  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6920\n",
            "12/02 21:04:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][200/332]  lr: 1.0000e-03  eta: 0:20:42  time: 0.2131  data_time: 0.0182  memory: 5586  grad_norm: 1.3208  loss: 0.6678  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6678\n",
            "12/02 21:04:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][220/332]  lr: 1.0000e-03  eta: 0:20:36  time: 0.2110  data_time: 0.0171  memory: 5586  grad_norm: 1.2859  loss: 0.7134  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7134\n",
            "12/02 21:04:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][240/332]  lr: 1.0000e-03  eta: 0:20:32  time: 0.2843  data_time: 0.0627  memory: 5586  grad_norm: 1.8563  loss: 0.6666  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6666\n",
            "12/02 21:04:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][260/332]  lr: 1.0000e-03  eta: 0:20:27  time: 0.2537  data_time: 0.0423  memory: 5586  grad_norm: 1.6787  loss: 0.7081  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7081\n",
            "12/02 21:04:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][280/332]  lr: 1.0000e-03  eta: 0:20:22  time: 0.2135  data_time: 0.0182  memory: 5586  grad_norm: 1.2496  loss: 0.6831  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6831\n",
            "12/02 21:04:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][300/332]  lr: 1.0000e-03  eta: 0:20:17  time: 0.2132  data_time: 0.0172  memory: 5586  grad_norm: 1.6025  loss: 0.6851  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6851\n",
            "12/02 21:05:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][320/332]  lr: 1.0000e-03  eta: 0:20:12  time: 0.2678  data_time: 0.0479  memory: 5586  grad_norm: 1.5691  loss: 0.6641  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6641\n",
            "12/02 21:05:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:05:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][332/332]  lr: 1.0000e-03  eta: 0:20:10  time: 0.2757  data_time: 0.0654  memory: 5586  grad_norm: 1.6484  loss: 0.7245  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7245\n",
            "12/02 21:05:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 35 epochs\n",
            "12/02 21:05:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][20/42]    eta: 0:00:03  time: 0.1439  data_time: 0.0507  memory: 1141  \n",
            "12/02 21:05:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][40/42]    eta: 0:00:00  time: 0.1366  data_time: 0.0454  memory: 1141  \n",
            "12/02 21:05:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][42/42]    acc/top1: 0.5589  acc/top5: 1.0000  acc/mean1: 0.5034  data_time: 0.0462  time: 0.1353\n",
            "12/02 21:05:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][ 20/332]  lr: 1.0000e-03  eta: 0:20:05  time: 0.2304  data_time: 0.0348  memory: 5586  grad_norm: 1.6938  loss: 0.7018  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7018\n",
            "12/02 21:05:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][ 40/332]  lr: 1.0000e-03  eta: 0:20:00  time: 0.2788  data_time: 0.0562  memory: 5586  grad_norm: 1.0357  loss: 0.6869  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6869\n",
            "12/02 21:05:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][ 60/332]  lr: 1.0000e-03  eta: 0:19:55  time: 0.2561  data_time: 0.0486  memory: 5586  grad_norm: 1.5413  loss: 0.6748  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6748\n",
            "12/02 21:05:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][ 80/332]  lr: 1.0000e-03  eta: 0:19:50  time: 0.2114  data_time: 0.0176  memory: 5586  grad_norm: 1.2196  loss: 0.6923  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6923\n",
            "12/02 21:05:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][100/332]  lr: 1.0000e-03  eta: 0:19:45  time: 0.2156  data_time: 0.0193  memory: 5586  grad_norm: 1.1849  loss: 0.6861  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6861\n",
            "12/02 21:05:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][120/332]  lr: 1.0000e-03  eta: 0:19:41  time: 0.2818  data_time: 0.0572  memory: 5586  grad_norm: 1.3187  loss: 0.7010  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7010\n",
            "12/02 21:05:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][140/332]  lr: 1.0000e-03  eta: 0:19:36  time: 0.2491  data_time: 0.0408  memory: 5586  grad_norm: 1.1419  loss: 0.7004  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7004\n",
            "12/02 21:05:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][160/332]  lr: 1.0000e-03  eta: 0:19:31  time: 0.2102  data_time: 0.0172  memory: 5586  grad_norm: 0.8902  loss: 0.7004  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7004\n",
            "12/02 21:05:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][180/332]  lr: 1.0000e-03  eta: 0:19:26  time: 0.2197  data_time: 0.0201  memory: 5586  grad_norm: 1.0279  loss: 0.6641  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6641\n",
            "12/02 21:06:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][200/332]  lr: 1.0000e-03  eta: 0:19:21  time: 0.2808  data_time: 0.0631  memory: 5586  grad_norm: 1.2003  loss: 0.6940  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6940\n",
            "12/02 21:06:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][220/332]  lr: 1.0000e-03  eta: 0:19:16  time: 0.2563  data_time: 0.0472  memory: 5586  grad_norm: 2.1204  loss: 0.6818  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6818\n",
            "12/02 21:06:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][240/332]  lr: 1.0000e-03  eta: 0:19:11  time: 0.2144  data_time: 0.0192  memory: 5586  grad_norm: 0.9839  loss: 0.6912  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6912\n",
            "12/02 21:06:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][260/332]  lr: 1.0000e-03  eta: 0:19:06  time: 0.2173  data_time: 0.0182  memory: 5586  grad_norm: 3.9105  loss: 0.6806  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6806\n",
            "12/02 21:06:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][280/332]  lr: 1.0000e-03  eta: 0:19:02  time: 0.2837  data_time: 0.0555  memory: 5586  grad_norm: 1.3502  loss: 0.6951  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6951\n",
            "12/02 21:06:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][300/332]  lr: 1.0000e-03  eta: 0:18:57  time: 0.2517  data_time: 0.0421  memory: 5586  grad_norm: 1.3577  loss: 0.6807  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6807\n",
            "12/02 21:06:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][320/332]  lr: 1.0000e-03  eta: 0:18:52  time: 0.2123  data_time: 0.0212  memory: 5586  grad_norm: 1.3568  loss: 0.6983  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6983\n",
            "12/02 21:06:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:06:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][332/332]  lr: 1.0000e-03  eta: 0:18:49  time: 0.2035  data_time: 0.0169  memory: 5586  grad_norm: 1.2442  loss: 0.6766  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6766\n",
            "12/02 21:06:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 36 epochs\n",
            "12/02 21:06:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [36][20/42]    eta: 0:00:04  time: 0.2131  data_time: 0.1112  memory: 1141  \n",
            "12/02 21:06:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [36][40/42]    eta: 0:00:00  time: 0.2236  data_time: 0.1252  memory: 1141  \n",
            "12/02 21:06:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [36][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5007  data_time: 0.1114  time: 0.2080\n",
            "12/02 21:06:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][ 20/332]  lr: 1.0000e-03  eta: 0:18:44  time: 0.2455  data_time: 0.0458  memory: 5586  grad_norm: 1.5753  loss: 0.6686  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6686\n",
            "12/02 21:06:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][ 40/332]  lr: 1.0000e-03  eta: 0:18:39  time: 0.2101  data_time: 0.0176  memory: 5586  grad_norm: 2.1009  loss: 0.6757  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6757\n",
            "12/02 21:06:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:06:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][ 60/332]  lr: 1.0000e-03  eta: 0:18:34  time: 0.2326  data_time: 0.0243  memory: 5586  grad_norm: 1.4107  loss: 0.6757  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6757\n",
            "12/02 21:07:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][ 80/332]  lr: 1.0000e-03  eta: 0:18:29  time: 0.2814  data_time: 0.0577  memory: 5586  grad_norm: 1.7419  loss: 0.7389  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7389\n",
            "12/02 21:07:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][100/332]  lr: 1.0000e-03  eta: 0:18:24  time: 0.2380  data_time: 0.0375  memory: 5586  grad_norm: 1.2862  loss: 0.7054  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7054\n",
            "12/02 21:07:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][120/332]  lr: 1.0000e-03  eta: 0:18:19  time: 0.2136  data_time: 0.0189  memory: 5586  grad_norm: 1.2245  loss: 0.6965  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6965\n",
            "12/02 21:07:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][140/332]  lr: 1.0000e-03  eta: 0:18:14  time: 0.2389  data_time: 0.0278  memory: 5586  grad_norm: 1.1015  loss: 0.6911  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6911\n",
            "12/02 21:07:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][160/332]  lr: 1.0000e-03  eta: 0:18:10  time: 0.2938  data_time: 0.0694  memory: 5586  grad_norm: 0.8965  loss: 0.6785  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6785\n",
            "12/02 21:07:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][180/332]  lr: 1.0000e-03  eta: 0:18:05  time: 0.2223  data_time: 0.0250  memory: 5586  grad_norm: 0.9839  loss: 0.6820  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6820\n",
            "12/02 21:07:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][200/332]  lr: 1.0000e-03  eta: 0:18:00  time: 0.2116  data_time: 0.0182  memory: 5586  grad_norm: 1.3067  loss: 0.6963  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6963\n",
            "12/02 21:07:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][220/332]  lr: 1.0000e-03  eta: 0:17:55  time: 0.2378  data_time: 0.0294  memory: 5586  grad_norm: 1.0211  loss: 0.6886  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6886\n",
            "12/02 21:07:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][240/332]  lr: 1.0000e-03  eta: 0:17:50  time: 0.2895  data_time: 0.0672  memory: 5586  grad_norm: 0.8248  loss: 0.6947  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6947\n",
            "12/02 21:07:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][260/332]  lr: 1.0000e-03  eta: 0:17:45  time: 0.2292  data_time: 0.0306  memory: 5586  grad_norm: 1.0295  loss: 0.6837  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6837\n",
            "12/02 21:07:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][280/332]  lr: 1.0000e-03  eta: 0:17:40  time: 0.2130  data_time: 0.0191  memory: 5586  grad_norm: 1.1008  loss: 0.6686  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6686\n",
            "12/02 21:07:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][300/332]  lr: 1.0000e-03  eta: 0:17:35  time: 0.2380  data_time: 0.0299  memory: 5586  grad_norm: 2.0212  loss: 0.6964  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6964\n",
            "12/02 21:08:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][320/332]  lr: 1.0000e-03  eta: 0:17:31  time: 0.3045  data_time: 0.0798  memory: 5586  grad_norm: 1.7651  loss: 0.6648  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6648\n",
            "12/02 21:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][332/332]  lr: 1.0000e-03  eta: 0:17:28  time: 0.2788  data_time: 0.0638  memory: 5586  grad_norm: 2.3382  loss: 0.6722  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6722\n",
            "12/02 21:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 37 epochs\n",
            "12/02 21:08:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [37][20/42]    eta: 0:00:03  time: 0.1473  data_time: 0.0539  memory: 1141  \n",
            "12/02 21:08:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [37][40/42]    eta: 0:00:00  time: 0.1467  data_time: 0.0557  memory: 1141  \n",
            "12/02 21:08:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [37][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0518  time: 0.1410\n",
            "12/02 21:08:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][ 20/332]  lr: 1.0000e-03  eta: 0:17:23  time: 0.2736  data_time: 0.0607  memory: 5586  grad_norm: 2.1946  loss: 0.7073  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7073\n",
            "12/02 21:08:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][ 40/332]  lr: 1.0000e-03  eta: 0:17:19  time: 0.3005  data_time: 0.0755  memory: 5586  grad_norm: 2.0262  loss: 0.7007  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7007\n",
            "12/02 21:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][ 60/332]  lr: 1.0000e-03  eta: 0:17:14  time: 0.2330  data_time: 0.0312  memory: 5586  grad_norm: 1.0423  loss: 0.6796  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6796\n",
            "12/02 21:08:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][ 80/332]  lr: 1.0000e-03  eta: 0:17:09  time: 0.2166  data_time: 0.0189  memory: 5586  grad_norm: 1.0577  loss: 0.6795  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6795\n",
            "12/02 21:08:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][100/332]  lr: 1.0000e-03  eta: 0:17:04  time: 0.2382  data_time: 0.0288  memory: 5586  grad_norm: 1.0763  loss: 0.6788  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6788\n",
            "12/02 21:08:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][120/332]  lr: 1.0000e-03  eta: 0:17:00  time: 0.2933  data_time: 0.0691  memory: 5586  grad_norm: 0.9293  loss: 0.6630  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6630\n",
            "12/02 21:08:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][140/332]  lr: 1.0000e-03  eta: 0:16:55  time: 0.2184  data_time: 0.0220  memory: 5586  grad_norm: 1.0424  loss: 0.6759  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6759\n",
            "12/02 21:08:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][160/332]  lr: 1.0000e-03  eta: 0:16:49  time: 0.2120  data_time: 0.0171  memory: 5586  grad_norm: 0.8792  loss: 0.7015  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7015\n",
            "12/02 21:08:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][180/332]  lr: 1.0000e-03  eta: 0:16:45  time: 0.2431  data_time: 0.0324  memory: 5586  grad_norm: 0.8957  loss: 0.6965  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6965\n",
            "12/02 21:09:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][200/332]  lr: 1.0000e-03  eta: 0:16:40  time: 0.2880  data_time: 0.0618  memory: 5586  grad_norm: 0.8190  loss: 0.6852  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6852\n",
            "12/02 21:09:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][220/332]  lr: 1.0000e-03  eta: 0:16:35  time: 0.2271  data_time: 0.0285  memory: 5586  grad_norm: 1.0274  loss: 0.7054  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7054\n",
            "12/02 21:09:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][240/332]  lr: 1.0000e-03  eta: 0:16:30  time: 0.2109  data_time: 0.0173  memory: 5586  grad_norm: 0.9439  loss: 0.6920  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6920\n",
            "12/02 21:09:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][260/332]  lr: 1.0000e-03  eta: 0:16:25  time: 0.2411  data_time: 0.0310  memory: 5586  grad_norm: 1.0694  loss: 0.6966  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6966\n",
            "12/02 21:09:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][280/332]  lr: 1.0000e-03  eta: 0:16:21  time: 0.2989  data_time: 0.0772  memory: 5586  grad_norm: 0.7745  loss: 0.6850  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6850\n",
            "12/02 21:09:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][300/332]  lr: 1.0000e-03  eta: 0:16:16  time: 0.2241  data_time: 0.0267  memory: 5586  grad_norm: 0.7101  loss: 0.6817  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6817\n",
            "12/02 21:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][320/332]  lr: 1.0000e-03  eta: 0:16:11  time: 0.2120  data_time: 0.0167  memory: 5586  grad_norm: 0.6732  loss: 0.6864  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6864\n",
            "12/02 21:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][332/332]  lr: 1.0000e-03  eta: 0:16:08  time: 0.2044  data_time: 0.0151  memory: 5586  grad_norm: 0.5981  loss: 0.6816  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6816\n",
            "12/02 21:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 38 epochs\n",
            "12/02 21:09:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [38][20/42]    eta: 0:00:04  time: 0.2203  data_time: 0.1224  memory: 1141  \n",
            "12/02 21:09:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [38][40/42]    eta: 0:00:00  time: 0.2188  data_time: 0.1205  memory: 1141  \n",
            "12/02 21:09:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [38][42/42]    acc/top1: 0.5619  acc/top5: 1.0000  acc/mean1: 0.5075  data_time: 0.1137  time: 0.2083\n",
            "12/02 21:09:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][ 20/332]  lr: 1.0000e-03  eta: 0:16:03  time: 0.2261  data_time: 0.0325  memory: 5586  grad_norm: 0.8786  loss: 0.6969  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6969\n",
            "12/02 21:09:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][ 40/332]  lr: 1.0000e-03  eta: 0:15:58  time: 0.2102  data_time: 0.0158  memory: 5586  grad_norm: 0.7532  loss: 0.7036  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7036\n",
            "12/02 21:09:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][ 60/332]  lr: 1.0000e-03  eta: 0:15:53  time: 0.2680  data_time: 0.0507  memory: 5586  grad_norm: 0.8666  loss: 0.6869  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6869\n",
            "12/02 21:10:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][ 80/332]  lr: 1.0000e-03  eta: 0:15:48  time: 0.2752  data_time: 0.0543  memory: 5586  grad_norm: 0.7798  loss: 0.6957  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6957\n",
            "12/02 21:10:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][100/332]  lr: 1.0000e-03  eta: 0:15:43  time: 0.2121  data_time: 0.0177  memory: 5586  grad_norm: 0.7865  loss: 0.6882  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6882\n",
            "12/02 21:10:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][120/332]  lr: 1.0000e-03  eta: 0:15:38  time: 0.2126  data_time: 0.0182  memory: 5586  grad_norm: 0.6676  loss: 0.6884  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6884\n",
            "12/02 21:10:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][140/332]  lr: 1.0000e-03  eta: 0:15:33  time: 0.2561  data_time: 0.0398  memory: 5586  grad_norm: 0.7848  loss: 0.6772  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6772\n",
            "12/02 21:10:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][160/332]  lr: 1.0000e-03  eta: 0:15:29  time: 0.2824  data_time: 0.0616  memory: 5586  grad_norm: 0.6530  loss: 0.6620  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6620\n",
            "12/02 21:10:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][180/332]  lr: 1.0000e-03  eta: 0:15:24  time: 0.2123  data_time: 0.0182  memory: 5586  grad_norm: 0.7961  loss: 0.6742  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6742\n",
            "12/02 21:10:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][200/332]  lr: 1.0000e-03  eta: 0:15:19  time: 0.2107  data_time: 0.0166  memory: 5586  grad_norm: 1.0770  loss: 0.6806  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6806\n",
            "12/02 21:10:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][220/332]  lr: 1.0000e-03  eta: 0:15:14  time: 0.2645  data_time: 0.0467  memory: 5586  grad_norm: 0.7008  loss: 0.6855  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6855\n",
            "12/02 21:10:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][240/332]  lr: 1.0000e-03  eta: 0:15:09  time: 0.2843  data_time: 0.0625  memory: 5586  grad_norm: 0.7007  loss: 0.6701  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6701\n",
            "12/02 21:10:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][260/332]  lr: 1.0000e-03  eta: 0:15:04  time: 0.2098  data_time: 0.0173  memory: 5586  grad_norm: 0.6108  loss: 0.6838  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6838\n",
            "12/02 21:10:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][280/332]  lr: 1.0000e-03  eta: 0:14:59  time: 0.2129  data_time: 0.0178  memory: 5586  grad_norm: 0.6600  loss: 0.6803  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6803\n",
            "12/02 21:10:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][300/332]  lr: 1.0000e-03  eta: 0:14:54  time: 0.2782  data_time: 0.0606  memory: 5586  grad_norm: 0.8598  loss: 0.6892  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6892\n",
            "12/02 21:10:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][320/332]  lr: 1.0000e-03  eta: 0:14:50  time: 0.2789  data_time: 0.0584  memory: 5586  grad_norm: 0.6837  loss: 0.6784  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6784\n",
            "12/02 21:11:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:11:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][332/332]  lr: 1.0000e-03  eta: 0:14:47  time: 0.2216  data_time: 0.0256  memory: 5586  grad_norm: 0.7804  loss: 0.6874  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6874\n",
            "12/02 21:11:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 39 epochs\n",
            "12/02 21:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [39][20/42]    eta: 0:00:03  time: 0.1476  data_time: 0.0531  memory: 1141  \n",
            "12/02 21:11:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [39][40/42]    eta: 0:00:00  time: 0.1379  data_time: 0.0461  memory: 1141  \n",
            "12/02 21:11:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [39][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0478  time: 0.1379\n",
            "12/02 21:11:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][ 20/332]  lr: 1.0000e-03  eta: 0:14:42  time: 0.3040  data_time: 0.0798  memory: 5586  grad_norm: 0.9478  loss: 0.6760  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6760\n",
            "12/02 21:11:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][ 40/332]  lr: 1.0000e-03  eta: 0:14:37  time: 0.2581  data_time: 0.0473  memory: 5586  grad_norm: 0.9149  loss: 0.6796  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6796\n",
            "12/02 21:11:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:11:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][ 60/332]  lr: 1.0000e-03  eta: 0:14:32  time: 0.2120  data_time: 0.0167  memory: 5586  grad_norm: 0.9689  loss: 0.7022  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7022\n",
            "12/02 21:11:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][ 80/332]  lr: 1.0000e-03  eta: 0:14:27  time: 0.2237  data_time: 0.0233  memory: 5586  grad_norm: 1.1774  loss: 0.6898  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6898\n",
            "12/02 21:11:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][100/332]  lr: 1.0000e-03  eta: 0:14:23  time: 0.2892  data_time: 0.0650  memory: 5586  grad_norm: 0.9548  loss: 0.7102  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7102\n",
            "12/02 21:11:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][120/332]  lr: 1.0000e-03  eta: 0:14:18  time: 0.2486  data_time: 0.0340  memory: 5586  grad_norm: 0.7090  loss: 0.6722  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6722\n",
            "12/02 21:11:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][140/332]  lr: 1.0000e-03  eta: 0:14:13  time: 0.2118  data_time: 0.0179  memory: 5586  grad_norm: 0.7708  loss: 0.6756  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6756\n",
            "12/02 21:11:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][160/332]  lr: 1.0000e-03  eta: 0:14:08  time: 0.2218  data_time: 0.0212  memory: 5586  grad_norm: 0.7216  loss: 0.6840  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6840\n",
            "12/02 21:11:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][180/332]  lr: 1.0000e-03  eta: 0:14:03  time: 0.2933  data_time: 0.0687  memory: 5586  grad_norm: 0.8505  loss: 0.7014  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7014\n",
            "12/02 21:11:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][200/332]  lr: 1.0000e-03  eta: 0:13:59  time: 0.2512  data_time: 0.0461  memory: 5586  grad_norm: 0.6375  loss: 0.6688  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6688\n",
            "12/02 21:12:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][220/332]  lr: 1.0000e-03  eta: 0:13:54  time: 0.2129  data_time: 0.0191  memory: 5586  grad_norm: 0.6227  loss: 0.6841  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6841\n",
            "12/02 21:12:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][240/332]  lr: 1.0000e-03  eta: 0:13:49  time: 0.2491  data_time: 0.0266  memory: 5586  grad_norm: 0.7405  loss: 0.6737  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6737\n",
            "12/02 21:12:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][260/332]  lr: 1.0000e-03  eta: 0:13:44  time: 0.2911  data_time: 0.0664  memory: 5586  grad_norm: 0.8125  loss: 0.6932  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6932\n",
            "12/02 21:12:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][280/332]  lr: 1.0000e-03  eta: 0:13:39  time: 0.2380  data_time: 0.0359  memory: 5586  grad_norm: 0.6344  loss: 0.6747  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6747\n",
            "12/02 21:12:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][300/332]  lr: 1.0000e-03  eta: 0:13:34  time: 0.2134  data_time: 0.0190  memory: 5586  grad_norm: 0.7123  loss: 0.7049  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7049\n",
            "12/02 21:12:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][320/332]  lr: 1.0000e-03  eta: 0:13:29  time: 0.2333  data_time: 0.0241  memory: 5586  grad_norm: 0.7062  loss: 0.6684  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6684\n",
            "12/02 21:12:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:12:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][332/332]  lr: 1.0000e-03  eta: 0:13:27  time: 0.2682  data_time: 0.0491  memory: 5586  grad_norm: 0.7460  loss: 0.6818  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6818\n",
            "12/02 21:12:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 40 epochs\n",
            "12/02 21:12:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][20/42]    eta: 0:00:04  time: 0.1946  data_time: 0.0966  memory: 1141  \n",
            "12/02 21:12:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][40/42]    eta: 0:00:00  time: 0.1415  data_time: 0.0535  memory: 1141  \n",
            "12/02 21:12:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0701  time: 0.1601\n",
            "12/02 21:12:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][ 20/332]  lr: 1.0000e-04  eta: 0:13:22  time: 0.2296  data_time: 0.0354  memory: 5586  grad_norm: 1.0568  loss: 0.7129  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7129\n",
            "12/02 21:12:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][ 40/332]  lr: 1.0000e-04  eta: 0:13:17  time: 0.2549  data_time: 0.0366  memory: 5586  grad_norm: 0.7114  loss: 0.6681  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6681\n",
            "12/02 21:12:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][ 60/332]  lr: 1.0000e-04  eta: 0:13:12  time: 0.2825  data_time: 0.0607  memory: 5586  grad_norm: 0.8705  loss: 0.6955  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6955\n",
            "12/02 21:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][ 80/332]  lr: 1.0000e-04  eta: 0:13:07  time: 0.2123  data_time: 0.0170  memory: 5586  grad_norm: 0.7863  loss: 0.6652  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6652\n",
            "12/02 21:13:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][100/332]  lr: 1.0000e-04  eta: 0:13:02  time: 0.2135  data_time: 0.0180  memory: 5586  grad_norm: 0.6130  loss: 0.6761  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6761\n",
            "12/02 21:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][120/332]  lr: 1.0000e-04  eta: 0:12:57  time: 0.2592  data_time: 0.0417  memory: 5586  grad_norm: 0.6771  loss: 0.6906  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6906\n",
            "12/02 21:13:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][140/332]  lr: 1.0000e-04  eta: 0:12:53  time: 0.2887  data_time: 0.0720  memory: 5586  grad_norm: 0.7253  loss: 0.6776  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6776\n",
            "12/02 21:13:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][160/332]  lr: 1.0000e-04  eta: 0:12:48  time: 0.2112  data_time: 0.0169  memory: 5586  grad_norm: 1.0184  loss: 0.6790  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6790\n",
            "12/02 21:13:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][180/332]  lr: 1.0000e-04  eta: 0:12:43  time: 0.2124  data_time: 0.0183  memory: 5586  grad_norm: 0.6883  loss: 0.6766  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6766\n",
            "12/02 21:13:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][200/332]  lr: 1.0000e-04  eta: 0:12:38  time: 0.2666  data_time: 0.0433  memory: 5586  grad_norm: 0.8056  loss: 0.6983  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6983\n",
            "12/02 21:13:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][220/332]  lr: 1.0000e-04  eta: 0:12:33  time: 0.2785  data_time: 0.0582  memory: 5586  grad_norm: 0.7444  loss: 0.6967  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6967\n",
            "12/02 21:13:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][240/332]  lr: 1.0000e-04  eta: 0:12:28  time: 0.2173  data_time: 0.0223  memory: 5586  grad_norm: 0.8610  loss: 0.7084  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7084\n",
            "12/02 21:13:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][260/332]  lr: 1.0000e-04  eta: 0:12:23  time: 0.2100  data_time: 0.0162  memory: 5586  grad_norm: 0.6408  loss: 0.6704  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6704\n",
            "12/02 21:13:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][280/332]  lr: 1.0000e-04  eta: 0:12:18  time: 0.2668  data_time: 0.0414  memory: 5586  grad_norm: 0.7300  loss: 0.6856  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6856\n",
            "12/02 21:13:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][300/332]  lr: 1.0000e-04  eta: 0:12:14  time: 0.2715  data_time: 0.0516  memory: 5586  grad_norm: 0.7116  loss: 0.6629  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6629\n",
            "12/02 21:13:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][320/332]  lr: 1.0000e-04  eta: 0:12:09  time: 0.2134  data_time: 0.0178  memory: 5586  grad_norm: 0.8749  loss: 0.7043  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7043\n",
            "12/02 21:13:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:13:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][332/332]  lr: 1.0000e-04  eta: 0:12:06  time: 0.2077  data_time: 0.0171  memory: 5586  grad_norm: 0.6970  loss: 0.6923  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6923\n",
            "12/02 21:13:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 41 epochs\n",
            "12/02 21:14:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [41][20/42]    eta: 0:00:04  time: 0.1993  data_time: 0.1015  memory: 1141  \n",
            "12/02 21:14:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [41][40/42]    eta: 0:00:00  time: 0.2235  data_time: 0.1226  memory: 1141  \n",
            "12/02 21:14:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [41][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.1075  time: 0.2034\n",
            "12/02 21:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][ 20/332]  lr: 1.0000e-04  eta: 0:12:01  time: 0.2572  data_time: 0.0534  memory: 5586  grad_norm: 0.6239  loss: 0.6599  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6599\n",
            "12/02 21:14:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][ 40/332]  lr: 1.0000e-04  eta: 0:11:56  time: 0.2107  data_time: 0.0171  memory: 5586  grad_norm: 0.7244  loss: 0.6704  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6704\n",
            "12/02 21:14:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][ 60/332]  lr: 1.0000e-04  eta: 0:11:51  time: 0.2270  data_time: 0.0229  memory: 5586  grad_norm: 0.7708  loss: 0.6898  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6898\n",
            "12/02 21:14:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][ 80/332]  lr: 1.0000e-04  eta: 0:11:46  time: 0.2860  data_time: 0.0562  memory: 5586  grad_norm: 0.6917  loss: 0.6899  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6899\n",
            "12/02 21:14:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][100/332]  lr: 1.0000e-04  eta: 0:11:41  time: 0.2379  data_time: 0.0355  memory: 5586  grad_norm: 0.7738  loss: 0.6793  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6793\n",
            "12/02 21:14:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][120/332]  lr: 1.0000e-04  eta: 0:11:36  time: 0.2138  data_time: 0.0216  memory: 5586  grad_norm: 0.6522  loss: 0.6815  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6815\n",
            "12/02 21:14:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][140/332]  lr: 1.0000e-04  eta: 0:11:32  time: 0.2303  data_time: 0.0234  memory: 5586  grad_norm: 0.6963  loss: 0.6726  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6726\n",
            "12/02 21:14:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][160/332]  lr: 1.0000e-04  eta: 0:11:27  time: 0.2926  data_time: 0.0653  memory: 5586  grad_norm: 0.7200  loss: 0.6664  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6664\n",
            "12/02 21:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][180/332]  lr: 1.0000e-04  eta: 0:11:22  time: 0.2323  data_time: 0.0276  memory: 5586  grad_norm: 0.7428  loss: 0.6826  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6826\n",
            "12/02 21:14:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][200/332]  lr: 1.0000e-04  eta: 0:11:17  time: 0.2167  data_time: 0.0207  memory: 5586  grad_norm: 0.7142  loss: 0.6745  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6745\n",
            "12/02 21:15:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][220/332]  lr: 1.0000e-04  eta: 0:11:12  time: 0.2339  data_time: 0.0254  memory: 5586  grad_norm: 0.6631  loss: 0.6668  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6668\n",
            "12/02 21:15:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][240/332]  lr: 1.0000e-04  eta: 0:11:07  time: 0.2951  data_time: 0.0720  memory: 5586  grad_norm: 0.8392  loss: 0.6987  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6987\n",
            "12/02 21:15:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][260/332]  lr: 1.0000e-04  eta: 0:11:03  time: 0.2354  data_time: 0.0322  memory: 5586  grad_norm: 0.8030  loss: 0.7112  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7112\n",
            "12/02 21:15:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][280/332]  lr: 1.0000e-04  eta: 0:10:58  time: 0.2145  data_time: 0.0196  memory: 5586  grad_norm: 0.7252  loss: 0.7230  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7230\n",
            "12/02 21:15:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][300/332]  lr: 1.0000e-04  eta: 0:10:53  time: 0.2373  data_time: 0.0274  memory: 5586  grad_norm: 0.7032  loss: 0.6669  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6669\n",
            "12/02 21:15:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][320/332]  lr: 1.0000e-04  eta: 0:10:48  time: 0.2985  data_time: 0.0709  memory: 5586  grad_norm: 0.6658  loss: 0.6694  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6694\n",
            "12/02 21:15:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:15:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][332/332]  lr: 1.0000e-04  eta: 0:10:45  time: 0.2545  data_time: 0.0490  memory: 5586  grad_norm: 0.7230  loss: 0.6848  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6848\n",
            "12/02 21:15:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 42 epochs\n",
            "12/02 21:15:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [42][20/42]    eta: 0:00:03  time: 0.1501  data_time: 0.0604  memory: 1141  \n",
            "12/02 21:15:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [42][40/42]    eta: 0:00:00  time: 0.1375  data_time: 0.0458  memory: 1141  \n",
            "12/02 21:15:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [42][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5014  data_time: 0.0502  time: 0.1380\n",
            "12/02 21:15:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][ 20/332]  lr: 1.0000e-04  eta: 0:10:40  time: 0.2784  data_time: 0.0667  memory: 5586  grad_norm: 0.6614  loss: 0.6760  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6760\n",
            "12/02 21:15:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][ 40/332]  lr: 1.0000e-04  eta: 0:10:36  time: 0.2868  data_time: 0.0721  memory: 5586  grad_norm: 0.7676  loss: 0.6843  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6843\n",
            "12/02 21:15:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:15:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][ 60/332]  lr: 1.0000e-04  eta: 0:10:31  time: 0.2143  data_time: 0.0204  memory: 5586  grad_norm: 0.7947  loss: 0.6878  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6878\n",
            "12/02 21:15:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][ 80/332]  lr: 1.0000e-04  eta: 0:10:26  time: 0.2119  data_time: 0.0179  memory: 5586  grad_norm: 0.7558  loss: 0.6848  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6848\n",
            "12/02 21:16:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][100/332]  lr: 1.0000e-04  eta: 0:10:21  time: 0.2576  data_time: 0.0420  memory: 5586  grad_norm: 0.8212  loss: 0.6791  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6791\n",
            "12/02 21:16:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][120/332]  lr: 1.0000e-04  eta: 0:10:16  time: 0.2915  data_time: 0.0762  memory: 5586  grad_norm: 1.1438  loss: 0.6751  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6751\n",
            "12/02 21:16:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][140/332]  lr: 1.0000e-04  eta: 0:10:11  time: 0.2144  data_time: 0.0186  memory: 5586  grad_norm: 1.4637  loss: 0.6688  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6688\n",
            "12/02 21:16:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][160/332]  lr: 1.0000e-04  eta: 0:10:06  time: 0.2101  data_time: 0.0164  memory: 5586  grad_norm: 0.7620  loss: 0.6817  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6817\n",
            "12/02 21:16:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][180/332]  lr: 1.0000e-04  eta: 0:10:01  time: 0.2647  data_time: 0.0395  memory: 5586  grad_norm: 0.6683  loss: 0.6766  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6766\n",
            "12/02 21:16:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][200/332]  lr: 1.0000e-04  eta: 0:09:57  time: 0.2835  data_time: 0.0640  memory: 5586  grad_norm: 0.6488  loss: 0.6662  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6662\n",
            "12/02 21:16:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][220/332]  lr: 1.0000e-04  eta: 0:09:52  time: 0.2150  data_time: 0.0193  memory: 5586  grad_norm: 0.7868  loss: 0.7082  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7082\n",
            "12/02 21:16:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][240/332]  lr: 1.0000e-04  eta: 0:09:47  time: 0.2094  data_time: 0.0163  memory: 5586  grad_norm: 0.7251  loss: 0.6793  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6793\n",
            "12/02 21:16:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][260/332]  lr: 1.0000e-04  eta: 0:09:42  time: 0.2689  data_time: 0.0495  memory: 5586  grad_norm: 0.9031  loss: 0.6941  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6941\n",
            "12/02 21:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][280/332]  lr: 1.0000e-04  eta: 0:09:37  time: 0.2750  data_time: 0.0551  memory: 5586  grad_norm: 0.6108  loss: 0.6932  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6932\n",
            "12/02 21:16:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][300/332]  lr: 1.0000e-04  eta: 0:09:32  time: 0.2171  data_time: 0.0220  memory: 5586  grad_norm: 0.8043  loss: 0.6999  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6999\n",
            "12/02 21:16:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][320/332]  lr: 1.0000e-04  eta: 0:09:27  time: 0.2129  data_time: 0.0190  memory: 5586  grad_norm: 0.8058  loss: 0.7088  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7088\n",
            "12/02 21:16:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:16:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][332/332]  lr: 1.0000e-04  eta: 0:09:24  time: 0.2290  data_time: 0.0255  memory: 5586  grad_norm: 0.8155  loss: 0.6689  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6689\n",
            "12/02 21:16:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 43 epochs\n",
            "12/02 21:17:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [43][20/42]    eta: 0:00:04  time: 0.2255  data_time: 0.1261  memory: 1141  \n",
            "12/02 21:17:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [43][40/42]    eta: 0:00:00  time: 0.1785  data_time: 0.0866  memory: 1141  \n",
            "12/02 21:17:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [43][42/42]    acc/top1: 0.5529  acc/top5: 1.0000  acc/mean1: 0.4973  data_time: 0.0995  time: 0.1919\n",
            "12/02 21:17:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][ 20/332]  lr: 1.0000e-04  eta: 0:09:20  time: 0.2252  data_time: 0.0322  memory: 5586  grad_norm: 0.7891  loss: 0.6581  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6581\n",
            "12/02 21:17:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][ 40/332]  lr: 1.0000e-04  eta: 0:09:15  time: 0.2198  data_time: 0.0211  memory: 5586  grad_norm: 0.8085  loss: 0.6814  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6814\n",
            "12/02 21:17:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][ 60/332]  lr: 1.0000e-04  eta: 0:09:10  time: 0.2901  data_time: 0.0630  memory: 5586  grad_norm: 0.8016  loss: 0.6923  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6923\n",
            "12/02 21:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][ 80/332]  lr: 1.0000e-04  eta: 0:09:05  time: 0.2499  data_time: 0.0411  memory: 5586  grad_norm: 0.6762  loss: 0.6964  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6964\n",
            "12/02 21:17:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][100/332]  lr: 1.0000e-04  eta: 0:09:00  time: 0.2106  data_time: 0.0176  memory: 5586  grad_norm: 0.7555  loss: 0.6876  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6876\n",
            "12/02 21:17:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][120/332]  lr: 1.0000e-04  eta: 0:08:55  time: 0.2175  data_time: 0.0192  memory: 5586  grad_norm: 0.8329  loss: 0.6671  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6671\n",
            "12/02 21:17:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][140/332]  lr: 1.0000e-04  eta: 0:08:50  time: 0.2852  data_time: 0.0601  memory: 5586  grad_norm: 0.7236  loss: 0.6893  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6893\n",
            "12/02 21:17:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][160/332]  lr: 1.0000e-04  eta: 0:08:46  time: 0.2541  data_time: 0.0433  memory: 5586  grad_norm: 0.7208  loss: 0.7012  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7012\n",
            "12/02 21:17:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][180/332]  lr: 1.0000e-04  eta: 0:08:41  time: 0.2113  data_time: 0.0179  memory: 5586  grad_norm: 0.6375  loss: 0.6749  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6749\n",
            "12/02 21:17:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][200/332]  lr: 1.0000e-04  eta: 0:08:36  time: 0.2251  data_time: 0.0262  memory: 5586  grad_norm: 0.8830  loss: 0.6630  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6630\n",
            "12/02 21:18:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][220/332]  lr: 1.0000e-04  eta: 0:08:31  time: 0.2748  data_time: 0.0556  memory: 5586  grad_norm: 0.7634  loss: 0.6732  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6732\n",
            "12/02 21:18:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][240/332]  lr: 1.0000e-04  eta: 0:08:26  time: 0.2596  data_time: 0.0503  memory: 5586  grad_norm: 0.8164  loss: 0.6951  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6951\n",
            "12/02 21:18:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][260/332]  lr: 1.0000e-04  eta: 0:08:21  time: 0.2120  data_time: 0.0176  memory: 5586  grad_norm: 0.8154  loss: 0.6971  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6971\n",
            "12/02 21:18:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][280/332]  lr: 1.0000e-04  eta: 0:08:16  time: 0.2206  data_time: 0.0211  memory: 5586  grad_norm: 0.7471  loss: 0.6872  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6872\n",
            "12/02 21:18:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][300/332]  lr: 1.0000e-04  eta: 0:08:12  time: 0.2910  data_time: 0.0633  memory: 5586  grad_norm: 0.7011  loss: 0.6734  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6734\n",
            "12/02 21:18:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][320/332]  lr: 1.0000e-04  eta: 0:08:07  time: 0.2481  data_time: 0.0402  memory: 5586  grad_norm: 0.6644  loss: 0.6715  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6715\n",
            "12/02 21:18:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:18:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][332/332]  lr: 1.0000e-04  eta: 0:08:04  time: 0.2070  data_time: 0.0177  memory: 5586  grad_norm: 0.7283  loss: 0.7044  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.7044\n",
            "12/02 21:18:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 44 epochs\n",
            "12/02 21:18:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [44][20/42]    eta: 0:00:03  time: 0.1417  data_time: 0.0503  memory: 1141  \n",
            "12/02 21:18:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [44][40/42]    eta: 0:00:00  time: 0.1942  data_time: 0.0954  memory: 1141  \n",
            "12/02 21:18:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [44][42/42]    acc/top1: 0.5589  acc/top5: 1.0000  acc/mean1: 0.5041  data_time: 0.0683  time: 0.1603\n",
            "12/02 21:18:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][ 20/332]  lr: 1.0000e-04  eta: 0:07:59  time: 0.3035  data_time: 0.0810  memory: 5586  grad_norm: 0.6731  loss: 0.7001  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7001\n",
            "12/02 21:18:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][ 40/332]  lr: 1.0000e-04  eta: 0:07:54  time: 0.2229  data_time: 0.0256  memory: 5586  grad_norm: 0.9211  loss: 0.6801  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6801\n",
            "12/02 21:18:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][ 60/332]  lr: 1.0000e-04  eta: 0:07:49  time: 0.2111  data_time: 0.0188  memory: 5586  grad_norm: 0.7637  loss: 0.6933  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6933\n",
            "12/02 21:18:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][ 80/332]  lr: 1.0000e-04  eta: 0:07:44  time: 0.2521  data_time: 0.0418  memory: 5586  grad_norm: 0.6198  loss: 0.6677  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6677\n",
            "12/02 21:19:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][100/332]  lr: 1.0000e-04  eta: 0:07:40  time: 0.2967  data_time: 0.0665  memory: 5586  grad_norm: 0.7342  loss: 0.6854  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6854\n",
            "12/02 21:19:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][120/332]  lr: 1.0000e-04  eta: 0:07:35  time: 0.2162  data_time: 0.0224  memory: 5586  grad_norm: 1.2890  loss: 0.6713  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6713\n",
            "12/02 21:19:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][140/332]  lr: 1.0000e-04  eta: 0:07:30  time: 0.2150  data_time: 0.0203  memory: 5586  grad_norm: 0.6708  loss: 0.6846  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6846\n",
            "12/02 21:19:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][160/332]  lr: 1.0000e-04  eta: 0:07:25  time: 0.2480  data_time: 0.0316  memory: 5586  grad_norm: 0.6252  loss: 0.6847  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6847\n",
            "12/02 21:19:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][180/332]  lr: 1.0000e-04  eta: 0:07:20  time: 0.3016  data_time: 0.0828  memory: 5586  grad_norm: 0.7567  loss: 0.6784  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6784\n",
            "12/02 21:19:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][200/332]  lr: 1.0000e-04  eta: 0:07:15  time: 0.2173  data_time: 0.0221  memory: 5586  grad_norm: 0.7754  loss: 0.6766  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6766\n",
            "12/02 21:19:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][220/332]  lr: 1.0000e-04  eta: 0:07:10  time: 0.2129  data_time: 0.0185  memory: 5586  grad_norm: 0.8120  loss: 0.6810  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6810\n",
            "12/02 21:19:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][240/332]  lr: 1.0000e-04  eta: 0:07:05  time: 0.2553  data_time: 0.0410  memory: 5586  grad_norm: 0.7769  loss: 0.6849  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6849\n",
            "12/02 21:19:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][260/332]  lr: 1.0000e-04  eta: 0:07:01  time: 0.2910  data_time: 0.0682  memory: 5586  grad_norm: 0.7616  loss: 0.6714  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6714\n",
            "12/02 21:19:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][280/332]  lr: 1.0000e-04  eta: 0:06:56  time: 0.2146  data_time: 0.0186  memory: 5586  grad_norm: 1.3140  loss: 0.7155  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7155\n",
            "12/02 21:19:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][300/332]  lr: 1.0000e-04  eta: 0:06:51  time: 0.2160  data_time: 0.0224  memory: 5586  grad_norm: 0.6268  loss: 0.6832  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6832\n",
            "12/02 21:19:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][320/332]  lr: 1.0000e-04  eta: 0:06:46  time: 0.2527  data_time: 0.0350  memory: 5586  grad_norm: 0.6735  loss: 0.6727  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6727\n",
            "12/02 21:19:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:19:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][332/332]  lr: 1.0000e-04  eta: 0:06:43  time: 0.2756  data_time: 0.0603  memory: 5586  grad_norm: 0.7790  loss: 0.6941  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6941\n",
            "12/02 21:19:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 45 epochs\n",
            "12/02 21:20:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [45][20/42]    eta: 0:00:03  time: 0.1659  data_time: 0.0719  memory: 1141  \n",
            "12/02 21:20:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [45][40/42]    eta: 0:00:00  time: 0.1381  data_time: 0.0474  memory: 1141  \n",
            "12/02 21:20:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [45][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5007  data_time: 0.0570  time: 0.1464\n",
            "12/02 21:20:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][ 20/332]  lr: 1.0000e-04  eta: 0:06:38  time: 0.2253  data_time: 0.0315  memory: 5586  grad_norm: 1.4562  loss: 0.6757  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6757\n",
            "12/02 21:20:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][ 40/332]  lr: 1.0000e-04  eta: 0:06:33  time: 0.2654  data_time: 0.0417  memory: 5586  grad_norm: 0.6844  loss: 0.6668  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6668\n",
            "12/02 21:20:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:20:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][ 60/332]  lr: 1.0000e-04  eta: 0:06:29  time: 0.2708  data_time: 0.0544  memory: 5586  grad_norm: 0.8235  loss: 0.7008  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7008\n",
            "12/02 21:20:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][ 80/332]  lr: 1.0000e-04  eta: 0:06:24  time: 0.2109  data_time: 0.0163  memory: 5586  grad_norm: 1.2864  loss: 0.6876  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6876\n",
            "12/02 21:20:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][100/332]  lr: 1.0000e-04  eta: 0:06:19  time: 0.2106  data_time: 0.0167  memory: 5586  grad_norm: 0.8745  loss: 0.7026  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7026\n",
            "12/02 21:20:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][120/332]  lr: 1.0000e-04  eta: 0:06:14  time: 0.2738  data_time: 0.0545  memory: 5586  grad_norm: 0.7550  loss: 0.6791  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6791\n",
            "12/02 21:20:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][140/332]  lr: 1.0000e-04  eta: 0:06:09  time: 0.2728  data_time: 0.0536  memory: 5586  grad_norm: 0.7313  loss: 0.7101  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7101\n",
            "12/02 21:20:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][160/332]  lr: 1.0000e-04  eta: 0:06:04  time: 0.2098  data_time: 0.0178  memory: 5586  grad_norm: 0.7918  loss: 0.6808  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6808\n",
            "12/02 21:20:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][180/332]  lr: 1.0000e-04  eta: 0:05:59  time: 0.2127  data_time: 0.0171  memory: 5586  grad_norm: 0.7477  loss: 0.6867  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6867\n",
            "12/02 21:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][200/332]  lr: 1.0000e-04  eta: 0:05:54  time: 0.2663  data_time: 0.0448  memory: 5586  grad_norm: 0.6539  loss: 0.6744  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6744\n",
            "12/02 21:20:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][220/332]  lr: 1.0000e-04  eta: 0:05:50  time: 0.2766  data_time: 0.0559  memory: 5586  grad_norm: 0.7025  loss: 0.7022  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7022\n",
            "12/02 21:21:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][240/332]  lr: 1.0000e-04  eta: 0:05:45  time: 0.2138  data_time: 0.0180  memory: 5586  grad_norm: 0.7878  loss: 0.7017  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7017\n",
            "12/02 21:21:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][260/332]  lr: 1.0000e-04  eta: 0:05:40  time: 0.2154  data_time: 0.0193  memory: 5586  grad_norm: 0.7240  loss: 0.6732  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6732\n",
            "12/02 21:21:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][280/332]  lr: 1.0000e-04  eta: 0:05:35  time: 0.2622  data_time: 0.0431  memory: 5586  grad_norm: 0.7482  loss: 0.6889  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6889\n",
            "12/02 21:21:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][300/332]  lr: 1.0000e-04  eta: 0:05:30  time: 0.2881  data_time: 0.0657  memory: 5586  grad_norm: 0.7318  loss: 0.6877  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6877\n",
            "12/02 21:21:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][320/332]  lr: 1.0000e-04  eta: 0:05:25  time: 0.2102  data_time: 0.0165  memory: 5586  grad_norm: 0.6401  loss: 0.6765  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6765\n",
            "12/02 21:21:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:21:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][332/332]  lr: 1.0000e-04  eta: 0:05:22  time: 0.2070  data_time: 0.0188  memory: 5586  grad_norm: 0.8360  loss: 0.6798  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6798\n",
            "12/02 21:21:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 46 epochs\n",
            "12/02 21:21:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [46][20/42]    eta: 0:00:04  time: 0.1969  data_time: 0.0986  memory: 1141  \n",
            "12/02 21:21:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [46][40/42]    eta: 0:00:00  time: 0.2209  data_time: 0.1198  memory: 1141  \n",
            "12/02 21:21:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [46][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5007  data_time: 0.1019  time: 0.1981\n",
            "12/02 21:21:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][ 20/332]  lr: 1.0000e-04  eta: 0:05:18  time: 0.2633  data_time: 0.0582  memory: 5586  grad_norm: 0.9513  loss: 0.7109  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7109\n",
            "12/02 21:21:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][ 40/332]  lr: 1.0000e-04  eta: 0:05:13  time: 0.2107  data_time: 0.0165  memory: 5586  grad_norm: 1.0203  loss: 0.6729  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6729\n",
            "12/02 21:21:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][ 60/332]  lr: 1.0000e-04  eta: 0:05:08  time: 0.2263  data_time: 0.0244  memory: 5586  grad_norm: 1.0968  loss: 0.6687  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6687\n",
            "12/02 21:21:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][ 80/332]  lr: 1.0000e-04  eta: 0:05:03  time: 0.2857  data_time: 0.0575  memory: 5586  grad_norm: 1.0431  loss: 0.6850  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6850\n",
            "12/02 21:21:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][100/332]  lr: 1.0000e-04  eta: 0:04:58  time: 0.2403  data_time: 0.0353  memory: 5586  grad_norm: 0.7198  loss: 0.6906  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6906\n",
            "12/02 21:22:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][120/332]  lr: 1.0000e-04  eta: 0:04:53  time: 0.2145  data_time: 0.0192  memory: 5586  grad_norm: 0.9532  loss: 0.6946  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6946\n",
            "12/02 21:22:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][140/332]  lr: 1.0000e-04  eta: 0:04:48  time: 0.2566  data_time: 0.0228  memory: 5586  grad_norm: 0.6260  loss: 0.6741  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6741\n",
            "12/02 21:22:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][160/332]  lr: 1.0000e-04  eta: 0:04:44  time: 0.2894  data_time: 0.0655  memory: 5586  grad_norm: 0.7845  loss: 0.6861  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6861\n",
            "12/02 21:22:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][180/332]  lr: 1.0000e-04  eta: 0:04:39  time: 0.2255  data_time: 0.0263  memory: 5586  grad_norm: 1.2271  loss: 0.6975  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6975\n",
            "12/02 21:22:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][200/332]  lr: 1.0000e-04  eta: 0:04:34  time: 0.2127  data_time: 0.0175  memory: 5586  grad_norm: 0.9737  loss: 0.6912  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6912\n",
            "12/02 21:22:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][220/332]  lr: 1.0000e-04  eta: 0:04:29  time: 0.2427  data_time: 0.0296  memory: 5586  grad_norm: 0.7424  loss: 0.6781  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6781\n",
            "12/02 21:22:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][240/332]  lr: 1.0000e-04  eta: 0:04:24  time: 0.2918  data_time: 0.0612  memory: 5586  grad_norm: 0.6823  loss: 0.7112  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7112\n",
            "12/02 21:22:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][260/332]  lr: 1.0000e-04  eta: 0:04:19  time: 0.2232  data_time: 0.0256  memory: 5586  grad_norm: 0.8301  loss: 0.6850  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6850\n",
            "12/02 21:22:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][280/332]  lr: 1.0000e-04  eta: 0:04:14  time: 0.2141  data_time: 0.0195  memory: 5586  grad_norm: 0.8018  loss: 0.6654  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6654\n",
            "12/02 21:22:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][300/332]  lr: 1.0000e-04  eta: 0:04:09  time: 0.2423  data_time: 0.0313  memory: 5586  grad_norm: 0.7420  loss: 0.6807  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6807\n",
            "12/02 21:22:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][320/332]  lr: 1.0000e-04  eta: 0:04:05  time: 0.3047  data_time: 0.0798  memory: 5586  grad_norm: 0.8070  loss: 0.6906  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6906\n",
            "12/02 21:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][332/332]  lr: 1.0000e-04  eta: 0:04:02  time: 0.2553  data_time: 0.0547  memory: 5586  grad_norm: 0.8495  loss: 0.6942  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6942\n",
            "12/02 21:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 47 epochs\n",
            "12/02 21:22:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [47][20/42]    eta: 0:00:03  time: 0.1510  data_time: 0.0608  memory: 1141  \n",
            "12/02 21:23:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [47][40/42]    eta: 0:00:00  time: 0.1389  data_time: 0.0454  memory: 1141  \n",
            "12/02 21:23:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [47][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0505  time: 0.1394\n",
            "12/02 21:23:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][ 20/332]  lr: 1.0000e-04  eta: 0:03:57  time: 0.2845  data_time: 0.0669  memory: 5586  grad_norm: 0.7282  loss: 0.6827  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6827\n",
            "12/02 21:23:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][ 40/332]  lr: 1.0000e-04  eta: 0:03:52  time: 0.2701  data_time: 0.0563  memory: 5586  grad_norm: 0.7257  loss: 0.6670  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6670\n",
            "12/02 21:23:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][ 60/332]  lr: 1.0000e-04  eta: 0:03:47  time: 0.2151  data_time: 0.0192  memory: 5586  grad_norm: 0.7149  loss: 0.7117  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7117\n",
            "12/02 21:23:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][ 80/332]  lr: 1.0000e-04  eta: 0:03:42  time: 0.2112  data_time: 0.0175  memory: 5586  grad_norm: 1.1397  loss: 0.6817  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6817\n",
            "12/02 21:23:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][100/332]  lr: 1.0000e-04  eta: 0:03:37  time: 0.2618  data_time: 0.0392  memory: 5586  grad_norm: 0.7174  loss: 0.6897  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6897\n",
            "12/02 21:23:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][120/332]  lr: 1.0000e-04  eta: 0:03:33  time: 0.2813  data_time: 0.0618  memory: 5586  grad_norm: 1.1558  loss: 0.6852  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6852\n",
            "12/02 21:23:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][140/332]  lr: 1.0000e-04  eta: 0:03:28  time: 0.2113  data_time: 0.0180  memory: 5586  grad_norm: 0.7377  loss: 0.6771  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6771\n",
            "12/02 21:23:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][160/332]  lr: 1.0000e-04  eta: 0:03:23  time: 0.2101  data_time: 0.0165  memory: 5586  grad_norm: 0.7077  loss: 0.6873  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6873\n",
            "12/02 21:23:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][180/332]  lr: 1.0000e-04  eta: 0:03:18  time: 0.2572  data_time: 0.0374  memory: 5586  grad_norm: 0.8952  loss: 0.6950  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6950\n",
            "12/02 21:23:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][200/332]  lr: 1.0000e-04  eta: 0:03:13  time: 0.2797  data_time: 0.0609  memory: 5586  grad_norm: 0.7917  loss: 0.6842  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6842\n",
            "12/02 21:23:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][220/332]  lr: 1.0000e-04  eta: 0:03:08  time: 0.2169  data_time: 0.0228  memory: 5586  grad_norm: 0.6487  loss: 0.6753  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6753\n",
            "12/02 21:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][240/332]  lr: 1.0000e-04  eta: 0:03:03  time: 0.2143  data_time: 0.0196  memory: 5586  grad_norm: 0.8066  loss: 0.6947  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6947\n",
            "12/02 21:24:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][260/332]  lr: 1.0000e-04  eta: 0:02:58  time: 0.2615  data_time: 0.0389  memory: 5586  grad_norm: 0.6895  loss: 0.6706  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6706\n",
            "12/02 21:24:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][280/332]  lr: 1.0000e-04  eta: 0:02:54  time: 0.2883  data_time: 0.0708  memory: 5586  grad_norm: 0.8033  loss: 0.7011  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7011\n",
            "12/02 21:24:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][300/332]  lr: 1.0000e-04  eta: 0:02:49  time: 0.2113  data_time: 0.0173  memory: 5586  grad_norm: 1.2362  loss: 0.6783  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6783\n",
            "12/02 21:24:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][320/332]  lr: 1.0000e-04  eta: 0:02:44  time: 0.2103  data_time: 0.0168  memory: 5586  grad_norm: 0.9357  loss: 0.7042  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7042\n",
            "12/02 21:24:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:24:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][332/332]  lr: 1.0000e-04  eta: 0:02:41  time: 0.2286  data_time: 0.0273  memory: 5586  grad_norm: 0.7274  loss: 0.6793  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6793\n",
            "12/02 21:24:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 48 epochs\n",
            "12/02 21:24:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [48][20/42]    eta: 0:00:05  time: 0.2288  data_time: 0.1277  memory: 1141  \n",
            "12/02 21:24:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [48][40/42]    eta: 0:00:00  time: 0.1698  data_time: 0.0757  memory: 1141  \n",
            "12/02 21:24:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [48][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0955  time: 0.1897\n",
            "12/02 21:24:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][ 20/332]  lr: 1.0000e-04  eta: 0:02:36  time: 0.2308  data_time: 0.0369  memory: 5586  grad_norm: 0.7605  loss: 0.7002  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7002\n",
            "12/02 21:24:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][ 40/332]  lr: 1.0000e-04  eta: 0:02:31  time: 0.2238  data_time: 0.0239  memory: 5586  grad_norm: 0.8712  loss: 0.7045  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7045\n",
            "12/02 21:24:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][ 60/332]  lr: 1.0000e-04  eta: 0:02:26  time: 0.2778  data_time: 0.0513  memory: 5586  grad_norm: 0.7802  loss: 0.6805  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6805\n",
            "12/02 21:24:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:24:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][ 80/332]  lr: 1.0000e-04  eta: 0:02:22  time: 0.2521  data_time: 0.0430  memory: 5586  grad_norm: 0.9769  loss: 0.6928  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6928\n",
            "12/02 21:24:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][100/332]  lr: 1.0000e-04  eta: 0:02:17  time: 0.2112  data_time: 0.0178  memory: 5586  grad_norm: 1.1790  loss: 0.6722  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6722\n",
            "12/02 21:25:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][120/332]  lr: 1.0000e-04  eta: 0:02:12  time: 0.2244  data_time: 0.0225  memory: 5586  grad_norm: 1.0520  loss: 0.6952  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6952\n",
            "12/02 21:25:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][140/332]  lr: 1.0000e-04  eta: 0:02:07  time: 0.2858  data_time: 0.0592  memory: 5586  grad_norm: 0.7908  loss: 0.6749  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6749\n",
            "12/02 21:25:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][160/332]  lr: 1.0000e-04  eta: 0:02:02  time: 0.2450  data_time: 0.0376  memory: 5586  grad_norm: 0.8138  loss: 0.6964  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6964\n",
            "12/02 21:25:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][180/332]  lr: 1.0000e-04  eta: 0:01:57  time: 0.2132  data_time: 0.0201  memory: 5586  grad_norm: 0.7069  loss: 0.6981  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6981\n",
            "12/02 21:25:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][200/332]  lr: 1.0000e-04  eta: 0:01:52  time: 0.2278  data_time: 0.0249  memory: 5586  grad_norm: 0.7487  loss: 0.6648  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6648\n",
            "12/02 21:25:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][220/332]  lr: 1.0000e-04  eta: 0:01:47  time: 0.2809  data_time: 0.0624  memory: 5586  grad_norm: 0.7691  loss: 0.6851  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6851\n",
            "12/02 21:25:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][240/332]  lr: 1.0000e-04  eta: 0:01:43  time: 0.2421  data_time: 0.0379  memory: 5586  grad_norm: 0.8214  loss: 0.6900  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6900\n",
            "12/02 21:25:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][260/332]  lr: 1.0000e-04  eta: 0:01:38  time: 0.2121  data_time: 0.0167  memory: 5586  grad_norm: 0.7319  loss: 0.7013  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7013\n",
            "12/02 21:25:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][280/332]  lr: 1.0000e-04  eta: 0:01:33  time: 0.2323  data_time: 0.0233  memory: 5586  grad_norm: 1.0316  loss: 0.6851  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6851\n",
            "12/02 21:25:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][300/332]  lr: 1.0000e-04  eta: 0:01:28  time: 0.2868  data_time: 0.0681  memory: 5586  grad_norm: 1.1189  loss: 0.6708  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6708\n",
            "12/02 21:25:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][320/332]  lr: 1.0000e-04  eta: 0:01:23  time: 0.2395  data_time: 0.0365  memory: 5586  grad_norm: 0.6212  loss: 0.6896  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6896\n",
            "12/02 21:25:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:25:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][332/332]  lr: 1.0000e-04  eta: 0:01:20  time: 0.2058  data_time: 0.0166  memory: 5586  grad_norm: 0.5510  loss: 0.6632  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6632\n",
            "12/02 21:25:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 49 epochs\n",
            "12/02 21:25:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [49][20/42]    eta: 0:00:03  time: 0.1447  data_time: 0.0527  memory: 1141  \n",
            "12/02 21:25:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [49][40/42]    eta: 0:00:00  time: 0.1969  data_time: 0.1030  memory: 1141  \n",
            "12/02 21:26:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [49][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5007  data_time: 0.0763  time: 0.1662\n",
            "12/02 21:26:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][ 20/332]  lr: 1.0000e-04  eta: 0:01:15  time: 0.3105  data_time: 0.0885  memory: 5586  grad_norm: 0.8687  loss: 0.6946  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6946\n",
            "12/02 21:26:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][ 40/332]  lr: 1.0000e-04  eta: 0:01:11  time: 0.2150  data_time: 0.0219  memory: 5586  grad_norm: 0.7368  loss: 0.6914  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6914\n",
            "12/02 21:26:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][ 60/332]  lr: 1.0000e-04  eta: 0:01:06  time: 0.2119  data_time: 0.0179  memory: 5586  grad_norm: 0.6666  loss: 0.6645  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6645\n",
            "12/02 21:26:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][ 80/332]  lr: 1.0000e-04  eta: 0:01:01  time: 0.2507  data_time: 0.0363  memory: 5586  grad_norm: 0.7361  loss: 0.6921  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6921\n",
            "12/02 21:26:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][100/332]  lr: 1.0000e-04  eta: 0:00:56  time: 0.2833  data_time: 0.0496  memory: 5586  grad_norm: 1.1245  loss: 0.6884  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6884\n",
            "12/02 21:26:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][120/332]  lr: 1.0000e-04  eta: 0:00:51  time: 0.2136  data_time: 0.0183  memory: 5586  grad_norm: 0.9104  loss: 0.7135  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7135\n",
            "12/02 21:26:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][140/332]  lr: 1.0000e-04  eta: 0:00:46  time: 0.2127  data_time: 0.0182  memory: 5586  grad_norm: 1.0044  loss: 0.7059  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7059\n",
            "12/02 21:26:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][160/332]  lr: 1.0000e-04  eta: 0:00:41  time: 0.2514  data_time: 0.0353  memory: 5586  grad_norm: 0.6075  loss: 0.6617  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6617\n",
            "12/02 21:26:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][180/332]  lr: 1.0000e-04  eta: 0:00:36  time: 0.2914  data_time: 0.0671  memory: 5586  grad_norm: 0.8550  loss: 0.6630  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6630\n",
            "12/02 21:26:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][200/332]  lr: 1.0000e-04  eta: 0:00:32  time: 0.2161  data_time: 0.0207  memory: 5586  grad_norm: 0.8056  loss: 0.6813  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6813\n",
            "12/02 21:26:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][220/332]  lr: 1.0000e-04  eta: 0:00:27  time: 0.2106  data_time: 0.0159  memory: 5586  grad_norm: 0.7433  loss: 0.6575  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6575\n",
            "12/02 21:26:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][240/332]  lr: 1.0000e-04  eta: 0:00:22  time: 0.2441  data_time: 0.0329  memory: 5586  grad_norm: 0.7937  loss: 0.6897  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6897\n",
            "12/02 21:27:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][260/332]  lr: 1.0000e-04  eta: 0:00:17  time: 0.3070  data_time: 0.0854  memory: 5586  grad_norm: 0.7293  loss: 0.6736  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6736\n",
            "12/02 21:27:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][280/332]  lr: 1.0000e-04  eta: 0:00:12  time: 0.2139  data_time: 0.0194  memory: 5586  grad_norm: 0.7754  loss: 0.6679  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6679\n",
            "12/02 21:27:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][300/332]  lr: 1.0000e-04  eta: 0:00:07  time: 0.2126  data_time: 0.0183  memory: 5586  grad_norm: 0.7287  loss: 0.6848  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6848\n",
            "12/02 21:27:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][320/332]  lr: 1.0000e-04  eta: 0:00:02  time: 0.2519  data_time: 0.0328  memory: 5586  grad_norm: 1.1602  loss: 0.6833  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6833\n",
            "12/02 21:27:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_rgb_activitynet_finetune_20231202_201303\n",
            "12/02 21:27:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][332/332]  lr: 1.0000e-04  eta: 0:00:00  time: 0.2684  data_time: 0.0483  memory: 5586  grad_norm: 0.8433  loss: 0.6845  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6845\n",
            "12/02 21:27:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 50 epochs\n",
            "12/02 21:27:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][20/42]    eta: 0:00:03  time: 0.1679  data_time: 0.0710  memory: 1141  \n",
            "12/02 21:27:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][40/42]    eta: 0:00:00  time: 0.1404  data_time: 0.0475  memory: 1141  \n",
            "12/02 21:27:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][42/42]    acc/top1: 0.5529  acc/top5: 1.0000  acc/mean1: 0.4973  data_time: 0.0556  time: 0.1474\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./rgb_checkpoints/epoch_50.pth /content/drive/MyDrive/accident-detection/models/tsn_r50_320p_1x1x8_50e_rgb_activitynet_finetune.pth"
      ],
      "metadata": {
        "id": "YEiK1ZH5IhaK"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f5VysiXbQr8j"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}