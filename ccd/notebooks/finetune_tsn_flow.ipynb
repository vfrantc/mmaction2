{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vfrantc/mmaction2/blob/main/ccd/notebooks/finetune_tsn_flow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eetlQsC7Gz2U",
        "outputId": "b79fc4aa-a58d-48bf-f873-3a2a1a1196c4"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/vfrantc/mmaction2.git\n",
        "%cd mmaction2\n",
        "!pip install timm\n",
        "!pip install -v -e .\n",
        "!pip install -U openmim\n",
        "!mim install mmengine\n",
        "!mim install mmcv\n",
        "!mim install mmdet\n",
        "!mim install mmpose"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IE0AXWotcaUb",
        "outputId": "80a5b706-6029-4668-e35f-ab49a23155e7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'mmaction2'...\n",
            "remote: Enumerating objects: 22310, done.\u001b[K\n",
            "remote: Counting objects: 100% (224/224), done.\u001b[K\n",
            "remote: Compressing objects: 100% (132/132), done.\u001b[K\n",
            "remote: Total 22310 (delta 124), reused 165 (delta 88), pack-reused 22086\u001b[K\n",
            "Receiving objects: 100% (22310/22310), 65.37 MiB | 19.13 MiB/s, done.\n",
            "Resolving deltas: 100% (15682/15682), done.\n",
            "/content/mmaction2\n",
            "Collecting timm\n",
            "  Downloading timm-0.9.12-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.7 in /usr/local/lib/python3.10/dist-packages (from timm) (2.1.0+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.16.0+cu118)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.1)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.7->timm) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (4.66.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->timm) (23.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.7->timm) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->timm) (2023.11.17)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.7->timm) (1.3.0)\n",
            "Installing collected packages: timm\n",
            "Successfully installed timm-0.9.12\n",
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Obtaining file:///content/mmaction2\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-2sw1klro/mmaction2.egg-info\n",
            "  writing /tmp/pip-pip-egg-info-2sw1klro/mmaction2.egg-info/PKG-INFO\n",
            "  writing dependency_links to /tmp/pip-pip-egg-info-2sw1klro/mmaction2.egg-info/dependency_links.txt\n",
            "  writing requirements to /tmp/pip-pip-egg-info-2sw1klro/mmaction2.egg-info/requires.txt\n",
            "  writing top-level names to /tmp/pip-pip-egg-info-2sw1klro/mmaction2.egg-info/top_level.txt\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-2sw1klro/mmaction2.egg-info/SOURCES.txt'\n",
            "  reading manifest file '/tmp/pip-pip-egg-info-2sw1klro/mmaction2.egg-info/SOURCES.txt'\n",
            "  reading manifest template 'MANIFEST.in'\n",
            "  warning: no files found matching 'mmaction/.mim/model-index.yml'\n",
            "  warning: no files found matching 'mmaction/.mim/dataset-index.yml'\n",
            "  warning: no files found matching '*.py' under directory 'mmaction/.mim/configs'\n",
            "  warning: no files found matching '*.yml' under directory 'mmaction/.mim/configs'\n",
            "  warning: no files found matching '*.sh' under directory 'mmaction/.mim/tools'\n",
            "  warning: no files found matching '*.py' under directory 'mmaction/.mim/tools'\n",
            "  adding license file 'LICENSE'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-2sw1klro/mmaction2.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting decord>=0.4.1 (from mmaction2==1.2.0)\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from mmaction2==1.2.0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmaction2==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->mmaction2==1.2.0) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->mmaction2==1.2.0) (1.3.0)\n",
            "Installing collected packages: einops, decord, mmaction2\n",
            "  Running setup.py develop for mmaction2\n",
            "    Running command python setup.py develop\n",
            "    running develop\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/develop.py:40: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "    !!\n",
            "\n",
            "            ********************************************************************************\n",
            "            Please avoid running ``setup.py`` and ``easy_install``.\n",
            "            Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "            other standards-based tools.\n",
            "\n",
            "            See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "            ********************************************************************************\n",
            "\n",
            "    !!\n",
            "      easy_install.initialize_options(self)\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "    !!\n",
            "\n",
            "            ********************************************************************************\n",
            "            Please avoid running ``setup.py`` directly.\n",
            "            Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "            other standards-based tools.\n",
            "\n",
            "            See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "            ********************************************************************************\n",
            "\n",
            "    !!\n",
            "      self.initialize_options()\n",
            "    running egg_info\n",
            "    creating mmaction2.egg-info\n",
            "    writing mmaction2.egg-info/PKG-INFO\n",
            "    writing dependency_links to mmaction2.egg-info/dependency_links.txt\n",
            "    writing requirements to mmaction2.egg-info/requires.txt\n",
            "    writing top-level names to mmaction2.egg-info/top_level.txt\n",
            "    writing manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    reading manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    reading manifest template 'MANIFEST.in'\n",
            "    adding license file 'LICENSE'\n",
            "    writing manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "    Creating /usr/local/lib/python3.10/dist-packages/mmaction2.egg-link (link to .)\n",
            "    Adding mmaction2 1.2.0 to easy-install.pth file\n",
            "\n",
            "    Installed /content/mmaction2\n",
            "Successfully installed decord-0.6.0 einops-0.7.0 mmaction2-1.2.0\n",
            "Collecting openmim\n",
            "  Downloading openmim-0.3.9-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click in /usr/local/lib/python3.10/dist-packages (from openmim) (8.1.7)\n",
            "Collecting colorama (from openmim)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting model-index (from openmim)\n",
            "  Downloading model_index-0.1.11-py3-none-any.whl (34 kB)\n",
            "Collecting opendatalab (from openmim)\n",
            "  Downloading opendatalab-0.0.10-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from openmim) (1.5.3)\n",
            "Requirement already satisfied: pip>=19.3 in /usr/local/lib/python3.10/dist-packages (from openmim) (23.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openmim) (2.31.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from openmim) (13.7.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from openmim) (0.9.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (6.0.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from model-index->openmim) (3.5.1)\n",
            "Collecting ordered-set (from model-index->openmim)\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting pycryptodome (from opendatalab->openmim)\n",
            "  Downloading pycryptodome-3.19.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from opendatalab->openmim) (4.66.1)\n",
            "Collecting openxlab (from opendatalab->openmim)\n",
            "  Downloading openxlab-0.0.29-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->openmim) (2023.11.17)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->openmim) (1.23.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->openmim) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->openmim) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->openmim) (1.16.0)\n",
            "Collecting oss2~=2.17.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading oss2-2.17.0.tar.gz (259 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests (from openmim)\n",
            "  Downloading requests-2.28.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rich (from openmim)\n",
            "  Downloading rich-13.4.2-py3-none-any.whl (239 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools~=60.2.0 (from openxlab->opendatalab->openmim)\n",
            "  Downloading setuptools-60.2.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm (from opendatalab->openmim)\n",
            "  Downloading tqdm-4.65.2-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<1.27,>=1.21.1 (from requests->openmim)\n",
            "  Downloading urllib3-1.26.18-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting crcmod>=1.7 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting aliyun-python-sdk-kms>=2.4.1 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun_python_sdk_kms-2.16.2-py2.py3-none-any.whl (94 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aliyun-python-sdk-core>=2.13.12 (from oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading aliyun-python-sdk-core-2.14.0.tar.gz (443 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jmespath<1.0.0,>=0.9.3 (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim)\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (41.0.7)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.10/dist-packages (from cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=2.6.0->aliyun-python-sdk-core>=2.13.12->oss2~=2.17.0->openxlab->opendatalab->openmim) (2.21)\n",
            "Building wheels for collected packages: oss2, aliyun-python-sdk-core, crcmod\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for oss2: filename=oss2-2.17.0-py3-none-any.whl size=112371 sha256=b28fd87a5a0752150305dd1ae1d5745a9d0b523e87f5b05926a6d3cc271d6d49\n",
            "  Stored in directory: /root/.cache/pip/wheels/87/04/7b/7e61b8157fdf211c5131375240d0d86ca82e2a88ead9672c88\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for aliyun-python-sdk-core: filename=aliyun_python_sdk_core-2.14.0-py3-none-any.whl size=535289 sha256=524b279884231b88397b7a0760304f518b6d829cd854d00f973c2e91ef9ea51e\n",
            "  Stored in directory: /root/.cache/pip/wheels/16/3c/68/b7eab618d9f1d5e7d386296f1e07e2cf36aaa1eb5161885038\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=31408 sha256=ee12a546360729abaa99e130ff642bf7df8d76dedd5eabbee28fdc3929b893e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
            "Successfully built oss2 aliyun-python-sdk-core crcmod\n",
            "Installing collected packages: crcmod, urllib3, tqdm, setuptools, pycryptodome, ordered-set, jmespath, colorama, rich, requests, model-index, aliyun-python-sdk-core, aliyun-python-sdk-kms, oss2, openxlab, opendatalab, openmim\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.66.1\n",
            "    Uninstalling tqdm-4.66.1:\n",
            "      Successfully uninstalled tqdm-4.66.1\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 67.7.2\n",
            "    Uninstalling setuptools-67.7.2:\n",
            "      Successfully uninstalled setuptools-67.7.2\n",
            "  Attempting uninstall: rich\n",
            "    Found existing installation: rich 13.7.0\n",
            "    Uninstalling rich-13.7.0:\n",
            "      Successfully uninstalled rich-13.7.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.31.0\n",
            "    Uninstalling requests-2.31.0:\n",
            "      Successfully uninstalled requests-2.31.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cvxpy 1.3.2 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.32 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aliyun-python-sdk-core-2.14.0 aliyun-python-sdk-kms-2.16.2 colorama-0.4.6 crcmod-1.7 jmespath-0.10.0 model-index-0.1.11 opendatalab-0.0.10 openmim-0.3.9 openxlab-0.0.29 ordered-set-4.1.0 oss2-2.17.0 pycryptodome-3.19.0 requests-2.28.2 rich-13.4.2 setuptools-60.2.0 tqdm-4.65.2 urllib3-1.26.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "_distutils_hack",
                  "pkg_resources",
                  "setuptools"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\n",
            "Collecting mmengine\n",
            "  Downloading mmengine-0.10.1-py3-none-any.whl (450 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.3/450.3 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting addict (from mmengine)\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmengine) (1.23.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmengine) (6.0.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine) (2.3.0)\n",
            "Collecting yapf (from mmengine)\n",
            "  Downloading yapf-0.40.2-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmengine) (4.8.0.76)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (23.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (4.0.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmengine) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmengine) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine) (1.16.0)\n",
            "Installing collected packages: addict, yapf, mmengine\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mmaction2 1.2.0 requires mmcv<2.2.0,>=2.0.0rc4, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed addict-2.4.0 mmengine-0.10.1 yapf-0.40.2\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\n",
            "Collecting mmcv\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/mmcv-2.1.0-cp310-cp310-manylinux1_x86_64.whl (99.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.3/99.3 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv) (2.4.0)\n",
            "Requirement already satisfied: mmengine>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from mmcv) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmcv) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv) (23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv) (0.40.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv) (4.8.0.76)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv) (3.7.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine>=0.3.0->mmcv) (2.3.0)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv) (4.0.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv) (3.17.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmengine>=0.3.0->mmcv) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine>=0.3.0->mmcv) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine>=0.3.0->mmcv) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmengine>=0.3.0->mmcv) (1.16.0)\n",
            "Installing collected packages: mmcv\n",
            "Successfully installed mmcv-2.1.0\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\n",
            "Collecting mmdet\n",
            "  Downloading mmdet-3.2.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmdet) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmdet) (1.23.5)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet) (2.0.7)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmdet) (1.11.4)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet) (1.16.0)\n",
            "Collecting terminaltables (from mmdet)\n",
            "  Downloading terminaltables-3.1.10-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mmdet) (4.65.2)\n",
            "Requirement already satisfied: mmcv<2.2.0,>=2.0.0rc4 in /usr/local/lib/python3.10/dist-packages (from mmdet) (2.1.0)\n",
            "Requirement already satisfied: mmengine<1.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from mmdet) (0.10.1)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (2.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (23.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (9.4.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (0.40.2)\n",
            "Requirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0rc4->mmdet) (4.8.0.76)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.7.1->mmdet) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.7.1->mmdet) (2.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmdet) (2.8.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.0.0,>=0.7.1->mmdet) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.0.0,>=0.7.1->mmdet) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0rc4->mmdet) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0rc4->mmdet) (4.0.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0rc4->mmdet) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv<2.2.0,>=2.0.0rc4->mmdet) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine<1.0.0,>=0.7.1->mmdet) (0.1.2)\n",
            "Installing collected packages: terminaltables, mmdet\n",
            "Successfully installed mmdet-3.2.0 terminaltables-3.1.10\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu118/torch2.1.0/index.html\n",
            "Collecting mmpose\n",
            "  Downloading mmpose-1.2.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting chumpy (from mmpose)\n",
            "  Downloading chumpy-0.70.tar.gz (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting json-tricks (from mmpose)\n",
            "  Downloading json_tricks-3.17.3-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmpose) (3.7.1)\n",
            "Collecting munkres (from mmpose)\n",
            "  Downloading munkres-1.1.4-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmpose) (1.23.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from mmpose) (4.8.0.76)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from mmpose) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmpose) (1.11.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from mmpose) (0.16.0+cu118)\n",
            "Collecting xtcocotools>=1.12 (from mmpose)\n",
            "  Downloading xtcocotools-1.14.3-cp310-cp310-manylinux1_x86_64.whl (436 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.0/436.0 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mmcv<2.2.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from mmpose) (2.1.0)\n",
            "Requirement already satisfied: mmdet<3.3.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from mmpose) (3.2.0)\n",
            "Requirement already satisfied: mmengine<1.0.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mmpose) (0.10.1)\n",
            "Requirement already satisfied: addict in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0->mmpose) (2.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0->mmpose) (23.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0->mmpose) (6.0.1)\n",
            "Requirement already satisfied: yapf in /usr/local/lib/python3.10/dist-packages (from mmcv<2.2.0,>=2.0.0->mmpose) (0.40.2)\n",
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.10/dist-packages (from mmdet<3.3.0,>=3.0.0->mmpose) (2.0.7)\n",
            "Requirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from mmdet<3.3.0,>=3.0.0->mmpose) (2.0.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from mmdet<3.3.0,>=3.0.0->mmpose) (1.16.0)\n",
            "Requirement already satisfied: terminaltables in /usr/local/lib/python3.10/dist-packages (from mmdet<3.3.0,>=3.0.0->mmpose) (3.1.10)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from mmdet<3.3.0,>=3.0.0->mmpose) (4.65.2)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.4.0->mmpose) (13.4.2)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from mmengine<1.0.0,>=0.4.0->mmpose) (2.3.0)\n",
            "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.10/dist-packages (from xtcocotools>=1.12->mmpose) (60.2.0)\n",
            "Requirement already satisfied: cython>=0.27.3 in /usr/local/lib/python3.10/dist-packages (from xtcocotools>=1.12->mmpose) (3.0.6)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmpose) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmpose) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmpose) (4.45.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmpose) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmpose) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmpose) (2.8.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision->mmpose) (2.28.2)\n",
            "Requirement already satisfied: torch==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->mmpose) (2.1.0+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.1.0->torchvision->mmpose) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->mmpose) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->mmpose) (3.6)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->mmpose) (1.26.18)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision->mmpose) (2023.11.17)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.0.0,>=0.4.0->mmpose) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->mmengine<1.0.0,>=0.4.0->mmpose) (2.16.1)\n",
            "Requirement already satisfied: importlib-metadata>=6.6.0 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0->mmpose) (6.8.0)\n",
            "Requirement already satisfied: platformdirs>=3.5.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0->mmpose) (4.0.0)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from yapf->mmcv<2.2.0,>=2.0.0->mmpose) (2.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=6.6.0->yapf->mmcv<2.2.0,>=2.0.0->mmpose) (3.17.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->mmengine<1.0.0,>=0.4.0->mmpose) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.1.0->torchvision->mmpose) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.1.0->torchvision->mmpose) (1.3.0)\n",
            "Building wheels for collected packages: chumpy\n",
            "  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chumpy: filename=chumpy-0.70-py3-none-any.whl size=58281 sha256=c3db378f1e33e876080d342897c5a7546c025c3a8e7c79b66f33039e3eb0bfa3\n",
            "  Stored in directory: /root/.cache/pip/wheels/e0/c1/ef/29ba7be03653a29ef6f2c3e1956d6c4d8877f2b243af411db1\n",
            "Successfully built chumpy\n",
            "Installing collected packages: munkres, json-tricks, chumpy, xtcocotools, mmpose\n",
            "Successfully installed chumpy-0.70 json-tricks-3.17.3 mmpose-1.2.0 munkres-1.1.4 xtcocotools-1.14.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/accident-detection/ccd_rgb_flow.zip .\n",
        "!unzip -q ccd_rgb_flow.zip"
      ],
      "metadata": {
        "id": "4U4R9DfkcLi6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python ./tools/data/activitynet/generate_rawframes_filelist.py"
      ],
      "metadata": {
        "id": "oVSAobzuOYlz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python tools/train.py ccd/configs/tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-ndxgxBL7E9",
        "outputId": "4257f91d-011d-4435-c9b1-decbdb1fa30f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "12/02 20:48:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    numpy_random_seed: 1239435285\n",
            "    GPU 0: Tesla V100-SXM2-16GB\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 11.8, V11.8.89\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.1.0+cu118\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX512\n",
            "  - CUDA Runtime 11.8\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.7\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.0+cu118\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.1\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1239435285\n",
            "    diff_rank_seed: False\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "12/02 20:48:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "ann_file_test = 'data/ActivityNet/anet_val_video.txt'\n",
            "ann_file_train = 'data/ActivityNet/anet_train_video.txt'\n",
            "ann_file_val = 'data/ActivityNet/anet_val_video.txt'\n",
            "checkpoint_config = dict(interval=5)\n",
            "data_root = 'data/ActivityNet/rawframes'\n",
            "data_root_val = 'data/ActivityNet/rawframes'\n",
            "dataset_type = 'RawframeDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(interval=1, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'),\n",
            "    timer=dict(type='IterTimerHook'))\n",
            "default_scope = 'mmaction'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "launcher = 'none'\n",
            "load_from = 'https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_320p_1x1x8_110e_kinetics400_flow/tsn_r50_320p_1x1x8_110e_kinetics400_flow_20200705-1f39486b.pth'\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
            "lr_config = dict(\n",
            "    policy='step', step=[\n",
            "        60,\n",
            "        120,\n",
            "    ])\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        depth=50,\n",
            "        in_channels=2,\n",
            "        norm_eval=False,\n",
            "        pretrained='https://download.pytorch.org/models/resnet50-11ad3fa6.pth',\n",
            "        type='ResNet'),\n",
            "    cls_head=dict(\n",
            "        average_clips='prob',\n",
            "        consensus=dict(dim=1, type='AvgConsensus'),\n",
            "        dropout_ratio=0.8,\n",
            "        in_channels=2048,\n",
            "        init_std=0.01,\n",
            "        num_classes=2,\n",
            "        spatial_type='avg',\n",
            "        type='TSNHead'),\n",
            "    data_preprocessor=dict(\n",
            "        format_shape='NCHW',\n",
            "        mean=[\n",
            "            128,\n",
            "            128,\n",
            "        ],\n",
            "        std=[\n",
            "            128,\n",
            "            128,\n",
            "        ],\n",
            "        type='ActionDataPreprocessor'),\n",
            "    test_cfg=None,\n",
            "    train_cfg=None,\n",
            "    type='Recognizer2D')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=dict(max_norm=40, norm_type=2),\n",
            "    optimizer=dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0001))\n",
            "optimizer = dict(lr=0.001, momentum=0.9, type='SGD', weight_decay=0.0001)\n",
            "optimizer_config = dict(grad_clip=dict(max_norm=40, norm_type=2))\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        end=50,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            20,\n",
            "            40,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "randomness = dict(deterministic=False, diff_rank_seed=False, seed=None)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='data/ActivityNet/anet_val_video.txt',\n",
            "        data_prefix=dict(img='data/ActivityNet/rawframes'),\n",
            "        filename_tmpl='flow_{}_{:05d}.jpg',\n",
            "        modality='Flow',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=25,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='RawFrameDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='TenCrop'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        start_index=0,\n",
            "        test_mode=True,\n",
            "        type='RawframeDataset',\n",
            "        with_offset=True),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "test_pipeline = [\n",
            "    dict(\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=25,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='RawFrameDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='TenCrop'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "total_epochs = 10\n",
            "train_cfg = dict(\n",
            "    max_epochs=50, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_size=8,\n",
            "    dataset=dict(\n",
            "        ann_file='data/ActivityNet/anet_train_video.txt',\n",
            "        data_prefix=dict(img='data/ActivityNet/rawframes'),\n",
            "        filename_tmpl='flow_{}_{:05d}.jpg',\n",
            "        modality='Flow',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                clip_len=1, frame_interval=1, num_clips=8,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='RawFrameDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(type='RandomResizedCrop'),\n",
            "            dict(keep_ratio=False, scale=(\n",
            "                224,\n",
            "                224,\n",
            "            ), type='Resize'),\n",
            "            dict(flip_ratio=0.5, type='Flip'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        start_index=0,\n",
            "        type='RawframeDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(clip_len=1, frame_interval=1, num_clips=8, type='SampleFrames'),\n",
            "    dict(type='RawFrameDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(type='RandomResizedCrop'),\n",
            "    dict(keep_ratio=False, scale=(\n",
            "        224,\n",
            "        224,\n",
            "    ), type='Resize'),\n",
            "    dict(flip_ratio=0.5, type='Flip'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=8,\n",
            "    dataset=dict(\n",
            "        ann_file='data/ActivityNet/anet_val_video.txt',\n",
            "        data_prefix=dict(img='data/ActivityNet/rawframes'),\n",
            "        filename_tmpl='flow_{}_{:05d}.jpg',\n",
            "        modality='Flow',\n",
            "        pipeline=[\n",
            "            dict(\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=8,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='RawFrameDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='CenterCrop'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        start_index=0,\n",
            "        test_mode=True,\n",
            "        type='RawframeDataset'),\n",
            "    num_workers=2,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "val_pipeline = [\n",
            "    dict(\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=8,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='RawFrameDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='CenterCrop'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './flow_checkpoints/'\n",
            "workflow = [\n",
            "    (\n",
            "        'train',\n",
            "        5,\n",
            "    ),\n",
            "]\n",
            "\n",
            "12/02 20:48:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "12/02 20:48:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "Loads checkpoint by http backend from path: https://download.pytorch.org/models/resnet50-11ad3fa6.pth\n",
            "12/02 20:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - These parameters in pretrained checkpoint are not loaded: {'fc.weight', 'conv1.weight', 'fc.bias'}\n",
            "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_320p_1x1x8_110e_kinetics400_flow/tsn_r50_320p_1x1x8_110e_kinetics400_flow_20200705-1f39486b.pth\n",
            "The model and loaded state dict do not match exactly\n",
            "\n",
            "size mismatch for backbone.conv1.conv.weight: copying a param with shape torch.Size([64, 10, 7, 7]) from checkpoint, the shape in current model is torch.Size([64, 2, 7, 7]).\n",
            "size mismatch for cls_head.fc_cls.weight: copying a param with shape torch.Size([400, 2048]) from checkpoint, the shape in current model is torch.Size([2, 2048]).\n",
            "size mismatch for cls_head.fc_cls.bias: copying a param with shape torch.Size([400]) from checkpoint, the shape in current model is torch.Size([2]).\n",
            "12/02 20:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load checkpoint from https://download.openmmlab.com/mmaction/recognition/tsn/tsn_r50_320p_1x1x8_110e_kinetics400_flow/tsn_r50_320p_1x1x8_110e_kinetics400_flow_20200705-1f39486b.pth\n",
            "12/02 20:48:53 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "12/02 20:48:53 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "12/02 20:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmaction2/flow_checkpoints.\n",
            "12/02 20:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 20/332]  lr: 1.0000e-02  eta: 1:42:45  time: 0.3719  data_time: 0.0275  memory: 5573  grad_norm: 16.2056  loss: 0.9429  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9429\n",
            "12/02 20:49:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 40/332]  lr: 1.0000e-02  eta: 1:22:27  time: 0.2257  data_time: 0.0199  memory: 5573  grad_norm: 15.1873  loss: 1.1442  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.1442\n",
            "12/02 20:49:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 60/332]  lr: 1.0000e-02  eta: 1:17:04  time: 0.2412  data_time: 0.0280  memory: 5573  grad_norm: 10.7323  loss: 1.0201  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 1.0201\n",
            "12/02 20:49:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 80/332]  lr: 1.0000e-02  eta: 1:12:18  time: 0.2117  data_time: 0.0162  memory: 5573  grad_norm: 5.1192  loss: 1.1481  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1481\n",
            "12/02 20:49:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][100/332]  lr: 1.0000e-02  eta: 1:08:52  time: 0.2019  data_time: 0.0130  memory: 5573  grad_norm: 5.4140  loss: 1.0385  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0385\n",
            "12/02 20:49:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][120/332]  lr: 1.0000e-02  eta: 1:06:59  time: 0.2109  data_time: 0.0152  memory: 5573  grad_norm: 6.7715  loss: 1.1517  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1517\n",
            "12/02 20:49:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][140/332]  lr: 1.0000e-02  eta: 1:06:44  time: 0.2396  data_time: 0.0257  memory: 5573  grad_norm: 6.7404  loss: 1.0678  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 1.0678\n",
            "12/02 20:49:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][160/332]  lr: 1.0000e-02  eta: 1:06:07  time: 0.2276  data_time: 0.0234  memory: 5573  grad_norm: 4.3721  loss: 0.9864  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9864\n",
            "12/02 20:49:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][180/332]  lr: 1.0000e-02  eta: 1:04:51  time: 0.2027  data_time: 0.0140  memory: 5573  grad_norm: 4.5605  loss: 1.0676  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0676\n",
            "12/02 20:49:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][200/332]  lr: 1.0000e-02  eta: 1:03:47  time: 0.2006  data_time: 0.0122  memory: 5573  grad_norm: 3.0570  loss: 0.8339  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8339\n",
            "12/02 20:49:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][220/332]  lr: 1.0000e-02  eta: 1:03:44  time: 0.2345  data_time: 0.0241  memory: 5573  grad_norm: 3.3580  loss: 0.9218  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.9218\n",
            "12/02 20:49:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][240/332]  lr: 1.0000e-02  eta: 1:03:54  time: 0.2445  data_time: 0.0293  memory: 5573  grad_norm: 4.7367  loss: 0.8568  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8568\n",
            "12/02 20:49:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][260/332]  lr: 1.0000e-02  eta: 1:03:10  time: 0.2031  data_time: 0.0126  memory: 5573  grad_norm: 3.9853  loss: 0.8591  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8591\n",
            "12/02 20:49:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][280/332]  lr: 1.0000e-02  eta: 1:02:31  time: 0.2027  data_time: 0.0137  memory: 5573  grad_norm: 3.2719  loss: 0.8406  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8406\n",
            "12/02 20:50:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][300/332]  lr: 1.0000e-02  eta: 1:02:19  time: 0.2231  data_time: 0.0203  memory: 5573  grad_norm: 3.0059  loss: 0.8245  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.8245\n",
            "12/02 20:50:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][320/332]  lr: 1.0000e-02  eta: 1:02:29  time: 0.2434  data_time: 0.0272  memory: 5573  grad_norm: 3.6627  loss: 0.8177  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8177\n",
            "12/02 20:50:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 20:50:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][332/332]  lr: 1.0000e-02  eta: 1:02:20  time: 0.2276  data_time: 0.0230  memory: 5573  grad_norm: 2.8009  loss: 0.7688  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7688\n",
            "12/02 20:50:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
            "12/02 20:50:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][20/42]    eta: 0:00:02  time: 0.1074  data_time: 0.0390  memory: 909  \n",
            "12/02 20:50:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][40/42]    eta: 0:00:00  time: 0.1023  data_time: 0.0366  memory: 909  \n",
            "12/02 20:50:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0363  time: 0.1028\n",
            "12/02 20:50:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.5559 acc/top1 at 1 epoch is saved to best_acc_top1_epoch_1.pth.\n",
            "12/02 20:50:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 20/332]  lr: 1.0000e-02  eta: 1:02:18  time: 0.2327  data_time: 0.0309  memory: 5573  grad_norm: 2.4441  loss: 0.7713  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7713\n",
            "12/02 20:50:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 40/332]  lr: 1.0000e-02  eta: 1:02:26  time: 0.2444  data_time: 0.0272  memory: 5573  grad_norm: 4.0563  loss: 0.8407  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8407\n",
            "12/02 20:50:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 60/332]  lr: 1.0000e-02  eta: 1:02:19  time: 0.2274  data_time: 0.0232  memory: 5573  grad_norm: 3.2786  loss: 0.8465  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8465\n",
            "12/02 20:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 80/332]  lr: 1.0000e-02  eta: 1:01:53  time: 0.2038  data_time: 0.0147  memory: 5573  grad_norm: 2.0140  loss: 0.7388  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7388\n",
            "12/02 20:50:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][100/332]  lr: 1.0000e-02  eta: 1:01:28  time: 0.2019  data_time: 0.0131  memory: 5573  grad_norm: 3.5975  loss: 0.8703  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8703\n",
            "12/02 20:50:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][120/332]  lr: 1.0000e-02  eta: 1:01:33  time: 0.2421  data_time: 0.0260  memory: 5573  grad_norm: 2.0471  loss: 0.7404  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7404\n",
            "12/02 20:50:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][140/332]  lr: 1.0000e-02  eta: 1:01:39  time: 0.2445  data_time: 0.0288  memory: 5573  grad_norm: 2.6209  loss: 0.8366  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8366\n",
            "12/02 20:50:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][160/332]  lr: 1.0000e-02  eta: 1:01:18  time: 0.2045  data_time: 0.0144  memory: 5573  grad_norm: 1.6636  loss: 0.7074  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7074\n",
            "12/02 20:50:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][180/332]  lr: 1.0000e-02  eta: 1:00:57  time: 0.2021  data_time: 0.0135  memory: 5573  grad_norm: 3.3942  loss: 0.7547  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7547\n",
            "12/02 20:51:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][200/332]  lr: 1.0000e-02  eta: 1:00:51  time: 0.2239  data_time: 0.0226  memory: 5573  grad_norm: 2.3706  loss: 0.7717  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7717\n",
            "12/02 20:51:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][220/332]  lr: 1.0000e-02  eta: 1:00:54  time: 0.2411  data_time: 0.0255  memory: 5573  grad_norm: 2.0109  loss: 0.7895  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7895\n",
            "12/02 20:51:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][240/332]  lr: 1.0000e-02  eta: 1:00:45  time: 0.2199  data_time: 0.0183  memory: 5573  grad_norm: 2.4157  loss: 0.7988  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7988\n",
            "12/02 20:51:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][260/332]  lr: 1.0000e-02  eta: 1:00:27  time: 0.2021  data_time: 0.0133  memory: 5573  grad_norm: 2.0059  loss: 0.6905  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6905\n",
            "12/02 20:51:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][280/332]  lr: 1.0000e-02  eta: 1:00:10  time: 0.2031  data_time: 0.0130  memory: 5573  grad_norm: 3.4106  loss: 0.9123  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.9123\n",
            "12/02 20:51:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][300/332]  lr: 1.0000e-02  eta: 1:00:13  time: 0.2403  data_time: 0.0251  memory: 5573  grad_norm: 2.3599  loss: 0.7520  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7520\n",
            "12/02 20:51:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][320/332]  lr: 1.0000e-02  eta: 1:00:16  time: 0.2425  data_time: 0.0275  memory: 5573  grad_norm: 2.7580  loss: 0.8160  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8160\n",
            "12/02 20:51:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 20:51:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][332/332]  lr: 1.0000e-02  eta: 1:00:03  time: 0.2099  data_time: 0.0177  memory: 5573  grad_norm: 2.4477  loss: 0.7822  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7822\n",
            "12/02 20:51:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
            "12/02 20:51:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][20/42]    eta: 0:00:02  time: 0.1017  data_time: 0.0319  memory: 909  \n",
            "12/02 20:51:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][40/42]    eta: 0:00:00  time: 0.0921  data_time: 0.0222  memory: 909  \n",
            "12/02 20:51:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][42/42]    acc/top1: 0.4743  acc/top5: 1.0000  acc/mean1: 0.4355  data_time: 0.0256  time: 0.0937\n",
            "12/02 20:51:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 20/332]  lr: 1.0000e-02  eta: 1:00:00  time: 0.2289  data_time: 0.0274  memory: 5573  grad_norm: 1.9104  loss: 0.7358  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7358\n",
            "12/02 20:51:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 40/332]  lr: 1.0000e-02  eta: 1:00:03  time: 0.2436  data_time: 0.0271  memory: 5573  grad_norm: 1.9946  loss: 0.7254  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7254\n",
            "12/02 20:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 60/332]  lr: 1.0000e-02  eta: 0:59:58  time: 0.2250  data_time: 0.0215  memory: 5573  grad_norm: 2.0982  loss: 0.7441  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7441\n",
            "12/02 20:51:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 80/332]  lr: 1.0000e-02  eta: 0:59:42  time: 0.2005  data_time: 0.0125  memory: 5573  grad_norm: 2.7821  loss: 0.8429  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8429\n",
            "12/02 20:51:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][100/332]  lr: 1.0000e-02  eta: 0:59:28  time: 0.2010  data_time: 0.0117  memory: 5573  grad_norm: 2.2198  loss: 0.7274  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7274\n",
            "12/02 20:52:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][120/332]  lr: 1.0000e-02  eta: 0:59:32  time: 0.2485  data_time: 0.0287  memory: 5573  grad_norm: 2.0766  loss: 0.8001  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8001\n",
            "12/02 20:52:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][140/332]  lr: 1.0000e-02  eta: 0:59:33  time: 0.2389  data_time: 0.0262  memory: 5573  grad_norm: 2.0266  loss: 0.7906  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7906\n",
            "12/02 20:52:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][160/332]  lr: 1.0000e-02  eta: 0:59:19  time: 0.2012  data_time: 0.0126  memory: 5573  grad_norm: 1.7357  loss: 0.7721  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7721\n",
            "12/02 20:52:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][180/332]  lr: 1.0000e-02  eta: 0:59:05  time: 0.1998  data_time: 0.0128  memory: 5573  grad_norm: 1.9092  loss: 0.7377  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7377\n",
            "12/02 20:52:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][200/332]  lr: 1.0000e-02  eta: 0:59:00  time: 0.2236  data_time: 0.0188  memory: 5573  grad_norm: 2.2044  loss: 0.7909  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7909\n",
            "12/02 20:52:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][220/332]  lr: 1.0000e-02  eta: 0:59:03  time: 0.2462  data_time: 0.0312  memory: 5573  grad_norm: 1.5091  loss: 0.7065  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7065\n",
            "12/02 20:52:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][240/332]  lr: 1.0000e-02  eta: 0:58:55  time: 0.2163  data_time: 0.0183  memory: 5573  grad_norm: 2.5166  loss: 0.7346  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7346\n",
            "12/02 20:52:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][260/332]  lr: 1.0000e-02  eta: 0:58:42  time: 0.2008  data_time: 0.0128  memory: 5573  grad_norm: 1.5333  loss: 0.7099  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7099\n",
            "12/02 20:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][280/332]  lr: 1.0000e-02  eta: 0:58:31  time: 0.2046  data_time: 0.0132  memory: 5573  grad_norm: 1.9615  loss: 0.7528  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7528\n",
            "12/02 20:52:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][300/332]  lr: 1.0000e-02  eta: 0:58:34  time: 0.2476  data_time: 0.0294  memory: 5573  grad_norm: 1.8643  loss: 0.7875  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7875\n",
            "12/02 20:52:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][320/332]  lr: 1.0000e-02  eta: 0:58:34  time: 0.2371  data_time: 0.0284  memory: 5573  grad_norm: 2.4254  loss: 0.7183  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7183\n",
            "12/02 20:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 20:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][332/332]  lr: 1.0000e-02  eta: 0:58:24  time: 0.2058  data_time: 0.0160  memory: 5573  grad_norm: 3.3422  loss: 0.7934  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7934\n",
            "12/02 20:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
            "12/02 20:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][20/42]    eta: 0:00:02  time: 0.1041  data_time: 0.0336  memory: 909  \n",
            "12/02 20:52:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][40/42]    eta: 0:00:00  time: 0.0923  data_time: 0.0224  memory: 909  \n",
            "12/02 20:52:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0265  time: 0.0943\n",
            "12/02 20:52:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 20:52:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 20/332]  lr: 1.0000e-02  eta: 0:58:24  time: 0.2365  data_time: 0.0311  memory: 5573  grad_norm: 1.6473  loss: 0.6734  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6734\n",
            "12/02 20:53:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 40/332]  lr: 1.0000e-02  eta: 0:58:24  time: 0.2404  data_time: 0.0275  memory: 5573  grad_norm: 1.9767  loss: 0.7740  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7740\n",
            "12/02 20:53:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 60/332]  lr: 1.0000e-02  eta: 0:58:17  time: 0.2169  data_time: 0.0180  memory: 5573  grad_norm: 1.8890  loss: 0.7358  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7358\n",
            "12/02 20:53:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 80/332]  lr: 1.0000e-02  eta: 0:58:05  time: 0.1997  data_time: 0.0120  memory: 5573  grad_norm: 2.1217  loss: 0.8025  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8025\n",
            "12/02 20:53:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][100/332]  lr: 1.0000e-02  eta: 0:57:54  time: 0.2017  data_time: 0.0128  memory: 5573  grad_norm: 3.2205  loss: 0.8314  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8314\n",
            "12/02 20:53:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][120/332]  lr: 1.0000e-02  eta: 0:57:56  time: 0.2475  data_time: 0.0295  memory: 5573  grad_norm: 2.9047  loss: 0.8403  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8403\n",
            "12/02 20:53:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][140/332]  lr: 1.0000e-02  eta: 0:57:55  time: 0.2360  data_time: 0.0248  memory: 5573  grad_norm: 1.8106  loss: 0.7566  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7566\n",
            "12/02 20:53:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][160/332]  lr: 1.0000e-02  eta: 0:57:43  time: 0.1992  data_time: 0.0118  memory: 5573  grad_norm: 2.3972  loss: 0.8048  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8048\n",
            "12/02 20:53:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][180/332]  lr: 1.0000e-02  eta: 0:57:32  time: 0.1996  data_time: 0.0124  memory: 5573  grad_norm: 2.4319  loss: 0.7647  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7647\n",
            "12/02 20:53:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][200/332]  lr: 1.0000e-02  eta: 0:57:30  time: 0.2299  data_time: 0.0226  memory: 5573  grad_norm: 1.6203  loss: 0.7018  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7018\n",
            "12/02 20:53:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][220/332]  lr: 1.0000e-02  eta: 0:57:31  time: 0.2467  data_time: 0.0300  memory: 5573  grad_norm: 1.6768  loss: 0.7841  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7841\n",
            "12/02 20:53:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][240/332]  lr: 1.0000e-02  eta: 0:57:24  time: 0.2143  data_time: 0.0181  memory: 5573  grad_norm: 1.6095  loss: 0.6807  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6807\n",
            "12/02 20:53:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][260/332]  lr: 1.0000e-02  eta: 0:57:13  time: 0.1999  data_time: 0.0120  memory: 5573  grad_norm: 1.5329  loss: 0.7558  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7558\n",
            "12/02 20:53:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][280/332]  lr: 1.0000e-02  eta: 0:57:06  time: 0.2107  data_time: 0.0152  memory: 5573  grad_norm: 1.8341  loss: 0.7851  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7851\n",
            "12/02 20:54:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][300/332]  lr: 1.0000e-02  eta: 0:57:06  time: 0.2433  data_time: 0.0272  memory: 5573  grad_norm: 1.7766  loss: 0.7650  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7650\n",
            "12/02 20:54:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][320/332]  lr: 1.0000e-02  eta: 0:57:04  time: 0.2327  data_time: 0.0233  memory: 5573  grad_norm: 1.3872  loss: 0.6777  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6777\n",
            "12/02 20:54:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 20:54:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][332/332]  lr: 1.0000e-02  eta: 0:56:56  time: 0.1966  data_time: 0.0121  memory: 5573  grad_norm: 1.3525  loss: 0.6519  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6519\n",
            "12/02 20:54:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
            "12/02 20:54:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][20/42]    eta: 0:00:02  time: 0.1009  data_time: 0.0320  memory: 909  \n",
            "12/02 20:54:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][40/42]    eta: 0:00:00  time: 0.0950  data_time: 0.0279  memory: 909  \n",
            "12/02 20:54:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0283  time: 0.0941\n",
            "12/02 20:54:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 20/332]  lr: 1.0000e-02  eta: 0:56:57  time: 0.2454  data_time: 0.0349  memory: 5573  grad_norm: 1.3527  loss: 0.7438  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7438\n",
            "12/02 20:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 40/332]  lr: 1.0000e-02  eta: 0:56:55  time: 0.2382  data_time: 0.0250  memory: 5573  grad_norm: 1.6461  loss: 0.7688  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7688\n",
            "12/02 20:54:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 60/332]  lr: 1.0000e-02  eta: 0:56:48  time: 0.2113  data_time: 0.0169  memory: 5573  grad_norm: 1.4351  loss: 0.6749  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6749\n",
            "12/02 20:54:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 80/332]  lr: 1.0000e-02  eta: 0:56:38  time: 0.1989  data_time: 0.0118  memory: 5573  grad_norm: 1.2695  loss: 0.7258  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7258\n",
            "12/02 20:54:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][100/332]  lr: 1.0000e-02  eta: 0:56:31  time: 0.2092  data_time: 0.0145  memory: 5573  grad_norm: 2.1161  loss: 0.7267  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7267\n",
            "12/02 20:54:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][120/332]  lr: 1.0000e-02  eta: 0:56:29  time: 0.2376  data_time: 0.0248  memory: 5573  grad_norm: 2.3347  loss: 0.8167  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8167\n",
            "12/02 20:54:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][140/332]  lr: 1.0000e-02  eta: 0:56:27  time: 0.2335  data_time: 0.0251  memory: 5573  grad_norm: 1.5823  loss: 0.7136  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7136\n",
            "12/02 20:54:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][160/332]  lr: 1.0000e-02  eta: 0:56:17  time: 0.1985  data_time: 0.0119  memory: 5573  grad_norm: 2.5413  loss: 0.7713  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7713\n",
            "12/02 20:54:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][180/332]  lr: 1.0000e-02  eta: 0:56:08  time: 0.1984  data_time: 0.0117  memory: 5573  grad_norm: 2.6215  loss: 0.7243  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7243\n",
            "12/02 20:54:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][200/332]  lr: 1.0000e-02  eta: 0:56:04  time: 0.2292  data_time: 0.0241  memory: 5573  grad_norm: 2.0592  loss: 0.7613  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7613\n",
            "12/02 20:55:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][220/332]  lr: 1.0000e-02  eta: 0:56:04  time: 0.2435  data_time: 0.0283  memory: 5573  grad_norm: 2.0926  loss: 0.7362  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7362\n",
            "12/02 20:55:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][240/332]  lr: 1.0000e-02  eta: 0:55:57  time: 0.2098  data_time: 0.0150  memory: 5573  grad_norm: 1.9040  loss: 0.7281  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7281\n",
            "12/02 20:55:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][260/332]  lr: 1.0000e-02  eta: 0:55:48  time: 0.2003  data_time: 0.0127  memory: 5573  grad_norm: 1.0348  loss: 0.6435  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6435\n",
            "12/02 20:55:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][280/332]  lr: 1.0000e-02  eta: 0:55:42  time: 0.2138  data_time: 0.0173  memory: 5573  grad_norm: 1.7995  loss: 0.7489  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7489\n",
            "12/02 20:55:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][300/332]  lr: 1.0000e-02  eta: 0:55:41  time: 0.2426  data_time: 0.0279  memory: 5573  grad_norm: 2.3310  loss: 0.7656  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7656\n",
            "12/02 20:55:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][320/332]  lr: 1.0000e-02  eta: 0:55:37  time: 0.2281  data_time: 0.0219  memory: 5573  grad_norm: 1.2735  loss: 0.7007  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7007\n",
            "12/02 20:55:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 20:55:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][332/332]  lr: 1.0000e-02  eta: 0:55:31  time: 0.1964  data_time: 0.0119  memory: 5573  grad_norm: 1.3625  loss: 0.6948  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6948\n",
            "12/02 20:55:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
            "12/02 20:55:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][20/42]    eta: 0:00:02  time: 0.1070  data_time: 0.0391  memory: 909  \n",
            "12/02 20:55:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][40/42]    eta: 0:00:00  time: 0.0924  data_time: 0.0255  memory: 909  \n",
            "12/02 20:55:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0304  time: 0.0957\n",
            "12/02 20:55:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 20/332]  lr: 1.0000e-02  eta: 0:55:30  time: 0.2399  data_time: 0.0307  memory: 5573  grad_norm: 1.8975  loss: 0.7468  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7468\n",
            "12/02 20:55:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 40/332]  lr: 1.0000e-02  eta: 0:55:28  time: 0.2367  data_time: 0.0268  memory: 5573  grad_norm: 1.6057  loss: 0.7408  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7408\n",
            "12/02 20:55:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 60/332]  lr: 1.0000e-02  eta: 0:55:21  time: 0.2126  data_time: 0.0176  memory: 5573  grad_norm: 1.5911  loss: 0.7254  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7254\n",
            "12/02 20:55:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 80/332]  lr: 1.0000e-02  eta: 0:55:13  time: 0.1984  data_time: 0.0122  memory: 5573  grad_norm: 1.7786  loss: 0.7319  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7319\n",
            "12/02 20:55:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][100/332]  lr: 1.0000e-02  eta: 0:55:05  time: 0.2049  data_time: 0.0152  memory: 5573  grad_norm: 3.4830  loss: 0.7772  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7772\n",
            "12/02 20:55:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][120/332]  lr: 1.0000e-02  eta: 0:55:04  time: 0.2429  data_time: 0.0290  memory: 5573  grad_norm: 1.4739  loss: 0.7198  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7198\n",
            "12/02 20:56:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][140/332]  lr: 1.0000e-02  eta: 0:55:01  time: 0.2350  data_time: 0.0252  memory: 5573  grad_norm: 1.4542  loss: 0.6901  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6901\n",
            "12/02 20:56:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][160/332]  lr: 1.0000e-02  eta: 0:54:53  time: 0.1981  data_time: 0.0117  memory: 5573  grad_norm: 1.8357  loss: 0.7338  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7338\n",
            "12/02 20:56:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][180/332]  lr: 1.0000e-02  eta: 0:54:45  time: 0.1985  data_time: 0.0117  memory: 5573  grad_norm: 1.5019  loss: 0.7575  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7575\n",
            "12/02 20:56:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][200/332]  lr: 1.0000e-02  eta: 0:54:40  time: 0.2247  data_time: 0.0213  memory: 5573  grad_norm: 1.7135  loss: 0.7441  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7441\n",
            "12/02 20:56:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][220/332]  lr: 1.0000e-02  eta: 0:54:39  time: 0.2391  data_time: 0.0265  memory: 5573  grad_norm: 2.6136  loss: 0.7732  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7732\n",
            "12/02 20:56:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][240/332]  lr: 1.0000e-02  eta: 0:54:33  time: 0.2165  data_time: 0.0176  memory: 5573  grad_norm: 1.8876  loss: 0.7001  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7001\n",
            "12/02 20:56:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][260/332]  lr: 1.0000e-02  eta: 0:54:25  time: 0.1982  data_time: 0.0116  memory: 5573  grad_norm: 1.7350  loss: 0.6876  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6876\n",
            "12/02 20:56:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][280/332]  lr: 1.0000e-02  eta: 0:54:18  time: 0.2091  data_time: 0.0159  memory: 5573  grad_norm: 2.4307  loss: 0.7232  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7232\n",
            "12/02 20:56:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][300/332]  lr: 1.0000e-02  eta: 0:54:16  time: 0.2382  data_time: 0.0272  memory: 5573  grad_norm: 2.4554  loss: 0.7984  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7984\n",
            "12/02 20:56:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][320/332]  lr: 1.0000e-02  eta: 0:54:14  time: 0.2332  data_time: 0.0228  memory: 5573  grad_norm: 2.3267  loss: 0.7800  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7800\n",
            "12/02 20:56:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 20:56:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][332/332]  lr: 1.0000e-02  eta: 0:54:08  time: 0.2060  data_time: 0.0142  memory: 5573  grad_norm: 2.0125  loss: 0.7447  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7447\n",
            "12/02 20:56:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
            "12/02 20:56:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][20/42]    eta: 0:00:02  time: 0.1119  data_time: 0.0440  memory: 909  \n",
            "12/02 20:56:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][40/42]    eta: 0:00:00  time: 0.0959  data_time: 0.0280  memory: 909  \n",
            "12/02 20:56:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0339  time: 0.0996\n",
            "12/02 20:56:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 20:56:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 20/332]  lr: 1.0000e-02  eta: 0:54:05  time: 0.2305  data_time: 0.0310  memory: 5573  grad_norm: 1.9453  loss: 0.7574  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7574\n",
            "12/02 20:56:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 40/332]  lr: 1.0000e-02  eta: 0:54:03  time: 0.2432  data_time: 0.0283  memory: 5573  grad_norm: 1.9074  loss: 0.7845  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7845\n",
            "12/02 20:57:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 60/332]  lr: 1.0000e-02  eta: 0:53:58  time: 0.2181  data_time: 0.0196  memory: 5573  grad_norm: 1.8266  loss: 0.7697  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7697\n",
            "12/02 20:57:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 80/332]  lr: 1.0000e-02  eta: 0:53:50  time: 0.1986  data_time: 0.0117  memory: 5573  grad_norm: 1.7634  loss: 0.7241  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7241\n",
            "12/02 20:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][100/332]  lr: 1.0000e-02  eta: 0:53:43  time: 0.2004  data_time: 0.0125  memory: 5573  grad_norm: 2.1994  loss: 0.7074  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7074\n",
            "12/02 20:57:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][120/332]  lr: 1.0000e-02  eta: 0:53:41  time: 0.2399  data_time: 0.0260  memory: 5573  grad_norm: 1.5933  loss: 0.6795  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6795\n",
            "12/02 20:57:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][140/332]  lr: 1.0000e-02  eta: 0:53:39  time: 0.2390  data_time: 0.0257  memory: 5573  grad_norm: 1.9126  loss: 0.7520  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7520\n",
            "12/02 20:57:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][160/332]  lr: 1.0000e-02  eta: 0:53:31  time: 0.1986  data_time: 0.0118  memory: 5573  grad_norm: 1.8070  loss: 0.7296  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7296\n",
            "12/02 20:57:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][180/332]  lr: 1.0000e-02  eta: 0:53:23  time: 0.1989  data_time: 0.0117  memory: 5573  grad_norm: 2.5964  loss: 0.7543  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7543\n",
            "12/02 20:57:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][200/332]  lr: 1.0000e-02  eta: 0:53:19  time: 0.2195  data_time: 0.0198  memory: 5573  grad_norm: 3.1243  loss: 0.7733  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7733\n",
            "12/02 20:57:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][220/332]  lr: 1.0000e-02  eta: 0:53:17  time: 0.2440  data_time: 0.0284  memory: 5573  grad_norm: 1.7190  loss: 0.6971  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6971\n",
            "12/02 20:57:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][240/332]  lr: 1.0000e-02  eta: 0:53:12  time: 0.2215  data_time: 0.0201  memory: 5573  grad_norm: 2.3617  loss: 0.7632  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7632\n",
            "12/02 20:57:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][260/332]  lr: 1.0000e-02  eta: 0:53:05  time: 0.1995  data_time: 0.0117  memory: 5573  grad_norm: 1.8263  loss: 0.7437  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7437\n",
            "12/02 20:57:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][280/332]  lr: 1.0000e-02  eta: 0:52:58  time: 0.1991  data_time: 0.0118  memory: 5573  grad_norm: 2.2068  loss: 0.7209  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7209\n",
            "12/02 20:57:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][300/332]  lr: 1.0000e-02  eta: 0:52:56  time: 0.2460  data_time: 0.0275  memory: 5573  grad_norm: 1.6302  loss: 0.7093  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7093\n",
            "12/02 20:57:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][320/332]  lr: 1.0000e-02  eta: 0:52:55  time: 0.2480  data_time: 0.0292  memory: 5573  grad_norm: 1.3749  loss: 0.7143  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7143\n",
            "12/02 20:58:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 20:58:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][332/332]  lr: 1.0000e-02  eta: 0:52:50  time: 0.2152  data_time: 0.0195  memory: 5573  grad_norm: 1.5252  loss: 0.6894  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6894\n",
            "12/02 20:58:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 7 epochs\n",
            "12/02 20:58:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][20/42]    eta: 0:00:02  time: 0.1056  data_time: 0.0351  memory: 909  \n",
            "12/02 20:58:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][40/42]    eta: 0:00:00  time: 0.0956  data_time: 0.0307  memory: 909  \n",
            "12/02 20:58:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [7][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0315  time: 0.0971\n",
            "12/02 20:58:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 20/332]  lr: 1.0000e-02  eta: 0:52:47  time: 0.2279  data_time: 0.0288  memory: 5573  grad_norm: 1.2371  loss: 0.6883  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6883\n",
            "12/02 20:58:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 40/332]  lr: 1.0000e-02  eta: 0:52:45  time: 0.2451  data_time: 0.0297  memory: 5573  grad_norm: 1.7227  loss: 0.7911  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7911\n",
            "12/02 20:58:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 60/332]  lr: 1.0000e-02  eta: 0:52:41  time: 0.2247  data_time: 0.0209  memory: 5573  grad_norm: 1.5558  loss: 0.6820  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6820\n",
            "12/02 20:58:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 80/332]  lr: 1.0000e-02  eta: 0:52:34  time: 0.1989  data_time: 0.0122  memory: 5573  grad_norm: 2.0949  loss: 0.7424  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7424\n",
            "12/02 20:58:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][100/332]  lr: 1.0000e-02  eta: 0:52:26  time: 0.1989  data_time: 0.0122  memory: 5573  grad_norm: 1.2954  loss: 0.6717  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6717\n",
            "12/02 20:58:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][120/332]  lr: 1.0000e-02  eta: 0:52:24  time: 0.2388  data_time: 0.0254  memory: 5573  grad_norm: 1.7994  loss: 0.7391  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7391\n",
            "12/02 20:58:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][140/332]  lr: 1.0000e-02  eta: 0:52:22  time: 0.2464  data_time: 0.0275  memory: 5573  grad_norm: 1.6296  loss: 0.7399  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7399\n",
            "12/02 20:58:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][160/332]  lr: 1.0000e-02  eta: 0:52:15  time: 0.2006  data_time: 0.0130  memory: 5573  grad_norm: 1.4635  loss: 0.7123  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7123\n",
            "12/02 20:58:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][180/332]  lr: 1.0000e-02  eta: 0:52:08  time: 0.1982  data_time: 0.0117  memory: 5573  grad_norm: 1.0767  loss: 0.6867  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6867\n",
            "12/02 20:58:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][200/332]  lr: 1.0000e-02  eta: 0:52:04  time: 0.2215  data_time: 0.0200  memory: 5573  grad_norm: 1.4819  loss: 0.7083  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7083\n",
            "12/02 20:58:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][220/332]  lr: 1.0000e-02  eta: 0:52:01  time: 0.2389  data_time: 0.0248  memory: 5573  grad_norm: 1.6029  loss: 0.7238  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7238\n",
            "12/02 20:59:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][240/332]  lr: 1.0000e-02  eta: 0:51:57  time: 0.2277  data_time: 0.0236  memory: 5573  grad_norm: 1.4679  loss: 0.7246  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7246\n",
            "12/02 20:59:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][260/332]  lr: 1.0000e-02  eta: 0:51:50  time: 0.1982  data_time: 0.0115  memory: 5573  grad_norm: 1.7287  loss: 0.7820  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7820\n",
            "12/02 20:59:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][280/332]  lr: 1.0000e-02  eta: 0:51:43  time: 0.1978  data_time: 0.0118  memory: 5573  grad_norm: 1.6321  loss: 0.7123  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7123\n",
            "12/02 20:59:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][300/332]  lr: 1.0000e-02  eta: 0:51:41  time: 0.2392  data_time: 0.0263  memory: 5573  grad_norm: 1.5156  loss: 0.6970  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6970\n",
            "12/02 20:59:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][320/332]  lr: 1.0000e-02  eta: 0:51:38  time: 0.2387  data_time: 0.0281  memory: 5573  grad_norm: 1.4727  loss: 0.7384  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7384\n",
            "12/02 20:59:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 20:59:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][332/332]  lr: 1.0000e-02  eta: 0:51:34  time: 0.2143  data_time: 0.0192  memory: 5573  grad_norm: 1.5600  loss: 0.7401  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7401\n",
            "12/02 20:59:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 8 epochs\n",
            "12/02 20:59:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][20/42]    eta: 0:00:02  time: 0.1043  data_time: 0.0335  memory: 909  \n",
            "12/02 20:59:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][40/42]    eta: 0:00:00  time: 0.0904  data_time: 0.0218  memory: 909  \n",
            "12/02 20:59:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][42/42]    acc/top1: 0.5529  acc/top5: 1.0000  acc/mean1: 0.4993  data_time: 0.0261  time: 0.0935\n",
            "12/02 20:59:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 20/332]  lr: 1.0000e-02  eta: 0:51:29  time: 0.2226  data_time: 0.0250  memory: 5573  grad_norm: 1.4844  loss: 0.7126  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7126\n",
            "12/02 20:59:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 40/332]  lr: 1.0000e-02  eta: 0:51:27  time: 0.2421  data_time: 0.0287  memory: 5573  grad_norm: 1.2962  loss: 0.7371  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7371\n",
            "12/02 20:59:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 60/332]  lr: 1.0000e-02  eta: 0:51:23  time: 0.2302  data_time: 0.0238  memory: 5573  grad_norm: 1.8574  loss: 0.7548  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7548\n",
            "12/02 20:59:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 80/332]  lr: 1.0000e-02  eta: 0:51:17  time: 0.1986  data_time: 0.0116  memory: 5573  grad_norm: 1.0929  loss: 0.6718  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6718\n",
            "12/02 20:59:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][100/332]  lr: 1.0000e-02  eta: 0:51:10  time: 0.1990  data_time: 0.0121  memory: 5573  grad_norm: 1.0799  loss: 0.6892  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6892\n",
            "12/02 20:59:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][120/332]  lr: 1.0000e-02  eta: 0:51:07  time: 0.2351  data_time: 0.0265  memory: 5573  grad_norm: 1.7387  loss: 0.7568  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7568\n",
            "12/02 20:59:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][140/332]  lr: 1.0000e-02  eta: 0:51:05  time: 0.2448  data_time: 0.0298  memory: 5573  grad_norm: 1.2958  loss: 0.7087  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7087\n",
            "12/02 21:00:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][160/332]  lr: 1.0000e-02  eta: 0:50:59  time: 0.2107  data_time: 0.0152  memory: 5573  grad_norm: 1.8253  loss: 0.7008  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7008\n",
            "12/02 21:00:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][180/332]  lr: 1.0000e-02  eta: 0:50:52  time: 0.1992  data_time: 0.0127  memory: 5573  grad_norm: 1.1307  loss: 0.6690  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6690\n",
            "12/02 21:00:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][200/332]  lr: 1.0000e-02  eta: 0:50:47  time: 0.2103  data_time: 0.0173  memory: 5573  grad_norm: 2.4273  loss: 0.6980  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6980\n",
            "12/02 21:00:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][220/332]  lr: 1.0000e-02  eta: 0:50:45  time: 0.2453  data_time: 0.0281  memory: 5573  grad_norm: 1.3922  loss: 0.7306  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7306\n",
            "12/02 21:00:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][240/332]  lr: 1.0000e-02  eta: 0:50:41  time: 0.2290  data_time: 0.0242  memory: 5573  grad_norm: 1.3899  loss: 0.7246  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7246\n",
            "12/02 21:00:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][260/332]  lr: 1.0000e-02  eta: 0:50:34  time: 0.1992  data_time: 0.0123  memory: 5573  grad_norm: 1.4010  loss: 0.7186  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7186\n",
            "12/02 21:00:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][280/332]  lr: 1.0000e-02  eta: 0:50:28  time: 0.1989  data_time: 0.0125  memory: 5573  grad_norm: 1.2121  loss: 0.7080  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7080\n",
            "12/02 21:00:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][300/332]  lr: 1.0000e-02  eta: 0:50:24  time: 0.2331  data_time: 0.0250  memory: 5573  grad_norm: 1.4648  loss: 0.6900  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6900\n",
            "12/02 21:00:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][320/332]  lr: 1.0000e-02  eta: 0:50:22  time: 0.2466  data_time: 0.0285  memory: 5573  grad_norm: 1.3214  loss: 0.7134  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7134\n",
            "12/02 21:00:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:00:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][332/332]  lr: 1.0000e-02  eta: 0:50:18  time: 0.2186  data_time: 0.0205  memory: 5573  grad_norm: 1.1467  loss: 0.7073  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7073\n",
            "12/02 21:00:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
            "12/02 21:00:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][20/42]    eta: 0:00:02  time: 0.1067  data_time: 0.0341  memory: 909  \n",
            "12/02 21:00:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][40/42]    eta: 0:00:00  time: 0.0894  data_time: 0.0211  memory: 909  \n",
            "12/02 21:00:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0261  time: 0.0942\n",
            "12/02 21:00:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:00:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 20/332]  lr: 1.0000e-02  eta: 0:50:14  time: 0.2201  data_time: 0.0267  memory: 5573  grad_norm: 1.3709  loss: 0.7069  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7069\n",
            "12/02 21:00:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 40/332]  lr: 1.0000e-02  eta: 0:50:12  time: 0.2463  data_time: 0.0285  memory: 5573  grad_norm: 1.1143  loss: 0.6660  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6660\n",
            "12/02 21:00:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 60/332]  lr: 1.0000e-02  eta: 0:50:08  time: 0.2315  data_time: 0.0241  memory: 5573  grad_norm: 1.1103  loss: 0.6930  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6930\n",
            "12/02 21:01:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 80/332]  lr: 1.0000e-02  eta: 0:50:01  time: 0.1979  data_time: 0.0116  memory: 5573  grad_norm: 1.0302  loss: 0.6849  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6849\n",
            "12/02 21:01:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][100/332]  lr: 1.0000e-02  eta: 0:49:55  time: 0.1988  data_time: 0.0120  memory: 5573  grad_norm: 1.0207  loss: 0.6495  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6495\n",
            "12/02 21:01:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][120/332]  lr: 1.0000e-02  eta: 0:49:51  time: 0.2295  data_time: 0.0219  memory: 5573  grad_norm: 1.7627  loss: 0.7734  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7734\n",
            "12/02 21:01:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][140/332]  lr: 1.0000e-02  eta: 0:49:49  time: 0.2464  data_time: 0.0284  memory: 5573  grad_norm: 1.3811  loss: 0.7036  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7036\n",
            "12/02 21:01:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][160/332]  lr: 1.0000e-02  eta: 0:49:44  time: 0.2111  data_time: 0.0192  memory: 5573  grad_norm: 1.2059  loss: 0.6970  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6970\n",
            "12/02 21:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][180/332]  lr: 1.0000e-02  eta: 0:49:37  time: 0.1999  data_time: 0.0130  memory: 5573  grad_norm: 1.4573  loss: 0.7690  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7690\n",
            "12/02 21:01:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][200/332]  lr: 1.0000e-02  eta: 0:49:32  time: 0.2095  data_time: 0.0156  memory: 5573  grad_norm: 1.4385  loss: 0.7449  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7449\n",
            "12/02 21:01:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][220/332]  lr: 1.0000e-02  eta: 0:49:29  time: 0.2441  data_time: 0.0278  memory: 5573  grad_norm: 1.3200  loss: 0.7388  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7388\n",
            "12/02 21:01:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][240/332]  lr: 1.0000e-02  eta: 0:49:26  time: 0.2318  data_time: 0.0238  memory: 5573  grad_norm: 1.1465  loss: 0.6664  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6664\n",
            "12/02 21:01:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][260/332]  lr: 1.0000e-02  eta: 0:49:19  time: 0.1992  data_time: 0.0120  memory: 5573  grad_norm: 1.4540  loss: 0.7108  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7108\n",
            "12/02 21:01:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][280/332]  lr: 1.0000e-02  eta: 0:49:13  time: 0.1990  data_time: 0.0123  memory: 5573  grad_norm: 1.0745  loss: 0.7226  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7226\n",
            "12/02 21:01:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][300/332]  lr: 1.0000e-02  eta: 0:49:09  time: 0.2292  data_time: 0.0237  memory: 5573  grad_norm: 0.9676  loss: 0.7016  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7016\n",
            "12/02 21:01:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][320/332]  lr: 1.0000e-02  eta: 0:49:06  time: 0.2417  data_time: 0.0285  memory: 5573  grad_norm: 0.8840  loss: 0.6654  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6654\n",
            "12/02 21:01:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:01:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][332/332]  lr: 1.0000e-02  eta: 0:49:03  time: 0.2189  data_time: 0.0218  memory: 5573  grad_norm: 1.0552  loss: 0.7066  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7066\n",
            "12/02 21:01:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n",
            "12/02 21:01:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][20/42]    eta: 0:00:02  time: 0.1140  data_time: 0.0425  memory: 909  \n",
            "12/02 21:02:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][40/42]    eta: 0:00:00  time: 0.0996  data_time: 0.0347  memory: 909  \n",
            "12/02 21:02:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0364  time: 0.1023\n",
            "12/02 21:02:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 20/332]  lr: 1.0000e-02  eta: 0:48:58  time: 0.2183  data_time: 0.0264  memory: 5573  grad_norm: 1.0210  loss: 0.7241  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7241\n",
            "12/02 21:02:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 40/332]  lr: 1.0000e-02  eta: 0:48:56  time: 0.2458  data_time: 0.0291  memory: 5573  grad_norm: 1.4306  loss: 0.7562  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7562\n",
            "12/02 21:02:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 60/332]  lr: 1.0000e-02  eta: 0:48:52  time: 0.2287  data_time: 0.0224  memory: 5573  grad_norm: 1.4935  loss: 0.7275  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.7275\n",
            "12/02 21:02:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 80/332]  lr: 1.0000e-02  eta: 0:48:46  time: 0.1982  data_time: 0.0116  memory: 5573  grad_norm: 1.0508  loss: 0.6863  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6863\n",
            "12/02 21:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][100/332]  lr: 1.0000e-02  eta: 0:48:39  time: 0.1986  data_time: 0.0121  memory: 5573  grad_norm: 1.2901  loss: 0.7094  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7094\n",
            "12/02 21:02:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][120/332]  lr: 1.0000e-02  eta: 0:48:36  time: 0.2303  data_time: 0.0247  memory: 5573  grad_norm: 1.5717  loss: 0.7222  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7222\n",
            "12/02 21:02:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][140/332]  lr: 1.0000e-02  eta: 0:48:33  time: 0.2419  data_time: 0.0283  memory: 5573  grad_norm: 0.9501  loss: 0.6799  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6799\n",
            "12/02 21:02:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][160/332]  lr: 1.0000e-02  eta: 0:48:28  time: 0.2130  data_time: 0.0174  memory: 5573  grad_norm: 1.0127  loss: 0.6700  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6700\n",
            "12/02 21:02:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][180/332]  lr: 1.0000e-02  eta: 0:48:21  time: 0.1978  data_time: 0.0111  memory: 5573  grad_norm: 1.4110  loss: 0.7394  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7394\n",
            "12/02 21:02:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][200/332]  lr: 1.0000e-02  eta: 0:48:16  time: 0.2053  data_time: 0.0140  memory: 5573  grad_norm: 1.3963  loss: 0.6929  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6929\n",
            "12/02 21:02:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][220/332]  lr: 1.0000e-02  eta: 0:48:13  time: 0.2433  data_time: 0.0288  memory: 5573  grad_norm: 1.2241  loss: 0.6864  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6864\n",
            "12/02 21:02:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][240/332]  lr: 1.0000e-02  eta: 0:48:09  time: 0.2333  data_time: 0.0241  memory: 5573  grad_norm: 1.6805  loss: 0.7242  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7242\n",
            "12/02 21:02:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][260/332]  lr: 1.0000e-02  eta: 0:48:03  time: 0.1975  data_time: 0.0114  memory: 5573  grad_norm: 1.6245  loss: 0.7528  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7528\n",
            "12/02 21:03:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][280/332]  lr: 1.0000e-02  eta: 0:47:57  time: 0.1985  data_time: 0.0122  memory: 5573  grad_norm: 1.4600  loss: 0.7089  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7089\n",
            "12/02 21:03:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][300/332]  lr: 1.0000e-02  eta: 0:47:53  time: 0.2276  data_time: 0.0242  memory: 5573  grad_norm: 1.3949  loss: 0.6735  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6735\n",
            "12/02 21:03:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][320/332]  lr: 1.0000e-02  eta: 0:47:50  time: 0.2404  data_time: 0.0285  memory: 5573  grad_norm: 1.6636  loss: 0.7109  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7109\n",
            "12/02 21:03:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:03:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][332/332]  lr: 1.0000e-02  eta: 0:47:47  time: 0.2209  data_time: 0.0226  memory: 5573  grad_norm: 1.5165  loss: 0.7184  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7184\n",
            "12/02 21:03:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 11 epochs\n",
            "12/02 21:03:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][20/42]    eta: 0:00:02  time: 0.1011  data_time: 0.0340  memory: 909  \n",
            "12/02 21:03:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][40/42]    eta: 0:00:00  time: 0.0905  data_time: 0.0236  memory: 909  \n",
            "12/02 21:03:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0271  time: 0.0920\n",
            "12/02 21:03:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 20/332]  lr: 1.0000e-02  eta: 0:47:42  time: 0.2135  data_time: 0.0247  memory: 5573  grad_norm: 1.1347  loss: 0.7250  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7250\n",
            "12/02 21:03:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 40/332]  lr: 1.0000e-02  eta: 0:47:39  time: 0.2397  data_time: 0.0273  memory: 5573  grad_norm: 1.1877  loss: 0.7163  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7163\n",
            "12/02 21:03:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 60/332]  lr: 1.0000e-02  eta: 0:47:35  time: 0.2358  data_time: 0.0251  memory: 5573  grad_norm: 1.2990  loss: 0.7116  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7116\n",
            "12/02 21:03:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 80/332]  lr: 1.0000e-02  eta: 0:47:29  time: 0.1970  data_time: 0.0110  memory: 5573  grad_norm: 1.1146  loss: 0.6791  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6791\n",
            "12/02 21:03:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][100/332]  lr: 1.0000e-02  eta: 0:47:23  time: 0.1978  data_time: 0.0113  memory: 5573  grad_norm: 1.1796  loss: 0.7373  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7373\n",
            "12/02 21:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][120/332]  lr: 1.0000e-02  eta: 0:47:19  time: 0.2268  data_time: 0.0220  memory: 5573  grad_norm: 0.9704  loss: 0.6783  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6783\n",
            "12/02 21:03:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][140/332]  lr: 1.0000e-02  eta: 0:47:16  time: 0.2338  data_time: 0.0257  memory: 5573  grad_norm: 1.5731  loss: 0.7265  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7265\n",
            "12/02 21:03:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][160/332]  lr: 1.0000e-02  eta: 0:47:11  time: 0.2129  data_time: 0.0172  memory: 5573  grad_norm: 1.1563  loss: 0.6990  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6990\n",
            "12/02 21:03:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][180/332]  lr: 1.0000e-02  eta: 0:47:04  time: 0.1973  data_time: 0.0116  memory: 5573  grad_norm: 1.1047  loss: 0.6689  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6689\n",
            "12/02 21:04:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][200/332]  lr: 1.0000e-02  eta: 0:46:59  time: 0.2060  data_time: 0.0144  memory: 5573  grad_norm: 1.3110  loss: 0.6853  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6853\n",
            "12/02 21:04:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][220/332]  lr: 1.0000e-02  eta: 0:46:56  time: 0.2381  data_time: 0.0288  memory: 5573  grad_norm: 1.0706  loss: 0.6869  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6869\n",
            "12/02 21:04:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][240/332]  lr: 1.0000e-02  eta: 0:46:52  time: 0.2284  data_time: 0.0241  memory: 5573  grad_norm: 1.1458  loss: 0.7056  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7056\n",
            "12/02 21:04:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][260/332]  lr: 1.0000e-02  eta: 0:46:46  time: 0.1977  data_time: 0.0114  memory: 5573  grad_norm: 1.0188  loss: 0.6837  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6837\n",
            "12/02 21:04:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][280/332]  lr: 1.0000e-02  eta: 0:46:40  time: 0.1980  data_time: 0.0120  memory: 5573  grad_norm: 1.4243  loss: 0.6880  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6880\n",
            "12/02 21:04:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][300/332]  lr: 1.0000e-02  eta: 0:46:36  time: 0.2267  data_time: 0.0245  memory: 5573  grad_norm: 1.3525  loss: 0.7409  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7409\n",
            "12/02 21:04:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][320/332]  lr: 1.0000e-02  eta: 0:46:32  time: 0.2361  data_time: 0.0292  memory: 5573  grad_norm: 1.1511  loss: 0.7049  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7049\n",
            "12/02 21:04:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:04:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][332/332]  lr: 1.0000e-02  eta: 0:46:29  time: 0.2211  data_time: 0.0237  memory: 5573  grad_norm: 1.2259  loss: 0.6956  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6956\n",
            "12/02 21:04:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n",
            "12/02 21:04:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][20/42]    eta: 0:00:02  time: 0.1015  data_time: 0.0349  memory: 909  \n",
            "12/02 21:04:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][40/42]    eta: 0:00:00  time: 0.0913  data_time: 0.0262  memory: 909  \n",
            "12/02 21:04:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0286  time: 0.0924\n",
            "12/02 21:04:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:04:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 20/332]  lr: 1.0000e-02  eta: 0:46:24  time: 0.2104  data_time: 0.0219  memory: 5573  grad_norm: 1.5697  loss: 0.6938  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6938\n",
            "12/02 21:04:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 40/332]  lr: 1.0000e-02  eta: 0:46:21  time: 0.2389  data_time: 0.0275  memory: 5573  grad_norm: 1.0098  loss: 0.6775  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6775\n",
            "12/02 21:04:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 60/332]  lr: 1.0000e-02  eta: 0:46:18  time: 0.2372  data_time: 0.0290  memory: 5573  grad_norm: 1.7342  loss: 0.7128  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7128\n",
            "12/02 21:04:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 80/332]  lr: 1.0000e-02  eta: 0:46:12  time: 0.1970  data_time: 0.0111  memory: 5573  grad_norm: 1.2478  loss: 0.7058  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7058\n",
            "12/02 21:04:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][100/332]  lr: 1.0000e-02  eta: 0:46:06  time: 0.1973  data_time: 0.0115  memory: 5573  grad_norm: 1.1943  loss: 0.7000  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7000\n",
            "12/02 21:05:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][120/332]  lr: 1.0000e-02  eta: 0:46:01  time: 0.2208  data_time: 0.0205  memory: 5573  grad_norm: 1.2202  loss: 0.7235  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7235\n",
            "12/02 21:05:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][140/332]  lr: 1.0000e-02  eta: 0:45:58  time: 0.2350  data_time: 0.0245  memory: 5573  grad_norm: 1.2153  loss: 0.7067  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7067\n",
            "12/02 21:05:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][160/332]  lr: 1.0000e-02  eta: 0:45:53  time: 0.2160  data_time: 0.0175  memory: 5573  grad_norm: 1.1443  loss: 0.6939  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6939\n",
            "12/02 21:05:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][180/332]  lr: 1.0000e-02  eta: 0:45:47  time: 0.1976  data_time: 0.0115  memory: 5573  grad_norm: 1.3417  loss: 0.6907  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6907\n",
            "12/02 21:05:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][200/332]  lr: 1.0000e-02  eta: 0:45:41  time: 0.1992  data_time: 0.0127  memory: 5573  grad_norm: 1.4325  loss: 0.7358  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7358\n",
            "12/02 21:05:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][220/332]  lr: 1.0000e-02  eta: 0:45:38  time: 0.2394  data_time: 0.0283  memory: 5573  grad_norm: 1.3399  loss: 0.7047  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7047\n",
            "12/02 21:05:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][240/332]  lr: 1.0000e-02  eta: 0:45:35  time: 0.2394  data_time: 0.0289  memory: 5573  grad_norm: 1.0057  loss: 0.6934  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6934\n",
            "12/02 21:05:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][260/332]  lr: 1.0000e-02  eta: 0:45:29  time: 0.1975  data_time: 0.0120  memory: 5573  grad_norm: 1.6286  loss: 0.7257  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7257\n",
            "12/02 21:05:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][280/332]  lr: 1.0000e-02  eta: 0:45:23  time: 0.1969  data_time: 0.0113  memory: 5573  grad_norm: 0.9002  loss: 0.6511  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6511\n",
            "12/02 21:05:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][300/332]  lr: 1.0000e-02  eta: 0:45:19  time: 0.2174  data_time: 0.0169  memory: 5573  grad_norm: 1.2429  loss: 0.7018  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7018\n",
            "12/02 21:05:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][320/332]  lr: 1.0000e-02  eta: 0:45:15  time: 0.2326  data_time: 0.0258  memory: 5573  grad_norm: 1.3009  loss: 0.7230  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7230\n",
            "12/02 21:05:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:05:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][332/332]  lr: 1.0000e-02  eta: 0:45:12  time: 0.2226  data_time: 0.0242  memory: 5573  grad_norm: 1.2093  loss: 0.7274  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7274\n",
            "12/02 21:05:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 13 epochs\n",
            "12/02 21:05:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][20/42]    eta: 0:00:02  time: 0.0982  data_time: 0.0308  memory: 909  \n",
            "12/02 21:05:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][40/42]    eta: 0:00:00  time: 0.0897  data_time: 0.0211  memory: 909  \n",
            "12/02 21:05:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][42/42]    acc/top1: 0.5589  acc/top5: 1.0000  acc/mean1: 0.5034  data_time: 0.0244  time: 0.0902\n",
            "12/02 21:05:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/flow_checkpoints/best_acc_top1_epoch_1.pth is removed\n",
            "12/02 21:05:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.5589 acc/top1 at 13 epoch is saved to best_acc_top1_epoch_13.pth.\n",
            "12/02 21:05:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 20/332]  lr: 1.0000e-02  eta: 0:45:07  time: 0.2123  data_time: 0.0220  memory: 5573  grad_norm: 1.4923  loss: 0.7137  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7137\n",
            "12/02 21:06:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 40/332]  lr: 1.0000e-02  eta: 0:45:04  time: 0.2393  data_time: 0.0274  memory: 5573  grad_norm: 0.9610  loss: 0.6528  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6528\n",
            "12/02 21:06:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 60/332]  lr: 1.0000e-02  eta: 0:45:00  time: 0.2388  data_time: 0.0309  memory: 5573  grad_norm: 1.2282  loss: 0.6954  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6954\n",
            "12/02 21:06:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 80/332]  lr: 1.0000e-02  eta: 0:44:55  time: 0.1963  data_time: 0.0110  memory: 5573  grad_norm: 1.0155  loss: 0.6586  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6586\n",
            "12/02 21:06:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][100/332]  lr: 1.0000e-02  eta: 0:44:49  time: 0.1973  data_time: 0.0115  memory: 5573  grad_norm: 1.0982  loss: 0.7024  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7024\n",
            "12/02 21:06:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][120/332]  lr: 1.0000e-02  eta: 0:44:44  time: 0.2218  data_time: 0.0202  memory: 5573  grad_norm: 1.1265  loss: 0.6933  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6933\n",
            "12/02 21:06:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][140/332]  lr: 1.0000e-02  eta: 0:44:41  time: 0.2377  data_time: 0.0287  memory: 5573  grad_norm: 1.4430  loss: 0.7263  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7263\n",
            "12/02 21:06:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][160/332]  lr: 1.0000e-02  eta: 0:44:37  time: 0.2202  data_time: 0.0205  memory: 5573  grad_norm: 1.1091  loss: 0.7124  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7124\n",
            "12/02 21:06:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][180/332]  lr: 1.0000e-02  eta: 0:44:31  time: 0.1976  data_time: 0.0115  memory: 5573  grad_norm: 0.7719  loss: 0.6385  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6385\n",
            "12/02 21:06:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][200/332]  lr: 1.0000e-02  eta: 0:44:25  time: 0.1996  data_time: 0.0127  memory: 5573  grad_norm: 0.8537  loss: 0.6865  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6865\n",
            "12/02 21:06:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][220/332]  lr: 1.0000e-02  eta: 0:44:22  time: 0.2381  data_time: 0.0288  memory: 5573  grad_norm: 1.0640  loss: 0.7021  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7021\n",
            "12/02 21:06:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][240/332]  lr: 1.0000e-02  eta: 0:44:18  time: 0.2383  data_time: 0.0284  memory: 5573  grad_norm: 0.9454  loss: 0.6752  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6752\n",
            "12/02 21:06:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][260/332]  lr: 1.0000e-02  eta: 0:44:13  time: 0.1971  data_time: 0.0109  memory: 5573  grad_norm: 1.2307  loss: 0.6992  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6992\n",
            "12/02 21:06:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][280/332]  lr: 1.0000e-02  eta: 0:44:07  time: 0.1974  data_time: 0.0118  memory: 5573  grad_norm: 1.1299  loss: 0.7122  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7122\n",
            "12/02 21:06:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][300/332]  lr: 1.0000e-02  eta: 0:44:02  time: 0.2172  data_time: 0.0203  memory: 5573  grad_norm: 0.9670  loss: 0.6941  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6941\n",
            "12/02 21:07:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][320/332]  lr: 1.0000e-02  eta: 0:43:59  time: 0.2382  data_time: 0.0294  memory: 5573  grad_norm: 1.4563  loss: 0.7409  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7409\n",
            "12/02 21:07:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:07:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][332/332]  lr: 1.0000e-02  eta: 0:43:56  time: 0.2236  data_time: 0.0241  memory: 5573  grad_norm: 1.1714  loss: 0.7030  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7030\n",
            "12/02 21:07:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 14 epochs\n",
            "12/02 21:07:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][20/42]    eta: 0:00:02  time: 0.1016  data_time: 0.0341  memory: 909  \n",
            "12/02 21:07:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][40/42]    eta: 0:00:00  time: 0.0870  data_time: 0.0200  memory: 909  \n",
            "12/02 21:07:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0256  time: 0.0907\n",
            "12/02 21:07:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 20/332]  lr: 1.0000e-02  eta: 0:43:51  time: 0.2060  data_time: 0.0193  memory: 5573  grad_norm: 0.9384  loss: 0.6928  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6928\n",
            "12/02 21:07:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 40/332]  lr: 1.0000e-02  eta: 0:43:47  time: 0.2267  data_time: 0.0227  memory: 5573  grad_norm: 1.1035  loss: 0.7092  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7092\n",
            "12/02 21:07:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 60/332]  lr: 1.0000e-02  eta: 0:43:43  time: 0.2388  data_time: 0.0294  memory: 5573  grad_norm: 0.9999  loss: 0.6995  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6995\n",
            "12/02 21:07:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 80/332]  lr: 1.0000e-02  eta: 0:43:38  time: 0.2065  data_time: 0.0159  memory: 5573  grad_norm: 1.1847  loss: 0.7316  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7316\n",
            "12/02 21:07:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][100/332]  lr: 1.0000e-02  eta: 0:43:33  time: 0.1971  data_time: 0.0115  memory: 5573  grad_norm: 1.1895  loss: 0.7069  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7069\n",
            "12/02 21:07:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][120/332]  lr: 1.0000e-02  eta: 0:43:27  time: 0.2061  data_time: 0.0141  memory: 5573  grad_norm: 1.1116  loss: 0.7050  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7050\n",
            "12/02 21:07:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][140/332]  lr: 1.0000e-02  eta: 0:43:24  time: 0.2374  data_time: 0.0279  memory: 5573  grad_norm: 0.9724  loss: 0.7047  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7047\n",
            "12/02 21:07:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][160/332]  lr: 1.0000e-02  eta: 0:43:20  time: 0.2297  data_time: 0.0254  memory: 5573  grad_norm: 1.1485  loss: 0.6831  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6831\n",
            "12/02 21:07:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][180/332]  lr: 1.0000e-02  eta: 0:43:14  time: 0.1971  data_time: 0.0116  memory: 5573  grad_norm: 0.7292  loss: 0.6650  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6650\n",
            "12/02 21:07:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][200/332]  lr: 1.0000e-02  eta: 0:43:09  time: 0.1979  data_time: 0.0122  memory: 5573  grad_norm: 0.8404  loss: 0.6654  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6654\n",
            "12/02 21:07:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][220/332]  lr: 1.0000e-02  eta: 0:43:05  time: 0.2265  data_time: 0.0233  memory: 5573  grad_norm: 1.1598  loss: 0.7106  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7106\n",
            "12/02 21:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][240/332]  lr: 1.0000e-02  eta: 0:43:01  time: 0.2297  data_time: 0.0230  memory: 5573  grad_norm: 1.1146  loss: 0.7232  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7232\n",
            "12/02 21:08:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][260/332]  lr: 1.0000e-02  eta: 0:42:56  time: 0.2118  data_time: 0.0177  memory: 5573  grad_norm: 1.4351  loss: 0.7169  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7169\n",
            "12/02 21:08:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][280/332]  lr: 1.0000e-02  eta: 0:42:51  time: 0.1981  data_time: 0.0119  memory: 5573  grad_norm: 1.1160  loss: 0.7064  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7064\n",
            "12/02 21:08:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][300/332]  lr: 1.0000e-02  eta: 0:42:45  time: 0.2038  data_time: 0.0140  memory: 5573  grad_norm: 0.9788  loss: 0.7031  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7031\n",
            "12/02 21:08:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][320/332]  lr: 1.0000e-02  eta: 0:42:42  time: 0.2349  data_time: 0.0272  memory: 5573  grad_norm: 0.9599  loss: 0.6960  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6960\n",
            "12/02 21:08:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:08:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][332/332]  lr: 1.0000e-02  eta: 0:42:39  time: 0.2225  data_time: 0.0241  memory: 5573  grad_norm: 1.1013  loss: 0.6809  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6809\n",
            "12/02 21:08:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 15 epochs\n",
            "12/02 21:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][20/42]    eta: 0:00:02  time: 0.0961  data_time: 0.0285  memory: 909  \n",
            "12/02 21:08:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][40/42]    eta: 0:00:00  time: 0.0885  data_time: 0.0204  memory: 909  \n",
            "12/02 21:08:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0233  time: 0.0889\n",
            "12/02 21:08:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:08:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 20/332]  lr: 1.0000e-02  eta: 0:42:34  time: 0.2087  data_time: 0.0217  memory: 5573  grad_norm: 1.0356  loss: 0.7062  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7062\n",
            "12/02 21:08:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 40/332]  lr: 1.0000e-02  eta: 0:42:29  time: 0.2165  data_time: 0.0182  memory: 5573  grad_norm: 0.7614  loss: 0.6686  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6686\n",
            "12/02 21:08:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 60/332]  lr: 1.0000e-02  eta: 0:42:26  time: 0.2359  data_time: 0.0267  memory: 5573  grad_norm: 0.8818  loss: 0.6872  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6872\n",
            "12/02 21:08:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 80/332]  lr: 1.0000e-02  eta: 0:42:21  time: 0.2221  data_time: 0.0244  memory: 5573  grad_norm: 1.4109  loss: 0.7178  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7178\n",
            "12/02 21:08:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][100/332]  lr: 1.0000e-02  eta: 0:42:16  time: 0.1970  data_time: 0.0113  memory: 5573  grad_norm: 1.2489  loss: 0.7453  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7453\n",
            "12/02 21:08:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][120/332]  lr: 1.0000e-02  eta: 0:42:10  time: 0.1979  data_time: 0.0116  memory: 5573  grad_norm: 1.0803  loss: 0.7037  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7037\n",
            "12/02 21:08:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][140/332]  lr: 1.0000e-02  eta: 0:42:07  time: 0.2312  data_time: 0.0244  memory: 5573  grad_norm: 1.6033  loss: 0.7620  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7620\n",
            "12/02 21:09:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][160/332]  lr: 1.0000e-02  eta: 0:42:03  time: 0.2382  data_time: 0.0267  memory: 5573  grad_norm: 1.0207  loss: 0.6909  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6909\n",
            "12/02 21:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][180/332]  lr: 1.0000e-02  eta: 0:41:58  time: 0.2019  data_time: 0.0142  memory: 5573  grad_norm: 0.7752  loss: 0.6606  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6606\n",
            "12/02 21:09:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][200/332]  lr: 1.0000e-02  eta: 0:41:52  time: 0.1977  data_time: 0.0118  memory: 5573  grad_norm: 1.0314  loss: 0.6631  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6631\n",
            "12/02 21:09:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][220/332]  lr: 1.0000e-02  eta: 0:41:48  time: 0.2128  data_time: 0.0185  memory: 5573  grad_norm: 1.2135  loss: 0.7107  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7107\n",
            "12/02 21:09:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][240/332]  lr: 1.0000e-02  eta: 0:41:44  time: 0.2370  data_time: 0.0285  memory: 5573  grad_norm: 1.2818  loss: 0.6996  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6996\n",
            "12/02 21:09:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][260/332]  lr: 1.0000e-02  eta: 0:41:40  time: 0.2220  data_time: 0.0206  memory: 5573  grad_norm: 1.5084  loss: 0.7084  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7084\n",
            "12/02 21:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][280/332]  lr: 1.0000e-02  eta: 0:41:34  time: 0.1978  data_time: 0.0116  memory: 5573  grad_norm: 0.8339  loss: 0.6923  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6923\n",
            "12/02 21:09:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][300/332]  lr: 1.0000e-02  eta: 0:41:29  time: 0.1974  data_time: 0.0116  memory: 5573  grad_norm: 1.0539  loss: 0.7002  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7002\n",
            "12/02 21:09:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][320/332]  lr: 1.0000e-02  eta: 0:41:25  time: 0.2295  data_time: 0.0244  memory: 5573  grad_norm: 0.8849  loss: 0.7013  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7013\n",
            "12/02 21:09:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:09:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][332/332]  lr: 1.0000e-02  eta: 0:41:22  time: 0.2248  data_time: 0.0258  memory: 5573  grad_norm: 0.8899  loss: 0.6676  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6676\n",
            "12/02 21:09:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 16 epochs\n",
            "12/02 21:09:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][20/42]    eta: 0:00:02  time: 0.1233  data_time: 0.0547  memory: 909  \n",
            "12/02 21:09:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][40/42]    eta: 0:00:00  time: 0.0906  data_time: 0.0258  memory: 909  \n",
            "12/02 21:09:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0378  time: 0.1025\n",
            "12/02 21:09:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 20/332]  lr: 1.0000e-02  eta: 0:41:17  time: 0.2081  data_time: 0.0213  memory: 5573  grad_norm: 0.8101  loss: 0.6871  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6871\n",
            "12/02 21:09:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 40/332]  lr: 1.0000e-02  eta: 0:41:13  time: 0.2116  data_time: 0.0158  memory: 5573  grad_norm: 0.9591  loss: 0.7024  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7024\n",
            "12/02 21:09:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 60/332]  lr: 1.0000e-02  eta: 0:41:09  time: 0.2363  data_time: 0.0248  memory: 5573  grad_norm: 1.0258  loss: 0.6931  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6931\n",
            "12/02 21:10:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 80/332]  lr: 1.0000e-02  eta: 0:41:05  time: 0.2263  data_time: 0.0231  memory: 5573  grad_norm: 0.8822  loss: 0.7031  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7031\n",
            "12/02 21:10:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][100/332]  lr: 1.0000e-02  eta: 0:40:59  time: 0.1971  data_time: 0.0115  memory: 5573  grad_norm: 1.2494  loss: 0.7505  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7505\n",
            "12/02 21:10:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][120/332]  lr: 1.0000e-02  eta: 0:40:54  time: 0.1985  data_time: 0.0123  memory: 5573  grad_norm: 1.0380  loss: 0.7124  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7124\n",
            "12/02 21:10:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][140/332]  lr: 1.0000e-02  eta: 0:40:50  time: 0.2317  data_time: 0.0255  memory: 5573  grad_norm: 1.0214  loss: 0.6720  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6720\n",
            "12/02 21:10:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][160/332]  lr: 1.0000e-02  eta: 0:40:46  time: 0.2334  data_time: 0.0261  memory: 5573  grad_norm: 0.9113  loss: 0.6812  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6812\n",
            "12/02 21:10:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][180/332]  lr: 1.0000e-02  eta: 0:40:41  time: 0.2060  data_time: 0.0159  memory: 5573  grad_norm: 1.1157  loss: 0.6907  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6907\n",
            "12/02 21:10:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][200/332]  lr: 1.0000e-02  eta: 0:40:36  time: 0.1981  data_time: 0.0123  memory: 5573  grad_norm: 1.1772  loss: 0.6934  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6934\n",
            "12/02 21:10:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][220/332]  lr: 1.0000e-02  eta: 0:40:31  time: 0.2120  data_time: 0.0158  memory: 5573  grad_norm: 1.0298  loss: 0.7311  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7311\n",
            "12/02 21:10:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][240/332]  lr: 1.0000e-02  eta: 0:40:28  time: 0.2383  data_time: 0.0278  memory: 5573  grad_norm: 0.9601  loss: 0.6939  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6939\n",
            "12/02 21:10:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][260/332]  lr: 1.0000e-02  eta: 0:40:24  time: 0.2245  data_time: 0.0232  memory: 5573  grad_norm: 0.8904  loss: 0.6947  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6947\n",
            "12/02 21:10:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][280/332]  lr: 1.0000e-02  eta: 0:40:18  time: 0.1970  data_time: 0.0116  memory: 5573  grad_norm: 1.1107  loss: 0.6933  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6933\n",
            "12/02 21:10:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][300/332]  lr: 1.0000e-02  eta: 0:40:13  time: 0.1977  data_time: 0.0115  memory: 5573  grad_norm: 0.9520  loss: 0.6758  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6758\n",
            "12/02 21:10:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][320/332]  lr: 1.0000e-02  eta: 0:40:09  time: 0.2302  data_time: 0.0241  memory: 5573  grad_norm: 0.9714  loss: 0.6988  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6988\n",
            "12/02 21:10:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:10:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][332/332]  lr: 1.0000e-02  eta: 0:40:06  time: 0.2237  data_time: 0.0238  memory: 5573  grad_norm: 1.0505  loss: 0.6865  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6865\n",
            "12/02 21:10:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 17 epochs\n",
            "12/02 21:11:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][20/42]    eta: 0:00:02  time: 0.1296  data_time: 0.0559  memory: 909  \n",
            "12/02 21:11:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][40/42]    eta: 0:00:00  time: 0.0938  data_time: 0.0270  memory: 909  \n",
            "12/02 21:11:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0389  time: 0.1067\n",
            "12/02 21:11:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 20/332]  lr: 1.0000e-02  eta: 0:40:01  time: 0.2084  data_time: 0.0209  memory: 5573  grad_norm: 0.8707  loss: 0.6720  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6720\n",
            "12/02 21:11:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 40/332]  lr: 1.0000e-02  eta: 0:39:57  time: 0.2058  data_time: 0.0147  memory: 5573  grad_norm: 1.3746  loss: 0.7288  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7288\n",
            "12/02 21:11:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 60/332]  lr: 1.0000e-02  eta: 0:39:53  time: 0.2329  data_time: 0.0274  memory: 5573  grad_norm: 1.2456  loss: 0.7304  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7304\n",
            "12/02 21:11:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 80/332]  lr: 1.0000e-02  eta: 0:39:49  time: 0.2323  data_time: 0.0255  memory: 5573  grad_norm: 0.8094  loss: 0.6758  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6758\n",
            "12/02 21:11:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][100/332]  lr: 1.0000e-02  eta: 0:39:44  time: 0.1977  data_time: 0.0116  memory: 5573  grad_norm: 0.8625  loss: 0.6745  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6745\n",
            "12/02 21:11:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][120/332]  lr: 1.0000e-02  eta: 0:39:38  time: 0.1975  data_time: 0.0120  memory: 5573  grad_norm: 0.9559  loss: 0.6610  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6610\n",
            "12/02 21:11:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][140/332]  lr: 1.0000e-02  eta: 0:39:34  time: 0.2263  data_time: 0.0248  memory: 5573  grad_norm: 1.0251  loss: 0.7375  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7375\n",
            "12/02 21:11:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][160/332]  lr: 1.0000e-02  eta: 0:39:30  time: 0.2384  data_time: 0.0284  memory: 5573  grad_norm: 0.8003  loss: 0.6796  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6796\n",
            "12/02 21:11:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][180/332]  lr: 1.0000e-02  eta: 0:39:26  time: 0.2115  data_time: 0.0156  memory: 5573  grad_norm: 0.9024  loss: 0.6995  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6995\n",
            "12/02 21:11:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][200/332]  lr: 1.0000e-02  eta: 0:39:21  time: 0.1981  data_time: 0.0120  memory: 5573  grad_norm: 1.2199  loss: 0.7055  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7055\n",
            "12/02 21:11:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][220/332]  lr: 1.0000e-02  eta: 0:39:15  time: 0.1998  data_time: 0.0124  memory: 5573  grad_norm: 1.1060  loss: 0.6616  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6616\n",
            "12/02 21:11:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][240/332]  lr: 1.0000e-02  eta: 0:39:12  time: 0.2406  data_time: 0.0311  memory: 5573  grad_norm: 0.7881  loss: 0.6423  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6423\n",
            "12/02 21:11:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][260/332]  lr: 1.0000e-02  eta: 0:39:08  time: 0.2309  data_time: 0.0262  memory: 5573  grad_norm: 0.8717  loss: 0.6560  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6560\n",
            "12/02 21:12:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][280/332]  lr: 1.0000e-02  eta: 0:39:03  time: 0.1978  data_time: 0.0121  memory: 5573  grad_norm: 1.1260  loss: 0.7446  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7446\n",
            "12/02 21:12:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][300/332]  lr: 1.0000e-02  eta: 0:38:58  time: 0.1972  data_time: 0.0113  memory: 5573  grad_norm: 1.0530  loss: 0.6930  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6930\n",
            "12/02 21:12:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][320/332]  lr: 1.0000e-02  eta: 0:38:53  time: 0.2204  data_time: 0.0188  memory: 5573  grad_norm: 1.1611  loss: 0.7134  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7134\n",
            "12/02 21:12:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:12:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][332/332]  lr: 1.0000e-02  eta: 0:38:51  time: 0.2325  data_time: 0.0234  memory: 5573  grad_norm: 1.2040  loss: 0.7110  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7110\n",
            "12/02 21:12:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 18 epochs\n",
            "12/02 21:12:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][20/42]    eta: 0:00:03  time: 0.1604  data_time: 0.0875  memory: 909  \n",
            "12/02 21:12:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][40/42]    eta: 0:00:00  time: 0.0983  data_time: 0.0344  memory: 909  \n",
            "12/02 21:12:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0570  time: 0.1231\n",
            "12/02 21:12:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 20/332]  lr: 1.0000e-02  eta: 0:38:46  time: 0.2090  data_time: 0.0217  memory: 5573  grad_norm: 1.1375  loss: 0.7464  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7464\n",
            "12/02 21:12:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:12:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 40/332]  lr: 1.0000e-02  eta: 0:38:41  time: 0.2015  data_time: 0.0137  memory: 5573  grad_norm: 1.3260  loss: 0.7590  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7590\n",
            "12/02 21:12:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 60/332]  lr: 1.0000e-02  eta: 0:38:38  time: 0.2509  data_time: 0.0332  memory: 5573  grad_norm: 0.8728  loss: 0.6934  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6934\n",
            "12/02 21:12:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 80/332]  lr: 1.0000e-02  eta: 0:38:34  time: 0.2416  data_time: 0.0293  memory: 5573  grad_norm: 1.0669  loss: 0.7250  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7250\n",
            "12/02 21:12:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][100/332]  lr: 1.0000e-02  eta: 0:38:29  time: 0.1995  data_time: 0.0125  memory: 5573  grad_norm: 0.9824  loss: 0.6978  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6978\n",
            "12/02 21:12:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][120/332]  lr: 1.0000e-02  eta: 0:38:24  time: 0.1994  data_time: 0.0129  memory: 5573  grad_norm: 0.8312  loss: 0.6749  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6749\n",
            "12/02 21:12:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][140/332]  lr: 1.0000e-02  eta: 0:38:19  time: 0.2193  data_time: 0.0194  memory: 5573  grad_norm: 1.0557  loss: 0.7222  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7222\n",
            "12/02 21:12:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][160/332]  lr: 1.0000e-02  eta: 0:38:16  time: 0.2411  data_time: 0.0303  memory: 5573  grad_norm: 1.1717  loss: 0.6742  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6742\n",
            "12/02 21:13:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][180/332]  lr: 1.0000e-02  eta: 0:38:11  time: 0.2161  data_time: 0.0181  memory: 5573  grad_norm: 0.9404  loss: 0.6691  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6691\n",
            "12/02 21:13:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][200/332]  lr: 1.0000e-02  eta: 0:38:06  time: 0.1981  data_time: 0.0120  memory: 5573  grad_norm: 0.9703  loss: 0.6917  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6917\n",
            "12/02 21:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][220/332]  lr: 1.0000e-02  eta: 0:38:01  time: 0.2025  data_time: 0.0135  memory: 5573  grad_norm: 1.2992  loss: 0.6851  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6851\n",
            "12/02 21:13:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][240/332]  lr: 1.0000e-02  eta: 0:37:58  time: 0.2462  data_time: 0.0285  memory: 5573  grad_norm: 0.9861  loss: 0.6968  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6968\n",
            "12/02 21:13:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][260/332]  lr: 1.0000e-02  eta: 0:37:54  time: 0.2378  data_time: 0.0262  memory: 5573  grad_norm: 1.0047  loss: 0.6535  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6535\n",
            "12/02 21:13:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][280/332]  lr: 1.0000e-02  eta: 0:37:49  time: 0.2015  data_time: 0.0134  memory: 5573  grad_norm: 0.9261  loss: 0.7127  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7127\n",
            "12/02 21:13:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][300/332]  lr: 1.0000e-02  eta: 0:37:44  time: 0.1979  data_time: 0.0116  memory: 5573  grad_norm: 1.4728  loss: 0.7128  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7128\n",
            "12/02 21:13:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][320/332]  lr: 1.0000e-02  eta: 0:37:39  time: 0.2196  data_time: 0.0189  memory: 5573  grad_norm: 1.1189  loss: 0.7235  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7235\n",
            "12/02 21:13:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:13:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][332/332]  lr: 1.0000e-02  eta: 0:37:37  time: 0.2294  data_time: 0.0247  memory: 5573  grad_norm: 0.9615  loss: 0.6969  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6969\n",
            "12/02 21:13:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 19 epochs\n",
            "12/02 21:13:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][20/42]    eta: 0:00:03  time: 0.1644  data_time: 0.0825  memory: 909  \n",
            "12/02 21:13:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][40/42]    eta: 0:00:00  time: 0.0972  data_time: 0.0328  memory: 909  \n",
            "12/02 21:13:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0541  time: 0.1246\n",
            "12/02 21:13:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 20/332]  lr: 1.0000e-02  eta: 0:37:32  time: 0.2056  data_time: 0.0201  memory: 5573  grad_norm: 1.4958  loss: 0.6972  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6972\n",
            "12/02 21:13:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 40/332]  lr: 1.0000e-02  eta: 0:37:27  time: 0.1972  data_time: 0.0113  memory: 5573  grad_norm: 0.8247  loss: 0.6795  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6795\n",
            "12/02 21:13:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 60/332]  lr: 1.0000e-02  eta: 0:37:23  time: 0.2346  data_time: 0.0300  memory: 5573  grad_norm: 1.0783  loss: 0.7005  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7005\n",
            "12/02 21:13:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 80/332]  lr: 1.0000e-02  eta: 0:37:19  time: 0.2403  data_time: 0.0305  memory: 5573  grad_norm: 1.0263  loss: 0.7119  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7119\n",
            "12/02 21:14:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][100/332]  lr: 1.0000e-02  eta: 0:37:14  time: 0.1984  data_time: 0.0123  memory: 5573  grad_norm: 1.2763  loss: 0.7294  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7294\n",
            "12/02 21:14:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][120/332]  lr: 1.0000e-02  eta: 0:37:09  time: 0.1963  data_time: 0.0110  memory: 5573  grad_norm: 0.8181  loss: 0.6760  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6760\n",
            "12/02 21:14:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][140/332]  lr: 1.0000e-02  eta: 0:37:05  time: 0.2170  data_time: 0.0193  memory: 5573  grad_norm: 0.8658  loss: 0.6658  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6658\n",
            "12/02 21:14:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][160/332]  lr: 1.0000e-02  eta: 0:37:01  time: 0.2360  data_time: 0.0269  memory: 5573  grad_norm: 0.9195  loss: 0.6829  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6829\n",
            "12/02 21:14:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][180/332]  lr: 1.0000e-02  eta: 0:36:56  time: 0.2222  data_time: 0.0236  memory: 5573  grad_norm: 1.3100  loss: 0.7280  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7280\n",
            "12/02 21:14:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][200/332]  lr: 1.0000e-02  eta: 0:36:51  time: 0.1972  data_time: 0.0115  memory: 5573  grad_norm: 0.8020  loss: 0.6832  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6832\n",
            "12/02 21:14:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][220/332]  lr: 1.0000e-02  eta: 0:36:46  time: 0.1978  data_time: 0.0114  memory: 5573  grad_norm: 1.2280  loss: 0.7177  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7177\n",
            "12/02 21:14:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][240/332]  lr: 1.0000e-02  eta: 0:36:42  time: 0.2306  data_time: 0.0254  memory: 5573  grad_norm: 1.2721  loss: 0.6999  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6999\n",
            "12/02 21:14:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][260/332]  lr: 1.0000e-02  eta: 0:36:39  time: 0.2447  data_time: 0.0298  memory: 5573  grad_norm: 0.9618  loss: 0.7382  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7382\n",
            "12/02 21:14:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][280/332]  lr: 1.0000e-02  eta: 0:36:34  time: 0.1993  data_time: 0.0131  memory: 5573  grad_norm: 0.9079  loss: 0.6757  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6757\n",
            "12/02 21:14:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][300/332]  lr: 1.0000e-02  eta: 0:36:29  time: 0.1978  data_time: 0.0118  memory: 5573  grad_norm: 1.2439  loss: 0.7169  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7169\n",
            "12/02 21:14:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][320/332]  lr: 1.0000e-02  eta: 0:36:24  time: 0.2188  data_time: 0.0205  memory: 5573  grad_norm: 0.7953  loss: 0.6892  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6892\n",
            "12/02 21:14:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:14:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][332/332]  lr: 1.0000e-02  eta: 0:36:22  time: 0.2275  data_time: 0.0258  memory: 5573  grad_norm: 0.8229  loss: 0.6638  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6638\n",
            "12/02 21:14:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 20 epochs\n",
            "12/02 21:14:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][20/42]    eta: 0:00:03  time: 0.1557  data_time: 0.0801  memory: 909  \n",
            "12/02 21:14:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][40/42]    eta: 0:00:00  time: 0.1082  data_time: 0.0401  memory: 909  \n",
            "12/02 21:14:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0563  time: 0.1257\n",
            "12/02 21:15:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 20/332]  lr: 1.0000e-03  eta: 0:36:17  time: 0.2080  data_time: 0.0218  memory: 5573  grad_norm: 1.1328  loss: 0.6792  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6792\n",
            "12/02 21:15:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 40/332]  lr: 1.0000e-03  eta: 0:36:12  time: 0.1980  data_time: 0.0119  memory: 5573  grad_norm: 1.0420  loss: 0.6877  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6877\n",
            "12/02 21:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 60/332]  lr: 1.0000e-03  eta: 0:36:08  time: 0.2364  data_time: 0.0291  memory: 5573  grad_norm: 1.1849  loss: 0.7469  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7469\n",
            "12/02 21:15:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 80/332]  lr: 1.0000e-03  eta: 0:36:04  time: 0.2375  data_time: 0.0295  memory: 5573  grad_norm: 0.8738  loss: 0.6670  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6670\n",
            "12/02 21:15:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][100/332]  lr: 1.0000e-03  eta: 0:35:59  time: 0.2036  data_time: 0.0147  memory: 5573  grad_norm: 1.0361  loss: 0.6913  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6913\n",
            "12/02 21:15:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][120/332]  lr: 1.0000e-03  eta: 0:35:54  time: 0.1973  data_time: 0.0113  memory: 5573  grad_norm: 0.9127  loss: 0.7398  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7398\n",
            "12/02 21:15:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][140/332]  lr: 1.0000e-03  eta: 0:35:50  time: 0.2128  data_time: 0.0172  memory: 5573  grad_norm: 1.1316  loss: 0.7266  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7266\n",
            "12/02 21:15:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][160/332]  lr: 1.0000e-03  eta: 0:35:46  time: 0.2363  data_time: 0.0262  memory: 5573  grad_norm: 0.8762  loss: 0.7010  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7010\n",
            "12/02 21:15:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][180/332]  lr: 1.0000e-03  eta: 0:35:42  time: 0.2228  data_time: 0.0219  memory: 5573  grad_norm: 1.3986  loss: 0.6798  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6798\n",
            "12/02 21:15:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][200/332]  lr: 1.0000e-03  eta: 0:35:37  time: 0.1986  data_time: 0.0125  memory: 5573  grad_norm: 0.8401  loss: 0.6910  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6910\n",
            "12/02 21:15:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][220/332]  lr: 1.0000e-03  eta: 0:35:32  time: 0.1972  data_time: 0.0117  memory: 5573  grad_norm: 0.8410  loss: 0.7161  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7161\n",
            "12/02 21:15:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][240/332]  lr: 1.0000e-03  eta: 0:35:28  time: 0.2358  data_time: 0.0246  memory: 5573  grad_norm: 0.9967  loss: 0.6855  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6855\n",
            "12/02 21:15:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][260/332]  lr: 1.0000e-03  eta: 0:35:24  time: 0.2403  data_time: 0.0291  memory: 5573  grad_norm: 0.8617  loss: 0.7078  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7078\n",
            "12/02 21:15:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][280/332]  lr: 1.0000e-03  eta: 0:35:19  time: 0.2014  data_time: 0.0146  memory: 5573  grad_norm: 1.0278  loss: 0.7001  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7001\n",
            "12/02 21:16:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][300/332]  lr: 1.0000e-03  eta: 0:35:14  time: 0.1980  data_time: 0.0121  memory: 5573  grad_norm: 0.7936  loss: 0.6594  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6594\n",
            "12/02 21:16:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][320/332]  lr: 1.0000e-03  eta: 0:35:10  time: 0.2091  data_time: 0.0165  memory: 5573  grad_norm: 0.7899  loss: 0.6721  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6721\n",
            "12/02 21:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][332/332]  lr: 1.0000e-03  eta: 0:35:07  time: 0.2178  data_time: 0.0216  memory: 5573  grad_norm: 0.8318  loss: 0.6811  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6811\n",
            "12/02 21:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 21 epochs\n",
            "12/02 21:16:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][20/42]    eta: 0:00:03  time: 0.1592  data_time: 0.0869  memory: 909  \n",
            "12/02 21:16:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][40/42]    eta: 0:00:00  time: 0.1099  data_time: 0.0399  memory: 909  \n",
            "12/02 21:16:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0593  time: 0.1280\n",
            "12/02 21:16:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 20/332]  lr: 1.0000e-03  eta: 0:35:02  time: 0.2063  data_time: 0.0202  memory: 5573  grad_norm: 1.0951  loss: 0.6764  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6764\n",
            "12/02 21:16:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:16:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 40/332]  lr: 1.0000e-03  eta: 0:34:57  time: 0.1971  data_time: 0.0114  memory: 5573  grad_norm: 0.8038  loss: 0.6700  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6700\n",
            "12/02 21:16:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 60/332]  lr: 1.0000e-03  eta: 0:34:53  time: 0.2353  data_time: 0.0290  memory: 5573  grad_norm: 0.9713  loss: 0.6762  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6762\n",
            "12/02 21:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 80/332]  lr: 1.0000e-03  eta: 0:34:49  time: 0.2398  data_time: 0.0296  memory: 5573  grad_norm: 1.0649  loss: 0.6903  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6903\n",
            "12/02 21:16:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][100/332]  lr: 1.0000e-03  eta: 0:34:44  time: 0.2003  data_time: 0.0127  memory: 5573  grad_norm: 0.9035  loss: 0.6727  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6727\n",
            "12/02 21:16:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][120/332]  lr: 1.0000e-03  eta: 0:34:40  time: 0.1980  data_time: 0.0123  memory: 5573  grad_norm: 0.7738  loss: 0.6601  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6601\n",
            "12/02 21:16:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][140/332]  lr: 1.0000e-03  eta: 0:34:35  time: 0.2149  data_time: 0.0177  memory: 5573  grad_norm: 0.8254  loss: 0.6869  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6869\n",
            "12/02 21:16:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][160/332]  lr: 1.0000e-03  eta: 0:34:31  time: 0.2382  data_time: 0.0287  memory: 5573  grad_norm: 0.9362  loss: 0.6911  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6911\n",
            "12/02 21:16:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][180/332]  lr: 1.0000e-03  eta: 0:34:27  time: 0.2267  data_time: 0.0239  memory: 5573  grad_norm: 2.1523  loss: 0.6887  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6887\n",
            "12/02 21:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][200/332]  lr: 1.0000e-03  eta: 0:34:22  time: 0.1976  data_time: 0.0116  memory: 5573  grad_norm: 1.3548  loss: 0.7538  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7538\n",
            "12/02 21:17:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][220/332]  lr: 1.0000e-03  eta: 0:34:17  time: 0.1973  data_time: 0.0116  memory: 5573  grad_norm: 0.7743  loss: 0.6724  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6724\n",
            "12/02 21:17:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][240/332]  lr: 1.0000e-03  eta: 0:34:13  time: 0.2310  data_time: 0.0261  memory: 5573  grad_norm: 0.8175  loss: 0.6641  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6641\n",
            "12/02 21:17:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][260/332]  lr: 1.0000e-03  eta: 0:34:09  time: 0.2380  data_time: 0.0260  memory: 5573  grad_norm: 1.2362  loss: 0.7173  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7173\n",
            "12/02 21:17:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][280/332]  lr: 1.0000e-03  eta: 0:34:05  time: 0.2065  data_time: 0.0145  memory: 5573  grad_norm: 0.9798  loss: 0.7109  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7109\n",
            "12/02 21:17:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][300/332]  lr: 1.0000e-03  eta: 0:34:00  time: 0.1997  data_time: 0.0128  memory: 5573  grad_norm: 0.9065  loss: 0.6836  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6836\n",
            "12/02 21:17:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][320/332]  lr: 1.0000e-03  eta: 0:33:55  time: 0.2104  data_time: 0.0169  memory: 5573  grad_norm: 0.8257  loss: 0.6636  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6636\n",
            "12/02 21:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][332/332]  lr: 1.0000e-03  eta: 0:33:52  time: 0.2237  data_time: 0.0242  memory: 5573  grad_norm: 0.8759  loss: 0.6792  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6792\n",
            "12/02 21:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 22 epochs\n",
            "12/02 21:17:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][20/42]    eta: 0:00:03  time: 0.1515  data_time: 0.0748  memory: 909  \n",
            "12/02 21:17:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][40/42]    eta: 0:00:00  time: 0.1177  data_time: 0.0497  memory: 909  \n",
            "12/02 21:17:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0583  time: 0.1281\n",
            "12/02 21:17:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 20/332]  lr: 1.0000e-03  eta: 0:33:48  time: 0.2068  data_time: 0.0207  memory: 5573  grad_norm: 0.8392  loss: 0.6774  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6774\n",
            "12/02 21:17:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 40/332]  lr: 1.0000e-03  eta: 0:33:43  time: 0.1975  data_time: 0.0117  memory: 5573  grad_norm: 0.9401  loss: 0.7077  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7077\n",
            "12/02 21:17:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 60/332]  lr: 1.0000e-03  eta: 0:33:39  time: 0.2340  data_time: 0.0282  memory: 5573  grad_norm: 1.0784  loss: 0.7047  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7047\n",
            "12/02 21:17:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 80/332]  lr: 1.0000e-03  eta: 0:33:35  time: 0.2380  data_time: 0.0254  memory: 5573  grad_norm: 0.8980  loss: 0.6840  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6840\n",
            "12/02 21:17:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][100/332]  lr: 1.0000e-03  eta: 0:33:30  time: 0.2066  data_time: 0.0150  memory: 5573  grad_norm: 0.8096  loss: 0.6615  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6615\n",
            "12/02 21:17:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][120/332]  lr: 1.0000e-03  eta: 0:33:25  time: 0.1975  data_time: 0.0119  memory: 5573  grad_norm: 1.3520  loss: 0.6960  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6960\n",
            "12/02 21:18:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][140/332]  lr: 1.0000e-03  eta: 0:33:21  time: 0.2127  data_time: 0.0188  memory: 5573  grad_norm: 0.7531  loss: 0.6753  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6753\n",
            "12/02 21:18:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][160/332]  lr: 1.0000e-03  eta: 0:33:17  time: 0.2366  data_time: 0.0268  memory: 5573  grad_norm: 1.2586  loss: 0.7152  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7152\n",
            "12/02 21:18:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][180/332]  lr: 1.0000e-03  eta: 0:33:13  time: 0.2261  data_time: 0.0243  memory: 5573  grad_norm: 0.7508  loss: 0.6566  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6566\n",
            "12/02 21:18:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][200/332]  lr: 1.0000e-03  eta: 0:33:08  time: 0.1975  data_time: 0.0117  memory: 5573  grad_norm: 0.9475  loss: 0.6973  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6973\n",
            "12/02 21:18:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][220/332]  lr: 1.0000e-03  eta: 0:33:03  time: 0.1978  data_time: 0.0118  memory: 5573  grad_norm: 0.8150  loss: 0.7001  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7001\n",
            "12/02 21:18:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][240/332]  lr: 1.0000e-03  eta: 0:32:59  time: 0.2263  data_time: 0.0216  memory: 5573  grad_norm: 0.9358  loss: 0.6812  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6812\n",
            "12/02 21:18:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][260/332]  lr: 1.0000e-03  eta: 0:32:55  time: 0.2354  data_time: 0.0278  memory: 5573  grad_norm: 0.7107  loss: 0.6472  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6472\n",
            "12/02 21:18:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][280/332]  lr: 1.0000e-03  eta: 0:32:50  time: 0.2114  data_time: 0.0169  memory: 5573  grad_norm: 0.9758  loss: 0.6827  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6827\n",
            "12/02 21:18:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][300/332]  lr: 1.0000e-03  eta: 0:32:46  time: 0.1988  data_time: 0.0121  memory: 5573  grad_norm: 0.7617  loss: 0.6755  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6755\n",
            "12/02 21:18:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][320/332]  lr: 1.0000e-03  eta: 0:32:41  time: 0.2086  data_time: 0.0180  memory: 5573  grad_norm: 0.8426  loss: 0.6871  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6871\n",
            "12/02 21:18:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:18:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][332/332]  lr: 1.0000e-03  eta: 0:32:38  time: 0.2201  data_time: 0.0230  memory: 5573  grad_norm: 0.7516  loss: 0.6756  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6756\n",
            "12/02 21:18:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 23 epochs\n",
            "12/02 21:18:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][20/42]    eta: 0:00:03  time: 0.1528  data_time: 0.0764  memory: 909  \n",
            "12/02 21:18:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][40/42]    eta: 0:00:00  time: 0.1090  data_time: 0.0391  memory: 909  \n",
            "12/02 21:18:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0542  time: 0.1247\n",
            "12/02 21:18:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 20/332]  lr: 1.0000e-03  eta: 0:32:34  time: 0.2088  data_time: 0.0223  memory: 5573  grad_norm: 0.8188  loss: 0.6786  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6786\n",
            "12/02 21:18:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 40/332]  lr: 1.0000e-03  eta: 0:32:29  time: 0.1984  data_time: 0.0124  memory: 5573  grad_norm: 0.9752  loss: 0.7150  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7150\n",
            "12/02 21:19:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 60/332]  lr: 1.0000e-03  eta: 0:32:25  time: 0.2293  data_time: 0.0264  memory: 5573  grad_norm: 0.8550  loss: 0.7072  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7072\n",
            "12/02 21:19:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 80/332]  lr: 1.0000e-03  eta: 0:32:21  time: 0.2392  data_time: 0.0304  memory: 5573  grad_norm: 0.8322  loss: 0.6792  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6792\n",
            "12/02 21:19:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][100/332]  lr: 1.0000e-03  eta: 0:32:16  time: 0.2076  data_time: 0.0162  memory: 5573  grad_norm: 0.9442  loss: 0.6928  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6928\n",
            "12/02 21:19:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][120/332]  lr: 1.0000e-03  eta: 0:32:11  time: 0.1990  data_time: 0.0127  memory: 5573  grad_norm: 0.9615  loss: 0.6788  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6788\n",
            "12/02 21:19:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][140/332]  lr: 1.0000e-03  eta: 0:32:07  time: 0.2098  data_time: 0.0171  memory: 5573  grad_norm: 1.9607  loss: 0.6900  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6900\n",
            "12/02 21:19:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][160/332]  lr: 1.0000e-03  eta: 0:32:03  time: 0.2333  data_time: 0.0246  memory: 5573  grad_norm: 0.7702  loss: 0.6740  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6740\n",
            "12/02 21:19:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][180/332]  lr: 1.0000e-03  eta: 0:31:59  time: 0.2295  data_time: 0.0278  memory: 5573  grad_norm: 0.8764  loss: 0.7064  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.7064\n",
            "12/02 21:19:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][200/332]  lr: 1.0000e-03  eta: 0:31:54  time: 0.1985  data_time: 0.0124  memory: 5573  grad_norm: 0.8992  loss: 0.6998  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6998\n",
            "12/02 21:19:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][220/332]  lr: 1.0000e-03  eta: 0:31:49  time: 0.1987  data_time: 0.0128  memory: 5573  grad_norm: 0.8318  loss: 0.6690  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6690\n",
            "12/02 21:19:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][240/332]  lr: 1.0000e-03  eta: 0:31:45  time: 0.2264  data_time: 0.0211  memory: 5573  grad_norm: 0.9269  loss: 0.6500  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6500\n",
            "12/02 21:19:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][260/332]  lr: 1.0000e-03  eta: 0:31:41  time: 0.2351  data_time: 0.0265  memory: 5573  grad_norm: 1.1395  loss: 0.6828  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6828\n",
            "12/02 21:19:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][280/332]  lr: 1.0000e-03  eta: 0:31:36  time: 0.2127  data_time: 0.0179  memory: 5573  grad_norm: 0.9537  loss: 0.6822  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6822\n",
            "12/02 21:19:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][300/332]  lr: 1.0000e-03  eta: 0:31:32  time: 0.1981  data_time: 0.0121  memory: 5573  grad_norm: 0.8429  loss: 0.6878  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6878\n",
            "12/02 21:20:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][320/332]  lr: 1.0000e-03  eta: 0:31:27  time: 0.2028  data_time: 0.0134  memory: 5573  grad_norm: 0.7827  loss: 0.6994  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6994\n",
            "12/02 21:20:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:20:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][332/332]  lr: 1.0000e-03  eta: 0:31:24  time: 0.2151  data_time: 0.0199  memory: 5573  grad_norm: 0.7472  loss: 0.6839  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6839\n",
            "12/02 21:20:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 24 epochs\n",
            "12/02 21:20:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][20/42]    eta: 0:00:03  time: 0.1590  data_time: 0.0822  memory: 909  \n",
            "12/02 21:20:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][40/42]    eta: 0:00:00  time: 0.1316  data_time: 0.0574  memory: 909  \n",
            "12/02 21:20:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0654  time: 0.1381\n",
            "12/02 21:20:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 20/332]  lr: 1.0000e-03  eta: 0:31:20  time: 0.2090  data_time: 0.0222  memory: 5573  grad_norm: 1.1883  loss: 0.7078  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7078\n",
            "12/02 21:20:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:20:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 40/332]  lr: 1.0000e-03  eta: 0:31:15  time: 0.1977  data_time: 0.0118  memory: 5573  grad_norm: 1.1146  loss: 0.6827  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6827\n",
            "12/02 21:20:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 60/332]  lr: 1.0000e-03  eta: 0:31:11  time: 0.2308  data_time: 0.0248  memory: 5573  grad_norm: 1.1901  loss: 0.7149  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7149\n",
            "12/02 21:20:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 80/332]  lr: 1.0000e-03  eta: 0:31:07  time: 0.2331  data_time: 0.0263  memory: 5573  grad_norm: 1.1333  loss: 0.6971  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6971\n",
            "12/02 21:20:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][100/332]  lr: 1.0000e-03  eta: 0:31:02  time: 0.2114  data_time: 0.0177  memory: 5573  grad_norm: 1.0155  loss: 0.6707  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6707\n",
            "12/02 21:20:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][120/332]  lr: 1.0000e-03  eta: 0:30:57  time: 0.1980  data_time: 0.0118  memory: 5573  grad_norm: 0.9879  loss: 0.6727  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6727\n",
            "12/02 21:20:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][140/332]  lr: 1.0000e-03  eta: 0:30:53  time: 0.2054  data_time: 0.0152  memory: 5573  grad_norm: 0.8831  loss: 0.6729  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6729\n",
            "12/02 21:20:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][160/332]  lr: 1.0000e-03  eta: 0:30:49  time: 0.2365  data_time: 0.0294  memory: 5573  grad_norm: 2.3609  loss: 0.7101  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7101\n",
            "12/02 21:20:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][180/332]  lr: 1.0000e-03  eta: 0:30:45  time: 0.2369  data_time: 0.0282  memory: 5573  grad_norm: 0.8719  loss: 0.6887  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6887\n",
            "12/02 21:20:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][200/332]  lr: 1.0000e-03  eta: 0:30:40  time: 0.1971  data_time: 0.0113  memory: 5573  grad_norm: 0.8246  loss: 0.7039  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7039\n",
            "12/02 21:20:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][220/332]  lr: 1.0000e-03  eta: 0:30:35  time: 0.1978  data_time: 0.0114  memory: 5573  grad_norm: 0.8070  loss: 0.6904  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6904\n",
            "12/02 21:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][240/332]  lr: 1.0000e-03  eta: 0:30:31  time: 0.2229  data_time: 0.0211  memory: 5573  grad_norm: 0.8051  loss: 0.7108  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7108\n",
            "12/02 21:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][260/332]  lr: 1.0000e-03  eta: 0:30:27  time: 0.2426  data_time: 0.0291  memory: 5573  grad_norm: 0.7423  loss: 0.6834  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6834\n",
            "12/02 21:21:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][280/332]  lr: 1.0000e-03  eta: 0:30:23  time: 0.2161  data_time: 0.0200  memory: 5573  grad_norm: 0.8236  loss: 0.7001  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7001\n",
            "12/02 21:21:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][300/332]  lr: 1.0000e-03  eta: 0:30:18  time: 0.1986  data_time: 0.0124  memory: 5573  grad_norm: 1.2303  loss: 0.6951  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6951\n",
            "12/02 21:21:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][320/332]  lr: 1.0000e-03  eta: 0:30:13  time: 0.2045  data_time: 0.0138  memory: 5573  grad_norm: 0.8870  loss: 0.6967  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6967\n",
            "12/02 21:21:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:21:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][332/332]  lr: 1.0000e-03  eta: 0:30:11  time: 0.2164  data_time: 0.0202  memory: 5573  grad_norm: 1.1017  loss: 0.7115  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7115\n",
            "12/02 21:21:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 25 epochs\n",
            "12/02 21:21:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][20/42]    eta: 0:00:03  time: 0.1559  data_time: 0.0816  memory: 909  \n",
            "12/02 21:21:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][40/42]    eta: 0:00:00  time: 0.1341  data_time: 0.0590  memory: 909  \n",
            "12/02 21:21:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0658  time: 0.1379\n",
            "12/02 21:21:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][ 20/332]  lr: 1.0000e-03  eta: 0:30:06  time: 0.2102  data_time: 0.0223  memory: 5573  grad_norm: 0.8912  loss: 0.6880  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6880\n",
            "12/02 21:21:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][ 40/332]  lr: 1.0000e-03  eta: 0:30:01  time: 0.1986  data_time: 0.0122  memory: 5573  grad_norm: 0.7237  loss: 0.6711  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6711\n",
            "12/02 21:21:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][ 60/332]  lr: 1.0000e-03  eta: 0:29:57  time: 0.2318  data_time: 0.0253  memory: 5573  grad_norm: 0.7025  loss: 0.6784  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6784\n",
            "12/02 21:21:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][ 80/332]  lr: 1.0000e-03  eta: 0:29:53  time: 0.2454  data_time: 0.0322  memory: 5573  grad_norm: 0.7055  loss: 0.6581  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6581\n",
            "12/02 21:21:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][100/332]  lr: 1.0000e-03  eta: 0:29:49  time: 0.2132  data_time: 0.0190  memory: 5573  grad_norm: 0.9297  loss: 0.6893  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6893\n",
            "12/02 21:21:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][120/332]  lr: 1.0000e-03  eta: 0:29:44  time: 0.2010  data_time: 0.0130  memory: 5573  grad_norm: 0.8173  loss: 0.7132  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7132\n",
            "12/02 21:21:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][140/332]  lr: 1.0000e-03  eta: 0:29:40  time: 0.2092  data_time: 0.0162  memory: 5573  grad_norm: 0.7863  loss: 0.6867  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6867\n",
            "12/02 21:22:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][160/332]  lr: 1.0000e-03  eta: 0:29:36  time: 0.2526  data_time: 0.0349  memory: 5573  grad_norm: 1.1834  loss: 0.7177  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7177\n",
            "12/02 21:22:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][180/332]  lr: 1.0000e-03  eta: 0:29:32  time: 0.2368  data_time: 0.0267  memory: 5573  grad_norm: 0.9228  loss: 0.6900  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6900\n",
            "12/02 21:22:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][200/332]  lr: 1.0000e-03  eta: 0:29:27  time: 0.2002  data_time: 0.0124  memory: 5573  grad_norm: 0.7063  loss: 0.6809  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6809\n",
            "12/02 21:22:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][220/332]  lr: 1.0000e-03  eta: 0:29:23  time: 0.1998  data_time: 0.0122  memory: 5573  grad_norm: 0.7604  loss: 0.6805  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6805\n",
            "12/02 21:22:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][240/332]  lr: 1.0000e-03  eta: 0:29:19  time: 0.2369  data_time: 0.0257  memory: 5573  grad_norm: 0.7497  loss: 0.6559  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6559\n",
            "12/02 21:22:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][260/332]  lr: 1.0000e-03  eta: 0:29:15  time: 0.2534  data_time: 0.0325  memory: 5573  grad_norm: 0.8777  loss: 0.7231  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7231\n",
            "12/02 21:22:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][280/332]  lr: 1.0000e-03  eta: 0:29:10  time: 0.2108  data_time: 0.0164  memory: 5573  grad_norm: 1.4320  loss: 0.6993  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6993\n",
            "12/02 21:22:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][300/332]  lr: 1.0000e-03  eta: 0:29:06  time: 0.1996  data_time: 0.0121  memory: 5573  grad_norm: 1.0765  loss: 0.6661  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6661\n",
            "12/02 21:22:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][320/332]  lr: 1.0000e-03  eta: 0:29:01  time: 0.2156  data_time: 0.0177  memory: 5573  grad_norm: 0.9517  loss: 0.7047  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7047\n",
            "12/02 21:22:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:22:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][332/332]  lr: 1.0000e-03  eta: 0:28:59  time: 0.2322  data_time: 0.0269  memory: 5573  grad_norm: 1.1346  loss: 0.7017  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7017\n",
            "12/02 21:22:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 26 epochs\n",
            "12/02 21:22:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [26][20/42]    eta: 0:00:03  time: 0.1710  data_time: 0.0883  memory: 909  \n",
            "12/02 21:22:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [26][40/42]    eta: 0:00:00  time: 0.1083  data_time: 0.0362  memory: 909  \n",
            "12/02 21:22:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [26][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0584  time: 0.1329\n",
            "12/02 21:22:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][ 20/332]  lr: 1.0000e-03  eta: 0:28:54  time: 0.2118  data_time: 0.0229  memory: 5573  grad_norm: 0.8022  loss: 0.6731  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6731\n",
            "12/02 21:22:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][ 40/332]  lr: 1.0000e-03  eta: 0:28:50  time: 0.2027  data_time: 0.0136  memory: 5573  grad_norm: 0.7132  loss: 0.6830  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6830\n",
            "12/02 21:23:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][ 60/332]  lr: 1.0000e-03  eta: 0:28:46  time: 0.2533  data_time: 0.0338  memory: 5573  grad_norm: 0.6651  loss: 0.6684  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6684\n",
            "12/02 21:23:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][ 80/332]  lr: 1.0000e-03  eta: 0:28:42  time: 0.2460  data_time: 0.0298  memory: 5573  grad_norm: 0.8533  loss: 0.6900  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6900\n",
            "12/02 21:23:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][100/332]  lr: 1.0000e-03  eta: 0:28:37  time: 0.1993  data_time: 0.0120  memory: 5573  grad_norm: 1.1362  loss: 0.6733  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6733\n",
            "12/02 21:23:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][120/332]  lr: 1.0000e-03  eta: 0:28:33  time: 0.1984  data_time: 0.0117  memory: 5573  grad_norm: 1.1864  loss: 0.6772  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6772\n",
            "12/02 21:23:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][140/332]  lr: 1.0000e-03  eta: 0:28:29  time: 0.2335  data_time: 0.0234  memory: 5573  grad_norm: 0.9000  loss: 0.6807  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6807\n",
            "12/02 21:23:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][160/332]  lr: 1.0000e-03  eta: 0:28:25  time: 0.2518  data_time: 0.0301  memory: 5573  grad_norm: 0.9464  loss: 0.6804  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6804\n",
            "12/02 21:23:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][180/332]  lr: 1.0000e-03  eta: 0:28:20  time: 0.2191  data_time: 0.0179  memory: 5573  grad_norm: 0.8915  loss: 0.7056  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7056\n",
            "12/02 21:23:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][200/332]  lr: 1.0000e-03  eta: 0:28:16  time: 0.2005  data_time: 0.0130  memory: 5573  grad_norm: 0.9295  loss: 0.7099  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7099\n",
            "12/02 21:23:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][220/332]  lr: 1.0000e-03  eta: 0:28:11  time: 0.2109  data_time: 0.0170  memory: 5573  grad_norm: 0.9657  loss: 0.6871  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6871\n",
            "12/02 21:23:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][240/332]  lr: 1.0000e-03  eta: 0:28:07  time: 0.2526  data_time: 0.0328  memory: 5573  grad_norm: 0.9064  loss: 0.7135  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7135\n",
            "12/02 21:23:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][260/332]  lr: 1.0000e-03  eta: 0:28:03  time: 0.2343  data_time: 0.0262  memory: 5573  grad_norm: 0.9787  loss: 0.7263  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7263\n",
            "12/02 21:23:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][280/332]  lr: 1.0000e-03  eta: 0:27:59  time: 0.1992  data_time: 0.0118  memory: 5573  grad_norm: 0.7983  loss: 0.6782  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6782\n",
            "12/02 21:23:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][300/332]  lr: 1.0000e-03  eta: 0:27:54  time: 0.1998  data_time: 0.0122  memory: 5573  grad_norm: 1.1453  loss: 0.6748  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6748\n",
            "12/02 21:23:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][320/332]  lr: 1.0000e-03  eta: 0:27:50  time: 0.2349  data_time: 0.0275  memory: 5573  grad_norm: 1.0173  loss: 0.6872  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6872\n",
            "12/02 21:24:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:24:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][332/332]  lr: 1.0000e-03  eta: 0:27:47  time: 0.2346  data_time: 0.0299  memory: 5573  grad_norm: 0.9903  loss: 0.7114  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7114\n",
            "12/02 21:24:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 27 epochs\n",
            "12/02 21:24:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [27][20/42]    eta: 0:00:03  time: 0.1458  data_time: 0.0724  memory: 909  \n",
            "12/02 21:24:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [27][40/42]    eta: 0:00:00  time: 0.1015  data_time: 0.0372  memory: 909  \n",
            "12/02 21:24:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [27][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0513  time: 0.1179\n",
            "12/02 21:24:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][ 20/332]  lr: 1.0000e-03  eta: 0:27:43  time: 0.2112  data_time: 0.0221  memory: 5573  grad_norm: 0.7917  loss: 0.6774  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6774\n",
            "12/02 21:24:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:24:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][ 40/332]  lr: 1.0000e-03  eta: 0:27:38  time: 0.2103  data_time: 0.0174  memory: 5573  grad_norm: 0.8192  loss: 0.6771  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6771\n",
            "12/02 21:24:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][ 60/332]  lr: 1.0000e-03  eta: 0:27:34  time: 0.2483  data_time: 0.0282  memory: 5573  grad_norm: 0.9184  loss: 0.6886  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6886\n",
            "12/02 21:24:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][ 80/332]  lr: 1.0000e-03  eta: 0:27:30  time: 0.2388  data_time: 0.0307  memory: 5573  grad_norm: 0.9018  loss: 0.6959  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6959\n",
            "12/02 21:24:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][100/332]  lr: 1.0000e-03  eta: 0:27:26  time: 0.2004  data_time: 0.0126  memory: 5573  grad_norm: 0.7365  loss: 0.6573  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6573\n",
            "12/02 21:24:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][120/332]  lr: 1.0000e-03  eta: 0:27:21  time: 0.1997  data_time: 0.0119  memory: 5573  grad_norm: 0.9420  loss: 0.6841  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6841\n",
            "12/02 21:24:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][140/332]  lr: 1.0000e-03  eta: 0:27:17  time: 0.2407  data_time: 0.0249  memory: 5573  grad_norm: 1.1029  loss: 0.6970  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6970\n",
            "12/02 21:24:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][160/332]  lr: 1.0000e-03  eta: 0:27:13  time: 0.2445  data_time: 0.0285  memory: 5573  grad_norm: 0.8620  loss: 0.7112  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7112\n",
            "12/02 21:24:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][180/332]  lr: 1.0000e-03  eta: 0:27:09  time: 0.2115  data_time: 0.0174  memory: 5573  grad_norm: 0.8242  loss: 0.7083  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7083\n",
            "12/02 21:24:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][200/332]  lr: 1.0000e-03  eta: 0:27:04  time: 0.1996  data_time: 0.0125  memory: 5573  grad_norm: 0.9657  loss: 0.6945  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6945\n",
            "12/02 21:24:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][220/332]  lr: 1.0000e-03  eta: 0:27:00  time: 0.2124  data_time: 0.0166  memory: 5573  grad_norm: 0.9796  loss: 0.7078  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7078\n",
            "12/02 21:25:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][240/332]  lr: 1.0000e-03  eta: 0:26:56  time: 0.2403  data_time: 0.0254  memory: 5573  grad_norm: 1.0344  loss: 0.7176  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7176\n",
            "12/02 21:25:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][260/332]  lr: 1.0000e-03  eta: 0:26:51  time: 0.2291  data_time: 0.0239  memory: 5573  grad_norm: 0.9877  loss: 0.6974  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6974\n",
            "12/02 21:25:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][280/332]  lr: 1.0000e-03  eta: 0:26:47  time: 0.1975  data_time: 0.0113  memory: 5573  grad_norm: 1.0002  loss: 0.7116  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7116\n",
            "12/02 21:25:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][300/332]  lr: 1.0000e-03  eta: 0:26:42  time: 0.1987  data_time: 0.0120  memory: 5573  grad_norm: 1.0176  loss: 0.6870  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6870\n",
            "12/02 21:25:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][320/332]  lr: 1.0000e-03  eta: 0:26:38  time: 0.2282  data_time: 0.0239  memory: 5573  grad_norm: 0.9200  loss: 0.6604  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6604\n",
            "12/02 21:25:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:25:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][332/332]  lr: 1.0000e-03  eta: 0:26:35  time: 0.2247  data_time: 0.0254  memory: 5573  grad_norm: 1.6072  loss: 0.6764  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6764\n",
            "12/02 21:25:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 28 epochs\n",
            "12/02 21:25:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [28][20/42]    eta: 0:00:02  time: 0.1340  data_time: 0.0577  memory: 909  \n",
            "12/02 21:25:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [28][40/42]    eta: 0:00:00  time: 0.0912  data_time: 0.0224  memory: 909  \n",
            "12/02 21:25:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [28][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0378  time: 0.1078\n",
            "12/02 21:25:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][ 20/332]  lr: 1.0000e-03  eta: 0:26:31  time: 0.2077  data_time: 0.0206  memory: 5573  grad_norm: 0.8899  loss: 0.6764  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6764\n",
            "12/02 21:25:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][ 40/332]  lr: 1.0000e-03  eta: 0:26:26  time: 0.2037  data_time: 0.0142  memory: 5573  grad_norm: 0.8370  loss: 0.7023  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7023\n",
            "12/02 21:25:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][ 60/332]  lr: 1.0000e-03  eta: 0:26:22  time: 0.2406  data_time: 0.0292  memory: 5573  grad_norm: 0.7614  loss: 0.6741  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6741\n",
            "12/02 21:25:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][ 80/332]  lr: 1.0000e-03  eta: 0:26:18  time: 0.2294  data_time: 0.0261  memory: 5573  grad_norm: 0.8975  loss: 0.6830  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6830\n",
            "12/02 21:25:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][100/332]  lr: 1.0000e-03  eta: 0:26:13  time: 0.1982  data_time: 0.0123  memory: 5573  grad_norm: 0.8390  loss: 0.6865  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6865\n",
            "12/02 21:25:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][120/332]  lr: 1.0000e-03  eta: 0:26:08  time: 0.1984  data_time: 0.0121  memory: 5573  grad_norm: 0.7257  loss: 0.6554  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6554\n",
            "12/02 21:25:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][140/332]  lr: 1.0000e-03  eta: 0:26:04  time: 0.2271  data_time: 0.0230  memory: 5573  grad_norm: 0.9293  loss: 0.6773  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6773\n",
            "12/02 21:26:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][160/332]  lr: 1.0000e-03  eta: 0:26:00  time: 0.2403  data_time: 0.0282  memory: 5573  grad_norm: 0.7752  loss: 0.6830  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6830\n",
            "12/02 21:26:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][180/332]  lr: 1.0000e-03  eta: 0:25:56  time: 0.2095  data_time: 0.0158  memory: 5573  grad_norm: 0.9645  loss: 0.6799  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6799\n",
            "12/02 21:26:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][200/332]  lr: 1.0000e-03  eta: 0:25:51  time: 0.1985  data_time: 0.0122  memory: 5573  grad_norm: 0.9647  loss: 0.6715  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6715\n",
            "12/02 21:26:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][220/332]  lr: 1.0000e-03  eta: 0:25:46  time: 0.2092  data_time: 0.0154  memory: 5573  grad_norm: 0.8833  loss: 0.6893  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6893\n",
            "12/02 21:26:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][240/332]  lr: 1.0000e-03  eta: 0:25:42  time: 0.2409  data_time: 0.0308  memory: 5573  grad_norm: 0.7643  loss: 0.6732  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6732\n",
            "12/02 21:26:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][260/332]  lr: 1.0000e-03  eta: 0:25:38  time: 0.2247  data_time: 0.0225  memory: 5573  grad_norm: 0.9417  loss: 0.7018  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7018\n",
            "12/02 21:26:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][280/332]  lr: 1.0000e-03  eta: 0:25:33  time: 0.1984  data_time: 0.0120  memory: 5573  grad_norm: 0.8547  loss: 0.7169  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7169\n",
            "12/02 21:26:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][300/332]  lr: 1.0000e-03  eta: 0:25:29  time: 0.1977  data_time: 0.0110  memory: 5573  grad_norm: 1.1686  loss: 0.7388  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7388\n",
            "12/02 21:26:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][320/332]  lr: 1.0000e-03  eta: 0:25:25  time: 0.2291  data_time: 0.0235  memory: 5573  grad_norm: 0.8991  loss: 0.6737  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6737\n",
            "12/02 21:26:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:26:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][332/332]  lr: 1.0000e-03  eta: 0:25:22  time: 0.2248  data_time: 0.0240  memory: 5573  grad_norm: 0.7205  loss: 0.6630  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6630\n",
            "12/02 21:26:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 29 epochs\n",
            "12/02 21:26:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [29][20/42]    eta: 0:00:03  time: 0.1402  data_time: 0.0669  memory: 909  \n",
            "12/02 21:26:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [29][40/42]    eta: 0:00:00  time: 0.0930  data_time: 0.0245  memory: 909  \n",
            "12/02 21:26:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [29][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0429  time: 0.1114\n",
            "12/02 21:26:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][ 20/332]  lr: 1.0000e-03  eta: 0:25:17  time: 0.2074  data_time: 0.0200  memory: 5573  grad_norm: 0.8305  loss: 0.6858  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6858\n",
            "12/02 21:26:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][ 40/332]  lr: 1.0000e-03  eta: 0:25:13  time: 0.2056  data_time: 0.0144  memory: 5573  grad_norm: 1.2782  loss: 0.7194  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7194\n",
            "12/02 21:26:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][ 60/332]  lr: 1.0000e-03  eta: 0:25:09  time: 0.2423  data_time: 0.0298  memory: 5573  grad_norm: 0.8709  loss: 0.6799  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6799\n",
            "12/02 21:27:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][ 80/332]  lr: 1.0000e-03  eta: 0:25:05  time: 0.2335  data_time: 0.0237  memory: 5573  grad_norm: 1.0733  loss: 0.7125  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7125\n",
            "12/02 21:27:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][100/332]  lr: 1.0000e-03  eta: 0:25:00  time: 0.1983  data_time: 0.0122  memory: 5573  grad_norm: 0.7510  loss: 0.6746  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6746\n",
            "12/02 21:27:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][120/332]  lr: 1.0000e-03  eta: 0:24:55  time: 0.1986  data_time: 0.0118  memory: 5573  grad_norm: 0.9246  loss: 0.7132  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7132\n",
            "12/02 21:27:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][140/332]  lr: 1.0000e-03  eta: 0:24:51  time: 0.2289  data_time: 0.0254  memory: 5573  grad_norm: 0.8976  loss: 0.6790  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6790\n",
            "12/02 21:27:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][160/332]  lr: 1.0000e-03  eta: 0:24:47  time: 0.2392  data_time: 0.0317  memory: 5573  grad_norm: 0.8922  loss: 0.6736  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6736\n",
            "12/02 21:27:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][180/332]  lr: 1.0000e-03  eta: 0:24:43  time: 0.2114  data_time: 0.0173  memory: 5573  grad_norm: 0.8058  loss: 0.6992  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6992\n",
            "12/02 21:27:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][200/332]  lr: 1.0000e-03  eta: 0:24:38  time: 0.1988  data_time: 0.0124  memory: 5573  grad_norm: 1.2561  loss: 0.6866  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6866\n",
            "12/02 21:27:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][220/332]  lr: 1.0000e-03  eta: 0:24:33  time: 0.2096  data_time: 0.0167  memory: 5573  grad_norm: 1.1326  loss: 0.7056  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7056\n",
            "12/02 21:27:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][240/332]  lr: 1.0000e-03  eta: 0:24:29  time: 0.2433  data_time: 0.0304  memory: 5573  grad_norm: 0.9349  loss: 0.6829  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6829\n",
            "12/02 21:27:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][260/332]  lr: 1.0000e-03  eta: 0:24:25  time: 0.2294  data_time: 0.0233  memory: 5573  grad_norm: 0.9865  loss: 0.7076  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7076\n",
            "12/02 21:27:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][280/332]  lr: 1.0000e-03  eta: 0:24:21  time: 0.1981  data_time: 0.0121  memory: 5573  grad_norm: 1.1670  loss: 0.6499  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6499\n",
            "12/02 21:27:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][300/332]  lr: 1.0000e-03  eta: 0:24:16  time: 0.1983  data_time: 0.0122  memory: 5573  grad_norm: 0.7573  loss: 0.6635  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6635\n",
            "12/02 21:27:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][320/332]  lr: 1.0000e-03  eta: 0:24:12  time: 0.2331  data_time: 0.0294  memory: 5573  grad_norm: 0.9357  loss: 0.6839  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6839\n",
            "12/02 21:27:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:27:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][332/332]  lr: 1.0000e-03  eta: 0:24:09  time: 0.2260  data_time: 0.0262  memory: 5573  grad_norm: 0.7932  loss: 0.6659  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6659\n",
            "12/02 21:27:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 30 epochs\n",
            "12/02 21:28:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][20/42]    eta: 0:00:02  time: 0.1214  data_time: 0.0535  memory: 909  \n",
            "12/02 21:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][40/42]    eta: 0:00:00  time: 0.0932  data_time: 0.0252  memory: 909  \n",
            "12/02 21:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0370  time: 0.1028\n",
            "12/02 21:28:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][ 20/332]  lr: 1.0000e-03  eta: 0:24:05  time: 0.2076  data_time: 0.0202  memory: 5573  grad_norm: 0.8114  loss: 0.6608  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6608\n",
            "12/02 21:28:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:28:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][ 40/332]  lr: 1.0000e-03  eta: 0:24:00  time: 0.2129  data_time: 0.0173  memory: 5573  grad_norm: 0.8477  loss: 0.6853  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6853\n",
            "12/02 21:28:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][ 60/332]  lr: 1.0000e-03  eta: 0:23:56  time: 0.2393  data_time: 0.0260  memory: 5573  grad_norm: 0.8880  loss: 0.7142  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7142\n",
            "12/02 21:28:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][ 80/332]  lr: 1.0000e-03  eta: 0:23:52  time: 0.2269  data_time: 0.0225  memory: 5573  grad_norm: 1.1008  loss: 0.6957  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6957\n",
            "12/02 21:28:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][100/332]  lr: 1.0000e-03  eta: 0:23:47  time: 0.1986  data_time: 0.0122  memory: 5573  grad_norm: 1.0302  loss: 0.6889  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6889\n",
            "12/02 21:28:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][120/332]  lr: 1.0000e-03  eta: 0:23:43  time: 0.1983  data_time: 0.0120  memory: 5573  grad_norm: 0.7717  loss: 0.6762  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6762\n",
            "12/02 21:28:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][140/332]  lr: 1.0000e-03  eta: 0:23:39  time: 0.2381  data_time: 0.0269  memory: 5573  grad_norm: 0.6855  loss: 0.6568  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6568\n",
            "12/02 21:28:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][160/332]  lr: 1.0000e-03  eta: 0:23:34  time: 0.2370  data_time: 0.0325  memory: 5573  grad_norm: 0.7100  loss: 0.6517  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6517\n",
            "12/02 21:28:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][180/332]  lr: 1.0000e-03  eta: 0:23:30  time: 0.2091  data_time: 0.0163  memory: 5573  grad_norm: 0.9581  loss: 0.6965  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6965\n",
            "12/02 21:28:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][200/332]  lr: 1.0000e-03  eta: 0:23:25  time: 0.1997  data_time: 0.0123  memory: 5573  grad_norm: 1.0051  loss: 0.6849  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6849\n",
            "12/02 21:28:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][220/332]  lr: 1.0000e-03  eta: 0:23:21  time: 0.2131  data_time: 0.0174  memory: 5573  grad_norm: 0.7841  loss: 0.6726  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6726\n",
            "12/02 21:28:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][240/332]  lr: 1.0000e-03  eta: 0:23:17  time: 0.2406  data_time: 0.0266  memory: 5573  grad_norm: 0.8798  loss: 0.6746  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6746\n",
            "12/02 21:29:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][260/332]  lr: 1.0000e-03  eta: 0:23:13  time: 0.2313  data_time: 0.0249  memory: 5573  grad_norm: 1.0993  loss: 0.7366  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7366\n",
            "12/02 21:29:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][280/332]  lr: 1.0000e-03  eta: 0:23:08  time: 0.1988  data_time: 0.0125  memory: 5573  grad_norm: 1.1371  loss: 0.7229  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7229\n",
            "12/02 21:29:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][300/332]  lr: 1.0000e-03  eta: 0:23:03  time: 0.1997  data_time: 0.0131  memory: 5573  grad_norm: 0.9929  loss: 0.6878  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6878\n",
            "12/02 21:29:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][320/332]  lr: 1.0000e-03  eta: 0:22:59  time: 0.2354  data_time: 0.0273  memory: 5573  grad_norm: 1.0143  loss: 0.6949  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6949\n",
            "12/02 21:29:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:29:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][332/332]  lr: 1.0000e-03  eta: 0:22:57  time: 0.2322  data_time: 0.0300  memory: 5573  grad_norm: 0.9780  loss: 0.6999  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6999\n",
            "12/02 21:29:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 31 epochs\n",
            "12/02 21:29:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [31][20/42]    eta: 0:00:02  time: 0.1361  data_time: 0.0610  memory: 909  \n",
            "12/02 21:29:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [31][40/42]    eta: 0:00:00  time: 0.0950  data_time: 0.0275  memory: 909  \n",
            "12/02 21:29:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [31][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0416  time: 0.1105\n",
            "12/02 21:29:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][ 20/332]  lr: 1.0000e-03  eta: 0:22:52  time: 0.2081  data_time: 0.0207  memory: 5573  grad_norm: 1.1754  loss: 0.7065  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7065\n",
            "12/02 21:29:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][ 40/332]  lr: 1.0000e-03  eta: 0:22:48  time: 0.2054  data_time: 0.0145  memory: 5573  grad_norm: 1.0588  loss: 0.6615  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6615\n",
            "12/02 21:29:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][ 60/332]  lr: 1.0000e-03  eta: 0:22:43  time: 0.2360  data_time: 0.0267  memory: 5573  grad_norm: 0.8154  loss: 0.6787  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6787\n",
            "12/02 21:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][ 80/332]  lr: 1.0000e-03  eta: 0:22:39  time: 0.2356  data_time: 0.0252  memory: 5573  grad_norm: 1.0130  loss: 0.6948  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6948\n",
            "12/02 21:29:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][100/332]  lr: 1.0000e-03  eta: 0:22:35  time: 0.1982  data_time: 0.0121  memory: 5573  grad_norm: 0.8263  loss: 0.6770  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6770\n",
            "12/02 21:29:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][120/332]  lr: 1.0000e-03  eta: 0:22:30  time: 0.1985  data_time: 0.0127  memory: 5573  grad_norm: 0.8907  loss: 0.6965  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6965\n",
            "12/02 21:29:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][140/332]  lr: 1.0000e-03  eta: 0:22:26  time: 0.2273  data_time: 0.0245  memory: 5573  grad_norm: 0.9265  loss: 0.6895  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6895\n",
            "12/02 21:29:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][160/332]  lr: 1.0000e-03  eta: 0:22:22  time: 0.2380  data_time: 0.0303  memory: 5573  grad_norm: 1.3281  loss: 0.6746  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6746\n",
            "12/02 21:30:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][180/332]  lr: 1.0000e-03  eta: 0:22:17  time: 0.2103  data_time: 0.0177  memory: 5573  grad_norm: 1.0385  loss: 0.7023  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7023\n",
            "12/02 21:30:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][200/332]  lr: 1.0000e-03  eta: 0:22:13  time: 0.1983  data_time: 0.0120  memory: 5573  grad_norm: 0.8381  loss: 0.6785  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6785\n",
            "12/02 21:30:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][220/332]  lr: 1.0000e-03  eta: 0:22:08  time: 0.2052  data_time: 0.0149  memory: 5573  grad_norm: 0.6933  loss: 0.6729  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6729\n",
            "12/02 21:30:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][240/332]  lr: 1.0000e-03  eta: 0:22:04  time: 0.2412  data_time: 0.0289  memory: 5573  grad_norm: 0.8058  loss: 0.6797  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6797\n",
            "12/02 21:30:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][260/332]  lr: 1.0000e-03  eta: 0:22:00  time: 0.2315  data_time: 0.0241  memory: 5573  grad_norm: 0.7882  loss: 0.6756  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6756\n",
            "12/02 21:30:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][280/332]  lr: 1.0000e-03  eta: 0:21:55  time: 0.1983  data_time: 0.0120  memory: 5573  grad_norm: 1.0552  loss: 0.6940  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6940\n",
            "12/02 21:30:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][300/332]  lr: 1.0000e-03  eta: 0:21:51  time: 0.1973  data_time: 0.0116  memory: 5573  grad_norm: 1.0104  loss: 0.7045  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7045\n",
            "12/02 21:30:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][320/332]  lr: 1.0000e-03  eta: 0:21:46  time: 0.2231  data_time: 0.0233  memory: 5573  grad_norm: 0.7209  loss: 0.6643  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6643\n",
            "12/02 21:30:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:30:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][332/332]  lr: 1.0000e-03  eta: 0:21:44  time: 0.2263  data_time: 0.0255  memory: 5573  grad_norm: 1.0550  loss: 0.6930  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6930\n",
            "12/02 21:30:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 32 epochs\n",
            "12/02 21:30:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [32][20/42]    eta: 0:00:03  time: 0.1529  data_time: 0.0768  memory: 909  \n",
            "12/02 21:30:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [32][40/42]    eta: 0:00:00  time: 0.0953  data_time: 0.0298  memory: 909  \n",
            "12/02 21:30:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [32][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0501  time: 0.1185\n",
            "12/02 21:30:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][ 20/332]  lr: 1.0000e-03  eta: 0:21:39  time: 0.2082  data_time: 0.0209  memory: 5573  grad_norm: 0.9289  loss: 0.6930  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6930\n",
            "12/02 21:30:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][ 40/332]  lr: 1.0000e-03  eta: 0:21:35  time: 0.2016  data_time: 0.0132  memory: 5573  grad_norm: 0.8058  loss: 0.6900  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6900\n",
            "12/02 21:30:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][ 60/332]  lr: 1.0000e-03  eta: 0:21:31  time: 0.2410  data_time: 0.0306  memory: 5573  grad_norm: 0.8637  loss: 0.6888  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6888\n",
            "12/02 21:30:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][ 80/332]  lr: 1.0000e-03  eta: 0:21:26  time: 0.2400  data_time: 0.0310  memory: 5573  grad_norm: 0.7249  loss: 0.6725  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6725\n",
            "12/02 21:31:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][100/332]  lr: 1.0000e-03  eta: 0:21:22  time: 0.1977  data_time: 0.0114  memory: 5573  grad_norm: 1.1761  loss: 0.6612  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6612\n",
            "12/02 21:31:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][120/332]  lr: 1.0000e-03  eta: 0:21:17  time: 0.1978  data_time: 0.0118  memory: 5573  grad_norm: 0.8667  loss: 0.7193  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7193\n",
            "12/02 21:31:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][140/332]  lr: 1.0000e-03  eta: 0:21:13  time: 0.2199  data_time: 0.0206  memory: 5573  grad_norm: 0.9274  loss: 0.7044  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7044\n",
            "12/02 21:31:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][160/332]  lr: 1.0000e-03  eta: 0:21:09  time: 0.2389  data_time: 0.0265  memory: 5573  grad_norm: 0.8465  loss: 0.6689  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6689\n",
            "12/02 21:31:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][180/332]  lr: 1.0000e-03  eta: 0:21:04  time: 0.2147  data_time: 0.0181  memory: 5573  grad_norm: 0.7986  loss: 0.6833  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6833\n",
            "12/02 21:31:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][200/332]  lr: 1.0000e-03  eta: 0:21:00  time: 0.1979  data_time: 0.0114  memory: 5573  grad_norm: 0.8684  loss: 0.7168  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7168\n",
            "12/02 21:31:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][220/332]  lr: 1.0000e-03  eta: 0:20:55  time: 0.1994  data_time: 0.0127  memory: 5573  grad_norm: 1.1003  loss: 0.7182  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7182\n",
            "12/02 21:31:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][240/332]  lr: 1.0000e-03  eta: 0:20:51  time: 0.2391  data_time: 0.0259  memory: 5573  grad_norm: 0.9743  loss: 0.6886  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6886\n",
            "12/02 21:31:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][260/332]  lr: 1.0000e-03  eta: 0:20:47  time: 0.2348  data_time: 0.0277  memory: 5573  grad_norm: 0.7682  loss: 0.6816  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6816\n",
            "12/02 21:31:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][280/332]  lr: 1.0000e-03  eta: 0:20:42  time: 0.1988  data_time: 0.0125  memory: 5573  grad_norm: 0.8843  loss: 0.6567  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6567\n",
            "12/02 21:31:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][300/332]  lr: 1.0000e-03  eta: 0:20:38  time: 0.1975  data_time: 0.0113  memory: 5573  grad_norm: 0.8273  loss: 0.6827  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6827\n",
            "12/02 21:31:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][320/332]  lr: 1.0000e-03  eta: 0:20:33  time: 0.2171  data_time: 0.0186  memory: 5573  grad_norm: 1.0457  loss: 0.6959  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6959\n",
            "12/02 21:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][332/332]  lr: 1.0000e-03  eta: 0:20:31  time: 0.2299  data_time: 0.0282  memory: 5573  grad_norm: 1.1982  loss: 0.6661  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6661\n",
            "12/02 21:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 33 epochs\n",
            "12/02 21:31:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [33][20/42]    eta: 0:00:03  time: 0.1551  data_time: 0.0777  memory: 909  \n",
            "12/02 21:31:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [33][40/42]    eta: 0:00:00  time: 0.1057  data_time: 0.0396  memory: 909  \n",
            "12/02 21:31:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [33][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0547  time: 0.1240\n",
            "12/02 21:32:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][ 20/332]  lr: 1.0000e-03  eta: 0:20:26  time: 0.2079  data_time: 0.0206  memory: 5573  grad_norm: 0.8167  loss: 0.6842  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6842\n",
            "12/02 21:32:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][ 40/332]  lr: 1.0000e-03  eta: 0:20:22  time: 0.1986  data_time: 0.0122  memory: 5573  grad_norm: 0.8096  loss: 0.6664  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6664\n",
            "12/02 21:32:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:32:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][ 60/332]  lr: 1.0000e-03  eta: 0:20:18  time: 0.2417  data_time: 0.0312  memory: 5573  grad_norm: 0.8848  loss: 0.6930  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6930\n",
            "12/02 21:32:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][ 80/332]  lr: 1.0000e-03  eta: 0:20:13  time: 0.2369  data_time: 0.0275  memory: 5573  grad_norm: 0.9190  loss: 0.6920  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6920\n",
            "12/02 21:32:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][100/332]  lr: 1.0000e-03  eta: 0:20:09  time: 0.1999  data_time: 0.0127  memory: 5573  grad_norm: 0.8829  loss: 0.7010  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7010\n",
            "12/02 21:32:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][120/332]  lr: 1.0000e-03  eta: 0:20:04  time: 0.1988  data_time: 0.0119  memory: 5573  grad_norm: 0.7359  loss: 0.6644  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6644\n",
            "12/02 21:32:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][140/332]  lr: 1.0000e-03  eta: 0:20:00  time: 0.2166  data_time: 0.0189  memory: 5573  grad_norm: 0.7994  loss: 0.6792  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6792\n",
            "12/02 21:32:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][160/332]  lr: 1.0000e-03  eta: 0:19:56  time: 0.2425  data_time: 0.0335  memory: 5573  grad_norm: 0.8067  loss: 0.6850  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6850\n",
            "12/02 21:32:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][180/332]  lr: 1.0000e-03  eta: 0:19:52  time: 0.2241  data_time: 0.0214  memory: 5573  grad_norm: 1.0202  loss: 0.7017  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7017\n",
            "12/02 21:32:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][200/332]  lr: 1.0000e-03  eta: 0:19:47  time: 0.1978  data_time: 0.0115  memory: 5573  grad_norm: 0.8314  loss: 0.6914  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6914\n",
            "12/02 21:32:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][220/332]  lr: 1.0000e-03  eta: 0:19:42  time: 0.1983  data_time: 0.0118  memory: 5573  grad_norm: 0.9607  loss: 0.6675  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6675\n",
            "12/02 21:32:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][240/332]  lr: 1.0000e-03  eta: 0:19:38  time: 0.2372  data_time: 0.0300  memory: 5573  grad_norm: 1.0280  loss: 0.6853  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6853\n",
            "12/02 21:32:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][260/332]  lr: 1.0000e-03  eta: 0:19:34  time: 0.2372  data_time: 0.0269  memory: 5573  grad_norm: 0.7071  loss: 0.6591  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6591\n",
            "12/02 21:32:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][280/332]  lr: 1.0000e-03  eta: 0:19:30  time: 0.2036  data_time: 0.0149  memory: 5573  grad_norm: 0.7873  loss: 0.6911  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6911\n",
            "12/02 21:33:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][300/332]  lr: 1.0000e-03  eta: 0:19:25  time: 0.1987  data_time: 0.0125  memory: 5573  grad_norm: 0.8394  loss: 0.6957  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6957\n",
            "12/02 21:33:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][320/332]  lr: 1.0000e-03  eta: 0:19:21  time: 0.2110  data_time: 0.0183  memory: 5573  grad_norm: 0.9337  loss: 0.6809  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6809\n",
            "12/02 21:33:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:33:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][332/332]  lr: 1.0000e-03  eta: 0:19:18  time: 0.2214  data_time: 0.0227  memory: 5573  grad_norm: 0.8131  loss: 0.6648  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6648\n",
            "12/02 21:33:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 34 epochs\n",
            "12/02 21:33:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [34][20/42]    eta: 0:00:03  time: 0.1636  data_time: 0.0860  memory: 909  \n",
            "12/02 21:33:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [34][40/42]    eta: 0:00:00  time: 0.0943  data_time: 0.0287  memory: 909  \n",
            "12/02 21:33:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [34][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0537  time: 0.1228\n",
            "12/02 21:33:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][ 20/332]  lr: 1.0000e-03  eta: 0:19:13  time: 0.2077  data_time: 0.0205  memory: 5573  grad_norm: 0.8461  loss: 0.6879  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6879\n",
            "12/02 21:33:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][ 40/332]  lr: 1.0000e-03  eta: 0:19:09  time: 0.1984  data_time: 0.0120  memory: 5573  grad_norm: 0.8884  loss: 0.6899  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6899\n",
            "12/02 21:33:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][ 60/332]  lr: 1.0000e-03  eta: 0:19:05  time: 0.2377  data_time: 0.0290  memory: 5573  grad_norm: 1.8841  loss: 0.6898  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6898\n",
            "12/02 21:33:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][ 80/332]  lr: 1.0000e-03  eta: 0:19:01  time: 0.2423  data_time: 0.0327  memory: 5573  grad_norm: 0.9265  loss: 0.7010  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7010\n",
            "12/02 21:33:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][100/332]  lr: 1.0000e-03  eta: 0:18:56  time: 0.1973  data_time: 0.0111  memory: 5573  grad_norm: 0.7481  loss: 0.6730  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6730\n",
            "12/02 21:33:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][120/332]  lr: 1.0000e-03  eta: 0:18:52  time: 0.1984  data_time: 0.0119  memory: 5573  grad_norm: 0.8835  loss: 0.6940  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6940\n",
            "12/02 21:33:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][140/332]  lr: 1.0000e-03  eta: 0:18:47  time: 0.2226  data_time: 0.0217  memory: 5573  grad_norm: 1.1282  loss: 0.6955  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6955\n",
            "12/02 21:33:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][160/332]  lr: 1.0000e-03  eta: 0:18:43  time: 0.2406  data_time: 0.0288  memory: 5573  grad_norm: 0.7683  loss: 0.6866  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6866\n",
            "12/02 21:33:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][180/332]  lr: 1.0000e-03  eta: 0:18:39  time: 0.2208  data_time: 0.0245  memory: 5573  grad_norm: 0.7186  loss: 0.6655  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6655\n",
            "12/02 21:33:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][200/332]  lr: 1.0000e-03  eta: 0:18:34  time: 0.1994  data_time: 0.0123  memory: 5573  grad_norm: 0.9121  loss: 0.6949  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6949\n",
            "12/02 21:34:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][220/332]  lr: 1.0000e-03  eta: 0:18:30  time: 0.1986  data_time: 0.0121  memory: 5573  grad_norm: 0.8742  loss: 0.7025  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7025\n",
            "12/02 21:34:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][240/332]  lr: 1.0000e-03  eta: 0:18:25  time: 0.2339  data_time: 0.0269  memory: 5573  grad_norm: 1.1123  loss: 0.6618  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6618\n",
            "12/02 21:34:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][260/332]  lr: 1.0000e-03  eta: 0:18:21  time: 0.2440  data_time: 0.0299  memory: 5573  grad_norm: 0.8322  loss: 0.6657  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6657\n",
            "12/02 21:34:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][280/332]  lr: 1.0000e-03  eta: 0:18:17  time: 0.1990  data_time: 0.0125  memory: 5573  grad_norm: 0.7674  loss: 0.6620  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6620\n",
            "12/02 21:34:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][300/332]  lr: 1.0000e-03  eta: 0:18:12  time: 0.1988  data_time: 0.0125  memory: 5573  grad_norm: 0.6653  loss: 0.6575  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6575\n",
            "12/02 21:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][320/332]  lr: 1.0000e-03  eta: 0:18:08  time: 0.2164  data_time: 0.0195  memory: 5573  grad_norm: 0.9304  loss: 0.6886  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6886\n",
            "12/02 21:34:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:34:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][332/332]  lr: 1.0000e-03  eta: 0:18:05  time: 0.2238  data_time: 0.0235  memory: 5573  grad_norm: 1.1695  loss: 0.6915  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6915\n",
            "12/02 21:34:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 35 epochs\n",
            "12/02 21:34:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][20/42]    eta: 0:00:03  time: 0.1624  data_time: 0.0845  memory: 909  \n",
            "12/02 21:34:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][40/42]    eta: 0:00:00  time: 0.0956  data_time: 0.0280  memory: 909  \n",
            "12/02 21:34:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0526  time: 0.1229\n",
            "12/02 21:34:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][ 20/332]  lr: 1.0000e-03  eta: 0:18:01  time: 0.2083  data_time: 0.0206  memory: 5573  grad_norm: 1.0656  loss: 0.7244  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7244\n",
            "12/02 21:34:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][ 40/332]  lr: 1.0000e-03  eta: 0:17:56  time: 0.1981  data_time: 0.0118  memory: 5573  grad_norm: 0.8411  loss: 0.6962  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6962\n",
            "12/02 21:34:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][ 60/332]  lr: 1.0000e-03  eta: 0:17:52  time: 0.2361  data_time: 0.0268  memory: 5573  grad_norm: 0.6931  loss: 0.6624  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6624\n",
            "12/02 21:34:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][ 80/332]  lr: 1.0000e-03  eta: 0:17:48  time: 0.2407  data_time: 0.0274  memory: 5573  grad_norm: 0.7975  loss: 0.6825  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6825\n",
            "12/02 21:34:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][100/332]  lr: 1.0000e-03  eta: 0:17:43  time: 0.1975  data_time: 0.0115  memory: 5573  grad_norm: 0.7969  loss: 0.6818  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6818\n",
            "12/02 21:34:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][120/332]  lr: 1.0000e-03  eta: 0:17:39  time: 0.1989  data_time: 0.0121  memory: 5573  grad_norm: 0.7801  loss: 0.6692  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6692\n",
            "12/02 21:35:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][140/332]  lr: 1.0000e-03  eta: 0:17:35  time: 0.2233  data_time: 0.0203  memory: 5573  grad_norm: 0.8322  loss: 0.6628  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6628\n",
            "12/02 21:35:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][160/332]  lr: 1.0000e-03  eta: 0:17:30  time: 0.2434  data_time: 0.0290  memory: 5573  grad_norm: 0.7337  loss: 0.6729  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6729\n",
            "12/02 21:35:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][180/332]  lr: 1.0000e-03  eta: 0:17:26  time: 0.2160  data_time: 0.0179  memory: 5573  grad_norm: 0.8775  loss: 0.6678  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6678\n",
            "12/02 21:35:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][200/332]  lr: 1.0000e-03  eta: 0:17:21  time: 0.1984  data_time: 0.0122  memory: 5573  grad_norm: 0.8072  loss: 0.6852  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6852\n",
            "12/02 21:35:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][220/332]  lr: 1.0000e-03  eta: 0:17:17  time: 0.2019  data_time: 0.0143  memory: 5573  grad_norm: 0.9187  loss: 0.6873  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6873\n",
            "12/02 21:35:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][240/332]  lr: 1.0000e-03  eta: 0:17:13  time: 0.2386  data_time: 0.0272  memory: 5573  grad_norm: 0.8443  loss: 0.6914  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6914\n",
            "12/02 21:35:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][260/332]  lr: 1.0000e-03  eta: 0:17:09  time: 0.2363  data_time: 0.0265  memory: 5573  grad_norm: 0.9277  loss: 0.7097  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7097\n",
            "12/02 21:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][280/332]  lr: 1.0000e-03  eta: 0:17:04  time: 0.1990  data_time: 0.0122  memory: 5573  grad_norm: 0.8564  loss: 0.7087  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7087\n",
            "12/02 21:35:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][300/332]  lr: 1.0000e-03  eta: 0:17:00  time: 0.1985  data_time: 0.0126  memory: 5573  grad_norm: 0.9823  loss: 0.7058  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7058\n",
            "12/02 21:35:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][320/332]  lr: 1.0000e-03  eta: 0:16:55  time: 0.2223  data_time: 0.0225  memory: 5573  grad_norm: 0.8398  loss: 0.6945  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6945\n",
            "12/02 21:35:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:35:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][332/332]  lr: 1.0000e-03  eta: 0:16:53  time: 0.2261  data_time: 0.0255  memory: 5573  grad_norm: 0.8147  loss: 0.6854  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6854\n",
            "12/02 21:35:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 36 epochs\n",
            "12/02 21:35:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [36][20/42]    eta: 0:00:03  time: 0.1533  data_time: 0.0759  memory: 909  \n",
            "12/02 21:35:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [36][40/42]    eta: 0:00:00  time: 0.0932  data_time: 0.0279  memory: 909  \n",
            "12/02 21:35:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [36][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0487  time: 0.1177\n",
            "12/02 21:35:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][ 20/332]  lr: 1.0000e-03  eta: 0:16:48  time: 0.2067  data_time: 0.0198  memory: 5573  grad_norm: 0.7848  loss: 0.6733  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6733\n",
            "12/02 21:36:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][ 40/332]  lr: 1.0000e-03  eta: 0:16:44  time: 0.1989  data_time: 0.0122  memory: 5573  grad_norm: 0.7605  loss: 0.6801  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6801\n",
            "12/02 21:36:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:36:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][ 60/332]  lr: 1.0000e-03  eta: 0:16:39  time: 0.2393  data_time: 0.0296  memory: 5573  grad_norm: 0.7216  loss: 0.6898  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6898\n",
            "12/02 21:36:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][ 80/332]  lr: 1.0000e-03  eta: 0:16:35  time: 0.2387  data_time: 0.0285  memory: 5573  grad_norm: 0.8422  loss: 0.6741  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6741\n",
            "12/02 21:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][100/332]  lr: 1.0000e-03  eta: 0:16:31  time: 0.1987  data_time: 0.0126  memory: 5573  grad_norm: 0.7397  loss: 0.6766  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6766\n",
            "12/02 21:36:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][120/332]  lr: 1.0000e-03  eta: 0:16:26  time: 0.1979  data_time: 0.0120  memory: 5573  grad_norm: 0.6950  loss: 0.6598  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6598\n",
            "12/02 21:36:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][140/332]  lr: 1.0000e-03  eta: 0:16:22  time: 0.2150  data_time: 0.0193  memory: 5573  grad_norm: 0.7525  loss: 0.6813  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6813\n",
            "12/02 21:36:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][160/332]  lr: 1.0000e-03  eta: 0:16:18  time: 0.2393  data_time: 0.0301  memory: 5573  grad_norm: 1.0492  loss: 0.6818  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6818\n",
            "12/02 21:36:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][180/332]  lr: 1.0000e-03  eta: 0:16:13  time: 0.2208  data_time: 0.0222  memory: 5573  grad_norm: 1.3952  loss: 0.6939  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6939\n",
            "12/02 21:36:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][200/332]  lr: 1.0000e-03  eta: 0:16:09  time: 0.1984  data_time: 0.0119  memory: 5573  grad_norm: 0.9362  loss: 0.6957  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6957\n",
            "12/02 21:36:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][220/332]  lr: 1.0000e-03  eta: 0:16:04  time: 0.1990  data_time: 0.0123  memory: 5573  grad_norm: 1.0575  loss: 0.6931  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6931\n",
            "12/02 21:36:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][240/332]  lr: 1.0000e-03  eta: 0:16:00  time: 0.2430  data_time: 0.0312  memory: 5573  grad_norm: 0.8546  loss: 0.6753  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6753\n",
            "12/02 21:36:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][260/332]  lr: 1.0000e-03  eta: 0:15:56  time: 0.2584  data_time: 0.0304  memory: 5573  grad_norm: 0.7948  loss: 0.6931  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6931\n",
            "12/02 21:36:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][280/332]  lr: 1.0000e-03  eta: 0:15:52  time: 0.1984  data_time: 0.0124  memory: 5573  grad_norm: 0.7822  loss: 0.6787  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6787\n",
            "12/02 21:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][300/332]  lr: 1.0000e-03  eta: 0:15:47  time: 0.1980  data_time: 0.0115  memory: 5573  grad_norm: 0.9601  loss: 0.7101  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7101\n",
            "12/02 21:37:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][320/332]  lr: 1.0000e-03  eta: 0:15:43  time: 0.2202  data_time: 0.0222  memory: 5573  grad_norm: 0.9874  loss: 0.6763  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6763\n",
            "12/02 21:37:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:37:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][332/332]  lr: 1.0000e-03  eta: 0:15:40  time: 0.2330  data_time: 0.0281  memory: 5573  grad_norm: 1.0461  loss: 0.6859  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6859\n",
            "12/02 21:37:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 37 epochs\n",
            "12/02 21:37:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [37][20/42]    eta: 0:00:03  time: 0.1626  data_time: 0.0868  memory: 909  \n",
            "12/02 21:37:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [37][40/42]    eta: 0:00:00  time: 0.0909  data_time: 0.0248  memory: 909  \n",
            "12/02 21:37:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [37][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0525  time: 0.1210\n",
            "12/02 21:37:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][ 20/332]  lr: 1.0000e-03  eta: 0:15:36  time: 0.2081  data_time: 0.0204  memory: 5573  grad_norm: 0.9297  loss: 0.6733  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6733\n",
            "12/02 21:37:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][ 40/332]  lr: 1.0000e-03  eta: 0:15:31  time: 0.1988  data_time: 0.0126  memory: 5573  grad_norm: 0.7209  loss: 0.6882  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6882\n",
            "12/02 21:37:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][ 60/332]  lr: 1.0000e-03  eta: 0:15:27  time: 0.2322  data_time: 0.0234  memory: 5573  grad_norm: 0.9202  loss: 0.7048  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7048\n",
            "12/02 21:37:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][ 80/332]  lr: 1.0000e-03  eta: 0:15:23  time: 0.2370  data_time: 0.0265  memory: 5573  grad_norm: 0.8416  loss: 0.7065  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7065\n",
            "12/02 21:37:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][100/332]  lr: 1.0000e-03  eta: 0:15:18  time: 0.2035  data_time: 0.0143  memory: 5573  grad_norm: 0.9018  loss: 0.6753  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6753\n",
            "12/02 21:37:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][120/332]  lr: 1.0000e-03  eta: 0:15:14  time: 0.1985  data_time: 0.0118  memory: 5573  grad_norm: 0.7382  loss: 0.6902  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6902\n",
            "12/02 21:37:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][140/332]  lr: 1.0000e-03  eta: 0:15:09  time: 0.2131  data_time: 0.0171  memory: 5573  grad_norm: 0.6261  loss: 0.6509  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6509\n",
            "12/02 21:37:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][160/332]  lr: 1.0000e-03  eta: 0:15:05  time: 0.2395  data_time: 0.0292  memory: 5573  grad_norm: 0.7537  loss: 0.6756  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6756\n",
            "12/02 21:37:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][180/332]  lr: 1.0000e-03  eta: 0:15:01  time: 0.2264  data_time: 0.0222  memory: 5573  grad_norm: 0.9311  loss: 0.6952  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6952\n",
            "12/02 21:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][200/332]  lr: 1.0000e-03  eta: 0:14:56  time: 0.1975  data_time: 0.0114  memory: 5573  grad_norm: 0.8904  loss: 0.6947  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6947\n",
            "12/02 21:37:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][220/332]  lr: 1.0000e-03  eta: 0:14:52  time: 0.1984  data_time: 0.0123  memory: 5573  grad_norm: 0.8186  loss: 0.6971  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6971\n",
            "12/02 21:38:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][240/332]  lr: 1.0000e-03  eta: 0:14:48  time: 0.2368  data_time: 0.0268  memory: 5573  grad_norm: 0.7382  loss: 0.6844  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6844\n",
            "12/02 21:38:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][260/332]  lr: 1.0000e-03  eta: 0:14:43  time: 0.2371  data_time: 0.0282  memory: 5573  grad_norm: 0.8223  loss: 0.7094  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.7094\n",
            "12/02 21:38:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][280/332]  lr: 1.0000e-03  eta: 0:14:39  time: 0.2038  data_time: 0.0158  memory: 5573  grad_norm: 0.9452  loss: 0.6818  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6818\n",
            "12/02 21:38:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][300/332]  lr: 1.0000e-03  eta: 0:14:35  time: 0.1981  data_time: 0.0115  memory: 5573  grad_norm: 0.6673  loss: 0.6640  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6640\n",
            "12/02 21:38:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][320/332]  lr: 1.0000e-03  eta: 0:14:30  time: 0.2146  data_time: 0.0182  memory: 5573  grad_norm: 1.1296  loss: 0.6991  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6991\n",
            "12/02 21:38:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:38:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][332/332]  lr: 1.0000e-03  eta: 0:14:28  time: 0.2257  data_time: 0.0238  memory: 5573  grad_norm: 0.7351  loss: 0.6907  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6907\n",
            "12/02 21:38:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 38 epochs\n",
            "12/02 21:38:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [38][20/42]    eta: 0:00:03  time: 0.1495  data_time: 0.0731  memory: 909  \n",
            "12/02 21:38:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [38][40/42]    eta: 0:00:00  time: 0.1205  data_time: 0.0505  memory: 909  \n",
            "12/02 21:38:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [38][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0578  time: 0.1285\n",
            "12/02 21:38:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][ 20/332]  lr: 1.0000e-03  eta: 0:14:23  time: 0.2078  data_time: 0.0206  memory: 5573  grad_norm: 0.8262  loss: 0.6975  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6975\n",
            "12/02 21:38:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][ 40/332]  lr: 1.0000e-03  eta: 0:14:19  time: 0.1980  data_time: 0.0113  memory: 5573  grad_norm: 0.6754  loss: 0.6784  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6784\n",
            "12/02 21:38:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][ 60/332]  lr: 1.0000e-03  eta: 0:14:14  time: 0.2355  data_time: 0.0254  memory: 5573  grad_norm: 0.6933  loss: 0.6766  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6766\n",
            "12/02 21:38:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][ 80/332]  lr: 1.0000e-03  eta: 0:14:10  time: 0.2403  data_time: 0.0313  memory: 5573  grad_norm: 0.7739  loss: 0.6792  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6792\n",
            "12/02 21:38:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][100/332]  lr: 1.0000e-03  eta: 0:14:06  time: 0.2017  data_time: 0.0136  memory: 5573  grad_norm: 1.0491  loss: 0.6823  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6823\n",
            "12/02 21:38:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][120/332]  lr: 1.0000e-03  eta: 0:14:01  time: 0.1990  data_time: 0.0123  memory: 5573  grad_norm: 0.9064  loss: 0.7028  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7028\n",
            "12/02 21:38:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][140/332]  lr: 1.0000e-03  eta: 0:13:57  time: 0.2115  data_time: 0.0168  memory: 5573  grad_norm: 0.7670  loss: 0.6840  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6840\n",
            "12/02 21:39:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][160/332]  lr: 1.0000e-03  eta: 0:13:53  time: 0.2406  data_time: 0.0289  memory: 5573  grad_norm: 0.9006  loss: 0.6930  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6930\n",
            "12/02 21:39:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][180/332]  lr: 1.0000e-03  eta: 0:13:48  time: 0.2328  data_time: 0.0254  memory: 5573  grad_norm: 0.9393  loss: 0.6877  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6877\n",
            "12/02 21:39:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][200/332]  lr: 1.0000e-03  eta: 0:13:44  time: 0.1990  data_time: 0.0124  memory: 5573  grad_norm: 0.8763  loss: 0.6746  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6746\n",
            "12/02 21:39:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][220/332]  lr: 1.0000e-03  eta: 0:13:39  time: 0.1986  data_time: 0.0122  memory: 5573  grad_norm: 0.7714  loss: 0.6941  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6941\n",
            "12/02 21:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][240/332]  lr: 1.0000e-03  eta: 0:13:35  time: 0.2285  data_time: 0.0247  memory: 5573  grad_norm: 0.9226  loss: 0.6776  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6776\n",
            "12/02 21:39:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][260/332]  lr: 1.0000e-03  eta: 0:13:31  time: 0.2404  data_time: 0.0304  memory: 5573  grad_norm: 0.7593  loss: 0.6671  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6671\n",
            "12/02 21:39:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][280/332]  lr: 1.0000e-03  eta: 0:13:26  time: 0.2098  data_time: 0.0161  memory: 5573  grad_norm: 0.8707  loss: 0.6897  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6897\n",
            "12/02 21:39:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][300/332]  lr: 1.0000e-03  eta: 0:13:22  time: 0.1988  data_time: 0.0122  memory: 5573  grad_norm: 0.7631  loss: 0.6840  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6840\n",
            "12/02 21:39:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][320/332]  lr: 1.0000e-03  eta: 0:13:18  time: 0.2077  data_time: 0.0159  memory: 5573  grad_norm: 0.8877  loss: 0.6987  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6987\n",
            "12/02 21:39:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:39:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][332/332]  lr: 1.0000e-03  eta: 0:13:15  time: 0.2233  data_time: 0.0259  memory: 5573  grad_norm: 0.7109  loss: 0.6808  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6808\n",
            "12/02 21:39:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 39 epochs\n",
            "12/02 21:39:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [39][20/42]    eta: 0:00:03  time: 0.1636  data_time: 0.0883  memory: 909  \n",
            "12/02 21:39:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [39][40/42]    eta: 0:00:00  time: 0.1159  data_time: 0.0442  memory: 909  \n",
            "12/02 21:39:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [39][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0620  time: 0.1329\n",
            "12/02 21:39:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][ 20/332]  lr: 1.0000e-03  eta: 0:13:11  time: 0.2064  data_time: 0.0196  memory: 5573  grad_norm: 0.7894  loss: 0.6762  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6762\n",
            "12/02 21:39:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][ 40/332]  lr: 1.0000e-03  eta: 0:13:06  time: 0.1987  data_time: 0.0125  memory: 5573  grad_norm: 0.6454  loss: 0.6576  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6576\n",
            "12/02 21:39:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:39:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][ 60/332]  lr: 1.0000e-03  eta: 0:13:02  time: 0.2273  data_time: 0.0237  memory: 5573  grad_norm: 0.7172  loss: 0.6744  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6744\n",
            "12/02 21:40:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][ 80/332]  lr: 1.0000e-03  eta: 0:12:58  time: 0.2358  data_time: 0.0264  memory: 5573  grad_norm: 0.7720  loss: 0.6851  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6851\n",
            "12/02 21:40:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][100/332]  lr: 1.0000e-03  eta: 0:12:53  time: 0.2125  data_time: 0.0172  memory: 5573  grad_norm: 0.7571  loss: 0.6786  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6786\n",
            "12/02 21:40:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][120/332]  lr: 1.0000e-03  eta: 0:12:49  time: 0.1978  data_time: 0.0116  memory: 5573  grad_norm: 0.7592  loss: 0.6926  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6926\n",
            "12/02 21:40:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][140/332]  lr: 1.0000e-03  eta: 0:12:44  time: 0.2024  data_time: 0.0139  memory: 5573  grad_norm: 1.0091  loss: 0.6538  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6538\n",
            "12/02 21:40:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][160/332]  lr: 1.0000e-03  eta: 0:12:40  time: 0.2409  data_time: 0.0297  memory: 5573  grad_norm: 1.1019  loss: 0.7095  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7095\n",
            "12/02 21:40:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][180/332]  lr: 1.0000e-03  eta: 0:12:36  time: 0.2340  data_time: 0.0240  memory: 5573  grad_norm: 0.7825  loss: 0.6961  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6961\n",
            "12/02 21:40:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][200/332]  lr: 1.0000e-03  eta: 0:12:31  time: 0.1998  data_time: 0.0125  memory: 5573  grad_norm: 0.7197  loss: 0.6869  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6869\n",
            "12/02 21:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][220/332]  lr: 1.0000e-03  eta: 0:12:27  time: 0.1995  data_time: 0.0123  memory: 5573  grad_norm: 0.7636  loss: 0.6761  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6761\n",
            "12/02 21:40:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][240/332]  lr: 1.0000e-03  eta: 0:12:23  time: 0.2337  data_time: 0.0241  memory: 5573  grad_norm: 0.8790  loss: 0.6848  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6848\n",
            "12/02 21:40:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][260/332]  lr: 1.0000e-03  eta: 0:12:18  time: 0.2452  data_time: 0.0314  memory: 5573  grad_norm: 0.6973  loss: 0.6785  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6785\n",
            "12/02 21:40:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][280/332]  lr: 1.0000e-03  eta: 0:12:14  time: 0.2202  data_time: 0.0197  memory: 5573  grad_norm: 0.6899  loss: 0.6651  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6651\n",
            "12/02 21:40:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][300/332]  lr: 1.0000e-03  eta: 0:12:10  time: 0.1987  data_time: 0.0121  memory: 5573  grad_norm: 0.9099  loss: 0.7190  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7190\n",
            "12/02 21:40:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][320/332]  lr: 1.0000e-03  eta: 0:12:05  time: 0.2024  data_time: 0.0138  memory: 5573  grad_norm: 0.8205  loss: 0.6744  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6744\n",
            "12/02 21:40:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:40:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][332/332]  lr: 1.0000e-03  eta: 0:12:03  time: 0.2162  data_time: 0.0204  memory: 5573  grad_norm: 0.8658  loss: 0.6715  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6715\n",
            "12/02 21:40:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 40 epochs\n",
            "12/02 21:41:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][20/42]    eta: 0:00:03  time: 0.1563  data_time: 0.0812  memory: 909  \n",
            "12/02 21:41:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][40/42]    eta: 0:00:00  time: 0.1503  data_time: 0.0763  memory: 909  \n",
            "12/02 21:41:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0736  time: 0.1455\n",
            "12/02 21:41:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][ 20/332]  lr: 1.0000e-04  eta: 0:11:58  time: 0.2089  data_time: 0.0215  memory: 5573  grad_norm: 0.8483  loss: 0.6997  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6997\n",
            "12/02 21:41:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][ 40/332]  lr: 1.0000e-04  eta: 0:11:54  time: 0.1982  data_time: 0.0119  memory: 5573  grad_norm: 0.7626  loss: 0.6619  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6619\n",
            "12/02 21:41:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][ 60/332]  lr: 1.0000e-04  eta: 0:11:49  time: 0.2302  data_time: 0.0243  memory: 5573  grad_norm: 0.9783  loss: 0.7020  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7020\n",
            "12/02 21:41:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][ 80/332]  lr: 1.0000e-04  eta: 0:11:45  time: 0.2448  data_time: 0.0314  memory: 5573  grad_norm: 0.7521  loss: 0.6890  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6890\n",
            "12/02 21:41:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][100/332]  lr: 1.0000e-04  eta: 0:11:41  time: 0.2207  data_time: 0.0215  memory: 5573  grad_norm: 1.0815  loss: 0.6958  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6958\n",
            "12/02 21:41:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][120/332]  lr: 1.0000e-04  eta: 0:11:36  time: 0.1979  data_time: 0.0118  memory: 5573  grad_norm: 0.9693  loss: 0.7246  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7246\n",
            "12/02 21:41:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][140/332]  lr: 1.0000e-04  eta: 0:11:32  time: 0.2001  data_time: 0.0127  memory: 5573  grad_norm: 0.7145  loss: 0.6725  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6725\n",
            "12/02 21:41:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][160/332]  lr: 1.0000e-04  eta: 0:11:28  time: 0.2431  data_time: 0.0317  memory: 5573  grad_norm: 0.8726  loss: 0.6715  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6715\n",
            "12/02 21:41:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][180/332]  lr: 1.0000e-04  eta: 0:11:23  time: 0.2389  data_time: 0.0292  memory: 5573  grad_norm: 0.6633  loss: 0.6706  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6706\n",
            "12/02 21:41:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][200/332]  lr: 1.0000e-04  eta: 0:11:19  time: 0.1978  data_time: 0.0116  memory: 5573  grad_norm: 0.9832  loss: 0.7005  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7005\n",
            "12/02 21:41:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][220/332]  lr: 1.0000e-04  eta: 0:11:15  time: 0.1976  data_time: 0.0117  memory: 5573  grad_norm: 1.1526  loss: 0.6889  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6889\n",
            "12/02 21:41:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][240/332]  lr: 1.0000e-04  eta: 0:11:10  time: 0.2142  data_time: 0.0177  memory: 5573  grad_norm: 1.0471  loss: 0.7193  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7193\n",
            "12/02 21:42:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][260/332]  lr: 1.0000e-04  eta: 0:11:06  time: 0.2379  data_time: 0.0272  memory: 5573  grad_norm: 0.7534  loss: 0.6919  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6919\n",
            "12/02 21:42:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][280/332]  lr: 1.0000e-04  eta: 0:11:02  time: 0.2228  data_time: 0.0198  memory: 5573  grad_norm: 0.8162  loss: 0.6692  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6692\n",
            "12/02 21:42:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][300/332]  lr: 1.0000e-04  eta: 0:10:57  time: 0.1982  data_time: 0.0123  memory: 5573  grad_norm: 0.8115  loss: 0.6835  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6835\n",
            "12/02 21:42:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][320/332]  lr: 1.0000e-04  eta: 0:10:53  time: 0.1980  data_time: 0.0120  memory: 5573  grad_norm: 1.1381  loss: 0.6802  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6802\n",
            "12/02 21:42:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:42:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][332/332]  lr: 1.0000e-04  eta: 0:10:50  time: 0.2058  data_time: 0.0162  memory: 5573  grad_norm: 0.7674  loss: 0.6699  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6699\n",
            "12/02 21:42:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 41 epochs\n",
            "12/02 21:42:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [41][20/42]    eta: 0:00:03  time: 0.1537  data_time: 0.0782  memory: 909  \n",
            "12/02 21:42:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [41][40/42]    eta: 0:00:00  time: 0.1544  data_time: 0.0813  memory: 909  \n",
            "12/02 21:42:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [41][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0753  time: 0.1470\n",
            "12/02 21:42:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][ 20/332]  lr: 1.0000e-04  eta: 0:10:46  time: 0.2096  data_time: 0.0221  memory: 5573  grad_norm: 0.8522  loss: 0.6839  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6839\n",
            "12/02 21:42:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][ 40/332]  lr: 1.0000e-04  eta: 0:10:41  time: 0.1977  data_time: 0.0119  memory: 5573  grad_norm: 0.8122  loss: 0.6877  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6877\n",
            "12/02 21:42:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][ 60/332]  lr: 1.0000e-04  eta: 0:10:37  time: 0.2218  data_time: 0.0204  memory: 5573  grad_norm: 0.8402  loss: 0.6521  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6521\n",
            "12/02 21:42:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][ 80/332]  lr: 1.0000e-04  eta: 0:10:33  time: 0.2414  data_time: 0.0313  memory: 5573  grad_norm: 1.4331  loss: 0.6881  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6881\n",
            "12/02 21:42:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][100/332]  lr: 1.0000e-04  eta: 0:10:28  time: 0.2169  data_time: 0.0202  memory: 5573  grad_norm: 0.7567  loss: 0.6632  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6632\n",
            "12/02 21:42:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][120/332]  lr: 1.0000e-04  eta: 0:10:24  time: 0.1983  data_time: 0.0120  memory: 5573  grad_norm: 0.6756  loss: 0.6718  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6718\n",
            "12/02 21:42:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][140/332]  lr: 1.0000e-04  eta: 0:10:19  time: 0.1980  data_time: 0.0117  memory: 5573  grad_norm: 0.7605  loss: 0.6668  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6668\n",
            "12/02 21:42:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][160/332]  lr: 1.0000e-04  eta: 0:10:15  time: 0.2419  data_time: 0.0248  memory: 5573  grad_norm: 0.8520  loss: 0.6913  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6913\n",
            "12/02 21:43:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][180/332]  lr: 1.0000e-04  eta: 0:10:11  time: 0.2411  data_time: 0.0295  memory: 5573  grad_norm: 0.7827  loss: 0.6904  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6904\n",
            "12/02 21:43:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][200/332]  lr: 1.0000e-04  eta: 0:10:06  time: 0.1987  data_time: 0.0124  memory: 5573  grad_norm: 0.7302  loss: 0.6798  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6798\n",
            "12/02 21:43:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][220/332]  lr: 1.0000e-04  eta: 0:10:02  time: 0.1991  data_time: 0.0127  memory: 5573  grad_norm: 0.8895  loss: 0.6817  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6817\n",
            "12/02 21:43:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][240/332]  lr: 1.0000e-04  eta: 0:09:58  time: 0.2184  data_time: 0.0196  memory: 5573  grad_norm: 0.7993  loss: 0.6855  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6855\n",
            "12/02 21:43:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][260/332]  lr: 1.0000e-04  eta: 0:09:53  time: 0.2367  data_time: 0.0294  memory: 5573  grad_norm: 0.8750  loss: 0.6975  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6975\n",
            "12/02 21:43:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][280/332]  lr: 1.0000e-04  eta: 0:09:49  time: 0.2184  data_time: 0.0200  memory: 5573  grad_norm: 0.8868  loss: 0.6855  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6855\n",
            "12/02 21:43:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][300/332]  lr: 1.0000e-04  eta: 0:09:45  time: 0.1982  data_time: 0.0116  memory: 5573  grad_norm: 0.7610  loss: 0.6801  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6801\n",
            "12/02 21:43:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][320/332]  lr: 1.0000e-04  eta: 0:09:40  time: 0.1987  data_time: 0.0121  memory: 5573  grad_norm: 0.6925  loss: 0.6744  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6744\n",
            "12/02 21:43:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:43:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][332/332]  lr: 1.0000e-04  eta: 0:09:38  time: 0.2077  data_time: 0.0165  memory: 5573  grad_norm: 0.7624  loss: 0.6998  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6998\n",
            "12/02 21:43:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 42 epochs\n",
            "12/02 21:43:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [42][20/42]    eta: 0:00:03  time: 0.1630  data_time: 0.0823  memory: 909  \n",
            "12/02 21:43:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [42][40/42]    eta: 0:00:00  time: 0.1520  data_time: 0.0736  memory: 909  \n",
            "12/02 21:43:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [42][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0730  time: 0.1496\n",
            "12/02 21:43:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][ 20/332]  lr: 1.0000e-04  eta: 0:09:33  time: 0.2069  data_time: 0.0199  memory: 5573  grad_norm: 1.1033  loss: 0.6757  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6757\n",
            "12/02 21:43:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][ 40/332]  lr: 1.0000e-04  eta: 0:09:29  time: 0.1983  data_time: 0.0116  memory: 5573  grad_norm: 0.7578  loss: 0.6854  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6854\n",
            "12/02 21:43:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:43:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][ 60/332]  lr: 1.0000e-04  eta: 0:09:24  time: 0.2261  data_time: 0.0254  memory: 5573  grad_norm: 0.8638  loss: 0.6976  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6976\n",
            "12/02 21:44:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][ 80/332]  lr: 1.0000e-04  eta: 0:09:20  time: 0.2403  data_time: 0.0313  memory: 5573  grad_norm: 1.0841  loss: 0.6860  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6860\n",
            "12/02 21:44:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][100/332]  lr: 1.0000e-04  eta: 0:09:16  time: 0.2198  data_time: 0.0196  memory: 5573  grad_norm: 0.7237  loss: 0.6830  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6830\n",
            "12/02 21:44:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][120/332]  lr: 1.0000e-04  eta: 0:09:11  time: 0.1990  data_time: 0.0121  memory: 5573  grad_norm: 0.6618  loss: 0.6759  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6759\n",
            "12/02 21:44:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][140/332]  lr: 1.0000e-04  eta: 0:09:07  time: 0.2006  data_time: 0.0130  memory: 5573  grad_norm: 0.7941  loss: 0.6875  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6875\n",
            "12/02 21:44:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][160/332]  lr: 1.0000e-04  eta: 0:09:03  time: 0.2439  data_time: 0.0317  memory: 5573  grad_norm: 0.6445  loss: 0.6613  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6613\n",
            "12/02 21:44:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][180/332]  lr: 1.0000e-04  eta: 0:08:58  time: 0.2395  data_time: 0.0278  memory: 5573  grad_norm: 0.6673  loss: 0.6761  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6761\n",
            "12/02 21:44:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][200/332]  lr: 1.0000e-04  eta: 0:08:54  time: 0.1986  data_time: 0.0115  memory: 5573  grad_norm: 0.9679  loss: 0.6997  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6997\n",
            "12/02 21:44:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][220/332]  lr: 1.0000e-04  eta: 0:08:50  time: 0.1990  data_time: 0.0119  memory: 5573  grad_norm: 0.7616  loss: 0.6689  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6689\n",
            "12/02 21:44:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][240/332]  lr: 1.0000e-04  eta: 0:08:45  time: 0.2224  data_time: 0.0224  memory: 5573  grad_norm: 1.0260  loss: 0.6878  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6878\n",
            "12/02 21:44:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][260/332]  lr: 1.0000e-04  eta: 0:08:41  time: 0.2481  data_time: 0.0321  memory: 5573  grad_norm: 0.8529  loss: 0.6708  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6708\n",
            "12/02 21:44:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][280/332]  lr: 1.0000e-04  eta: 0:08:37  time: 0.2165  data_time: 0.0190  memory: 5573  grad_norm: 0.8836  loss: 0.7048  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7048\n",
            "12/02 21:44:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][300/332]  lr: 1.0000e-04  eta: 0:08:32  time: 0.1987  data_time: 0.0121  memory: 5573  grad_norm: 0.8443  loss: 0.6824  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6824\n",
            "12/02 21:44:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][320/332]  lr: 1.0000e-04  eta: 0:08:28  time: 0.1996  data_time: 0.0130  memory: 5573  grad_norm: 0.8382  loss: 0.6674  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6674\n",
            "12/02 21:44:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:44:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][332/332]  lr: 1.0000e-04  eta: 0:08:25  time: 0.2142  data_time: 0.0175  memory: 5573  grad_norm: 1.0588  loss: 0.6882  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6882\n",
            "12/02 21:44:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 43 epochs\n",
            "12/02 21:45:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [43][20/42]    eta: 0:00:03  time: 0.1598  data_time: 0.0814  memory: 909  \n",
            "12/02 21:45:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [43][40/42]    eta: 0:00:00  time: 0.1335  data_time: 0.0582  memory: 909  \n",
            "12/02 21:45:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [43][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0654  time: 0.1395\n",
            "12/02 21:45:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][ 20/332]  lr: 1.0000e-04  eta: 0:08:21  time: 0.2081  data_time: 0.0201  memory: 5573  grad_norm: 0.8274  loss: 0.6812  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6812\n",
            "12/02 21:45:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][ 40/332]  lr: 1.0000e-04  eta: 0:08:16  time: 0.1979  data_time: 0.0118  memory: 5573  grad_norm: 1.0562  loss: 0.6835  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6835\n",
            "12/02 21:45:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][ 60/332]  lr: 1.0000e-04  eta: 0:08:12  time: 0.2283  data_time: 0.0240  memory: 5573  grad_norm: 0.8541  loss: 0.6917  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6917\n",
            "12/02 21:45:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][ 80/332]  lr: 1.0000e-04  eta: 0:08:08  time: 0.2419  data_time: 0.0303  memory: 5573  grad_norm: 0.7985  loss: 0.6717  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6717\n",
            "12/02 21:45:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][100/332]  lr: 1.0000e-04  eta: 0:08:04  time: 0.2142  data_time: 0.0203  memory: 5573  grad_norm: 0.7052  loss: 0.6606  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6606\n",
            "12/02 21:45:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][120/332]  lr: 1.0000e-04  eta: 0:07:59  time: 0.1981  data_time: 0.0118  memory: 5573  grad_norm: 0.8587  loss: 0.6783  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6783\n",
            "12/02 21:45:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][140/332]  lr: 1.0000e-04  eta: 0:07:55  time: 0.2036  data_time: 0.0132  memory: 5573  grad_norm: 0.8340  loss: 0.6728  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6728\n",
            "12/02 21:45:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][160/332]  lr: 1.0000e-04  eta: 0:07:50  time: 0.2368  data_time: 0.0269  memory: 5573  grad_norm: 0.9492  loss: 0.7158  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7158\n",
            "12/02 21:45:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][180/332]  lr: 1.0000e-04  eta: 0:07:46  time: 0.2327  data_time: 0.0252  memory: 5573  grad_norm: 0.9164  loss: 0.6920  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6920\n",
            "12/02 21:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][200/332]  lr: 1.0000e-04  eta: 0:07:42  time: 0.1983  data_time: 0.0121  memory: 5573  grad_norm: 1.1597  loss: 0.6737  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6737\n",
            "12/02 21:45:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][220/332]  lr: 1.0000e-04  eta: 0:07:37  time: 0.1986  data_time: 0.0128  memory: 5573  grad_norm: 0.7161  loss: 0.6689  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6689\n",
            "12/02 21:45:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][240/332]  lr: 1.0000e-04  eta: 0:07:33  time: 0.2297  data_time: 0.0237  memory: 5573  grad_norm: 0.8423  loss: 0.6861  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6861\n",
            "12/02 21:46:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][260/332]  lr: 1.0000e-04  eta: 0:07:29  time: 0.2453  data_time: 0.0336  memory: 5573  grad_norm: 0.9189  loss: 0.6710  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6710\n",
            "12/02 21:46:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][280/332]  lr: 1.0000e-04  eta: 0:07:24  time: 0.2131  data_time: 0.0180  memory: 5573  grad_norm: 0.8024  loss: 0.7013  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7013\n",
            "12/02 21:46:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][300/332]  lr: 1.0000e-04  eta: 0:07:20  time: 0.2000  data_time: 0.0128  memory: 5573  grad_norm: 0.9479  loss: 0.7028  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7028\n",
            "12/02 21:46:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][320/332]  lr: 1.0000e-04  eta: 0:07:16  time: 0.2057  data_time: 0.0151  memory: 5573  grad_norm: 0.9710  loss: 0.6966  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6966\n",
            "12/02 21:46:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:46:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][332/332]  lr: 1.0000e-04  eta: 0:07:13  time: 0.2212  data_time: 0.0225  memory: 5573  grad_norm: 1.1186  loss: 0.6869  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6869\n",
            "12/02 21:46:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 44 epochs\n",
            "12/02 21:46:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [44][20/42]    eta: 0:00:03  time: 0.1729  data_time: 0.1006  memory: 909  \n",
            "12/02 21:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [44][40/42]    eta: 0:00:00  time: 0.1278  data_time: 0.0513  memory: 909  \n",
            "12/02 21:46:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [44][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0711  time: 0.1428\n",
            "12/02 21:46:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][ 20/332]  lr: 1.0000e-04  eta: 0:07:09  time: 0.2098  data_time: 0.0222  memory: 5573  grad_norm: 0.8031  loss: 0.6703  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6703\n",
            "12/02 21:46:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][ 40/332]  lr: 1.0000e-04  eta: 0:07:04  time: 0.1986  data_time: 0.0122  memory: 5573  grad_norm: 0.8563  loss: 0.6731  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6731\n",
            "12/02 21:46:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][ 60/332]  lr: 1.0000e-04  eta: 0:07:00  time: 0.2344  data_time: 0.0267  memory: 5573  grad_norm: 0.6450  loss: 0.6729  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6729\n",
            "12/02 21:46:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][ 80/332]  lr: 1.0000e-04  eta: 0:06:56  time: 0.2445  data_time: 0.0306  memory: 5573  grad_norm: 0.9503  loss: 0.6920  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6920\n",
            "12/02 21:46:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][100/332]  lr: 1.0000e-04  eta: 0:06:51  time: 0.2086  data_time: 0.0152  memory: 5573  grad_norm: 0.8307  loss: 0.6695  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6695\n",
            "12/02 21:46:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][120/332]  lr: 1.0000e-04  eta: 0:06:47  time: 0.1992  data_time: 0.0123  memory: 5573  grad_norm: 0.8872  loss: 0.7165  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7165\n",
            "12/02 21:46:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][140/332]  lr: 1.0000e-04  eta: 0:06:42  time: 0.2095  data_time: 0.0154  memory: 5573  grad_norm: 0.8003  loss: 0.6888  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6888\n",
            "12/02 21:46:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][160/332]  lr: 1.0000e-04  eta: 0:06:38  time: 0.2444  data_time: 0.0286  memory: 5573  grad_norm: 0.8629  loss: 0.6701  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6701\n",
            "12/02 21:47:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][180/332]  lr: 1.0000e-04  eta: 0:06:34  time: 0.2357  data_time: 0.0244  memory: 5573  grad_norm: 0.9845  loss: 0.7052  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7052\n",
            "12/02 21:47:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][200/332]  lr: 1.0000e-04  eta: 0:06:29  time: 0.1981  data_time: 0.0116  memory: 5573  grad_norm: 0.9487  loss: 0.6970  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6970\n",
            "12/02 21:47:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][220/332]  lr: 1.0000e-04  eta: 0:06:25  time: 0.1985  data_time: 0.0123  memory: 5573  grad_norm: 0.8055  loss: 0.6950  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6950\n",
            "12/02 21:47:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][240/332]  lr: 1.0000e-04  eta: 0:06:21  time: 0.2283  data_time: 0.0247  memory: 5573  grad_norm: 0.7792  loss: 0.6714  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6714\n",
            "12/02 21:47:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][260/332]  lr: 1.0000e-04  eta: 0:06:16  time: 0.2453  data_time: 0.0268  memory: 5573  grad_norm: 0.7619  loss: 0.6808  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6808\n",
            "12/02 21:47:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][280/332]  lr: 1.0000e-04  eta: 0:06:12  time: 0.2156  data_time: 0.0180  memory: 5573  grad_norm: 0.8479  loss: 0.6721  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6721\n",
            "12/02 21:47:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][300/332]  lr: 1.0000e-04  eta: 0:06:08  time: 0.1985  data_time: 0.0116  memory: 5573  grad_norm: 0.7821  loss: 0.7094  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7094\n",
            "12/02 21:47:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][320/332]  lr: 1.0000e-04  eta: 0:06:03  time: 0.2050  data_time: 0.0141  memory: 5573  grad_norm: 0.9267  loss: 0.6947  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6947\n",
            "12/02 21:47:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:47:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][332/332]  lr: 1.0000e-04  eta: 0:06:01  time: 0.2221  data_time: 0.0225  memory: 5573  grad_norm: 0.8081  loss: 0.6930  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6930\n",
            "12/02 21:47:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 45 epochs\n",
            "12/02 21:47:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [45][20/42]    eta: 0:00:03  time: 0.1606  data_time: 0.0831  memory: 909  \n",
            "12/02 21:47:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [45][40/42]    eta: 0:00:00  time: 0.1294  data_time: 0.0559  memory: 909  \n",
            "12/02 21:47:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [45][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0650  time: 0.1378\n",
            "12/02 21:47:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][ 20/332]  lr: 1.0000e-04  eta: 0:05:56  time: 0.2087  data_time: 0.0210  memory: 5573  grad_norm: 0.7996  loss: 0.6558  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6558\n",
            "12/02 21:47:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][ 40/332]  lr: 1.0000e-04  eta: 0:05:52  time: 0.1996  data_time: 0.0127  memory: 5573  grad_norm: 0.9006  loss: 0.6977  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6977\n",
            "12/02 21:47:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:47:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][ 60/332]  lr: 1.0000e-04  eta: 0:05:48  time: 0.2260  data_time: 0.0224  memory: 5573  grad_norm: 1.1087  loss: 0.7201  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7201\n",
            "12/02 21:47:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][ 80/332]  lr: 1.0000e-04  eta: 0:05:43  time: 0.2429  data_time: 0.0323  memory: 5573  grad_norm: 0.5668  loss: 0.6562  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6562\n",
            "12/02 21:48:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][100/332]  lr: 1.0000e-04  eta: 0:05:39  time: 0.2157  data_time: 0.0194  memory: 5573  grad_norm: 0.7179  loss: 0.6857  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6857\n",
            "12/02 21:48:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][120/332]  lr: 1.0000e-04  eta: 0:05:35  time: 0.2000  data_time: 0.0126  memory: 5573  grad_norm: 0.7013  loss: 0.6767  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6767\n",
            "12/02 21:48:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][140/332]  lr: 1.0000e-04  eta: 0:05:30  time: 0.2044  data_time: 0.0145  memory: 5573  grad_norm: 0.7857  loss: 0.6945  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6945\n",
            "12/02 21:48:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][160/332]  lr: 1.0000e-04  eta: 0:05:26  time: 0.2391  data_time: 0.0279  memory: 5573  grad_norm: 1.0212  loss: 0.6756  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6756\n",
            "12/02 21:48:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][180/332]  lr: 1.0000e-04  eta: 0:05:22  time: 0.2349  data_time: 0.0256  memory: 5573  grad_norm: 0.7348  loss: 0.6748  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6748\n",
            "12/02 21:48:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][200/332]  lr: 1.0000e-04  eta: 0:05:17  time: 0.2000  data_time: 0.0133  memory: 5573  grad_norm: 0.9223  loss: 0.6959  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6959\n",
            "12/02 21:48:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][220/332]  lr: 1.0000e-04  eta: 0:05:13  time: 0.1997  data_time: 0.0125  memory: 5573  grad_norm: 0.8211  loss: 0.6912  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6912\n",
            "12/02 21:48:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][240/332]  lr: 1.0000e-04  eta: 0:05:08  time: 0.2279  data_time: 0.0229  memory: 5573  grad_norm: 0.8221  loss: 0.6655  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6655\n",
            "12/02 21:48:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][260/332]  lr: 1.0000e-04  eta: 0:05:04  time: 0.2474  data_time: 0.0294  memory: 5573  grad_norm: 0.9546  loss: 0.6990  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6990\n",
            "12/02 21:48:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][280/332]  lr: 1.0000e-04  eta: 0:05:00  time: 0.2126  data_time: 0.0185  memory: 5573  grad_norm: 0.9424  loss: 0.6981  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6981\n",
            "12/02 21:48:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][300/332]  lr: 1.0000e-04  eta: 0:04:55  time: 0.1985  data_time: 0.0118  memory: 5573  grad_norm: 1.0645  loss: 0.7240  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7240\n",
            "12/02 21:48:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][320/332]  lr: 1.0000e-04  eta: 0:04:51  time: 0.2089  data_time: 0.0169  memory: 5573  grad_norm: 1.1252  loss: 0.6540  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6540\n",
            "12/02 21:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][332/332]  lr: 1.0000e-04  eta: 0:04:48  time: 0.2225  data_time: 0.0253  memory: 5573  grad_norm: 1.2067  loss: 0.6861  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6861\n",
            "12/02 21:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 46 epochs\n",
            "12/02 21:48:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [46][20/42]    eta: 0:00:03  time: 0.1641  data_time: 0.0865  memory: 909  \n",
            "12/02 21:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [46][40/42]    eta: 0:00:00  time: 0.1290  data_time: 0.0569  memory: 909  \n",
            "12/02 21:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [46][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0672  time: 0.1393\n",
            "12/02 21:49:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][ 20/332]  lr: 1.0000e-04  eta: 0:04:44  time: 0.2096  data_time: 0.0224  memory: 5573  grad_norm: 0.8677  loss: 0.7039  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7039\n",
            "12/02 21:49:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][ 40/332]  lr: 1.0000e-04  eta: 0:04:40  time: 0.1997  data_time: 0.0125  memory: 5573  grad_norm: 0.9094  loss: 0.7116  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7116\n",
            "12/02 21:49:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][ 60/332]  lr: 1.0000e-04  eta: 0:04:35  time: 0.2362  data_time: 0.0264  memory: 5573  grad_norm: 0.9731  loss: 0.6962  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6962\n",
            "12/02 21:49:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][ 80/332]  lr: 1.0000e-04  eta: 0:04:31  time: 0.2434  data_time: 0.0289  memory: 5573  grad_norm: 0.8035  loss: 0.6894  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6894\n",
            "12/02 21:49:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][100/332]  lr: 1.0000e-04  eta: 0:04:27  time: 0.2100  data_time: 0.0158  memory: 5573  grad_norm: 0.9584  loss: 0.7015  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7015\n",
            "12/02 21:49:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][120/332]  lr: 1.0000e-04  eta: 0:04:22  time: 0.1999  data_time: 0.0127  memory: 5573  grad_norm: 0.7941  loss: 0.7021  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7021\n",
            "12/02 21:49:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][140/332]  lr: 1.0000e-04  eta: 0:04:18  time: 0.2146  data_time: 0.0182  memory: 5573  grad_norm: 0.9971  loss: 0.6746  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6746\n",
            "12/02 21:49:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][160/332]  lr: 1.0000e-04  eta: 0:04:14  time: 0.2374  data_time: 0.0261  memory: 5573  grad_norm: 1.0240  loss: 0.6906  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6906\n",
            "12/02 21:49:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][180/332]  lr: 1.0000e-04  eta: 0:04:09  time: 0.2327  data_time: 0.0258  memory: 5573  grad_norm: 1.0093  loss: 0.7090  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7090\n",
            "12/02 21:49:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][200/332]  lr: 1.0000e-04  eta: 0:04:05  time: 0.1990  data_time: 0.0122  memory: 5573  grad_norm: 0.7678  loss: 0.6504  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6504\n",
            "12/02 21:49:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][220/332]  lr: 1.0000e-04  eta: 0:04:01  time: 0.1989  data_time: 0.0121  memory: 5573  grad_norm: 0.8354  loss: 0.6681  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6681\n",
            "12/02 21:49:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][240/332]  lr: 1.0000e-04  eta: 0:03:56  time: 0.2322  data_time: 0.0262  memory: 5573  grad_norm: 0.9537  loss: 0.6819  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6819\n",
            "12/02 21:49:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][260/332]  lr: 1.0000e-04  eta: 0:03:52  time: 0.2421  data_time: 0.0304  memory: 5573  grad_norm: 0.8765  loss: 0.6998  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6998\n",
            "12/02 21:50:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][280/332]  lr: 1.0000e-04  eta: 0:03:48  time: 0.2091  data_time: 0.0155  memory: 5573  grad_norm: 0.6927  loss: 0.6851  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6851\n",
            "12/02 21:50:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][300/332]  lr: 1.0000e-04  eta: 0:03:43  time: 0.2000  data_time: 0.0132  memory: 5573  grad_norm: 1.2583  loss: 0.6769  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6769\n",
            "12/02 21:50:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][320/332]  lr: 1.0000e-04  eta: 0:03:39  time: 0.2080  data_time: 0.0162  memory: 5573  grad_norm: 0.8296  loss: 0.6838  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6838\n",
            "12/02 21:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][332/332]  lr: 1.0000e-04  eta: 0:03:36  time: 0.2210  data_time: 0.0237  memory: 5573  grad_norm: 0.8124  loss: 0.6783  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6783\n",
            "12/02 21:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 47 epochs\n",
            "12/02 21:50:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [47][20/42]    eta: 0:00:03  time: 0.1590  data_time: 0.0837  memory: 909  \n",
            "12/02 21:50:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [47][40/42]    eta: 0:00:00  time: 0.1207  data_time: 0.0478  memory: 909  \n",
            "12/02 21:50:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [47][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0616  time: 0.1331\n",
            "12/02 21:50:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][ 20/332]  lr: 1.0000e-04  eta: 0:03:32  time: 0.2085  data_time: 0.0212  memory: 5573  grad_norm: 1.0883  loss: 0.6790  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6790\n",
            "12/02 21:50:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][ 40/332]  lr: 1.0000e-04  eta: 0:03:27  time: 0.1998  data_time: 0.0125  memory: 5573  grad_norm: 0.9687  loss: 0.6944  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6944\n",
            "12/02 21:50:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][ 60/332]  lr: 1.0000e-04  eta: 0:03:23  time: 0.2364  data_time: 0.0257  memory: 5573  grad_norm: 1.2123  loss: 0.6726  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6726\n",
            "12/02 21:50:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][ 80/332]  lr: 1.0000e-04  eta: 0:03:19  time: 0.2413  data_time: 0.0301  memory: 5573  grad_norm: 0.7673  loss: 0.6709  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6709\n",
            "12/02 21:50:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][100/332]  lr: 1.0000e-04  eta: 0:03:14  time: 0.2087  data_time: 0.0165  memory: 5573  grad_norm: 0.7807  loss: 0.6902  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6902\n",
            "12/02 21:50:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][120/332]  lr: 1.0000e-04  eta: 0:03:10  time: 0.1995  data_time: 0.0128  memory: 5573  grad_norm: 0.7066  loss: 0.6723  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6723\n",
            "12/02 21:50:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][140/332]  lr: 1.0000e-04  eta: 0:03:06  time: 0.2154  data_time: 0.0185  memory: 5573  grad_norm: 0.7425  loss: 0.6782  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6782\n",
            "12/02 21:50:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][160/332]  lr: 1.0000e-04  eta: 0:03:01  time: 0.2475  data_time: 0.0319  memory: 5573  grad_norm: 0.8451  loss: 0.6987  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6987\n",
            "12/02 21:50:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][180/332]  lr: 1.0000e-04  eta: 0:02:57  time: 0.2265  data_time: 0.0244  memory: 5573  grad_norm: 1.1132  loss: 0.6638  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6638\n",
            "12/02 21:51:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][200/332]  lr: 1.0000e-04  eta: 0:02:53  time: 0.1984  data_time: 0.0119  memory: 5573  grad_norm: 0.9178  loss: 0.6975  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6975\n",
            "12/02 21:51:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][220/332]  lr: 1.0000e-04  eta: 0:02:48  time: 0.1990  data_time: 0.0120  memory: 5573  grad_norm: 1.4511  loss: 0.6938  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6938\n",
            "12/02 21:51:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][240/332]  lr: 1.0000e-04  eta: 0:02:44  time: 0.2352  data_time: 0.0286  memory: 5573  grad_norm: 1.0108  loss: 0.6787  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6787\n",
            "12/02 21:51:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][260/332]  lr: 1.0000e-04  eta: 0:02:40  time: 0.2384  data_time: 0.0266  memory: 5573  grad_norm: 0.9581  loss: 0.7122  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7122\n",
            "12/02 21:51:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][280/332]  lr: 1.0000e-04  eta: 0:02:35  time: 0.2087  data_time: 0.0160  memory: 5573  grad_norm: 0.7407  loss: 0.6660  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6660\n",
            "12/02 21:51:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][300/332]  lr: 1.0000e-04  eta: 0:02:31  time: 0.1994  data_time: 0.0123  memory: 5573  grad_norm: 0.8820  loss: 0.6772  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6772\n",
            "12/02 21:51:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][320/332]  lr: 1.0000e-04  eta: 0:02:27  time: 0.2095  data_time: 0.0153  memory: 5573  grad_norm: 1.0626  loss: 0.6852  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6852\n",
            "12/02 21:51:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:51:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][332/332]  lr: 1.0000e-04  eta: 0:02:24  time: 0.2216  data_time: 0.0222  memory: 5573  grad_norm: 0.8019  loss: 0.6581  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6581\n",
            "12/02 21:51:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 48 epochs\n",
            "12/02 21:51:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [48][20/42]    eta: 0:00:03  time: 0.1660  data_time: 0.0888  memory: 909  \n",
            "12/02 21:51:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [48][40/42]    eta: 0:00:00  time: 0.1201  data_time: 0.0485  memory: 909  \n",
            "12/02 21:51:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [48][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0644  time: 0.1361\n",
            "12/02 21:51:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][ 20/332]  lr: 1.0000e-04  eta: 0:02:20  time: 0.2099  data_time: 0.0222  memory: 5573  grad_norm: 0.7472  loss: 0.6607  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6607\n",
            "12/02 21:51:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][ 40/332]  lr: 1.0000e-04  eta: 0:02:15  time: 0.1993  data_time: 0.0127  memory: 5573  grad_norm: 0.8262  loss: 0.6805  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6805\n",
            "12/02 21:51:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][ 60/332]  lr: 1.0000e-04  eta: 0:02:11  time: 0.2361  data_time: 0.0263  memory: 5573  grad_norm: 0.9752  loss: 0.7059  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7059\n",
            "12/02 21:51:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:51:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][ 80/332]  lr: 1.0000e-04  eta: 0:02:07  time: 0.2481  data_time: 0.0292  memory: 5573  grad_norm: 0.8227  loss: 0.6860  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6860\n",
            "12/02 21:52:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][100/332]  lr: 1.0000e-04  eta: 0:02:02  time: 0.2040  data_time: 0.0138  memory: 5573  grad_norm: 0.9623  loss: 0.7157  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7157\n",
            "12/02 21:52:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][120/332]  lr: 1.0000e-04  eta: 0:01:58  time: 0.1989  data_time: 0.0117  memory: 5573  grad_norm: 0.7931  loss: 0.6894  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6894\n",
            "12/02 21:52:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][140/332]  lr: 1.0000e-04  eta: 0:01:53  time: 0.2159  data_time: 0.0160  memory: 5573  grad_norm: 0.9114  loss: 0.6788  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6788\n",
            "12/02 21:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][160/332]  lr: 1.0000e-04  eta: 0:01:49  time: 0.2414  data_time: 0.0301  memory: 5573  grad_norm: 0.7654  loss: 0.6629  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6629\n",
            "12/02 21:52:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][180/332]  lr: 1.0000e-04  eta: 0:01:45  time: 0.2267  data_time: 0.0221  memory: 5573  grad_norm: 0.6580  loss: 0.6726  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6726\n",
            "12/02 21:52:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][200/332]  lr: 1.0000e-04  eta: 0:01:40  time: 0.1992  data_time: 0.0126  memory: 5573  grad_norm: 0.7426  loss: 0.6541  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6541\n",
            "12/02 21:52:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][220/332]  lr: 1.0000e-04  eta: 0:01:36  time: 0.1987  data_time: 0.0119  memory: 5573  grad_norm: 0.8456  loss: 0.7290  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7290\n",
            "12/02 21:52:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][240/332]  lr: 1.0000e-04  eta: 0:01:32  time: 0.2345  data_time: 0.0278  memory: 5573  grad_norm: 0.9570  loss: 0.6807  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6807\n",
            "12/02 21:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][260/332]  lr: 1.0000e-04  eta: 0:01:27  time: 0.2426  data_time: 0.0302  memory: 5573  grad_norm: 0.7878  loss: 0.6852  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6852\n",
            "12/02 21:52:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][280/332]  lr: 1.0000e-04  eta: 0:01:23  time: 0.2096  data_time: 0.0160  memory: 5573  grad_norm: 0.8385  loss: 0.6919  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6919\n",
            "12/02 21:52:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][300/332]  lr: 1.0000e-04  eta: 0:01:19  time: 0.1982  data_time: 0.0118  memory: 5573  grad_norm: 0.8718  loss: 0.6869  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6869\n",
            "12/02 21:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][320/332]  lr: 1.0000e-04  eta: 0:01:14  time: 0.2116  data_time: 0.0165  memory: 5573  grad_norm: 0.8001  loss: 0.6782  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6782\n",
            "12/02 21:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][332/332]  lr: 1.0000e-04  eta: 0:01:12  time: 0.2250  data_time: 0.0241  memory: 5573  grad_norm: 0.8698  loss: 0.6804  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6804\n",
            "12/02 21:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 49 epochs\n",
            "12/02 21:52:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [49][20/42]    eta: 0:00:03  time: 0.1581  data_time: 0.0813  memory: 909  \n",
            "12/02 21:52:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [49][40/42]    eta: 0:00:00  time: 0.1174  data_time: 0.0466  memory: 909  \n",
            "12/02 21:52:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [49][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0598  time: 0.1311\n",
            "12/02 21:53:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][ 20/332]  lr: 1.0000e-04  eta: 0:01:07  time: 0.2080  data_time: 0.0204  memory: 5573  grad_norm: 0.9358  loss: 0.6818  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6818\n",
            "12/02 21:53:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][ 40/332]  lr: 1.0000e-04  eta: 0:01:03  time: 0.1984  data_time: 0.0120  memory: 5573  grad_norm: 0.8200  loss: 0.6630  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6630\n",
            "12/02 21:53:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][ 60/332]  lr: 1.0000e-04  eta: 0:00:59  time: 0.2361  data_time: 0.0258  memory: 5573  grad_norm: 0.7584  loss: 0.6751  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6751\n",
            "12/02 21:53:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][ 80/332]  lr: 1.0000e-04  eta: 0:00:54  time: 0.2413  data_time: 0.0305  memory: 5573  grad_norm: 0.7188  loss: 0.6649  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6649\n",
            "12/02 21:53:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][100/332]  lr: 1.0000e-04  eta: 0:00:50  time: 0.2069  data_time: 0.0153  memory: 5573  grad_norm: 0.6870  loss: 0.6774  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6774\n",
            "12/02 21:53:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][120/332]  lr: 1.0000e-04  eta: 0:00:46  time: 0.1983  data_time: 0.0118  memory: 5573  grad_norm: 0.8128  loss: 0.6828  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6828\n",
            "12/02 21:53:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][140/332]  lr: 1.0000e-04  eta: 0:00:41  time: 0.2139  data_time: 0.0178  memory: 5573  grad_norm: 0.6872  loss: 0.6731  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6731\n",
            "12/02 21:53:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][160/332]  lr: 1.0000e-04  eta: 0:00:37  time: 0.2449  data_time: 0.0327  memory: 5573  grad_norm: 0.8871  loss: 0.6861  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6861\n",
            "12/02 21:53:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][180/332]  lr: 1.0000e-04  eta: 0:00:33  time: 0.2249  data_time: 0.0238  memory: 5573  grad_norm: 0.8492  loss: 0.6752  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6752\n",
            "12/02 21:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][200/332]  lr: 1.0000e-04  eta: 0:00:28  time: 0.1985  data_time: 0.0119  memory: 5573  grad_norm: 0.8650  loss: 0.6887  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6887\n",
            "12/02 21:53:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][220/332]  lr: 1.0000e-04  eta: 0:00:24  time: 0.1992  data_time: 0.0123  memory: 5573  grad_norm: 0.7272  loss: 0.6884  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6884\n",
            "12/02 21:53:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][240/332]  lr: 1.0000e-04  eta: 0:00:20  time: 0.2390  data_time: 0.0283  memory: 5573  grad_norm: 0.9352  loss: 0.7180  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7180\n",
            "12/02 21:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][260/332]  lr: 1.0000e-04  eta: 0:00:15  time: 0.2393  data_time: 0.0270  memory: 5573  grad_norm: 1.1570  loss: 0.6883  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6883\n",
            "12/02 21:53:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][280/332]  lr: 1.0000e-04  eta: 0:00:11  time: 0.2076  data_time: 0.0162  memory: 5573  grad_norm: 0.8840  loss: 0.7096  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7096\n",
            "12/02 21:54:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][300/332]  lr: 1.0000e-04  eta: 0:00:06  time: 0.1989  data_time: 0.0117  memory: 5573  grad_norm: 0.7602  loss: 0.6974  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6974\n",
            "12/02 21:54:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][320/332]  lr: 1.0000e-04  eta: 0:00:02  time: 0.2105  data_time: 0.0173  memory: 5573  grad_norm: 0.8399  loss: 0.6947  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6947\n",
            "12/02 21:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: tsn_r50_320p_1x1x8_10e_flow_activitynet_finetune_20231202_204840\n",
            "12/02 21:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][332/332]  lr: 1.0000e-04  eta: 0:00:00  time: 0.2243  data_time: 0.0229  memory: 5573  grad_norm: 0.8694  loss: 0.6864  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6864\n",
            "12/02 21:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 50 epochs\n",
            "12/02 21:54:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][20/42]    eta: 0:00:03  time: 0.1735  data_time: 0.0925  memory: 909  \n",
            "12/02 21:54:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][40/42]    eta: 0:00:00  time: 0.1085  data_time: 0.0430  memory: 909  \n",
            "12/02 21:54:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][42/42]    acc/top1: 0.5559  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0634  time: 0.1340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp ./flow_checkpoints/epoch_50.pth /content/drive/MyDrive/accident-detection/models/tsn_r50_320p_1x1x8_50e_flow_activitynet_finetune.pth"
      ],
      "metadata": {
        "id": "YEiK1ZH5IhaK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Poq3YxJTL2AS"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}