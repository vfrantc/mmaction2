{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vfrantc/mmaction2/blob/main/cuny/experiments/no_pretrain_tsm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIT8tO-DStuc",
        "outputId": "20b6d6b8-a11d-4665-e462-2bff358332e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cvxpy 1.3.3 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.36 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.1/94.1 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.0/436.0 kB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n",
            "rm: cannot remove '/content/mmaction2/': No such file or directory\n",
            "Cloning into 'mmaction2'...\n",
            "remote: Enumerating objects: 22460, done.\u001b[K\n",
            "remote: Counting objects: 100% (374/374), done.\u001b[K\n",
            "remote: Compressing objects: 100% (183/183), done.\u001b[K\n",
            "remote: Total 22460 (delta 213), reused 331 (delta 185), pack-reused 22086\u001b[K\n",
            "Receiving objects: 100% (22460/22460), 65.52 MiB | 7.56 MiB/s, done.\n",
            "Resolving deltas: 100% (15771/15771), done.\n",
            "/content/mmaction2\n",
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Obtaining file:///content/mmaction2\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-t5fqvpnp/mmaction2.egg-info\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-t5fqvpnp/mmaction2.egg-info/SOURCES.txt'\n",
            "  warning: no files found matching 'mmaction/.mim/model-index.yml'\n",
            "  warning: no files found matching 'mmaction/.mim/dataset-index.yml'\n",
            "  warning: no files found matching '*.py' under directory 'mmaction/.mim/configs'\n",
            "  warning: no files found matching '*.yml' under directory 'mmaction/.mim/configs'\n",
            "  warning: no files found matching '*.sh' under directory 'mmaction/.mim/tools'\n",
            "  warning: no files found matching '*.py' under directory 'mmaction/.mim/tools'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-t5fqvpnp/mmaction2.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting decord>=0.4.1 (from mmaction2==1.2.0)\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m58.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from mmaction2==1.2.0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmaction2==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->mmaction2==1.2.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->mmaction2==1.2.0) (1.3.0)\n",
            "Installing collected packages: einops, decord, mmaction2\n",
            "  Running setup.py develop for mmaction2\n",
            "    Running command python setup.py develop\n",
            "    running develop\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    running egg_info\n",
            "    creating mmaction2.egg-info\n",
            "    writing manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "Successfully installed decord-0.6.0 einops-0.7.0 mmaction2-1.2.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# INSTALL REQUIREMENTS AND MMACTION\n",
        "!pip install pytorchvideo --quiet\n",
        "!pip install timm --quiet\n",
        "!pip install -U openmim --quiet\n",
        "!mim install mmengine --quiet\n",
        "!mim install mmcv --quiet\n",
        "!mim install mmdet --quiet\n",
        "!mim install mmpose --quiet\n",
        "\n",
        "# INSTALL MMACTION, OUR CONFIGS ARE THERE AS WELL\n",
        "%cd /content/\n",
        "!rm -r /content/mmaction2/\n",
        "!git clone https://github.com/vfrantc/mmaction2.git\n",
        "%cd mmaction2\n",
        "!pip install -v -e .\n",
        "\n",
        "# COPY DATASET\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!cp /content/drive/MyDrive/cuny_dataset/cuny_dataset.zip .\n",
        "!unzip -qq cuny_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv content/mmaction2/data ."
      ],
      "metadata": {
        "id": "p-HNQ4rOzZf1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYI5XnUtioeV"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07a89_KO_34J",
        "outputId": "6b19e5af-567c-46c6-da1b-85e932676d05"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E-8hE5fOhTMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89c6b766-3e2c-44bd-c4b0-d47796888388"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/09 13:16:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1104947480\n",
            "    GPU 0: Tesla V100-SXM2-16GB\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.1.0+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX512\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.0+cu121\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.3\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1104947480\n",
            "    diff_rank_seed: False\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "02/09 13:16:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "ann_file_train = 'data/kinetics400/kinetics400_train_list_videos.txt'\n",
            "ann_file_val = 'data/kinetics400/kinetics400_val_list_videos.txt'\n",
            "auto_scale_lr = dict(base_batch_size=128, enable=False)\n",
            "data_root = 'data/kinetics400/videos_train'\n",
            "data_root_val = 'data/kinetics400/videos_val'\n",
            "dataset_type = 'VideoDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=3, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'),\n",
            "    timer=dict(type='IterTimerHook'))\n",
            "default_scope = 'mmaction'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "file_client_args = dict(io_backend='disk')\n",
            "launcher = 'none'\n",
            "load_from = None\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        depth=50,\n",
            "        norm_eval=False,\n",
            "        pretrained='torchvision://resnet50',\n",
            "        shift_div=8,\n",
            "        type='ResNetTSM'),\n",
            "    cls_head=dict(\n",
            "        average_clips='prob',\n",
            "        consensus=dict(dim=1, type='AvgConsensus'),\n",
            "        dropout_ratio=0.5,\n",
            "        in_channels=2048,\n",
            "        init_std=0.001,\n",
            "        is_shift=True,\n",
            "        num_classes=2,\n",
            "        spatial_type='avg',\n",
            "        type='TSMHead'),\n",
            "    data_preprocessor=dict(\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='ActionDataPreprocessor'),\n",
            "    test_cfg=None,\n",
            "    train_cfg=None,\n",
            "    type='Recognizer2D')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=dict(max_norm=20, norm_type=2),\n",
            "    constructor='TSMOptimWrapperConstructor',\n",
            "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0001),\n",
            "    paramwise_cfg=dict(fc_lr5=True))\n",
            "param_scheduler = [\n",
            "    dict(begin=0, by_epoch=True, end=5, start_factor=0.1, type='LinearLR'),\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        end=50,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            25,\n",
            "            45,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "preprocess_cfg = dict(\n",
            "    mean=[\n",
            "        123.675,\n",
            "        116.28,\n",
            "        103.53,\n",
            "    ], std=[\n",
            "        58.395,\n",
            "        57.12,\n",
            "        57.375,\n",
            "    ])\n",
            "randomness = dict(deterministic=False, diff_rank_seed=False, seed=None)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='data/kinetics400/kinetics400_val_list_videos.txt',\n",
            "        data_prefix=dict(video='data/kinetics400/videos_val'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=8,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='TenCrop'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "test_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=8,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='TenCrop'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "train_cfg = dict(\n",
            "    max_epochs=50, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='data/kinetics400/kinetics400_train_list_videos.txt',\n",
            "        data_prefix=dict(video='data/kinetics400/videos_train'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=1, frame_interval=1, num_clips=8,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(\n",
            "                input_size=224,\n",
            "                max_wh_scale_gap=1,\n",
            "                num_fixed_crops=13,\n",
            "                random_crop=False,\n",
            "                scales=(\n",
            "                    1,\n",
            "                    0.875,\n",
            "                    0.75,\n",
            "                    0.66,\n",
            "                ),\n",
            "                type='MultiScaleCrop'),\n",
            "            dict(keep_ratio=False, scale=(\n",
            "                224,\n",
            "                224,\n",
            "            ), type='Resize'),\n",
            "            dict(flip_ratio=0.5, type='Flip'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(clip_len=1, frame_interval=1, num_clips=8, type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(\n",
            "        input_size=224,\n",
            "        max_wh_scale_gap=1,\n",
            "        num_fixed_crops=13,\n",
            "        random_crop=False,\n",
            "        scales=(\n",
            "            1,\n",
            "            0.875,\n",
            "            0.75,\n",
            "            0.66,\n",
            "        ),\n",
            "        type='MultiScaleCrop'),\n",
            "    dict(keep_ratio=False, scale=(\n",
            "        224,\n",
            "        224,\n",
            "    ), type='Resize'),\n",
            "    dict(flip_ratio=0.5, type='Flip'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='data/kinetics400/kinetics400_val_list_videos.txt',\n",
            "        data_prefix=dict(video='data/kinetics400/videos_val'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=1,\n",
            "                frame_interval=1,\n",
            "                num_clips=8,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='CenterCrop'),\n",
            "            dict(input_format='NCHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "val_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(\n",
            "        clip_len=1,\n",
            "        frame_interval=1,\n",
            "        num_clips=8,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='CenterCrop'),\n",
            "    dict(input_format='NCHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb'\n",
            "\n",
            "02/09 13:16:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "02/09 13:16:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "Loads checkpoint by torchvision backend from path: torchvision://resnet50\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 409MB/s]\n",
            "wrapped_name layer1.0.conv1.conv.net.weight\n",
            "wrapped_name layer1.1.conv1.conv.net.weight\n",
            "wrapped_name layer1.2.conv1.conv.net.weight\n",
            "wrapped_name layer2.0.conv1.conv.net.weight\n",
            "wrapped_name layer2.1.conv1.conv.net.weight\n",
            "wrapped_name layer2.2.conv1.conv.net.weight\n",
            "wrapped_name layer2.3.conv1.conv.net.weight\n",
            "wrapped_name layer3.0.conv1.conv.net.weight\n",
            "wrapped_name layer3.1.conv1.conv.net.weight\n",
            "wrapped_name layer3.2.conv1.conv.net.weight\n",
            "wrapped_name layer3.3.conv1.conv.net.weight\n",
            "wrapped_name layer3.4.conv1.conv.net.weight\n",
            "wrapped_name layer3.5.conv1.conv.net.weight\n",
            "wrapped_name layer4.0.conv1.conv.net.weight\n",
            "wrapped_name layer4.1.conv1.conv.net.weight\n",
            "wrapped_name layer4.2.conv1.conv.net.weight\n",
            "02/09 13:16:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - _IncompatibleKeys(missing_keys=[], unexpected_keys=['fc.weight', 'fc.bias'])\n",
            "02/09 13:16:18 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "02/09 13:16:18 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "02/09 13:16:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmaction2/work_dirs/no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb.\n",
            "02/09 13:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 1:38:57  time: 0.7171  data_time: 0.1062  memory: 13533  grad_norm: 11.2395  loss: 1.0803  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 1.0803\n",
            "02/09 13:16:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 1:25:03  time: 0.5186  data_time: 0.0173  memory: 13533  grad_norm: 17.4752  loss: 1.1549  top1_acc: 0.4375  top5_acc: 1.0000  loss_cls: 1.1549\n",
            "02/09 13:16:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 1:20:18  time: 0.5187  data_time: 0.0173  memory: 13533  grad_norm: 19.1590  loss: 1.2215  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.2215\n",
            "02/09 13:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 1:17:54  time: 0.5204  data_time: 0.0186  memory: 13533  grad_norm: 17.9216  loss: 0.9307  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.9307\n",
            "02/09 13:17:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 1:16:21  time: 0.5190  data_time: 0.0177  memory: 13533  grad_norm: 17.3712  loss: 1.0209  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 1.0209\n",
            "02/09 13:17:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 1:15:17  time: 0.5201  data_time: 0.0186  memory: 13533  grad_norm: 17.3636  loss: 0.9917  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.9917\n",
            "02/09 13:17:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 1:14:30  time: 0.5211  data_time: 0.0186  memory: 13533  grad_norm: 20.3906  loss: 1.3321  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 1.3321\n",
            "02/09 13:17:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 1:13:51  time: 0.5199  data_time: 0.0179  memory: 13533  grad_norm: 15.0689  loss: 0.9660  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.9660\n",
            "02/09 13:17:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:17:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 1:13:38  time: 0.5174  data_time: 0.0174  memory: 13533  grad_norm: 13.5616  loss: 0.9121  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.9121\n",
            "02/09 13:17:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [1][20/21]    eta: 0:00:00  time: 0.2735  data_time: 0.1329  memory: 1642  \n",
            "02/09 13:17:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][21/21]    acc/top1: 0.6596  acc/top5: 1.0000  acc/mean1: 0.6487  data_time: 0.1269  time: 0.2658\n",
            "02/09 13:17:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6596 acc/top1 at 1 epoch is saved to best_acc_top1_epoch_1.pth.\n",
            "02/09 13:18:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 20/166]  base_lr: 6.5000e-03 lr: 6.5000e-03  eta: 1:13:59  time: 0.5798  data_time: 0.0762  memory: 13533  grad_norm: 13.6465  loss: 1.6764  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.6764\n",
            "02/09 13:18:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 40/166]  base_lr: 6.5000e-03 lr: 6.5000e-03  eta: 1:13:27  time: 0.5201  data_time: 0.0188  memory: 13533  grad_norm: 6.4513  loss: 0.9709  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.9709\n",
            "02/09 13:18:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 60/166]  base_lr: 6.5000e-03 lr: 6.5000e-03  eta: 1:12:58  time: 0.5193  data_time: 0.0182  memory: 13533  grad_norm: 4.3037  loss: 0.8798  top1_acc: 0.4375  top5_acc: 1.0000  loss_cls: 0.8798\n",
            "02/09 13:18:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][ 80/166]  base_lr: 6.5000e-03 lr: 6.5000e-03  eta: 1:12:32  time: 0.5196  data_time: 0.0178  memory: 13533  grad_norm: 3.8128  loss: 0.7727  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7727\n",
            "02/09 13:18:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][100/166]  base_lr: 6.5000e-03 lr: 6.5000e-03  eta: 1:12:09  time: 0.5196  data_time: 0.0181  memory: 13533  grad_norm: 3.7862  loss: 0.7539  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7539\n",
            "02/09 13:18:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][120/166]  base_lr: 6.5000e-03 lr: 6.5000e-03  eta: 1:11:48  time: 0.5213  data_time: 0.0193  memory: 13533  grad_norm: 4.1503  loss: 0.7656  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7656\n",
            "02/09 13:19:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][140/166]  base_lr: 6.5000e-03 lr: 6.5000e-03  eta: 1:11:28  time: 0.5196  data_time: 0.0184  memory: 13533  grad_norm: 5.4119  loss: 0.8728  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.8728\n",
            "02/09 13:19:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][160/166]  base_lr: 6.5000e-03 lr: 6.5000e-03  eta: 1:11:08  time: 0.5179  data_time: 0.0171  memory: 13533  grad_norm: 4.3260  loss: 0.7445  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7445\n",
            "02/09 13:19:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:19:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][166/166]  base_lr: 6.5000e-03 lr: 6.5000e-03  eta: 1:11:01  time: 0.5138  data_time: 0.0161  memory: 13533  grad_norm: 4.7391  loss: 0.7582  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.7582\n",
            "02/09 13:19:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [2][20/21]    eta: 0:00:00  time: 0.2356  data_time: 0.1003  memory: 1642  \n",
            "02/09 13:19:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][21/21]    acc/top1: 0.5813  acc/top5: 1.0000  acc/mean1: 0.5540  data_time: 0.0917  time: 0.2239\n",
            "02/09 13:19:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 20/166]  base_lr: 1.1000e-02 lr: 1.1000e-02  eta: 1:11:08  time: 0.5741  data_time: 0.0704  memory: 13533  grad_norm: 7.8770  loss: 1.0336  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 1.0336\n",
            "02/09 13:19:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 40/166]  base_lr: 1.1000e-02 lr: 1.1000e-02  eta: 1:10:50  time: 0.5202  data_time: 0.0183  memory: 13533  grad_norm: 3.9631  loss: 0.8701  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8701\n",
            "02/09 13:19:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 60/166]  base_lr: 1.1000e-02 lr: 1.1000e-02  eta: 1:10:33  time: 0.5206  data_time: 0.0187  memory: 13533  grad_norm: 3.3499  loss: 0.6944  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6944\n",
            "02/09 13:20:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][ 80/166]  base_lr: 1.1000e-02 lr: 1.1000e-02  eta: 1:10:16  time: 0.5201  data_time: 0.0183  memory: 13533  grad_norm: 3.2537  loss: 0.7337  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.7337\n",
            "02/09 13:20:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][100/166]  base_lr: 1.1000e-02 lr: 1.1000e-02  eta: 1:10:00  time: 0.5194  data_time: 0.0178  memory: 13533  grad_norm: 2.1694  loss: 0.7691  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.7691\n",
            "02/09 13:20:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][120/166]  base_lr: 1.1000e-02 lr: 1.1000e-02  eta: 1:09:45  time: 0.5206  data_time: 0.0186  memory: 13533  grad_norm: 2.4036  loss: 0.6818  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6818\n",
            "02/09 13:20:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][140/166]  base_lr: 1.1000e-02 lr: 1.1000e-02  eta: 1:09:30  time: 0.5193  data_time: 0.0176  memory: 13533  grad_norm: 2.4090  loss: 0.7053  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7053\n",
            "02/09 13:20:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][160/166]  base_lr: 1.1000e-02 lr: 1.1000e-02  eta: 1:09:15  time: 0.5191  data_time: 0.0179  memory: 13533  grad_norm: 1.9795  loss: 0.8142  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8142\n",
            "02/09 13:20:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:20:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][166/166]  base_lr: 1.1000e-02 lr: 1.1000e-02  eta: 1:09:09  time: 0.5156  data_time: 0.0175  memory: 13533  grad_norm: 1.6469  loss: 0.7053  top1_acc: 0.5714  top5_acc: 1.0000  loss_cls: 0.7053\n",
            "02/09 13:20:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
            "02/09 13:21:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [3][20/21]    eta: 0:00:00  time: 0.2451  data_time: 0.1078  memory: 1642  \n",
            "02/09 13:21:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][21/21]    acc/top1: 0.5873  acc/top5: 1.0000  acc/mean1: 0.5797  data_time: 0.0985  time: 0.2323\n",
            "02/09 13:21:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 20/166]  base_lr: 1.5500e-02 lr: 1.5500e-02  eta: 1:09:14  time: 0.5834  data_time: 0.0797  memory: 13533  grad_norm: 1.9610  loss: 0.7345  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7345\n",
            "02/09 13:21:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 40/166]  base_lr: 1.5500e-02 lr: 1.5500e-02  eta: 1:08:59  time: 0.5198  data_time: 0.0185  memory: 13533  grad_norm: 1.7803  loss: 0.6712  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6712\n",
            "02/09 13:21:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 60/166]  base_lr: 1.5500e-02 lr: 1.5500e-02  eta: 1:08:45  time: 0.5193  data_time: 0.0174  memory: 13533  grad_norm: 2.4872  loss: 0.7239  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.7239\n",
            "02/09 13:21:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][ 80/166]  base_lr: 1.5500e-02 lr: 1.5500e-02  eta: 1:08:31  time: 0.5196  data_time: 0.0180  memory: 13533  grad_norm: 2.1601  loss: 0.7696  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7696\n",
            "02/09 13:21:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][100/166]  base_lr: 1.5500e-02 lr: 1.5500e-02  eta: 1:08:17  time: 0.5205  data_time: 0.0184  memory: 13533  grad_norm: 1.5827  loss: 0.7797  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.7797\n",
            "02/09 13:22:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][120/166]  base_lr: 1.5500e-02 lr: 1.5500e-02  eta: 1:08:04  time: 0.5214  data_time: 0.0195  memory: 13533  grad_norm: 1.5435  loss: 0.7180  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7180\n",
            "02/09 13:22:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][140/166]  base_lr: 1.5500e-02 lr: 1.5500e-02  eta: 1:07:50  time: 0.5209  data_time: 0.0194  memory: 13533  grad_norm: 1.7389  loss: 0.6875  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6875\n",
            "02/09 13:22:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][160/166]  base_lr: 1.5500e-02 lr: 1.5500e-02  eta: 1:07:37  time: 0.5200  data_time: 0.0185  memory: 13533  grad_norm: 2.0609  loss: 0.6546  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6546\n",
            "02/09 13:22:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:22:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][166/166]  base_lr: 1.5500e-02 lr: 1.5500e-02  eta: 1:07:32  time: 0.5157  data_time: 0.0174  memory: 13533  grad_norm: 1.9805  loss: 0.6448  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.6448\n",
            "02/09 13:22:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [4][20/21]    eta: 0:00:00  time: 0.2328  data_time: 0.0964  memory: 1642  \n",
            "02/09 13:22:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][21/21]    acc/top1: 0.6295  acc/top5: 1.0000  acc/mean1: 0.6181  data_time: 0.0881  time: 0.2212\n",
            "02/09 13:22:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:07:36  time: 0.5935  data_time: 0.0889  memory: 13533  grad_norm: 1.7006  loss: 0.7057  top1_acc: 0.4375  top5_acc: 1.0000  loss_cls: 0.7057\n",
            "02/09 13:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:07:22  time: 0.5205  data_time: 0.0187  memory: 13533  grad_norm: 1.7329  loss: 0.7024  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.7024\n",
            "02/09 13:23:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:07:09  time: 0.5202  data_time: 0.0185  memory: 13533  grad_norm: 1.7555  loss: 0.7180  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.7180\n",
            "02/09 13:23:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:06:56  time: 0.5207  data_time: 0.0191  memory: 13533  grad_norm: 1.4107  loss: 0.6201  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6201\n",
            "02/09 13:23:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:06:44  time: 0.5216  data_time: 0.0193  memory: 13533  grad_norm: 1.2571  loss: 0.6417  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6417\n",
            "02/09 13:23:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:06:31  time: 0.5189  data_time: 0.0176  memory: 13533  grad_norm: 1.4797  loss: 0.6890  top1_acc: 0.4375  top5_acc: 1.0000  loss_cls: 0.6890\n",
            "02/09 13:23:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:06:18  time: 0.5199  data_time: 0.0181  memory: 13533  grad_norm: 1.5479  loss: 0.7776  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.7776\n",
            "02/09 13:23:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:06:05  time: 0.5191  data_time: 0.0176  memory: 13533  grad_norm: 1.1510  loss: 0.6971  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6971\n",
            "02/09 13:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:06:01  time: 0.5150  data_time: 0.0169  memory: 13533  grad_norm: 1.0939  loss: 0.6744  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.6744\n",
            "02/09 13:24:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [5][20/21]    eta: 0:00:00  time: 0.2525  data_time: 0.1160  memory: 1642  \n",
            "02/09 13:24:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][21/21]    acc/top1: 0.5934  acc/top5: 1.0000  acc/mean1: 0.5657  data_time: 0.1060  time: 0.2391\n",
            "02/09 13:24:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:05:59  time: 0.5827  data_time: 0.0787  memory: 13533  grad_norm: 1.1791  loss: 0.6884  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6884\n",
            "02/09 13:24:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:05:47  time: 0.5194  data_time: 0.0179  memory: 13533  grad_norm: 1.2743  loss: 0.6342  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6342\n",
            "02/09 13:24:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:05:34  time: 0.5202  data_time: 0.0186  memory: 13533  grad_norm: 1.1890  loss: 0.6335  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6335\n",
            "02/09 13:24:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:05:22  time: 0.5206  data_time: 0.0187  memory: 13533  grad_norm: 1.2583  loss: 0.6645  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6645\n",
            "02/09 13:24:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:05:10  time: 0.5201  data_time: 0.0183  memory: 13533  grad_norm: 1.2190  loss: 0.6161  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6161\n",
            "02/09 13:25:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:04:57  time: 0.5203  data_time: 0.0189  memory: 13533  grad_norm: 1.1685  loss: 0.6741  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6741\n",
            "02/09 13:25:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:04:45  time: 0.5201  data_time: 0.0184  memory: 13533  grad_norm: 1.3283  loss: 0.6428  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6428\n",
            "02/09 13:25:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:04:33  time: 0.5185  data_time: 0.0175  memory: 13533  grad_norm: 1.4534  loss: 0.5985  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5985\n",
            "02/09 13:25:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:25:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:04:29  time: 0.5151  data_time: 0.0173  memory: 13533  grad_norm: 1.5037  loss: 0.6464  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.6464\n",
            "02/09 13:25:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
            "02/09 13:25:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [6][20/21]    eta: 0:00:00  time: 0.2327  data_time: 0.0968  memory: 1642  \n",
            "02/09 13:25:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][21/21]    acc/top1: 0.6205  acc/top5: 1.0000  acc/mean1: 0.6064  data_time: 0.0885  time: 0.2211\n",
            "02/09 13:25:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:25:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:04:24  time: 0.5713  data_time: 0.0659  memory: 13533  grad_norm: 1.1093  loss: 0.6053  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6053\n",
            "02/09 13:26:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:04:12  time: 0.5201  data_time: 0.0185  memory: 13533  grad_norm: 1.3605  loss: 0.6510  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6510\n",
            "02/09 13:26:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:04:00  time: 0.5202  data_time: 0.0187  memory: 13533  grad_norm: 0.9606  loss: 0.6745  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6745\n",
            "02/09 13:26:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:03:48  time: 0.5199  data_time: 0.0184  memory: 13533  grad_norm: 1.0263  loss: 0.6566  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6566\n",
            "02/09 13:26:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:03:36  time: 0.5191  data_time: 0.0176  memory: 13533  grad_norm: 1.1982  loss: 0.6319  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6319\n",
            "02/09 13:26:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:03:24  time: 0.5195  data_time: 0.0179  memory: 13533  grad_norm: 1.2828  loss: 0.6399  top1_acc: 0.4375  top5_acc: 1.0000  loss_cls: 0.6399\n",
            "02/09 13:26:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:03:12  time: 0.5195  data_time: 0.0181  memory: 13533  grad_norm: 0.9765  loss: 0.6387  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6387\n",
            "02/09 13:27:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:03:01  time: 0.5202  data_time: 0.0190  memory: 13533  grad_norm: 1.1480  loss: 0.6528  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6528\n",
            "02/09 13:27:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:27:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:02:57  time: 0.5161  data_time: 0.0182  memory: 13533  grad_norm: 1.2781  loss: 0.6482  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6482\n",
            "02/09 13:27:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [7][20/21]    eta: 0:00:00  time: 0.2479  data_time: 0.1095  memory: 1642  \n",
            "02/09 13:27:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [7][21/21]    acc/top1: 0.6596  acc/top5: 1.0000  acc/mean1: 0.6399  data_time: 0.1001  time: 0.2349\n",
            "02/09 13:27:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:02:51  time: 0.5694  data_time: 0.0659  memory: 13533  grad_norm: 1.2453  loss: 0.6241  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6241\n",
            "02/09 13:27:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:02:39  time: 0.5190  data_time: 0.0178  memory: 13533  grad_norm: 1.1066  loss: 0.6139  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6139\n",
            "02/09 13:27:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:02:27  time: 0.5207  data_time: 0.0189  memory: 13533  grad_norm: 1.4418  loss: 0.6523  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6523\n",
            "02/09 13:27:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:02:16  time: 0.5201  data_time: 0.0185  memory: 13533  grad_norm: 1.2300  loss: 0.6345  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6345\n",
            "02/09 13:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:02:04  time: 0.5201  data_time: 0.0186  memory: 13533  grad_norm: 1.5116  loss: 0.6502  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6502\n",
            "02/09 13:28:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:01:53  time: 0.5199  data_time: 0.0185  memory: 13533  grad_norm: 1.2016  loss: 0.6703  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6703\n",
            "02/09 13:28:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:01:41  time: 0.5204  data_time: 0.0186  memory: 13533  grad_norm: 1.1009  loss: 0.5963  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5963\n",
            "02/09 13:28:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:01:29  time: 0.5185  data_time: 0.0175  memory: 13533  grad_norm: 1.1269  loss: 0.5751  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5751\n",
            "02/09 13:28:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:28:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:01:26  time: 0.5152  data_time: 0.0173  memory: 13533  grad_norm: 1.1728  loss: 0.5773  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.5773\n",
            "02/09 13:28:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [8][20/21]    eta: 0:00:00  time: 0.2380  data_time: 0.1043  memory: 1642  \n",
            "02/09 13:28:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][21/21]    acc/top1: 0.6687  acc/top5: 1.0000  acc/mean1: 0.6492  data_time: 0.0953  time: 0.2259\n",
            "02/09 13:28:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb/best_acc_top1_epoch_1.pth is removed\n",
            "02/09 13:28:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6687 acc/top1 at 8 epoch is saved to best_acc_top1_epoch_8.pth.\n",
            "02/09 13:28:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:01:19  time: 0.5712  data_time: 0.0674  memory: 13533  grad_norm: 1.4804  loss: 0.5992  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.5992\n",
            "02/09 13:29:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:01:08  time: 0.5198  data_time: 0.0185  memory: 13533  grad_norm: 1.0933  loss: 0.6564  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6564\n",
            "02/09 13:29:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:00:56  time: 0.5208  data_time: 0.0188  memory: 13533  grad_norm: 1.0908  loss: 0.6450  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6450\n",
            "02/09 13:29:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:00:45  time: 0.5202  data_time: 0.0183  memory: 13533  grad_norm: 1.3040  loss: 0.5934  top1_acc: 0.4375  top5_acc: 1.0000  loss_cls: 0.5934\n",
            "02/09 13:29:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:00:33  time: 0.5198  data_time: 0.0182  memory: 13533  grad_norm: 1.1658  loss: 0.5848  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5848\n",
            "02/09 13:29:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:00:22  time: 0.5196  data_time: 0.0181  memory: 13533  grad_norm: 1.4740  loss: 0.6637  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6637\n",
            "02/09 13:29:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 1:00:11  time: 0.5220  data_time: 0.0200  memory: 13533  grad_norm: 1.2446  loss: 0.6547  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6547\n",
            "02/09 13:30:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:59:59  time: 0.5200  data_time: 0.0186  memory: 13533  grad_norm: 1.2165  loss: 0.6435  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6435\n",
            "02/09 13:30:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:30:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:59:56  time: 0.5157  data_time: 0.0176  memory: 13533  grad_norm: 1.1817  loss: 0.6201  top1_acc: 0.5714  top5_acc: 1.0000  loss_cls: 0.6201\n",
            "02/09 13:30:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
            "02/09 13:30:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [9][20/21]    eta: 0:00:00  time: 0.2563  data_time: 0.1163  memory: 1642  \n",
            "02/09 13:30:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][21/21]    acc/top1: 0.6566  acc/top5: 1.0000  acc/mean1: 0.6507  data_time: 0.1062  time: 0.2425\n",
            "02/09 13:30:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:59:51  time: 0.5883  data_time: 0.0844  memory: 13533  grad_norm: 1.0890  loss: 0.5428  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5428\n",
            "02/09 13:30:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:59:39  time: 0.5187  data_time: 0.0174  memory: 13533  grad_norm: 1.6232  loss: 0.6301  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6301\n",
            "02/09 13:30:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:59:28  time: 0.5202  data_time: 0.0183  memory: 13533  grad_norm: 1.3503  loss: 0.6678  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6678\n",
            "02/09 13:31:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:59:16  time: 0.5199  data_time: 0.0181  memory: 13533  grad_norm: 1.4179  loss: 0.6640  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6640\n",
            "02/09 13:31:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:59:05  time: 0.5203  data_time: 0.0186  memory: 13533  grad_norm: 1.1026  loss: 0.5850  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5850\n",
            "02/09 13:31:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:58:54  time: 0.5197  data_time: 0.0184  memory: 13533  grad_norm: 1.1969  loss: 0.6343  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6343\n",
            "02/09 13:31:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:58:42  time: 0.5205  data_time: 0.0190  memory: 13533  grad_norm: 1.0679  loss: 0.5858  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5858\n",
            "02/09 13:31:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:58:31  time: 0.5186  data_time: 0.0177  memory: 13533  grad_norm: 1.2278  loss: 0.5652  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5652\n",
            "02/09 13:31:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:31:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:58:27  time: 0.5152  data_time: 0.0173  memory: 13533  grad_norm: 1.4208  loss: 0.5934  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.5934\n",
            "02/09 13:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][20/21]    eta: 0:00:00  time: 0.2346  data_time: 0.1004  memory: 1642  \n",
            "02/09 13:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][21/21]    acc/top1: 0.6024  acc/top5: 1.0000  acc/mean1: 0.5794  data_time: 0.0918  time: 0.2228\n",
            "02/09 13:32:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:58:21  time: 0.5770  data_time: 0.0737  memory: 13533  grad_norm: 1.4265  loss: 0.6153  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6153\n",
            "02/09 13:32:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:58:10  time: 0.5217  data_time: 0.0197  memory: 13533  grad_norm: 1.1402  loss: 0.6347  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6347\n",
            "02/09 13:32:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:57:58  time: 0.5205  data_time: 0.0190  memory: 13533  grad_norm: 1.3604  loss: 0.6446  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6446\n",
            "02/09 13:32:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:57:47  time: 0.5199  data_time: 0.0186  memory: 13533  grad_norm: 1.2811  loss: 0.7189  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.7189\n",
            "02/09 13:32:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:57:36  time: 0.5210  data_time: 0.0190  memory: 13533  grad_norm: 0.9506  loss: 0.5939  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.5939\n",
            "02/09 13:32:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:57:25  time: 0.5196  data_time: 0.0180  memory: 13533  grad_norm: 1.1235  loss: 0.6103  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6103\n",
            "02/09 13:33:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:57:14  time: 0.5214  data_time: 0.0193  memory: 13533  grad_norm: 1.7665  loss: 0.6406  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6406\n",
            "02/09 13:33:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:57:02  time: 0.5191  data_time: 0.0178  memory: 13533  grad_norm: 1.8616  loss: 0.6491  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6491\n",
            "02/09 13:33:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:33:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:56:59  time: 0.5149  data_time: 0.0168  memory: 13533  grad_norm: 2.0410  loss: 0.6935  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.6935\n",
            "02/09 13:33:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][20/21]    eta: 0:00:00  time: 0.2446  data_time: 0.1046  memory: 1642  \n",
            "02/09 13:33:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][21/21]    acc/top1: 0.5482  acc/top5: 1.0000  acc/mean1: 0.5598  data_time: 0.0956  time: 0.2320\n",
            "02/09 13:33:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:56:52  time: 0.5811  data_time: 0.0774  memory: 13533  grad_norm: 1.1846  loss: 0.6761  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6761\n",
            "02/09 13:33:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:56:41  time: 0.5200  data_time: 0.0185  memory: 13533  grad_norm: 1.1211  loss: 0.6194  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6194\n",
            "02/09 13:33:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:56:30  time: 0.5208  data_time: 0.0188  memory: 13533  grad_norm: 1.2408  loss: 0.6527  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6527\n",
            "02/09 13:34:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:56:19  time: 0.5208  data_time: 0.0189  memory: 13533  grad_norm: 0.9960  loss: 0.6511  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6511\n",
            "02/09 13:34:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:56:07  time: 0.5199  data_time: 0.0182  memory: 13533  grad_norm: 0.9597  loss: 0.6003  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6003\n",
            "02/09 13:34:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:55:56  time: 0.5210  data_time: 0.0190  memory: 13533  grad_norm: 1.1252  loss: 0.5932  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5932\n",
            "02/09 13:34:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:55:45  time: 0.5211  data_time: 0.0188  memory: 13533  grad_norm: 1.0152  loss: 0.5536  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5536\n",
            "02/09 13:34:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:55:34  time: 0.5191  data_time: 0.0174  memory: 13533  grad_norm: 1.2532  loss: 0.5648  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5648\n",
            "02/09 13:34:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:34:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:55:31  time: 0.5149  data_time: 0.0164  memory: 13533  grad_norm: 1.2946  loss: 0.5853  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.5853\n",
            "02/09 13:34:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n",
            "02/09 13:34:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][20/21]    eta: 0:00:00  time: 0.2385  data_time: 0.1021  memory: 1642  \n",
            "02/09 13:34:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][21/21]    acc/top1: 0.6175  acc/top5: 1.0000  acc/mean1: 0.6140  data_time: 0.0933  time: 0.2263\n",
            "02/09 13:35:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:35:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:55:23  time: 0.5718  data_time: 0.0678  memory: 13533  grad_norm: 1.2364  loss: 0.5975  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5975\n",
            "02/09 13:35:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:55:12  time: 0.5216  data_time: 0.0192  memory: 13533  grad_norm: 1.4032  loss: 0.5983  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5983\n",
            "02/09 13:35:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:55:01  time: 0.5197  data_time: 0.0180  memory: 13533  grad_norm: 1.2393  loss: 0.5894  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5894\n",
            "02/09 13:35:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:54:50  time: 0.5201  data_time: 0.0184  memory: 13533  grad_norm: 1.2651  loss: 0.7062  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.7062\n",
            "02/09 13:35:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:54:39  time: 0.5199  data_time: 0.0182  memory: 13533  grad_norm: 1.0780  loss: 0.6002  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6002\n",
            "02/09 13:35:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:54:28  time: 0.5204  data_time: 0.0187  memory: 13533  grad_norm: 1.3791  loss: 0.6003  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6003\n",
            "02/09 13:36:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:54:17  time: 0.5206  data_time: 0.0187  memory: 13533  grad_norm: 1.1875  loss: 0.6426  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6426\n",
            "02/09 13:36:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:54:06  time: 0.5197  data_time: 0.0184  memory: 13533  grad_norm: 1.1536  loss: 0.6062  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6062\n",
            "02/09 13:36:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:36:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:54:02  time: 0.5156  data_time: 0.0174  memory: 13533  grad_norm: 1.1974  loss: 0.5894  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.5894\n",
            "02/09 13:36:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][20/21]    eta: 0:00:00  time: 0.2598  data_time: 0.1202  memory: 1642  \n",
            "02/09 13:36:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][21/21]    acc/top1: 0.6295  acc/top5: 1.0000  acc/mean1: 0.6293  data_time: 0.1098  time: 0.2456\n",
            "02/09 13:36:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:53:55  time: 0.5912  data_time: 0.0879  memory: 13533  grad_norm: 1.2379  loss: 0.5761  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5761\n",
            "02/09 13:36:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:53:44  time: 0.5195  data_time: 0.0180  memory: 13533  grad_norm: 1.2808  loss: 0.5996  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5996\n",
            "02/09 13:37:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:53:33  time: 0.5210  data_time: 0.0194  memory: 13533  grad_norm: 1.3904  loss: 0.5658  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5658\n",
            "02/09 13:37:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:53:22  time: 0.5219  data_time: 0.0198  memory: 13533  grad_norm: 1.3235  loss: 0.6375  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6375\n",
            "02/09 13:37:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:53:11  time: 0.5210  data_time: 0.0196  memory: 13533  grad_norm: 1.1279  loss: 0.5921  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5921\n",
            "02/09 13:37:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:53:00  time: 0.5215  data_time: 0.0192  memory: 13533  grad_norm: 1.1026  loss: 0.6092  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6092\n",
            "02/09 13:37:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:52:49  time: 0.5220  data_time: 0.0197  memory: 13533  grad_norm: 1.2063  loss: 0.6396  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6396\n",
            "02/09 13:37:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:52:38  time: 0.5188  data_time: 0.0175  memory: 13533  grad_norm: 1.1552  loss: 0.5588  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5588\n",
            "02/09 13:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:37:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:52:35  time: 0.5151  data_time: 0.0170  memory: 13533  grad_norm: 1.3036  loss: 0.5815  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.5815\n",
            "02/09 13:38:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][20/21]    eta: 0:00:00  time: 0.2310  data_time: 0.0945  memory: 1642  \n",
            "02/09 13:38:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][21/21]    acc/top1: 0.6807  acc/top5: 1.0000  acc/mean1: 0.6789  data_time: 0.0864  time: 0.2195\n",
            "02/09 13:38:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb/best_acc_top1_epoch_8.pth is removed\n",
            "02/09 13:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6807 acc/top1 at 14 epoch is saved to best_acc_top1_epoch_14.pth.\n",
            "02/09 13:38:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:52:27  time: 0.5766  data_time: 0.0689  memory: 13533  grad_norm: 1.2483  loss: 0.5784  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.5784\n",
            "02/09 13:38:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:52:16  time: 0.5208  data_time: 0.0190  memory: 13533  grad_norm: 1.4973  loss: 0.5993  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5993\n",
            "02/09 13:38:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:52:05  time: 0.5217  data_time: 0.0194  memory: 13533  grad_norm: 1.3381  loss: 0.5948  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.5948\n",
            "02/09 13:38:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:51:54  time: 0.5197  data_time: 0.0182  memory: 13533  grad_norm: 1.2117  loss: 0.5379  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5379\n",
            "02/09 13:38:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:51:43  time: 0.5205  data_time: 0.0188  memory: 13533  grad_norm: 1.3836  loss: 0.6231  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6231\n",
            "02/09 13:39:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:51:32  time: 0.5200  data_time: 0.0182  memory: 13533  grad_norm: 1.0651  loss: 0.6611  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6611\n",
            "02/09 13:39:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:51:21  time: 0.5228  data_time: 0.0204  memory: 13533  grad_norm: 1.0602  loss: 0.5763  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5763\n",
            "02/09 13:39:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:51:10  time: 0.5204  data_time: 0.0190  memory: 13533  grad_norm: 1.5095  loss: 0.5924  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5924\n",
            "02/09 13:39:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:39:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:51:07  time: 0.5155  data_time: 0.0176  memory: 13533  grad_norm: 1.5132  loss: 0.6164  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.6164\n",
            "02/09 13:39:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 15 epochs\n",
            "02/09 13:39:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][20/21]    eta: 0:00:00  time: 0.2502  data_time: 0.1134  memory: 1642  \n",
            "02/09 13:39:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][21/21]    acc/top1: 0.6687  acc/top5: 1.0000  acc/mean1: 0.6484  data_time: 0.1036  time: 0.2369\n",
            "02/09 13:39:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:50:58  time: 0.5760  data_time: 0.0722  memory: 13533  grad_norm: 1.1389  loss: 0.5440  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5440\n",
            "02/09 13:39:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:50:47  time: 0.5197  data_time: 0.0184  memory: 13533  grad_norm: 1.1918  loss: 0.6199  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6199\n",
            "02/09 13:40:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:50:37  time: 0.5207  data_time: 0.0190  memory: 13533  grad_norm: 1.2604  loss: 0.5686  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5686\n",
            "02/09 13:40:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:50:26  time: 0.5212  data_time: 0.0192  memory: 13533  grad_norm: 1.4385  loss: 0.5685  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5685\n",
            "02/09 13:40:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:50:15  time: 0.5200  data_time: 0.0185  memory: 13533  grad_norm: 1.2465  loss: 0.5735  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5735\n",
            "02/09 13:40:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:50:04  time: 0.5202  data_time: 0.0185  memory: 13533  grad_norm: 1.3162  loss: 0.6039  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6039\n",
            "02/09 13:40:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:49:53  time: 0.5211  data_time: 0.0192  memory: 13533  grad_norm: 1.2140  loss: 0.6105  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6105\n",
            "02/09 13:41:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:49:42  time: 0.5182  data_time: 0.0172  memory: 13533  grad_norm: 1.4664  loss: 0.5927  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.5927\n",
            "02/09 13:41:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:41:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:49:39  time: 0.5152  data_time: 0.0170  memory: 13533  grad_norm: 1.5390  loss: 0.6301  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6301\n",
            "02/09 13:41:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][20/21]    eta: 0:00:00  time: 0.2301  data_time: 0.0943  memory: 1642  \n",
            "02/09 13:41:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][21/21]    acc/top1: 0.5783  acc/top5: 1.0000  acc/mean1: 0.5500  data_time: 0.0862  time: 0.2187\n",
            "02/09 13:41:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:49:31  time: 0.5899  data_time: 0.0856  memory: 13533  grad_norm: 1.4549  loss: 0.6364  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6364\n",
            "02/09 13:41:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:49:20  time: 0.5210  data_time: 0.0190  memory: 13533  grad_norm: 1.2809  loss: 0.6167  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6167\n",
            "02/09 13:41:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:49:09  time: 0.5219  data_time: 0.0200  memory: 13533  grad_norm: 1.2267  loss: 0.5592  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5592\n",
            "02/09 13:41:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:48:58  time: 0.5203  data_time: 0.0185  memory: 13533  grad_norm: 1.5394  loss: 0.5375  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5375\n",
            "02/09 13:42:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:48:47  time: 0.5204  data_time: 0.0186  memory: 13533  grad_norm: 1.5853  loss: 0.5560  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5560\n",
            "02/09 13:42:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:48:36  time: 0.5207  data_time: 0.0185  memory: 13533  grad_norm: 1.3647  loss: 0.5206  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5206\n",
            "02/09 13:42:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:48:26  time: 0.5212  data_time: 0.0195  memory: 13533  grad_norm: 1.4056  loss: 0.5621  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.5621\n",
            "02/09 13:42:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:48:15  time: 0.5199  data_time: 0.0182  memory: 13533  grad_norm: 1.4865  loss: 0.6166  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6166\n",
            "02/09 13:42:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:42:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:48:11  time: 0.5160  data_time: 0.0176  memory: 13533  grad_norm: 1.4408  loss: 0.5825  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5825\n",
            "02/09 13:42:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][20/21]    eta: 0:00:00  time: 0.2464  data_time: 0.1056  memory: 1642  \n",
            "02/09 13:42:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][21/21]    acc/top1: 0.6506  acc/top5: 1.0000  acc/mean1: 0.6475  data_time: 0.0966  time: 0.2335\n",
            "02/09 13:42:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:48:02  time: 0.5698  data_time: 0.0647  memory: 13533  grad_norm: 1.4552  loss: 0.6001  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6001\n",
            "02/09 13:43:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:47:51  time: 0.5204  data_time: 0.0190  memory: 13533  grad_norm: 1.3418  loss: 0.6301  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6301\n",
            "02/09 13:43:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:47:41  time: 0.5212  data_time: 0.0196  memory: 13533  grad_norm: 1.2969  loss: 0.5952  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5952\n",
            "02/09 13:43:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:47:30  time: 0.5209  data_time: 0.0191  memory: 13533  grad_norm: 1.3633  loss: 0.5563  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.5563\n",
            "02/09 13:43:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:47:19  time: 0.5214  data_time: 0.0195  memory: 13533  grad_norm: 1.4314  loss: 0.5950  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5950\n",
            "02/09 13:43:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:47:08  time: 0.5198  data_time: 0.0180  memory: 13533  grad_norm: 1.6042  loss: 0.5823  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5823\n",
            "02/09 13:43:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:46:57  time: 0.5209  data_time: 0.0189  memory: 13533  grad_norm: 1.3949  loss: 0.6069  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6069\n",
            "02/09 13:44:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:46:46  time: 0.5200  data_time: 0.0188  memory: 13533  grad_norm: 1.1513  loss: 0.5534  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5534\n",
            "02/09 13:44:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:44:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:46:43  time: 0.5160  data_time: 0.0179  memory: 13533  grad_norm: 1.4433  loss: 0.5801  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.5801\n",
            "02/09 13:44:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 18 epochs\n",
            "02/09 13:44:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][20/21]    eta: 0:00:00  time: 0.2466  data_time: 0.1121  memory: 1642  \n",
            "02/09 13:44:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][21/21]    acc/top1: 0.6476  acc/top5: 1.0000  acc/mean1: 0.6386  data_time: 0.1024  time: 0.2337\n",
            "02/09 13:44:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:44:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:46:34  time: 0.5805  data_time: 0.0742  memory: 13533  grad_norm: 1.2919  loss: 0.5696  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5696\n",
            "02/09 13:44:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:46:24  time: 0.5202  data_time: 0.0188  memory: 13533  grad_norm: 1.6493  loss: 0.6581  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6581\n",
            "02/09 13:44:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:46:13  time: 0.5214  data_time: 0.0190  memory: 13533  grad_norm: 1.3372  loss: 0.5887  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.5887\n",
            "02/09 13:44:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:46:02  time: 0.5208  data_time: 0.0188  memory: 13533  grad_norm: 1.3893  loss: 0.6524  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6524\n",
            "02/09 13:45:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:45:51  time: 0.5197  data_time: 0.0179  memory: 13533  grad_norm: 1.3388  loss: 0.5809  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5809\n",
            "02/09 13:45:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:45:40  time: 0.5202  data_time: 0.0185  memory: 13533  grad_norm: 1.1821  loss: 0.5468  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5468\n",
            "02/09 13:45:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:45:29  time: 0.5193  data_time: 0.0177  memory: 13533  grad_norm: 1.3350  loss: 0.5284  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5284\n",
            "02/09 13:45:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:45:19  time: 0.5200  data_time: 0.0184  memory: 13533  grad_norm: 1.4009  loss: 0.5722  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.5722\n",
            "02/09 13:45:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:45:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:45:15  time: 0.5162  data_time: 0.0179  memory: 13533  grad_norm: 1.3748  loss: 0.5631  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.5631\n",
            "02/09 13:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][20/21]    eta: 0:00:00  time: 0.2507  data_time: 0.1098  memory: 1642  \n",
            "02/09 13:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][21/21]    acc/top1: 0.6416  acc/top5: 1.0000  acc/mean1: 0.6193  data_time: 0.1004  time: 0.2374\n",
            "02/09 13:45:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:45:06  time: 0.5770  data_time: 0.0719  memory: 13533  grad_norm: 1.1362  loss: 0.5632  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5632\n",
            "02/09 13:46:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:44:56  time: 0.5199  data_time: 0.0184  memory: 13533  grad_norm: 1.3139  loss: 0.5635  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5635\n",
            "02/09 13:46:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:44:45  time: 0.5208  data_time: 0.0191  memory: 13533  grad_norm: 1.3950  loss: 0.6448  top1_acc: 0.4375  top5_acc: 1.0000  loss_cls: 0.6448\n",
            "02/09 13:46:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:44:34  time: 0.5218  data_time: 0.0198  memory: 13533  grad_norm: 1.2322  loss: 0.5774  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5774\n",
            "02/09 13:46:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:44:23  time: 0.5202  data_time: 0.0184  memory: 13533  grad_norm: 1.2619  loss: 0.5345  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5345\n",
            "02/09 13:46:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:44:12  time: 0.5216  data_time: 0.0198  memory: 13533  grad_norm: 1.4119  loss: 0.6171  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6171\n",
            "02/09 13:47:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:44:02  time: 0.5213  data_time: 0.0199  memory: 13533  grad_norm: 1.3208  loss: 0.5670  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.5670\n",
            "02/09 13:47:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:43:51  time: 0.5190  data_time: 0.0172  memory: 13533  grad_norm: 1.1561  loss: 0.5177  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5177\n",
            "02/09 13:47:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:47:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:43:48  time: 0.5150  data_time: 0.0167  memory: 13533  grad_norm: 1.2644  loss: 0.5263  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.5263\n",
            "02/09 13:47:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][20/21]    eta: 0:00:00  time: 0.2326  data_time: 0.0958  memory: 1642  \n",
            "02/09 13:47:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][21/21]    acc/top1: 0.6536  acc/top5: 1.0000  acc/mean1: 0.6379  data_time: 0.0876  time: 0.2209\n",
            "02/09 13:47:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:43:39  time: 0.5849  data_time: 0.0809  memory: 13533  grad_norm: 1.4307  loss: 0.5440  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5440\n",
            "02/09 13:47:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:43:28  time: 0.5211  data_time: 0.0192  memory: 13533  grad_norm: 1.6718  loss: 0.6237  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6237\n",
            "02/09 13:47:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:43:17  time: 0.5204  data_time: 0.0186  memory: 13533  grad_norm: 1.3981  loss: 0.6116  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6116\n",
            "02/09 13:48:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:43:06  time: 0.5203  data_time: 0.0183  memory: 13533  grad_norm: 1.5003  loss: 0.6105  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6105\n",
            "02/09 13:48:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:42:56  time: 0.5221  data_time: 0.0196  memory: 13533  grad_norm: 1.7820  loss: 0.5609  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5609\n",
            "02/09 13:48:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:42:45  time: 0.5200  data_time: 0.0186  memory: 13533  grad_norm: 1.3126  loss: 0.5540  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5540\n",
            "02/09 13:48:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:42:34  time: 0.5225  data_time: 0.0204  memory: 13533  grad_norm: 1.5081  loss: 0.6207  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6207\n",
            "02/09 13:48:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:42:23  time: 0.5185  data_time: 0.0175  memory: 13533  grad_norm: 1.5339  loss: 0.6256  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6256\n",
            "02/09 13:48:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:48:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:42:20  time: 0.5147  data_time: 0.0167  memory: 13533  grad_norm: 1.2923  loss: 0.5844  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.5844\n",
            "02/09 13:48:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 21 epochs\n",
            "02/09 13:48:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][20/21]    eta: 0:00:00  time: 0.2661  data_time: 0.1271  memory: 1642  \n",
            "02/09 13:48:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][21/21]    acc/top1: 0.6627  acc/top5: 1.0000  acc/mean1: 0.6431  data_time: 0.1161  time: 0.2514\n",
            "02/09 13:49:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:42:11  time: 0.5776  data_time: 0.0727  memory: 13533  grad_norm: 1.1976  loss: 0.5391  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5391\n",
            "02/09 13:49:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:42:00  time: 0.5202  data_time: 0.0184  memory: 13533  grad_norm: 1.3058  loss: 0.5683  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5683\n",
            "02/09 13:49:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:41:49  time: 0.5206  data_time: 0.0189  memory: 13533  grad_norm: 1.4444  loss: 0.4983  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.4983\n",
            "02/09 13:49:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:41:38  time: 0.5208  data_time: 0.0188  memory: 13533  grad_norm: 1.7693  loss: 0.6191  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6191\n",
            "02/09 13:49:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:41:28  time: 0.5208  data_time: 0.0189  memory: 13533  grad_norm: 1.2375  loss: 0.5143  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5143\n",
            "02/09 13:49:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:41:17  time: 0.5212  data_time: 0.0187  memory: 13533  grad_norm: 1.7104  loss: 0.6482  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6482\n",
            "02/09 13:50:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:41:06  time: 0.5199  data_time: 0.0186  memory: 13533  grad_norm: 1.6452  loss: 0.5694  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5694\n",
            "02/09 13:50:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:40:55  time: 0.5183  data_time: 0.0171  memory: 13533  grad_norm: 1.4439  loss: 0.5460  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5460\n",
            "02/09 13:50:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:50:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:40:52  time: 0.5153  data_time: 0.0170  memory: 13533  grad_norm: 1.5295  loss: 0.5490  top1_acc: 0.5714  top5_acc: 1.0000  loss_cls: 0.5490\n",
            "02/09 13:50:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][20/21]    eta: 0:00:00  time: 0.2471  data_time: 0.1120  memory: 1642  \n",
            "02/09 13:50:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][21/21]    acc/top1: 0.6807  acc/top5: 1.0000  acc/mean1: 0.6789  data_time: 0.1023  time: 0.2342\n",
            "02/09 13:50:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:40:43  time: 0.5900  data_time: 0.0843  memory: 13533  grad_norm: 1.6195  loss: 0.5014  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5014\n",
            "02/09 13:50:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:40:32  time: 0.5211  data_time: 0.0188  memory: 13533  grad_norm: 2.0434  loss: 0.6004  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.6004\n",
            "02/09 13:50:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:40:22  time: 0.5203  data_time: 0.0183  memory: 13533  grad_norm: 1.6658  loss: 0.6036  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6036\n",
            "02/09 13:51:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:40:11  time: 0.5219  data_time: 0.0192  memory: 13533  grad_norm: 1.4311  loss: 0.5531  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5531\n",
            "02/09 13:51:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:40:00  time: 0.5211  data_time: 0.0186  memory: 13533  grad_norm: 1.4728  loss: 0.5724  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.5724\n",
            "02/09 13:51:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:39:50  time: 0.5202  data_time: 0.0180  memory: 13533  grad_norm: 1.3261  loss: 0.5288  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5288\n",
            "02/09 13:51:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:39:39  time: 0.5215  data_time: 0.0194  memory: 13533  grad_norm: 1.7470  loss: 0.5908  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.5908\n",
            "02/09 13:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:39:28  time: 0.5197  data_time: 0.0181  memory: 13533  grad_norm: 1.3171  loss: 0.5446  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5446\n",
            "02/09 13:51:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:51:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:39:25  time: 0.5161  data_time: 0.0177  memory: 13533  grad_norm: 1.4023  loss: 0.5365  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.5365\n",
            "02/09 13:51:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][20/21]    eta: 0:00:00  time: 0.2640  data_time: 0.1267  memory: 1642  \n",
            "02/09 13:51:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][21/21]    acc/top1: 0.6205  acc/top5: 1.0000  acc/mean1: 0.6256  data_time: 0.1157  time: 0.2495\n",
            "02/09 13:52:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:39:16  time: 0.5952  data_time: 0.0919  memory: 13533  grad_norm: 1.6023  loss: 0.5557  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5557\n",
            "02/09 13:52:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:39:05  time: 0.5212  data_time: 0.0190  memory: 13533  grad_norm: 1.5183  loss: 0.5590  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5590\n",
            "02/09 13:52:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:38:54  time: 0.5201  data_time: 0.0183  memory: 13533  grad_norm: 1.3728  loss: 0.5288  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5288\n",
            "02/09 13:52:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:38:44  time: 0.5215  data_time: 0.0192  memory: 13533  grad_norm: 1.5584  loss: 0.6184  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6184\n",
            "02/09 13:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:38:33  time: 0.5218  data_time: 0.0193  memory: 13533  grad_norm: 1.3331  loss: 0.6104  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6104\n",
            "02/09 13:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:38:22  time: 0.5217  data_time: 0.0192  memory: 13533  grad_norm: 1.2521  loss: 0.5650  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5650\n",
            "02/09 13:53:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:38:12  time: 0.5218  data_time: 0.0195  memory: 13533  grad_norm: 1.4035  loss: 0.5344  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5344\n",
            "02/09 13:53:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:38:01  time: 0.5196  data_time: 0.0181  memory: 13533  grad_norm: 1.4291  loss: 0.5694  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5694\n",
            "02/09 13:53:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:53:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:37:57  time: 0.5155  data_time: 0.0173  memory: 13533  grad_norm: 1.3828  loss: 0.5824  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.5824\n",
            "02/09 13:53:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 24 epochs\n",
            "02/09 13:53:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][20/21]    eta: 0:00:00  time: 0.2443  data_time: 0.1057  memory: 1642  \n",
            "02/09 13:53:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][21/21]    acc/top1: 0.6807  acc/top5: 1.0000  acc/mean1: 0.6749  data_time: 0.0966  time: 0.2316\n",
            "02/09 13:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:53:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 20/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:37:48  time: 0.5749  data_time: 0.0673  memory: 13533  grad_norm: 1.2637  loss: 0.5982  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5982\n",
            "02/09 13:53:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 40/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:37:37  time: 0.5227  data_time: 0.0203  memory: 13533  grad_norm: 1.1091  loss: 0.5464  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5464\n",
            "02/09 13:54:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 60/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:37:27  time: 0.5212  data_time: 0.0192  memory: 13533  grad_norm: 1.2247  loss: 0.5129  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5129\n",
            "02/09 13:54:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][ 80/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:37:16  time: 0.5222  data_time: 0.0198  memory: 13533  grad_norm: 1.5976  loss: 0.5661  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5661\n",
            "02/09 13:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][100/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:37:05  time: 0.5202  data_time: 0.0183  memory: 13533  grad_norm: 1.5952  loss: 0.5367  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5367\n",
            "02/09 13:54:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][120/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:36:54  time: 0.5196  data_time: 0.0180  memory: 13533  grad_norm: 1.4415  loss: 0.5783  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5783\n",
            "02/09 13:54:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][140/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:36:44  time: 0.5195  data_time: 0.0179  memory: 13533  grad_norm: 1.4939  loss: 0.5884  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5884\n",
            "02/09 13:54:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][160/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:36:33  time: 0.5197  data_time: 0.0180  memory: 13533  grad_norm: 1.2571  loss: 0.5870  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5870\n",
            "02/09 13:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][166/166]  base_lr: 2.0000e-02 lr: 2.0000e-02  eta: 0:36:30  time: 0.5151  data_time: 0.0168  memory: 13533  grad_norm: 1.2229  loss: 0.5509  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.5509\n",
            "02/09 13:55:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][20/21]    eta: 0:00:00  time: 0.2560  data_time: 0.1179  memory: 1642  \n",
            "02/09 13:55:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][21/21]    acc/top1: 0.6446  acc/top5: 1.0000  acc/mean1: 0.6230  data_time: 0.1077  time: 0.2422\n",
            "02/09 13:55:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:36:20  time: 0.5862  data_time: 0.0811  memory: 13533  grad_norm: 1.3235  loss: 0.5486  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5486\n",
            "02/09 13:55:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:36:10  time: 0.5190  data_time: 0.0175  memory: 13533  grad_norm: 1.2562  loss: 0.5138  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5138\n",
            "02/09 13:55:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:35:59  time: 0.5211  data_time: 0.0193  memory: 13533  grad_norm: 1.3499  loss: 0.5495  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5495\n",
            "02/09 13:55:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:35:48  time: 0.5216  data_time: 0.0197  memory: 13533  grad_norm: 1.3252  loss: 0.5210  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.5210\n",
            "02/09 13:55:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:35:37  time: 0.5204  data_time: 0.0188  memory: 13533  grad_norm: 1.2373  loss: 0.4756  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.4756\n",
            "02/09 13:56:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:35:27  time: 0.5215  data_time: 0.0193  memory: 13533  grad_norm: 1.3234  loss: 0.5273  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5273\n",
            "02/09 13:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:35:16  time: 0.5196  data_time: 0.0181  memory: 13533  grad_norm: 1.3394  loss: 0.4867  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4867\n",
            "02/09 13:56:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:35:05  time: 0.5202  data_time: 0.0186  memory: 13533  grad_norm: 1.3102  loss: 0.4780  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4780\n",
            "02/09 13:56:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:56:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:35:02  time: 0.5161  data_time: 0.0178  memory: 13533  grad_norm: 1.3081  loss: 0.4841  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.4841\n",
            "02/09 13:56:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [26][20/21]    eta: 0:00:00  time: 0.2299  data_time: 0.0920  memory: 1642  \n",
            "02/09 13:56:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [26][21/21]    acc/top1: 0.6747  acc/top5: 1.0000  acc/mean1: 0.6656  data_time: 0.0842  time: 0.2185\n",
            "02/09 13:56:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:34:53  time: 0.5874  data_time: 0.0825  memory: 13533  grad_norm: 1.3651  loss: 0.5018  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5018\n",
            "02/09 13:56:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:34:42  time: 0.5209  data_time: 0.0189  memory: 13533  grad_norm: 1.4223  loss: 0.5001  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5001\n",
            "02/09 13:57:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:34:31  time: 0.5209  data_time: 0.0189  memory: 13533  grad_norm: 1.3847  loss: 0.4880  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4880\n",
            "02/09 13:57:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:34:21  time: 0.5207  data_time: 0.0187  memory: 13533  grad_norm: 1.4978  loss: 0.5007  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5007\n",
            "02/09 13:57:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:34:10  time: 0.5205  data_time: 0.0187  memory: 13533  grad_norm: 1.4222  loss: 0.4591  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4591\n",
            "02/09 13:57:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:33:59  time: 0.5211  data_time: 0.0191  memory: 13533  grad_norm: 1.4648  loss: 0.4908  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4908\n",
            "02/09 13:57:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:33:49  time: 0.5209  data_time: 0.0188  memory: 13533  grad_norm: 1.4543  loss: 0.5079  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5079\n",
            "02/09 13:58:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:33:38  time: 0.5193  data_time: 0.0180  memory: 13533  grad_norm: 1.3966  loss: 0.4603  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4603\n",
            "02/09 13:58:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:58:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:33:35  time: 0.5155  data_time: 0.0173  memory: 13533  grad_norm: 1.3898  loss: 0.4165  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.4165\n",
            "02/09 13:58:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 27 epochs\n",
            "02/09 13:58:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [27][20/21]    eta: 0:00:00  time: 0.2647  data_time: 0.1245  memory: 1642  \n",
            "02/09 13:58:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [27][21/21]    acc/top1: 0.6657  acc/top5: 1.0000  acc/mean1: 0.6548  data_time: 0.1137  time: 0.2501\n",
            "02/09 13:58:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:33:25  time: 0.5900  data_time: 0.0866  memory: 13533  grad_norm: 1.4146  loss: 0.4321  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4321\n",
            "02/09 13:58:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:33:14  time: 0.5216  data_time: 0.0196  memory: 13533  grad_norm: 1.5545  loss: 0.4752  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4752\n",
            "02/09 13:58:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:33:04  time: 0.5197  data_time: 0.0180  memory: 13533  grad_norm: 1.6449  loss: 0.4955  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4955\n",
            "02/09 13:58:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:32:53  time: 0.5208  data_time: 0.0188  memory: 13533  grad_norm: 1.6911  loss: 0.5036  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.5036\n",
            "02/09 13:59:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:32:42  time: 0.5211  data_time: 0.0189  memory: 13533  grad_norm: 1.5659  loss: 0.4464  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4464\n",
            "02/09 13:59:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:32:32  time: 0.5222  data_time: 0.0200  memory: 13533  grad_norm: 1.5176  loss: 0.4384  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4384\n",
            "02/09 13:59:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:32:21  time: 0.5207  data_time: 0.0188  memory: 13533  grad_norm: 1.5640  loss: 0.4752  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4752\n",
            "02/09 13:59:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:32:10  time: 0.5194  data_time: 0.0179  memory: 13533  grad_norm: 1.6476  loss: 0.4893  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4893\n",
            "02/09 13:59:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 13:59:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:32:07  time: 0.5156  data_time: 0.0173  memory: 13533  grad_norm: 1.6917  loss: 0.4784  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.4784\n",
            "02/09 13:59:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [28][20/21]    eta: 0:00:00  time: 0.2402  data_time: 0.1035  memory: 1642  \n",
            "02/09 13:59:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [28][21/21]    acc/top1: 0.6717  acc/top5: 1.0000  acc/mean1: 0.6640  data_time: 0.0946  time: 0.2278\n",
            "02/09 13:59:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:31:57  time: 0.5666  data_time: 0.0602  memory: 13533  grad_norm: 1.7132  loss: 0.4685  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4685\n",
            "02/09 14:00:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:31:46  time: 0.5206  data_time: 0.0186  memory: 13533  grad_norm: 1.7705  loss: 0.4909  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4909\n",
            "02/09 14:00:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:31:36  time: 0.5211  data_time: 0.0192  memory: 13533  grad_norm: 1.6744  loss: 0.4281  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4281\n",
            "02/09 14:00:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:31:25  time: 0.5206  data_time: 0.0185  memory: 13533  grad_norm: 1.6969  loss: 0.4670  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4670\n",
            "02/09 14:00:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:31:14  time: 0.5205  data_time: 0.0189  memory: 13533  grad_norm: 1.7525  loss: 0.4402  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4402\n",
            "02/09 14:00:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:31:04  time: 0.5204  data_time: 0.0186  memory: 13533  grad_norm: 1.9661  loss: 0.5044  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5044\n",
            "02/09 14:00:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:30:53  time: 0.5208  data_time: 0.0190  memory: 13533  grad_norm: 1.8279  loss: 0.4606  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4606\n",
            "02/09 14:01:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:30:42  time: 0.5196  data_time: 0.0177  memory: 13533  grad_norm: 1.6175  loss: 0.4226  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4226\n",
            "02/09 14:01:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:01:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:30:39  time: 0.5155  data_time: 0.0169  memory: 13533  grad_norm: 1.7861  loss: 0.4492  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.4492\n",
            "02/09 14:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [29][20/21]    eta: 0:00:00  time: 0.2451  data_time: 0.1069  memory: 1642  \n",
            "02/09 14:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [29][21/21]    acc/top1: 0.6777  acc/top5: 1.0000  acc/mean1: 0.6637  data_time: 0.0977  time: 0.2323\n",
            "02/09 14:01:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:30:29  time: 0.5814  data_time: 0.0773  memory: 13533  grad_norm: 1.7059  loss: 0.4678  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4678\n",
            "02/09 14:01:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:30:19  time: 0.5204  data_time: 0.0186  memory: 13533  grad_norm: 1.6572  loss: 0.4151  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4151\n",
            "02/09 14:01:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:30:08  time: 0.5207  data_time: 0.0186  memory: 13533  grad_norm: 1.7471  loss: 0.4398  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4398\n",
            "02/09 14:01:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:29:57  time: 0.5209  data_time: 0.0187  memory: 13533  grad_norm: 1.7036  loss: 0.3872  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3872\n",
            "02/09 14:02:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:29:47  time: 0.5205  data_time: 0.0186  memory: 13533  grad_norm: 2.0501  loss: 0.4307  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4307\n",
            "02/09 14:02:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:29:36  time: 0.5208  data_time: 0.0189  memory: 13533  grad_norm: 2.1794  loss: 0.4696  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.4696\n",
            "02/09 14:02:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:29:25  time: 0.5207  data_time: 0.0186  memory: 13533  grad_norm: 2.2293  loss: 0.5222  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5222\n",
            "02/09 14:02:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:29:15  time: 0.5187  data_time: 0.0175  memory: 13533  grad_norm: 1.9780  loss: 0.5156  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.5156\n",
            "02/09 14:02:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:02:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:29:12  time: 0.5151  data_time: 0.0167  memory: 13533  grad_norm: 1.9602  loss: 0.5139  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.5139\n",
            "02/09 14:02:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 30 epochs\n",
            "02/09 14:02:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][20/21]    eta: 0:00:00  time: 0.2328  data_time: 0.0982  memory: 1642  \n",
            "02/09 14:02:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][21/21]    acc/top1: 0.6687  acc/top5: 1.0000  acc/mean1: 0.6640  data_time: 0.0898  time: 0.2212\n",
            "02/09 14:03:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:03:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:29:02  time: 0.5729  data_time: 0.0676  memory: 13533  grad_norm: 1.8705  loss: 0.4347  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4347\n",
            "02/09 14:03:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:28:51  time: 0.5211  data_time: 0.0190  memory: 13533  grad_norm: 1.6636  loss: 0.4254  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4254\n",
            "02/09 14:03:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:28:40  time: 0.5213  data_time: 0.0195  memory: 13533  grad_norm: 2.0044  loss: 0.4452  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4452\n",
            "02/09 14:03:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:28:30  time: 0.5216  data_time: 0.0195  memory: 13533  grad_norm: 2.1357  loss: 0.5195  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5195\n",
            "02/09 14:03:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:28:19  time: 0.5205  data_time: 0.0188  memory: 13533  grad_norm: 1.9222  loss: 0.5011  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5011\n",
            "02/09 14:03:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:28:08  time: 0.5204  data_time: 0.0184  memory: 13533  grad_norm: 1.8338  loss: 0.4447  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4447\n",
            "02/09 14:04:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:27:58  time: 0.5210  data_time: 0.0189  memory: 13533  grad_norm: 2.3093  loss: 0.5154  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5154\n",
            "02/09 14:04:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:27:47  time: 0.5193  data_time: 0.0178  memory: 13533  grad_norm: 1.7183  loss: 0.4434  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4434\n",
            "02/09 14:04:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:04:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:27:44  time: 0.5158  data_time: 0.0176  memory: 13533  grad_norm: 1.7684  loss: 0.4604  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.4604\n",
            "02/09 14:04:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [31][20/21]    eta: 0:00:00  time: 0.2442  data_time: 0.1030  memory: 1642  \n",
            "02/09 14:04:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [31][21/21]    acc/top1: 0.6566  acc/top5: 1.0000  acc/mean1: 0.6459  data_time: 0.0941  time: 0.2316\n",
            "02/09 14:04:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:27:34  time: 0.5821  data_time: 0.0780  memory: 13533  grad_norm: 2.0560  loss: 0.4672  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4672\n",
            "02/09 14:04:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:27:23  time: 0.5194  data_time: 0.0180  memory: 13533  grad_norm: 1.7367  loss: 0.4254  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4254\n",
            "02/09 14:04:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:27:13  time: 0.5205  data_time: 0.0185  memory: 13533  grad_norm: 2.2178  loss: 0.4547  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4547\n",
            "02/09 14:05:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:27:02  time: 0.5219  data_time: 0.0194  memory: 13533  grad_norm: 1.8940  loss: 0.4251  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4251\n",
            "02/09 14:05:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:26:51  time: 0.5207  data_time: 0.0188  memory: 13533  grad_norm: 1.8972  loss: 0.4086  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4086\n",
            "02/09 14:05:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:26:41  time: 0.5212  data_time: 0.0191  memory: 13533  grad_norm: 2.2854  loss: 0.4776  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4776\n",
            "02/09 14:05:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:26:30  time: 0.5207  data_time: 0.0185  memory: 13533  grad_norm: 2.0458  loss: 0.4699  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4699\n",
            "02/09 14:05:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:26:19  time: 0.5213  data_time: 0.0193  memory: 13533  grad_norm: 1.9643  loss: 0.4470  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4470\n",
            "02/09 14:05:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:05:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:26:16  time: 0.5176  data_time: 0.0188  memory: 13533  grad_norm: 2.1740  loss: 0.4769  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.4769\n",
            "02/09 14:05:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [32][20/21]    eta: 0:00:00  time: 0.2410  data_time: 0.1047  memory: 1642  \n",
            "02/09 14:05:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [32][21/21]    acc/top1: 0.6687  acc/top5: 1.0000  acc/mean1: 0.6588  data_time: 0.0957  time: 0.2287\n",
            "02/09 14:06:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:26:06  time: 0.5902  data_time: 0.0855  memory: 13533  grad_norm: 2.1201  loss: 0.4140  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4140\n",
            "02/09 14:06:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:25:56  time: 0.5225  data_time: 0.0203  memory: 13533  grad_norm: 2.1875  loss: 0.4517  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4517\n",
            "02/09 14:06:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:25:45  time: 0.5209  data_time: 0.0188  memory: 13533  grad_norm: 2.1461  loss: 0.4459  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4459\n",
            "02/09 14:06:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:25:34  time: 0.5212  data_time: 0.0190  memory: 13533  grad_norm: 2.2442  loss: 0.4620  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4620\n",
            "02/09 14:06:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:25:24  time: 0.5208  data_time: 0.0190  memory: 13533  grad_norm: 2.4153  loss: 0.4819  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4819\n",
            "02/09 14:06:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:25:13  time: 0.5215  data_time: 0.0192  memory: 13533  grad_norm: 2.0471  loss: 0.4089  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4089\n",
            "02/09 14:07:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:25:03  time: 0.5225  data_time: 0.0200  memory: 13533  grad_norm: 2.1707  loss: 0.4473  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4473\n",
            "02/09 14:07:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:24:52  time: 0.5201  data_time: 0.0182  memory: 13533  grad_norm: 2.2807  loss: 0.4491  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4491\n",
            "02/09 14:07:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:07:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:24:49  time: 0.5160  data_time: 0.0174  memory: 13533  grad_norm: 2.2186  loss: 0.4502  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.4502\n",
            "02/09 14:07:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 33 epochs\n",
            "02/09 14:07:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [33][20/21]    eta: 0:00:00  time: 0.2511  data_time: 0.1114  memory: 1642  \n",
            "02/09 14:07:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [33][21/21]    acc/top1: 0.6747  acc/top5: 1.0000  acc/mean1: 0.6717  data_time: 0.1019  time: 0.2378\n",
            "02/09 14:07:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:24:39  time: 0.5682  data_time: 0.0629  memory: 13533  grad_norm: 2.5570  loss: 0.4664  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4664\n",
            "02/09 14:07:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:24:28  time: 0.5203  data_time: 0.0185  memory: 13533  grad_norm: 2.0106  loss: 0.3920  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3920\n",
            "02/09 14:07:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:24:17  time: 0.5205  data_time: 0.0188  memory: 13533  grad_norm: 2.4487  loss: 0.4769  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4769\n",
            "02/09 14:08:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:24:07  time: 0.5208  data_time: 0.0190  memory: 13533  grad_norm: 2.1448  loss: 0.4471  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.4471\n",
            "02/09 14:08:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:23:56  time: 0.5204  data_time: 0.0185  memory: 13533  grad_norm: 2.4277  loss: 0.5037  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5037\n",
            "02/09 14:08:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:23:45  time: 0.5212  data_time: 0.0187  memory: 13533  grad_norm: 2.1743  loss: 0.4590  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4590\n",
            "02/09 14:08:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:23:35  time: 0.5218  data_time: 0.0194  memory: 13533  grad_norm: 2.1128  loss: 0.4482  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4482\n",
            "02/09 14:08:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:23:24  time: 0.5203  data_time: 0.0188  memory: 13533  grad_norm: 2.2703  loss: 0.4617  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4617\n",
            "02/09 14:08:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:08:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:23:21  time: 0.5163  data_time: 0.0179  memory: 13533  grad_norm: 2.1047  loss: 0.4365  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.4365\n",
            "02/09 14:08:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [34][20/21]    eta: 0:00:00  time: 0.2369  data_time: 0.0958  memory: 1642  \n",
            "02/09 14:08:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [34][21/21]    acc/top1: 0.6627  acc/top5: 1.0000  acc/mean1: 0.6547  data_time: 0.0876  time: 0.2249\n",
            "02/09 14:09:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:23:11  time: 0.5758  data_time: 0.0708  memory: 13533  grad_norm: 2.2715  loss: 0.4372  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4372\n",
            "02/09 14:09:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:23:00  time: 0.5209  data_time: 0.0190  memory: 13533  grad_norm: 2.1973  loss: 0.4359  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4359\n",
            "02/09 14:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:22:50  time: 0.5204  data_time: 0.0184  memory: 13533  grad_norm: 2.1294  loss: 0.4148  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4148\n",
            "02/09 14:09:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:22:39  time: 0.5208  data_time: 0.0183  memory: 13533  grad_norm: 2.4115  loss: 0.4786  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4786\n",
            "02/09 14:09:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:22:28  time: 0.5215  data_time: 0.0193  memory: 13533  grad_norm: 2.2752  loss: 0.4491  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4491\n",
            "02/09 14:10:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:22:18  time: 0.5215  data_time: 0.0193  memory: 13533  grad_norm: 2.2319  loss: 0.3946  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3946\n",
            "02/09 14:10:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:22:07  time: 0.5210  data_time: 0.0191  memory: 13533  grad_norm: 2.4994  loss: 0.4701  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4701\n",
            "02/09 14:10:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:21:57  time: 0.5205  data_time: 0.0186  memory: 13533  grad_norm: 2.3107  loss: 0.4587  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4587\n",
            "02/09 14:10:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:10:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:21:53  time: 0.5163  data_time: 0.0178  memory: 13533  grad_norm: 2.4332  loss: 0.4734  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.4734\n",
            "02/09 14:10:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][20/21]    eta: 0:00:00  time: 0.2428  data_time: 0.1043  memory: 1642  \n",
            "02/09 14:10:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][21/21]    acc/top1: 0.6717  acc/top5: 1.0000  acc/mean1: 0.6664  data_time: 0.0954  time: 0.2302\n",
            "02/09 14:10:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:21:43  time: 0.5808  data_time: 0.0761  memory: 13533  grad_norm: 2.0935  loss: 0.4109  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4109\n",
            "02/09 14:10:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:21:33  time: 0.5204  data_time: 0.0187  memory: 13533  grad_norm: 2.0921  loss: 0.4333  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4333\n",
            "02/09 14:11:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:21:22  time: 0.5215  data_time: 0.0189  memory: 13533  grad_norm: 2.7519  loss: 0.4984  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4984\n",
            "02/09 14:11:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:21:11  time: 0.5216  data_time: 0.0195  memory: 13533  grad_norm: 2.2232  loss: 0.4169  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4169\n",
            "02/09 14:11:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:21:01  time: 0.5217  data_time: 0.0194  memory: 13533  grad_norm: 2.4387  loss: 0.4518  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4518\n",
            "02/09 14:11:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:20:50  time: 0.5212  data_time: 0.0190  memory: 13533  grad_norm: 2.2262  loss: 0.4645  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4645\n",
            "02/09 14:11:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:20:40  time: 0.5207  data_time: 0.0185  memory: 13533  grad_norm: 2.0548  loss: 0.3899  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3899\n",
            "02/09 14:11:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:20:29  time: 0.5188  data_time: 0.0174  memory: 13533  grad_norm: 2.2110  loss: 0.4385  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4385\n",
            "02/09 14:11:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:11:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:20:26  time: 0.5153  data_time: 0.0170  memory: 13533  grad_norm: 2.2707  loss: 0.4473  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.4473\n",
            "02/09 14:11:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 36 epochs\n",
            "02/09 14:12:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [36][20/21]    eta: 0:00:00  time: 0.2338  data_time: 0.0999  memory: 1642  \n",
            "02/09 14:12:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [36][21/21]    acc/top1: 0.6596  acc/top5: 1.0000  acc/mean1: 0.6507  data_time: 0.0914  time: 0.2221\n",
            "02/09 14:12:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:20:16  time: 0.5856  data_time: 0.0813  memory: 13533  grad_norm: 2.4459  loss: 0.4059  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4059\n",
            "02/09 14:12:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:12:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:20:05  time: 0.5217  data_time: 0.0195  memory: 13533  grad_norm: 2.3210  loss: 0.4137  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4137\n",
            "02/09 14:12:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:19:54  time: 0.5208  data_time: 0.0188  memory: 13533  grad_norm: 2.4956  loss: 0.4566  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4566\n",
            "02/09 14:12:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:19:44  time: 0.5205  data_time: 0.0187  memory: 13533  grad_norm: 2.7316  loss: 0.4315  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4315\n",
            "02/09 14:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:19:33  time: 0.5206  data_time: 0.0183  memory: 13533  grad_norm: 2.5328  loss: 0.4014  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4014\n",
            "02/09 14:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:19:23  time: 0.5208  data_time: 0.0190  memory: 13533  grad_norm: 2.4159  loss: 0.4224  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4224\n",
            "02/09 14:13:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:19:12  time: 0.5225  data_time: 0.0191  memory: 13533  grad_norm: 2.5469  loss: 0.4565  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4565\n",
            "02/09 14:13:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:19:01  time: 0.5206  data_time: 0.0190  memory: 13533  grad_norm: 2.6417  loss: 0.4492  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4492\n",
            "02/09 14:13:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:13:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:18:58  time: 0.5166  data_time: 0.0181  memory: 13533  grad_norm: 2.5364  loss: 0.4331  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.4331\n",
            "02/09 14:13:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [37][20/21]    eta: 0:00:00  time: 0.2543  data_time: 0.1138  memory: 1642  \n",
            "02/09 14:13:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [37][21/21]    acc/top1: 0.6536  acc/top5: 1.0000  acc/mean1: 0.6435  data_time: 0.1039  time: 0.2406\n",
            "02/09 14:13:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:18:48  time: 0.5744  data_time: 0.0716  memory: 13533  grad_norm: 2.1883  loss: 0.3908  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3908\n",
            "02/09 14:14:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:18:37  time: 0.5209  data_time: 0.0190  memory: 13533  grad_norm: 2.4384  loss: 0.4074  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4074\n",
            "02/09 14:14:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:18:27  time: 0.5210  data_time: 0.0192  memory: 13533  grad_norm: 2.6902  loss: 0.4104  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4104\n",
            "02/09 14:14:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:18:16  time: 0.5213  data_time: 0.0193  memory: 13533  grad_norm: 2.6228  loss: 0.4033  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4033\n",
            "02/09 14:14:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:18:06  time: 0.5212  data_time: 0.0188  memory: 13533  grad_norm: 2.4081  loss: 0.3850  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3850\n",
            "02/09 14:14:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:17:55  time: 0.5217  data_time: 0.0193  memory: 13533  grad_norm: 2.6807  loss: 0.4518  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4518\n",
            "02/09 14:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:17:44  time: 0.5198  data_time: 0.0180  memory: 13533  grad_norm: 2.5600  loss: 0.4505  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4505\n",
            "02/09 14:15:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:17:34  time: 0.5190  data_time: 0.0176  memory: 13533  grad_norm: 2.7214  loss: 0.4475  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4475\n",
            "02/09 14:15:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:15:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:17:31  time: 0.5159  data_time: 0.0173  memory: 13533  grad_norm: 2.6505  loss: 0.4569  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.4569\n",
            "02/09 14:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [38][20/21]    eta: 0:00:00  time: 0.2333  data_time: 0.0975  memory: 1642  \n",
            "02/09 14:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [38][21/21]    acc/top1: 0.6476  acc/top5: 1.0000  acc/mean1: 0.6402  data_time: 0.0891  time: 0.2216\n",
            "02/09 14:15:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:17:20  time: 0.5870  data_time: 0.0819  memory: 13533  grad_norm: 2.2768  loss: 0.3874  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3874\n",
            "02/09 14:15:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:17:10  time: 0.5204  data_time: 0.0184  memory: 13533  grad_norm: 2.7025  loss: 0.4209  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4209\n",
            "02/09 14:15:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:16:59  time: 0.5219  data_time: 0.0194  memory: 13533  grad_norm: 2.8098  loss: 0.4609  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4609\n",
            "02/09 14:15:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:16:49  time: 0.5213  data_time: 0.0192  memory: 13533  grad_norm: 2.6565  loss: 0.4601  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4601\n",
            "02/09 14:16:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:16:38  time: 0.5202  data_time: 0.0181  memory: 13533  grad_norm: 2.3629  loss: 0.4286  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4286\n",
            "02/09 14:16:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:16:27  time: 0.5213  data_time: 0.0192  memory: 13533  grad_norm: 2.1880  loss: 0.4027  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4027\n",
            "02/09 14:16:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:16:17  time: 0.5198  data_time: 0.0178  memory: 13533  grad_norm: 2.2712  loss: 0.3697  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3697\n",
            "02/09 14:16:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:16:06  time: 0.5201  data_time: 0.0185  memory: 13533  grad_norm: 2.7288  loss: 0.4181  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4181\n",
            "02/09 14:16:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:16:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:16:03  time: 0.5164  data_time: 0.0179  memory: 13533  grad_norm: 2.7870  loss: 0.4287  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.4287\n",
            "02/09 14:16:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 39 epochs\n",
            "02/09 14:16:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [39][20/21]    eta: 0:00:00  time: 0.2497  data_time: 0.1103  memory: 1642  \n",
            "02/09 14:16:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [39][21/21]    acc/top1: 0.6627  acc/top5: 1.0000  acc/mean1: 0.6499  data_time: 0.1008  time: 0.2364\n",
            "02/09 14:16:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:15:53  time: 0.5944  data_time: 0.0899  memory: 13533  grad_norm: 2.7255  loss: 0.4341  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4341\n",
            "02/09 14:17:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:15:42  time: 0.5206  data_time: 0.0188  memory: 13533  grad_norm: 2.5921  loss: 0.4140  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4140\n",
            "02/09 14:17:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:15:32  time: 0.5216  data_time: 0.0195  memory: 13533  grad_norm: 2.4812  loss: 0.3813  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3813\n",
            "02/09 14:17:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:15:21  time: 0.5205  data_time: 0.0188  memory: 13533  grad_norm: 2.5588  loss: 0.3801  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3801\n",
            "02/09 14:17:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:15:10  time: 0.5217  data_time: 0.0195  memory: 13533  grad_norm: 2.6109  loss: 0.3760  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3760\n",
            "02/09 14:17:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:15:00  time: 0.5218  data_time: 0.0192  memory: 13533  grad_norm: 3.1373  loss: 0.4735  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4735\n",
            "02/09 14:17:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:14:49  time: 0.5219  data_time: 0.0197  memory: 13533  grad_norm: 2.6056  loss: 0.3652  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3652\n",
            "02/09 14:18:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:14:39  time: 0.5196  data_time: 0.0178  memory: 13533  grad_norm: 3.2673  loss: 0.4608  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4608\n",
            "02/09 14:18:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:18:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:14:36  time: 0.5155  data_time: 0.0169  memory: 13533  grad_norm: 3.1160  loss: 0.4468  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.4468\n",
            "02/09 14:18:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][20/21]    eta: 0:00:00  time: 0.2437  data_time: 0.1062  memory: 1642  \n",
            "02/09 14:18:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][21/21]    acc/top1: 0.6566  acc/top5: 1.0000  acc/mean1: 0.6463  data_time: 0.0970  time: 0.2310\n",
            "02/09 14:18:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:14:25  time: 0.5918  data_time: 0.0852  memory: 13533  grad_norm: 2.8195  loss: 0.4318  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4318\n",
            "02/09 14:18:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:14:15  time: 0.5204  data_time: 0.0184  memory: 13533  grad_norm: 2.5610  loss: 0.3798  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.3798\n",
            "02/09 14:18:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:14:04  time: 0.5211  data_time: 0.0190  memory: 13533  grad_norm: 2.5452  loss: 0.3889  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3889\n",
            "02/09 14:18:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:13:54  time: 0.5214  data_time: 0.0194  memory: 13533  grad_norm: 2.6922  loss: 0.3970  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.3970\n",
            "02/09 14:19:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:13:43  time: 0.5210  data_time: 0.0192  memory: 13533  grad_norm: 2.6471  loss: 0.3908  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3908\n",
            "02/09 14:19:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:13:32  time: 0.5209  data_time: 0.0188  memory: 13533  grad_norm: 3.1148  loss: 0.4200  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4200\n",
            "02/09 14:19:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:13:22  time: 0.5225  data_time: 0.0201  memory: 13533  grad_norm: 3.1564  loss: 0.4392  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4392\n",
            "02/09 14:19:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:13:11  time: 0.5199  data_time: 0.0183  memory: 13533  grad_norm: 2.9265  loss: 0.4032  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4032\n",
            "02/09 14:19:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:19:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:13:08  time: 0.5158  data_time: 0.0173  memory: 13533  grad_norm: 2.9809  loss: 0.4033  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.4033\n",
            "02/09 14:19:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [41][20/21]    eta: 0:00:00  time: 0.2624  data_time: 0.1247  memory: 1642  \n",
            "02/09 14:19:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [41][21/21]    acc/top1: 0.6747  acc/top5: 1.0000  acc/mean1: 0.6644  data_time: 0.1139  time: 0.2481\n",
            "02/09 14:20:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:12:58  time: 0.5791  data_time: 0.0756  memory: 13533  grad_norm: 2.5402  loss: 0.3742  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3742\n",
            "02/09 14:20:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:12:47  time: 0.5198  data_time: 0.0177  memory: 13533  grad_norm: 2.5525  loss: 0.4025  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4025\n",
            "02/09 14:20:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:12:36  time: 0.5220  data_time: 0.0197  memory: 13533  grad_norm: 2.6555  loss: 0.3817  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3817\n",
            "02/09 14:20:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:12:26  time: 0.5209  data_time: 0.0187  memory: 13533  grad_norm: 3.2246  loss: 0.4315  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4315\n",
            "02/09 14:20:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:12:15  time: 0.5221  data_time: 0.0194  memory: 13533  grad_norm: 3.0479  loss: 0.4396  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4396\n",
            "02/09 14:20:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:12:05  time: 0.5221  data_time: 0.0196  memory: 13533  grad_norm: 2.7427  loss: 0.4124  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4124\n",
            "02/09 14:21:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:11:54  time: 0.5222  data_time: 0.0197  memory: 13533  grad_norm: 2.9006  loss: 0.4166  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4166\n",
            "02/09 14:21:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:11:44  time: 0.5193  data_time: 0.0178  memory: 13533  grad_norm: 3.0888  loss: 0.4253  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4253\n",
            "02/09 14:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:11:40  time: 0.5164  data_time: 0.0180  memory: 13533  grad_norm: 2.8872  loss: 0.4148  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.4148\n",
            "02/09 14:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 42 epochs\n",
            "02/09 14:21:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [42][20/21]    eta: 0:00:00  time: 0.2509  data_time: 0.1167  memory: 1642  \n",
            "02/09 14:21:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [42][21/21]    acc/top1: 0.6687  acc/top5: 1.0000  acc/mean1: 0.6576  data_time: 0.1066  time: 0.2376\n",
            "02/09 14:21:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:11:30  time: 0.5726  data_time: 0.0661  memory: 13533  grad_norm: 2.8144  loss: 0.3867  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3867\n",
            "02/09 14:21:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:11:19  time: 0.5208  data_time: 0.0185  memory: 13533  grad_norm: 2.7723  loss: 0.4052  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4052\n",
            "02/09 14:21:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:11:09  time: 0.5210  data_time: 0.0188  memory: 13533  grad_norm: 3.3058  loss: 0.4486  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4486\n",
            "02/09 14:22:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:10:58  time: 0.5214  data_time: 0.0192  memory: 13533  grad_norm: 2.7021  loss: 0.4003  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4003\n",
            "02/09 14:22:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:10:48  time: 0.5214  data_time: 0.0191  memory: 13533  grad_norm: 3.0250  loss: 0.4426  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4426\n",
            "02/09 14:22:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:10:37  time: 0.5206  data_time: 0.0186  memory: 13533  grad_norm: 2.9211  loss: 0.4031  top1_acc: 0.4375  top5_acc: 1.0000  loss_cls: 0.4031\n",
            "02/09 14:22:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:10:26  time: 0.5211  data_time: 0.0192  memory: 13533  grad_norm: 3.1789  loss: 0.4478  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4478\n",
            "02/09 14:22:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:10:16  time: 0.5199  data_time: 0.0180  memory: 13533  grad_norm: 2.8792  loss: 0.4086  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4086\n",
            "02/09 14:22:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:22:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:10:13  time: 0.5157  data_time: 0.0170  memory: 13533  grad_norm: 2.7139  loss: 0.3800  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3800\n",
            "02/09 14:22:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [43][20/21]    eta: 0:00:00  time: 0.2526  data_time: 0.1135  memory: 1642  \n",
            "02/09 14:22:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [43][21/21]    acc/top1: 0.6777  acc/top5: 1.0000  acc/mean1: 0.6709  data_time: 0.1037  time: 0.2392\n",
            "02/09 14:23:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:10:02  time: 0.5745  data_time: 0.0689  memory: 13533  grad_norm: 2.9321  loss: 0.4055  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.4055\n",
            "02/09 14:23:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:09:52  time: 0.5203  data_time: 0.0188  memory: 13533  grad_norm: 2.5140  loss: 0.3575  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3575\n",
            "02/09 14:23:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:09:41  time: 0.5213  data_time: 0.0193  memory: 13533  grad_norm: 3.3144  loss: 0.4270  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4270\n",
            "02/09 14:23:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:09:31  time: 0.5210  data_time: 0.0188  memory: 13533  grad_norm: 2.9735  loss: 0.4095  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4095\n",
            "02/09 14:23:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:09:20  time: 0.5217  data_time: 0.0194  memory: 13533  grad_norm: 3.4252  loss: 0.4280  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4280\n",
            "02/09 14:23:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:09:09  time: 0.5210  data_time: 0.0188  memory: 13533  grad_norm: 3.2942  loss: 0.4420  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4420\n",
            "02/09 14:24:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:08:59  time: 0.5215  data_time: 0.0194  memory: 13533  grad_norm: 2.8836  loss: 0.4023  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4023\n",
            "02/09 14:24:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:08:48  time: 0.5199  data_time: 0.0181  memory: 13533  grad_norm: 2.9270  loss: 0.4250  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4250\n",
            "02/09 14:24:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:24:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:08:45  time: 0.5166  data_time: 0.0177  memory: 13533  grad_norm: 2.8768  loss: 0.4332  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.4332\n",
            "02/09 14:24:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [44][20/21]    eta: 0:00:00  time: 0.2394  data_time: 0.1027  memory: 1642  \n",
            "02/09 14:24:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [44][21/21]    acc/top1: 0.6476  acc/top5: 1.0000  acc/mean1: 0.6378  data_time: 0.0939  time: 0.2271\n",
            "02/09 14:24:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][ 20/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:08:35  time: 0.5798  data_time: 0.0749  memory: 13533  grad_norm: 3.0199  loss: 0.3894  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3894\n",
            "02/09 14:24:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][ 40/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:08:24  time: 0.5208  data_time: 0.0191  memory: 13533  grad_norm: 3.0547  loss: 0.4154  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4154\n",
            "02/09 14:25:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][ 60/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:08:14  time: 0.5202  data_time: 0.0183  memory: 13533  grad_norm: 3.2142  loss: 0.4230  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4230\n",
            "02/09 14:25:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][ 80/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:08:03  time: 0.5217  data_time: 0.0195  memory: 13533  grad_norm: 3.0699  loss: 0.3885  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3885\n",
            "02/09 14:25:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][100/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:07:52  time: 0.5199  data_time: 0.0180  memory: 13533  grad_norm: 2.6768  loss: 0.3419  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3419\n",
            "02/09 14:25:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][120/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:07:42  time: 0.5209  data_time: 0.0182  memory: 13533  grad_norm: 3.5639  loss: 0.4108  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4108\n",
            "02/09 14:25:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][140/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:07:31  time: 0.5229  data_time: 0.0201  memory: 13533  grad_norm: 3.4003  loss: 0.3895  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3895\n",
            "02/09 14:25:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][160/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:07:21  time: 0.5200  data_time: 0.0181  memory: 13533  grad_norm: 3.0374  loss: 0.3909  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3909\n",
            "02/09 14:25:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:25:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][166/166]  base_lr: 2.0000e-03 lr: 2.0000e-03  eta: 0:07:17  time: 0.5161  data_time: 0.0176  memory: 13533  grad_norm: 3.0344  loss: 0.3859  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.3859\n",
            "02/09 14:25:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 45 epochs\n",
            "02/09 14:26:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [45][20/21]    eta: 0:00:00  time: 0.2508  data_time: 0.1112  memory: 1642  \n",
            "02/09 14:26:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [45][21/21]    acc/top1: 0.6627  acc/top5: 1.0000  acc/mean1: 0.6560  data_time: 0.1016  time: 0.2376\n",
            "02/09 14:26:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][ 20/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:07:07  time: 0.5772  data_time: 0.0700  memory: 13533  grad_norm: 3.3514  loss: 0.4148  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4148\n",
            "02/09 14:26:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][ 40/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:06:56  time: 0.5209  data_time: 0.0191  memory: 13533  grad_norm: 3.1342  loss: 0.3845  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3845\n",
            "02/09 14:26:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][ 60/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:06:46  time: 0.5210  data_time: 0.0189  memory: 13533  grad_norm: 3.1898  loss: 0.4022  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4022\n",
            "02/09 14:26:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][ 80/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:06:35  time: 0.5212  data_time: 0.0193  memory: 13533  grad_norm: 2.6889  loss: 0.3518  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3518\n",
            "02/09 14:26:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][100/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:06:25  time: 0.5209  data_time: 0.0190  memory: 13533  grad_norm: 3.2524  loss: 0.4274  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4274\n",
            "02/09 14:27:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][120/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:06:14  time: 0.5215  data_time: 0.0192  memory: 13533  grad_norm: 2.8164  loss: 0.3530  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3530\n",
            "02/09 14:27:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][140/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:06:04  time: 0.5215  data_time: 0.0193  memory: 13533  grad_norm: 3.3002  loss: 0.3663  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3663\n",
            "02/09 14:27:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][160/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:05:53  time: 0.5209  data_time: 0.0188  memory: 13533  grad_norm: 2.9171  loss: 0.3687  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3687\n",
            "02/09 14:27:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:27:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][166/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:05:50  time: 0.5170  data_time: 0.0181  memory: 13533  grad_norm: 2.9285  loss: 0.3829  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3829\n",
            "02/09 14:27:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [46][20/21]    eta: 0:00:00  time: 0.2351  data_time: 0.0962  memory: 1642  \n",
            "02/09 14:27:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [46][21/21]    acc/top1: 0.6717  acc/top5: 1.0000  acc/mean1: 0.6660  data_time: 0.0880  time: 0.2233\n",
            "02/09 14:27:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][ 20/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:05:39  time: 0.5906  data_time: 0.0875  memory: 13533  grad_norm: 2.6021  loss: 0.3225  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3225\n",
            "02/09 14:27:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][ 40/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:05:29  time: 0.5204  data_time: 0.0184  memory: 13533  grad_norm: 2.9491  loss: 0.3478  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3478\n",
            "02/09 14:28:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][ 60/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:05:18  time: 0.5209  data_time: 0.0189  memory: 13533  grad_norm: 3.2285  loss: 0.3934  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3934\n",
            "02/09 14:28:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][ 80/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:05:08  time: 0.5210  data_time: 0.0186  memory: 13533  grad_norm: 3.0483  loss: 0.3839  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3839\n",
            "02/09 14:28:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][100/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:04:57  time: 0.5223  data_time: 0.0196  memory: 13533  grad_norm: 2.6542  loss: 0.3312  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3312\n",
            "02/09 14:28:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][120/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:04:47  time: 0.5212  data_time: 0.0190  memory: 13533  grad_norm: 3.1883  loss: 0.4013  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4013\n",
            "02/09 14:28:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][140/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:04:36  time: 0.5212  data_time: 0.0190  memory: 13533  grad_norm: 3.3147  loss: 0.3940  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3940\n",
            "02/09 14:28:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][160/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:04:25  time: 0.5204  data_time: 0.0185  memory: 13533  grad_norm: 2.7794  loss: 0.3279  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3279\n",
            "02/09 14:29:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:29:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][166/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:04:22  time: 0.5170  data_time: 0.0184  memory: 13533  grad_norm: 3.1472  loss: 0.3799  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.3799\n",
            "02/09 14:29:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [47][20/21]    eta: 0:00:00  time: 0.2543  data_time: 0.1143  memory: 1642  \n",
            "02/09 14:29:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [47][21/21]    acc/top1: 0.6657  acc/top5: 1.0000  acc/mean1: 0.6560  data_time: 0.1044  time: 0.2407\n",
            "02/09 14:29:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][ 20/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:04:12  time: 0.5720  data_time: 0.0677  memory: 13533  grad_norm: 3.0915  loss: 0.4079  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4079\n",
            "02/09 14:29:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][ 40/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:04:01  time: 0.5212  data_time: 0.0191  memory: 13533  grad_norm: 3.0786  loss: 0.3491  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3491\n",
            "02/09 14:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][ 60/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:03:51  time: 0.5207  data_time: 0.0186  memory: 13533  grad_norm: 2.8460  loss: 0.3580  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3580\n",
            "02/09 14:29:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][ 80/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:03:40  time: 0.5214  data_time: 0.0190  memory: 13533  grad_norm: 3.5855  loss: 0.4293  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4293\n",
            "02/09 14:30:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][100/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:03:30  time: 0.5214  data_time: 0.0191  memory: 13533  grad_norm: 2.8361  loss: 0.3222  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3222\n",
            "02/09 14:30:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][120/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:03:19  time: 0.5217  data_time: 0.0192  memory: 13533  grad_norm: 3.1771  loss: 0.3383  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3383\n",
            "02/09 14:30:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][140/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:03:08  time: 0.5205  data_time: 0.0185  memory: 13533  grad_norm: 3.4401  loss: 0.4091  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4091\n",
            "02/09 14:30:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][160/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:02:58  time: 0.5189  data_time: 0.0177  memory: 13533  grad_norm: 3.3363  loss: 0.3922  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3922\n",
            "02/09 14:30:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:30:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][166/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:02:55  time: 0.5156  data_time: 0.0173  memory: 13533  grad_norm: 3.5771  loss: 0.4233  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.4233\n",
            "02/09 14:30:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 48 epochs\n",
            "02/09 14:30:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [48][20/21]    eta: 0:00:00  time: 0.2308  data_time: 0.0924  memory: 1642  \n",
            "02/09 14:30:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [48][21/21]    acc/top1: 0.6596  acc/top5: 1.0000  acc/mean1: 0.6519  data_time: 0.0845  time: 0.2193\n",
            "02/09 14:30:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][ 20/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:02:44  time: 0.5829  data_time: 0.0788  memory: 13533  grad_norm: 3.1801  loss: 0.3596  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3596\n",
            "02/09 14:30:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:31:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][ 40/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:02:34  time: 0.5210  data_time: 0.0190  memory: 13533  grad_norm: 3.2052  loss: 0.3793  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3793\n",
            "02/09 14:31:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][ 60/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:02:23  time: 0.5211  data_time: 0.0190  memory: 13533  grad_norm: 3.0920  loss: 0.3776  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3776\n",
            "02/09 14:31:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][ 80/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:02:13  time: 0.5208  data_time: 0.0189  memory: 13533  grad_norm: 3.0676  loss: 0.3618  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3618\n",
            "02/09 14:31:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][100/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:02:02  time: 0.5207  data_time: 0.0190  memory: 13533  grad_norm: 2.7040  loss: 0.3400  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3400\n",
            "02/09 14:31:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][120/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:01:51  time: 0.5201  data_time: 0.0183  memory: 13533  grad_norm: 3.2454  loss: 0.3796  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3796\n",
            "02/09 14:31:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][140/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:01:41  time: 0.5207  data_time: 0.0188  memory: 13533  grad_norm: 2.7586  loss: 0.3253  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3253\n",
            "02/09 14:32:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][160/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:01:30  time: 0.5195  data_time: 0.0182  memory: 13533  grad_norm: 3.7444  loss: 0.4181  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4181\n",
            "02/09 14:32:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:32:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][166/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:01:27  time: 0.5150  data_time: 0.0168  memory: 13533  grad_norm: 3.4444  loss: 0.3749  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3749\n",
            "02/09 14:32:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [49][20/21]    eta: 0:00:00  time: 0.2470  data_time: 0.1072  memory: 1642  \n",
            "02/09 14:32:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [49][21/21]    acc/top1: 0.6566  acc/top5: 1.0000  acc/mean1: 0.6479  data_time: 0.0980  time: 0.2341\n",
            "02/09 14:32:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][ 20/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:01:17  time: 0.5696  data_time: 0.0660  memory: 13533  grad_norm: 3.0206  loss: 0.3400  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3400\n",
            "02/09 14:32:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][ 40/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:01:06  time: 0.5196  data_time: 0.0181  memory: 13533  grad_norm: 3.4208  loss: 0.3885  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3885\n",
            "02/09 14:32:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][ 60/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:00:55  time: 0.5206  data_time: 0.0187  memory: 13533  grad_norm: 3.1513  loss: 0.3589  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3589\n",
            "02/09 14:32:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][ 80/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:00:45  time: 0.5212  data_time: 0.0188  memory: 13533  grad_norm: 3.2822  loss: 0.3861  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3861\n",
            "02/09 14:33:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][100/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:00:34  time: 0.5216  data_time: 0.0195  memory: 13533  grad_norm: 3.6184  loss: 0.3906  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3906\n",
            "02/09 14:33:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][120/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:00:24  time: 0.5206  data_time: 0.0188  memory: 13533  grad_norm: 2.9886  loss: 0.3395  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3395\n",
            "02/09 14:33:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][140/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:00:13  time: 0.5205  data_time: 0.0186  memory: 13533  grad_norm: 2.8546  loss: 0.3316  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3316\n",
            "02/09 14:33:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][160/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:00:03  time: 0.5192  data_time: 0.0175  memory: 13533  grad_norm: 3.2187  loss: 0.3408  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3408\n",
            "02/09 14:33:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb_20240209_131610\n",
            "02/09 14:33:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][166/166]  base_lr: 2.0000e-04 lr: 2.0000e-04  eta: 0:00:00  time: 0.5153  data_time: 0.0168  memory: 13533  grad_norm: 2.8692  loss: 0.3123  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.3123\n",
            "02/09 14:33:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 50 epochs\n",
            "02/09 14:33:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][20/21]    eta: 0:00:00  time: 0.2350  data_time: 0.0982  memory: 1642  \n",
            "02/09 14:33:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][21/21]    acc/top1: 0.6506  acc/top5: 1.0000  acc/mean1: 0.6406  data_time: 0.0899  time: 0.2231\n"
          ]
        }
      ],
      "source": [
        "!python ./tools/train.py ./cuny/configs/tsm/no_pretrain_tsm_imagenet-pretrained-r50_8xb16-1x1x8-50e_kinetics400-rgb.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "TsVCPys7dO1d"
      },
      "outputs": [],
      "source": [
        "!cp -r work_dirs /content/drive/MyDrive/cuny_dataset/"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ykj0I2v7v5ao"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "sZPZBHM3OI8B",
        "MOMG99M2x_lB",
        "jSFCCD9iEI4m",
        "Y69fbwNbApkt",
        "g-rfsT58ebgd"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}