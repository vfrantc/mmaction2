{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vfrantc/mmaction2/blob/main/cuny/experiments/no_pretrain_uniformer_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIT8tO-DStuc",
        "outputId": "e0fe390c-1989-497e-cc37-266947db0a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cvxpy 1.3.3 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.36 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.1/94.1 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.0/436.0 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n",
            "rm: cannot remove '/content/mmaction2/': No such file or directory\n",
            "Cloning into 'mmaction2'...\n",
            "remote: Enumerating objects: 22455, done.\u001b[K\n",
            "remote: Counting objects: 100% (369/369), done.\u001b[K\n",
            "remote: Compressing objects: 100% (178/178), done.\u001b[K\n",
            "remote: Total 22455 (delta 210), reused 334 (delta 185), pack-reused 22086\u001b[K\n",
            "Receiving objects: 100% (22455/22455), 65.47 MiB | 21.82 MiB/s, done.\n",
            "Resolving deltas: 100% (15768/15768), done.\n",
            "/content/mmaction2\n",
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Obtaining file:///content/mmaction2\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-cmjib8ci/mmaction2.egg-info\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-cmjib8ci/mmaction2.egg-info/SOURCES.txt'\n",
            "  warning: no files found matching 'mmaction/.mim/model-index.yml'\n",
            "  warning: no files found matching 'mmaction/.mim/dataset-index.yml'\n",
            "  warning: no files found matching '*.py' under directory 'mmaction/.mim/configs'\n",
            "  warning: no files found matching '*.yml' under directory 'mmaction/.mim/configs'\n",
            "  warning: no files found matching '*.sh' under directory 'mmaction/.mim/tools'\n",
            "  warning: no files found matching '*.py' under directory 'mmaction/.mim/tools'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-cmjib8ci/mmaction2.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting decord>=0.4.1 (from mmaction2==1.2.0)\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from mmaction2==1.2.0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmaction2==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->mmaction2==1.2.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->mmaction2==1.2.0) (1.3.0)\n",
            "Installing collected packages: einops, decord, mmaction2\n",
            "  Running setup.py develop for mmaction2\n",
            "    Running command python setup.py develop\n",
            "    running develop\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    running egg_info\n",
            "    creating mmaction2.egg-info\n",
            "    writing manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "Successfully installed decord-0.6.0 einops-0.7.0 mmaction2-1.2.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# INSTALL REQUIREMENTS AND MMACTION\n",
        "!pip install pytorchvideo --quiet\n",
        "!pip install timm --quiet\n",
        "!pip install -U openmim --quiet\n",
        "!mim install mmengine --quiet\n",
        "!mim install mmcv --quiet\n",
        "!mim install mmdet --quiet\n",
        "!mim install mmpose --quiet\n",
        "\n",
        "# INSTALL MMACTION, OUR CONFIGS ARE THERE AS WELL\n",
        "%cd /content/\n",
        "!rm -r /content/mmaction2/\n",
        "!git clone https://github.com/vfrantc/mmaction2.git\n",
        "%cd mmaction2\n",
        "!pip install -v -e .\n",
        "\n",
        "# COPY DATASET\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!cp /content/drive/MyDrive/cuny_dataset/cuny_dataset.zip .\n",
        "!unzip -qq cuny_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "p-HNQ4rOzZf1"
      },
      "outputs": [],
      "source": [
        "!mv content/mmaction2/data ."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./cuny/configs/uniformerv2/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s_8SpIh85GJH",
        "outputId": "32f94554-8f57-4fa7-a5b1-56b3e71070fb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb.py\n",
            "uniformerv2-base-p16-res224_clip_8xb32-u8_kinetics400-rgb.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYI5XnUtioeV"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-8hE5fOhTMd",
        "outputId": "f84009a3-3267-4647-b378-71dbc83214d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/09 12:44:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 1449964383\n",
            "    GPU 0: Tesla V100-SXM2-16GB\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.1.0+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX512\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.0+cu121\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.3\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 1449964383\n",
            "    diff_rank_seed: False\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "02/09 12:44:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "ann_file_test = 'data/kinetics400/kinetics400_val_list_videos.txt'\n",
            "ann_file_train = 'data/kinetics400/kinetics400_train_list_videos.txt'\n",
            "ann_file_val = 'data/kinetics400/kinetics400_val_list_videos.txt'\n",
            "auto_scale_lr = dict(base_batch_size=256, enable=True)\n",
            "base_lr = 1e-05\n",
            "data_root = 'data/kinetics400/videos_train'\n",
            "data_root_val = 'data/kinetics400/videos_val'\n",
            "dataset_type = 'VideoDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=3, max_keep_ckpts=5, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(ignore_last=False, interval=100, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'),\n",
            "    timer=dict(type='IterTimerHook'))\n",
            "default_scope = 'mmaction'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "file_client_args = dict(io_backend='disk')\n",
            "launcher = 'none'\n",
            "load_from = None\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        backbone_drop_path_rate=0.0,\n",
            "        clip_pretrained=True,\n",
            "        double_lmhra=True,\n",
            "        drop_path_rate=0.0,\n",
            "        dw_reduction=1.5,\n",
            "        heads=12,\n",
            "        input_resolution=224,\n",
            "        layers=12,\n",
            "        mlp_dropout=[\n",
            "            0.5,\n",
            "            0.5,\n",
            "            0.5,\n",
            "            0.5,\n",
            "        ],\n",
            "        mlp_factor=4.0,\n",
            "        n_dim=768,\n",
            "        n_head=12,\n",
            "        n_layers=4,\n",
            "        no_lmhra=True,\n",
            "        patch_size=16,\n",
            "        pretrained='ViT-B/16',\n",
            "        return_list=[\n",
            "            8,\n",
            "            9,\n",
            "            10,\n",
            "            11,\n",
            "        ],\n",
            "        t_size=8,\n",
            "        temporal_downsample=False,\n",
            "        type='UniFormerV2',\n",
            "        width=768),\n",
            "    cls_head=dict(\n",
            "        average_clips='prob',\n",
            "        dropout_ratio=0.5,\n",
            "        in_channels=768,\n",
            "        num_classes=2,\n",
            "        type='UniFormerHead'),\n",
            "    data_preprocessor=dict(\n",
            "        format_shape='NCTHW',\n",
            "        mean=[\n",
            "            114.75,\n",
            "            114.75,\n",
            "            114.75,\n",
            "        ],\n",
            "        std=[\n",
            "            57.375,\n",
            "            57.375,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='ActionDataPreprocessor'),\n",
            "    type='Recognizer3D')\n",
            "num_frames = 8\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=dict(max_norm=20, norm_type=2),\n",
            "    optimizer=dict(\n",
            "        betas=(\n",
            "            0.9,\n",
            "            0.999,\n",
            "        ), lr=1e-05, type='AdamW', weight_decay=0.05),\n",
            "    paramwise_cfg=dict(bias_decay_mult=0.0, norm_decay_mult=0.0))\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        convert_to_iter_based=True,\n",
            "        end=5,\n",
            "        start_factor=0.1,\n",
            "        type='LinearLR'),\n",
            "    dict(\n",
            "        T_max=50,\n",
            "        begin=5,\n",
            "        by_epoch=True,\n",
            "        convert_to_iter_based=True,\n",
            "        end=55,\n",
            "        eta_min_ratio=0.1,\n",
            "        type='CosineAnnealingLR'),\n",
            "]\n",
            "randomness = dict(deterministic=False, diff_rank_seed=False, seed=None)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=8,\n",
            "    dataset=dict(\n",
            "        ann_file='data/kinetics400/kinetics400_val_list_videos.txt',\n",
            "        data_prefix=dict(video='data/kinetics400/videos_val'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=8, num_clips=4, test_mode=True, type='UniformSample'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                224,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='ThreeCrop'),\n",
            "            dict(input_format='NCTHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "test_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(clip_len=8, num_clips=4, test_mode=True, type='UniformSample'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        224,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='ThreeCrop'),\n",
            "    dict(input_format='NCTHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "train_cfg = dict(\n",
            "    max_epochs=55, type='EpochBasedTrainLoop', val_begin=1, val_interval=1)\n",
            "train_dataloader = dict(\n",
            "    batch_size=8,\n",
            "    dataset=dict(\n",
            "        ann_file='data/kinetics400/kinetics400_train_list_videos.txt',\n",
            "        data_prefix=dict(video='data/kinetics400/videos_train'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(clip_len=8, num_clips=1, type='UniformSample'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(\n",
            "                magnitude=7,\n",
            "                num_layers=4,\n",
            "                op='RandAugment',\n",
            "                type='PytorchVideoWrapper'),\n",
            "            dict(type='RandomResizedCrop'),\n",
            "            dict(keep_ratio=False, scale=(\n",
            "                224,\n",
            "                224,\n",
            "            ), type='Resize'),\n",
            "            dict(flip_ratio=0.5, type='Flip'),\n",
            "            dict(input_format='NCTHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(clip_len=8, num_clips=1, type='UniformSample'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(\n",
            "        magnitude=7,\n",
            "        num_layers=4,\n",
            "        op='RandAugment',\n",
            "        type='PytorchVideoWrapper'),\n",
            "    dict(type='RandomResizedCrop'),\n",
            "    dict(keep_ratio=False, scale=(\n",
            "        224,\n",
            "        224,\n",
            "    ), type='Resize'),\n",
            "    dict(flip_ratio=0.5, type='Flip'),\n",
            "    dict(input_format='NCTHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=8,\n",
            "    dataset=dict(\n",
            "        ann_file='data/kinetics400/kinetics400_val_list_videos.txt',\n",
            "        data_prefix=dict(video='data/kinetics400/videos_val'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=8, num_clips=1, test_mode=True, type='UniformSample'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                224,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='CenterCrop'),\n",
            "            dict(input_format='NCTHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "val_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(clip_len=8, num_clips=1, test_mode=True, type='UniformSample'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        224,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='CenterCrop'),\n",
            "    dict(input_format='NCTHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb'\n",
            "\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - No L_MHRA: True\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Double L_MHRA: True\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - No L_MHRA: True\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Double L_MHRA: True\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - No L_MHRA: True\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Double L_MHRA: True\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - No L_MHRA: True\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Double L_MHRA: True\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - No L_MHRA: True\n",
            "02/09 12:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Double L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - No L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Double L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - No L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Double L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - No L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Double L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - No L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Double L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - No L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Double L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - No L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Double L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - No L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Double L_MHRA: True\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Drop path rate: 0.0\n",
            "02/09 12:44:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "02/09 12:44:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
            "  warnings.warn(\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.ln_pre.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.ln_pre.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.0.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.0.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.0.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.0.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.0.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.0.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.0.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.1.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.1.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.1.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.1.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.1.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.1.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.1.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.2.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.2.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.2.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.2.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.2.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.2.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.2.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.3.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.3.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.3.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.3.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.3.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.3.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.3.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.4.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.4.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.4.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.4.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.4.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.4.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.4.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.5.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.5.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.5.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.5.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.5.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.5.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.5.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.6.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.6.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.6.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.6.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.6.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.6.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.6.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.7.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.7.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.7.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.7.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.7.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.7.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.7.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.8.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.8.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.8.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.8.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.8.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.8.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.8.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.9.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.9.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.9.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.9.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.9.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.9.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.9.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.10.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.10.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.10.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.10.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.10.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.10.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.10.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.11.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.11.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.11.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.11.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.11.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.11.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.resblocks.11.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dpe.0.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dpe.1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dpe.2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dpe.3.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.0.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.0.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.0.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.0.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.0.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.0.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.0.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.0.ln_3.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.0.ln_3.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.1.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.1.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.1.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.1.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.1.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.1.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.1.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.1.ln_3.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.1.ln_3.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.2.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.2.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.2.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.2.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.2.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.2.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.2.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.2.ln_3.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.2.ln_3.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.3.attn.out_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.3.ln_1.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.3.ln_1.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.3.mlp.c_fc.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.3.mlp.c_proj.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.3.ln_2.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.3.ln_2.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.3.ln_3.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.dec.3.ln_3.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.norm.weight:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- backbone.transformer.norm.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - paramwise_options -- cls_head.fc_cls.bias:weight_decay=0.0\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - LR is set based on batch size of 256 and the current batch size is 8. Scaling the original LR by 0.03125.\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: ViT-B/16\n",
            "02/09 12:44:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Load CLIP pretrained model from https://download.openmmlab.com/mmaction/v1.0/recognition/uniformerv2/clipVisualEncoder/vit-base-p16-res224_clip-rgb_20221219-b8a5da86.pth\n",
            "Loads checkpoint by http backend from path: https://download.openmmlab.com/mmaction/v1.0/recognition/uniformerv2/clipVisualEncoder/vit-base-p16-res224_clip-rgb_20221219-b8a5da86.pth\n",
            "Downloading: \"https://download.openmmlab.com/mmaction/v1.0/recognition/uniformerv2/clipVisualEncoder/vit-base-p16-res224_clip-rgb_20221219-b8a5da86.pth\" to /root/.cache/torch/hub/checkpoints/vit-base-p16-res224_clip-rgb_20221219-b8a5da86.pth\n",
            "100% 327M/327M [00:09<00:00, 35.1MB/s]\n",
            "02/09 12:44:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])\n",
            "02/09 12:44:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Init center: True\n",
            "02/09 12:44:25 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "02/09 12:44:25 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "02/09 12:44:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb.\n",
            "02/09 12:45:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][100/332]  base_lr: 1.5371e-06 lr: 4.8033e-08  eta: 4:37:36  time: 0.8824  data_time: 0.0107  memory: 11653  grad_norm: 63.5956  loss: 0.7242  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7242\n",
            "02/09 12:47:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][200/332]  base_lr: 2.0796e-06 lr: 6.4986e-08  eta: 4:31:07  time: 0.8848  data_time: 0.0111  memory: 11652  grad_norm: 74.8377  loss: 0.7776  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7776\n",
            "02/09 12:48:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][300/332]  base_lr: 2.6221e-06 lr: 8.1939e-08  eta: 4:28:21  time: 0.8875  data_time: 0.0113  memory: 11652  grad_norm: 63.7535  loss: 0.7012  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7012\n",
            "02/09 12:49:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 12:49:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [1][332/332]  base_lr: 2.7957e-06 lr: 8.7364e-08  eta: 4:27:25  time: 0.8770  data_time: 0.0108  memory: 11652  grad_norm: 71.1004  loss: 0.7377  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7377\n",
            "02/09 12:49:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [1][42/42]    acc/top1: 0.4849  acc/top5: 1.0000  acc/mean1: 0.4929  data_time: 0.0350  time: 0.2632\n",
            "02/09 12:49:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.4849 acc/top1 at 1 epoch is saved to best_acc_top1_epoch_1.pth.\n",
            "02/09 12:51:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][100/332]  base_lr: 3.3382e-06 lr: 1.0432e-07  eta: 4:26:13  time: 0.8881  data_time: 0.0113  memory: 11652  grad_norm: 99.6596  loss: 0.8159  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8159\n",
            "02/09 12:52:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][200/332]  base_lr: 3.8807e-06 lr: 1.2127e-07  eta: 4:24:15  time: 0.8872  data_time: 0.0114  memory: 11652  grad_norm: 168.4331  loss: 0.6254  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6254\n",
            "02/09 12:54:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][300/332]  base_lr: 4.4231e-06 lr: 1.3822e-07  eta: 4:22:22  time: 0.8876  data_time: 0.0110  memory: 11652  grad_norm: 214.6316  loss: 0.6132  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6132\n",
            "02/09 12:54:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 12:54:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [2][332/332]  base_lr: 4.5967e-06 lr: 1.4365e-07  eta: 4:21:43  time: 0.8773  data_time: 0.0107  memory: 11652  grad_norm: 224.2225  loss: 0.6243  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6243\n",
            "02/09 12:54:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [2][42/42]    acc/top1: 0.6476  acc/top5: 1.0000  acc/mean1: 0.6462  data_time: 0.0236  time: 0.2492\n",
            "02/09 12:54:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_1.pth is removed\n",
            "02/09 12:54:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6476 acc/top1 at 2 epoch is saved to best_acc_top1_epoch_2.pth.\n",
            "02/09 12:56:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][100/332]  base_lr: 5.1392e-06 lr: 1.6060e-07  eta: 4:20:35  time: 0.8848  data_time: 0.0103  memory: 11652  grad_norm: 225.3409  loss: 0.6645  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6645\n",
            "02/09 12:57:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][200/332]  base_lr: 5.6817e-06 lr: 1.7755e-07  eta: 4:18:52  time: 0.8878  data_time: 0.0110  memory: 11652  grad_norm: 355.2777  loss: 0.6559  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6559\n",
            "02/09 12:59:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][300/332]  base_lr: 6.2242e-06 lr: 1.9451e-07  eta: 4:17:11  time: 0.8873  data_time: 0.0109  memory: 11652  grad_norm: 409.6179  loss: 0.5918  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5918\n",
            "02/09 12:59:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 12:59:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [3][332/332]  base_lr: 6.3978e-06 lr: 1.9993e-07  eta: 4:16:36  time: 0.8761  data_time: 0.0102  memory: 11652  grad_norm: 318.6189  loss: 0.6323  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6323\n",
            "02/09 12:59:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
            "02/09 12:59:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [3][42/42]    acc/top1: 0.6687  acc/top5: 1.0000  acc/mean1: 0.6672  data_time: 0.0245  time: 0.2495\n",
            "02/09 12:59:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_2.pth is removed\n",
            "02/09 12:59:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6687 acc/top1 at 3 epoch is saved to best_acc_top1_epoch_3.pth.\n",
            "02/09 13:00:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:01:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][100/332]  base_lr: 6.9403e-06 lr: 2.1689e-07  eta: 4:15:16  time: 0.8875  data_time: 0.0113  memory: 11652  grad_norm: 436.3905  loss: 0.6714  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6714\n",
            "02/09 13:03:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][200/332]  base_lr: 7.4828e-06 lr: 2.3384e-07  eta: 4:13:40  time: 0.8889  data_time: 0.0114  memory: 11652  grad_norm: 320.7522  loss: 0.6757  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6757\n",
            "02/09 13:04:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][300/332]  base_lr: 8.0253e-06 lr: 2.5079e-07  eta: 4:12:04  time: 0.8875  data_time: 0.0114  memory: 11652  grad_norm: 316.9180  loss: 0.5787  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5787\n",
            "02/09 13:05:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:05:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [4][332/332]  base_lr: 8.1989e-06 lr: 2.5622e-07  eta: 4:11:32  time: 0.8788  data_time: 0.0107  memory: 11652  grad_norm: 393.8183  loss: 0.6116  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6116\n",
            "02/09 13:05:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [4][42/42]    acc/top1: 0.6717  acc/top5: 1.0000  acc/mean1: 0.6736  data_time: 0.0231  time: 0.2482\n",
            "02/09 13:05:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_3.pth is removed\n",
            "02/09 13:05:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6717 acc/top1 at 4 epoch is saved to best_acc_top1_epoch_4.pth.\n",
            "02/09 13:06:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][100/332]  base_lr: 8.7414e-06 lr: 2.7317e-07  eta: 4:10:18  time: 0.8892  data_time: 0.0115  memory: 11652  grad_norm: 289.5987  loss: 0.6348  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6348\n",
            "02/09 13:08:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][200/332]  base_lr: 9.2839e-06 lr: 2.9012e-07  eta: 4:08:44  time: 0.8885  data_time: 0.0111  memory: 11652  grad_norm: 372.2252  loss: 0.6403  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6403\n",
            "02/09 13:09:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][300/332]  base_lr: 9.8264e-06 lr: 3.0708e-07  eta: 4:07:10  time: 0.8863  data_time: 0.0108  memory: 11652  grad_norm: 496.1982  loss: 0.6978  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6978\n",
            "02/09 13:10:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:10:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [5][332/332]  base_lr: 1.0000e-05 lr: 3.1250e-07  eta: 4:06:39  time: 0.8781  data_time: 0.0108  memory: 11652  grad_norm: 303.0047  loss: 0.5974  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5974\n",
            "02/09 13:10:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][42/42]    acc/top1: 0.6325  acc/top5: 1.0000  acc/mean1: 0.6393  data_time: 0.0235  time: 0.2489\n",
            "02/09 13:11:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][100/332]  base_lr: 9.9992e-06 lr: 3.1248e-07  eta: 4:05:16  time: 0.8864  data_time: 0.0112  memory: 11652  grad_norm: 250.3394  loss: 0.6750  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6750\n",
            "02/09 13:13:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][200/332]  base_lr: 9.9968e-06 lr: 3.1240e-07  eta: 4:03:44  time: 0.8882  data_time: 0.0119  memory: 11652  grad_norm: 356.8137  loss: 0.6802  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6802\n",
            "02/09 13:14:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][300/332]  base_lr: 9.9928e-06 lr: 3.1227e-07  eta: 4:02:11  time: 0.8881  data_time: 0.0113  memory: 11652  grad_norm: 192.2310  loss: 0.5992  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5992\n",
            "02/09 13:15:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:15:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [6][332/332]  base_lr: 9.9912e-06 lr: 3.1222e-07  eta: 4:01:40  time: 0.8780  data_time: 0.0107  memory: 11652  grad_norm: 268.1530  loss: 0.6654  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6654\n",
            "02/09 13:15:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
            "02/09 13:15:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [6][42/42]    acc/top1: 0.6807  acc/top5: 1.0000  acc/mean1: 0.6789  data_time: 0.0283  time: 0.2541\n",
            "02/09 13:15:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_4.pth is removed\n",
            "02/09 13:15:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6807 acc/top1 at 6 epoch is saved to best_acc_top1_epoch_6.pth.\n",
            "02/09 13:15:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:17:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][100/332]  base_lr: 9.9850e-06 lr: 3.1203e-07  eta: 4:00:18  time: 0.8846  data_time: 0.0111  memory: 11652  grad_norm: 262.4059  loss: 0.5792  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5792\n",
            "02/09 13:18:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][200/332]  base_lr: 9.9773e-06 lr: 3.1179e-07  eta: 3:58:45  time: 0.8866  data_time: 0.0112  memory: 11652  grad_norm: 202.3187  loss: 0.6600  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6600\n",
            "02/09 13:20:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][300/332]  base_lr: 9.9680e-06 lr: 3.1150e-07  eta: 3:57:12  time: 0.8848  data_time: 0.0110  memory: 11652  grad_norm: 198.7591  loss: 0.6559  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6559\n",
            "02/09 13:20:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:20:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [7][332/332]  base_lr: 9.9646e-06 lr: 3.1139e-07  eta: 3:56:42  time: 0.8765  data_time: 0.0106  memory: 11652  grad_norm: 258.7256  loss: 0.6237  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6237\n",
            "02/09 13:20:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [7][42/42]    acc/top1: 0.6777  acc/top5: 1.0000  acc/mean1: 0.6745  data_time: 0.0252  time: 0.2514\n",
            "02/09 13:22:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][100/332]  base_lr: 9.9532e-06 lr: 3.1104e-07  eta: 3:55:19  time: 0.8870  data_time: 0.0116  memory: 11652  grad_norm: 191.4307  loss: 0.6017  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6017\n",
            "02/09 13:23:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][200/332]  base_lr: 9.9401e-06 lr: 3.1063e-07  eta: 3:53:47  time: 0.8853  data_time: 0.0110  memory: 11652  grad_norm: 208.1587  loss: 0.6049  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6049\n",
            "02/09 13:25:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][300/332]  base_lr: 9.9255e-06 lr: 3.1017e-07  eta: 3:52:15  time: 0.8862  data_time: 0.0113  memory: 11652  grad_norm: 254.8280  loss: 0.5535  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5535\n",
            "02/09 13:25:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:25:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [8][332/332]  base_lr: 9.9205e-06 lr: 3.1001e-07  eta: 3:51:44  time: 0.8762  data_time: 0.0110  memory: 11652  grad_norm: 200.5525  loss: 0.5582  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.5582\n",
            "02/09 13:25:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [8][42/42]    acc/top1: 0.6928  acc/top5: 1.0000  acc/mean1: 0.6914  data_time: 0.0227  time: 0.2482\n",
            "02/09 13:25:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_6.pth is removed\n",
            "02/09 13:25:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6928 acc/top1 at 8 epoch is saved to best_acc_top1_epoch_8.pth.\n",
            "02/09 13:27:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][100/332]  base_lr: 9.9037e-06 lr: 3.0949e-07  eta: 3:50:21  time: 0.8870  data_time: 0.0116  memory: 11652  grad_norm: 215.2694  loss: 0.4924  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4924\n",
            "02/09 13:29:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][200/332]  base_lr: 9.8854e-06 lr: 3.0892e-07  eta: 3:48:50  time: 0.8873  data_time: 0.0113  memory: 11652  grad_norm: 370.0383  loss: 0.7105  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7105\n",
            "02/09 13:30:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][300/332]  base_lr: 9.8655e-06 lr: 3.0830e-07  eta: 3:47:20  time: 0.8878  data_time: 0.0111  memory: 11652  grad_norm: 225.6271  loss: 0.5117  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5117\n",
            "02/09 13:31:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:31:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [9][332/332]  base_lr: 9.8588e-06 lr: 3.0809e-07  eta: 3:46:50  time: 0.8759  data_time: 0.0109  memory: 11652  grad_norm: 200.8306  loss: 0.5610  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.5610\n",
            "02/09 13:31:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
            "02/09 13:31:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [9][42/42]    acc/top1: 0.6777  acc/top5: 1.0000  acc/mean1: 0.6673  data_time: 0.0262  time: 0.2510\n",
            "02/09 13:31:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:32:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][100/332]  base_lr: 9.8369e-06 lr: 3.0740e-07  eta: 3:45:25  time: 0.8894  data_time: 0.0113  memory: 11652  grad_norm: 214.3880  loss: 0.6282  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6282\n",
            "02/09 13:34:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][200/332]  base_lr: 9.8134e-06 lr: 3.0667e-07  eta: 3:43:54  time: 0.8869  data_time: 0.0115  memory: 11652  grad_norm: 183.4529  loss: 0.6016  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6016\n",
            "02/09 13:35:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][300/332]  base_lr: 9.7884e-06 lr: 3.0589e-07  eta: 3:42:23  time: 0.8865  data_time: 0.0114  memory: 11652  grad_norm: 265.1179  loss: 0.6055  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6055\n",
            "02/09 13:36:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:36:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [10][332/332]  base_lr: 9.7800e-06 lr: 3.0563e-07  eta: 3:41:53  time: 0.8789  data_time: 0.0115  memory: 11652  grad_norm: 194.9816  loss: 0.6844  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6844\n",
            "02/09 13:36:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][42/42]    acc/top1: 0.6898  acc/top5: 1.0000  acc/mean1: 0.6930  data_time: 0.0229  time: 0.2484\n",
            "02/09 13:37:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][100/332]  base_lr: 9.7530e-06 lr: 3.0478e-07  eta: 3:40:28  time: 0.8869  data_time: 0.0110  memory: 11652  grad_norm: 192.0734  loss: 0.5840  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5840\n",
            "02/09 13:39:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][200/332]  base_lr: 9.7244e-06 lr: 3.0389e-07  eta: 3:38:58  time: 0.8869  data_time: 0.0116  memory: 11652  grad_norm: 189.6985  loss: 0.5746  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5746\n",
            "02/09 13:40:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][300/332]  base_lr: 9.6943e-06 lr: 3.0295e-07  eta: 3:37:27  time: 0.8894  data_time: 0.0116  memory: 11652  grad_norm: 138.0829  loss: 0.5619  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5619\n",
            "02/09 13:41:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:41:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [11][332/332]  base_lr: 9.6843e-06 lr: 3.0263e-07  eta: 3:36:57  time: 0.8778  data_time: 0.0113  memory: 11652  grad_norm: 177.5892  loss: 0.6314  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6314\n",
            "02/09 13:41:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [11][42/42]    acc/top1: 0.7018  acc/top5: 1.0000  acc/mean1: 0.6983  data_time: 0.0237  time: 0.2493\n",
            "02/09 13:41:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_8.pth is removed\n",
            "02/09 13:41:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7018 acc/top1 at 11 epoch is saved to best_acc_top1_epoch_11.pth.\n",
            "02/09 13:43:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][100/332]  base_lr: 9.6522e-06 lr: 3.0163e-07  eta: 3:35:31  time: 0.8873  data_time: 0.0117  memory: 11652  grad_norm: 246.1979  loss: 0.6437  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6437\n",
            "02/09 13:44:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][200/332]  base_lr: 9.6187e-06 lr: 3.0058e-07  eta: 3:34:01  time: 0.8862  data_time: 0.0113  memory: 11652  grad_norm: 141.7847  loss: 0.6074  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6074\n",
            "02/09 13:46:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][300/332]  base_lr: 9.5836e-06 lr: 2.9949e-07  eta: 3:32:30  time: 0.8912  data_time: 0.0125  memory: 11652  grad_norm: 183.5693  loss: 0.5222  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5222\n",
            "02/09 13:46:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:46:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [12][332/332]  base_lr: 9.5721e-06 lr: 2.9913e-07  eta: 3:32:01  time: 0.8780  data_time: 0.0111  memory: 11652  grad_norm: 260.7039  loss: 0.5839  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.5839\n",
            "02/09 13:46:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n",
            "02/09 13:46:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [12][42/42]    acc/top1: 0.7108  acc/top5: 1.0000  acc/mean1: 0.7007  data_time: 0.0239  time: 0.2489\n",
            "02/09 13:46:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_11.pth is removed\n",
            "02/09 13:46:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7108 acc/top1 at 12 epoch is saved to best_acc_top1_epoch_12.pth.\n",
            "02/09 13:47:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:48:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][100/332]  base_lr: 9.5351e-06 lr: 2.9797e-07  eta: 3:30:34  time: 0.8864  data_time: 0.0115  memory: 11652  grad_norm: 166.5942  loss: 0.4844  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4844\n",
            "02/09 13:49:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][200/332]  base_lr: 9.4967e-06 lr: 2.9677e-07  eta: 3:29:04  time: 0.8862  data_time: 0.0112  memory: 11652  grad_norm: 181.7950  loss: 0.5897  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5897\n",
            "02/09 13:51:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][300/332]  base_lr: 9.4568e-06 lr: 2.9553e-07  eta: 3:27:33  time: 0.8863  data_time: 0.0116  memory: 11652  grad_norm: 167.3966  loss: 0.4931  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4931\n",
            "02/09 13:51:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:51:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [13][332/332]  base_lr: 9.4438e-06 lr: 2.9512e-07  eta: 3:27:04  time: 0.8763  data_time: 0.0109  memory: 11652  grad_norm: 238.1738  loss: 0.7002  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7002\n",
            "02/09 13:52:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [13][42/42]    acc/top1: 0.7139  acc/top5: 1.0000  acc/mean1: 0.7080  data_time: 0.0258  time: 0.2506\n",
            "02/09 13:52:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_12.pth is removed\n",
            "02/09 13:52:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7139 acc/top1 at 13 epoch is saved to best_acc_top1_epoch_13.pth.\n",
            "02/09 13:53:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][100/332]  base_lr: 9.4021e-06 lr: 2.9381e-07  eta: 3:25:38  time: 0.8874  data_time: 0.0117  memory: 11652  grad_norm: 223.6347  loss: 0.5616  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.5616\n",
            "02/09 13:55:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][200/332]  base_lr: 9.3590e-06 lr: 2.9247e-07  eta: 3:24:07  time: 0.8871  data_time: 0.0111  memory: 11652  grad_norm: 134.4769  loss: 0.4116  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4116\n",
            "02/09 13:56:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][300/332]  base_lr: 9.3145e-06 lr: 2.9108e-07  eta: 3:22:37  time: 0.8885  data_time: 0.0120  memory: 11652  grad_norm: 153.5814  loss: 0.5938  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5938\n",
            "02/09 13:57:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 13:57:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [14][332/332]  base_lr: 9.2999e-06 lr: 2.9062e-07  eta: 3:22:08  time: 0.8779  data_time: 0.0109  memory: 11652  grad_norm: 144.4694  loss: 0.5578  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.5578\n",
            "02/09 13:57:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [14][42/42]    acc/top1: 0.7139  acc/top5: 1.0000  acc/mean1: 0.7104  data_time: 0.0244  time: 0.2494\n",
            "02/09 13:58:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][100/332]  base_lr: 9.2536e-06 lr: 2.8918e-07  eta: 3:20:41  time: 0.8867  data_time: 0.0112  memory: 11652  grad_norm: 174.9629  loss: 0.6237  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6237\n",
            "02/09 14:00:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][200/332]  base_lr: 9.2060e-06 lr: 2.8769e-07  eta: 3:19:11  time: 0.8884  data_time: 0.0115  memory: 11652  grad_norm: 166.2957  loss: 0.6132  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6132\n",
            "02/09 14:01:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][300/332]  base_lr: 9.1570e-06 lr: 2.8616e-07  eta: 3:17:41  time: 0.8879  data_time: 0.0118  memory: 11652  grad_norm: 123.3280  loss: 0.4838  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4838\n",
            "02/09 14:02:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:02:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [15][332/332]  base_lr: 9.1411e-06 lr: 2.8566e-07  eta: 3:17:12  time: 0.8768  data_time: 0.0110  memory: 11652  grad_norm: 166.7271  loss: 0.4568  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4568\n",
            "02/09 14:02:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 15 epochs\n",
            "02/09 14:02:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][42/42]    acc/top1: 0.7259  acc/top5: 1.0000  acc/mean1: 0.7145  data_time: 0.0263  time: 0.2516\n",
            "02/09 14:02:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_13.pth is removed\n",
            "02/09 14:02:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7259 acc/top1 at 15 epoch is saved to best_acc_top1_epoch_15.pth.\n",
            "02/09 14:02:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:04:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][100/332]  base_lr: 9.0904e-06 lr: 2.8407e-07  eta: 3:15:47  time: 0.8884  data_time: 0.0116  memory: 11652  grad_norm: 157.0024  loss: 0.4601  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.4601\n",
            "02/09 14:05:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][200/332]  base_lr: 9.0384e-06 lr: 2.8245e-07  eta: 3:14:17  time: 0.8870  data_time: 0.0115  memory: 11652  grad_norm: 205.5478  loss: 0.5264  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5264\n",
            "02/09 14:07:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][300/332]  base_lr: 8.9852e-06 lr: 2.8079e-07  eta: 3:12:47  time: 0.8859  data_time: 0.0115  memory: 11652  grad_norm: 172.8370  loss: 0.5972  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5972\n",
            "02/09 14:07:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:07:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [16][332/332]  base_lr: 8.9679e-06 lr: 2.8025e-07  eta: 3:12:17  time: 0.8777  data_time: 0.0112  memory: 11652  grad_norm: 122.6836  loss: 0.5420  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5420\n",
            "02/09 14:07:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [16][42/42]    acc/top1: 0.7289  acc/top5: 1.0000  acc/mean1: 0.7293  data_time: 0.0246  time: 0.2500\n",
            "02/09 14:07:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_15.pth is removed\n",
            "02/09 14:07:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7289 acc/top1 at 16 epoch is saved to best_acc_top1_epoch_16.pth.\n",
            "02/09 14:09:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][100/332]  base_lr: 8.9130e-06 lr: 2.7853e-07  eta: 3:10:51  time: 0.8888  data_time: 0.0112  memory: 11652  grad_norm: 178.2772  loss: 0.5360  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5360\n",
            "02/09 14:10:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][200/332]  base_lr: 8.8568e-06 lr: 2.7678e-07  eta: 3:09:22  time: 0.8874  data_time: 0.0115  memory: 11652  grad_norm: 144.8503  loss: 0.5103  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5103\n",
            "02/09 14:12:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][300/332]  base_lr: 8.7995e-06 lr: 2.7499e-07  eta: 3:07:52  time: 0.8875  data_time: 0.0115  memory: 11652  grad_norm: 172.9628  loss: 0.5249  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5249\n",
            "02/09 14:12:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:12:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [17][332/332]  base_lr: 8.7809e-06 lr: 2.7440e-07  eta: 3:07:22  time: 0.8759  data_time: 0.0108  memory: 11652  grad_norm: 177.3562  loss: 0.5668  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5668\n",
            "02/09 14:12:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [17][42/42]    acc/top1: 0.7229  acc/top5: 1.0000  acc/mean1: 0.7217  data_time: 0.0254  time: 0.2507\n",
            "02/09 14:14:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][100/332]  base_lr: 8.7221e-06 lr: 2.7256e-07  eta: 3:05:56  time: 0.8889  data_time: 0.0114  memory: 11652  grad_norm: 135.2087  loss: 0.4381  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4381\n",
            "02/09 14:15:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][200/332]  base_lr: 8.6620e-06 lr: 2.7069e-07  eta: 3:04:26  time: 0.8898  data_time: 0.0112  memory: 11652  grad_norm: 180.2158  loss: 0.5463  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5463\n",
            "02/09 14:17:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][300/332]  base_lr: 8.6009e-06 lr: 2.6878e-07  eta: 3:02:56  time: 0.8887  data_time: 0.0117  memory: 11652  grad_norm: 211.6759  loss: 0.6502  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6502\n",
            "02/09 14:17:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:17:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [18][332/332]  base_lr: 8.5811e-06 lr: 2.6816e-07  eta: 3:02:27  time: 0.8764  data_time: 0.0112  memory: 11652  grad_norm: 142.5673  loss: 0.5081  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.5081\n",
            "02/09 14:17:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 18 epochs\n",
            "02/09 14:18:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [18][42/42]    acc/top1: 0.7229  acc/top5: 1.0000  acc/mean1: 0.7161  data_time: 0.0243  time: 0.2495\n",
            "02/09 14:18:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][100/332]  base_lr: 8.5185e-06 lr: 2.6620e-07  eta: 3:01:00  time: 0.8901  data_time: 0.0114  memory: 11652  grad_norm: 228.1958  loss: 0.5464  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5464\n",
            "02/09 14:21:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][200/332]  base_lr: 8.4548e-06 lr: 2.6421e-07  eta: 2:59:30  time: 0.8869  data_time: 0.0110  memory: 11652  grad_norm: 143.7721  loss: 0.5441  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.5441\n",
            "02/09 14:22:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][300/332]  base_lr: 8.3900e-06 lr: 2.6219e-07  eta: 2:58:00  time: 0.8886  data_time: 0.0114  memory: 11652  grad_norm: 228.9769  loss: 0.6105  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6105\n",
            "02/09 14:23:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:23:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [19][332/332]  base_lr: 8.3691e-06 lr: 2.6153e-07  eta: 2:57:31  time: 0.8771  data_time: 0.0111  memory: 11652  grad_norm: 187.8588  loss: 0.5536  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.5536\n",
            "02/09 14:23:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [19][42/42]    acc/top1: 0.7199  acc/top5: 1.0000  acc/mean1: 0.7152  data_time: 0.0250  time: 0.2504\n",
            "02/09 14:24:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][100/332]  base_lr: 8.3029e-06 lr: 2.5947e-07  eta: 2:56:04  time: 0.8877  data_time: 0.0119  memory: 11652  grad_norm: 234.6171  loss: 0.5838  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5838\n",
            "02/09 14:26:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][200/332]  base_lr: 8.2358e-06 lr: 2.5737e-07  eta: 2:54:34  time: 0.8886  data_time: 0.0115  memory: 11652  grad_norm: 143.2676  loss: 0.5144  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5144\n",
            "02/09 14:27:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][300/332]  base_lr: 8.1677e-06 lr: 2.5524e-07  eta: 2:53:05  time: 0.8866  data_time: 0.0118  memory: 11652  grad_norm: 162.4416  loss: 0.5063  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5063\n",
            "02/09 14:28:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:28:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [20][332/332]  base_lr: 8.1457e-06 lr: 2.5455e-07  eta: 2:52:36  time: 0.8770  data_time: 0.0108  memory: 11652  grad_norm: 186.8709  loss: 0.5259  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5259\n",
            "02/09 14:28:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][42/42]    acc/top1: 0.7169  acc/top5: 1.0000  acc/mean1: 0.7184  data_time: 0.0260  time: 0.2529\n",
            "02/09 14:29:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][100/332]  base_lr: 8.0764e-06 lr: 2.5239e-07  eta: 2:51:08  time: 0.8879  data_time: 0.0114  memory: 11652  grad_norm: 169.2016  loss: 0.5458  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5458\n",
            "02/09 14:31:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][200/332]  base_lr: 8.0061e-06 lr: 2.5019e-07  eta: 2:49:39  time: 0.8888  data_time: 0.0117  memory: 11652  grad_norm: 129.4605  loss: 0.5167  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5167\n",
            "02/09 14:32:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][300/332]  base_lr: 7.9349e-06 lr: 2.4797e-07  eta: 2:48:09  time: 0.8908  data_time: 0.0117  memory: 11652  grad_norm: 208.7131  loss: 0.5833  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5833\n",
            "02/09 14:33:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:33:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [21][332/332]  base_lr: 7.9119e-06 lr: 2.4725e-07  eta: 2:47:40  time: 0.8782  data_time: 0.0109  memory: 11652  grad_norm: 124.5011  loss: 0.5154  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5154\n",
            "02/09 14:33:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 21 epochs\n",
            "02/09 14:33:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [21][42/42]    acc/top1: 0.7078  acc/top5: 1.0000  acc/mean1: 0.7067  data_time: 0.0270  time: 0.2524\n",
            "02/09 14:34:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:35:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][100/332]  base_lr: 7.8396e-06 lr: 2.4499e-07  eta: 2:46:13  time: 0.8866  data_time: 0.0109  memory: 11652  grad_norm: 190.1371  loss: 0.4896  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4896\n",
            "02/09 14:36:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][200/332]  base_lr: 7.7665e-06 lr: 2.4270e-07  eta: 2:44:43  time: 0.8905  data_time: 0.0117  memory: 11652  grad_norm: 193.0948  loss: 0.4675  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4675\n",
            "02/09 14:38:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][300/332]  base_lr: 7.6925e-06 lr: 2.4039e-07  eta: 2:43:14  time: 0.8876  data_time: 0.0113  memory: 11652  grad_norm: 149.1036  loss: 0.5021  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5021\n",
            "02/09 14:38:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:38:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [22][332/332]  base_lr: 7.6686e-06 lr: 2.3964e-07  eta: 2:42:45  time: 0.8805  data_time: 0.0113  memory: 11652  grad_norm: 148.4709  loss: 0.5238  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5238\n",
            "02/09 14:38:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [22][42/42]    acc/top1: 0.7139  acc/top5: 1.0000  acc/mean1: 0.7048  data_time: 0.0253  time: 0.2511\n",
            "02/09 14:40:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][100/332]  base_lr: 7.5936e-06 lr: 2.3730e-07  eta: 2:41:17  time: 0.8887  data_time: 0.0121  memory: 11652  grad_norm: 188.9175  loss: 0.4917  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4917\n",
            "02/09 14:41:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][200/332]  base_lr: 7.5179e-06 lr: 2.3493e-07  eta: 2:39:47  time: 0.8883  data_time: 0.0114  memory: 11652  grad_norm: 205.7189  loss: 0.5217  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5217\n",
            "02/09 14:43:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][300/332]  base_lr: 7.4414e-06 lr: 2.3254e-07  eta: 2:38:18  time: 0.8881  data_time: 0.0115  memory: 11652  grad_norm: 211.1412  loss: 0.4129  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4129\n",
            "02/09 14:43:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:43:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [23][332/332]  base_lr: 7.4168e-06 lr: 2.3177e-07  eta: 2:37:49  time: 0.8773  data_time: 0.0110  memory: 11652  grad_norm: 199.5078  loss: 0.5326  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5326\n",
            "02/09 14:43:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [23][42/42]    acc/top1: 0.7229  acc/top5: 1.0000  acc/mean1: 0.7100  data_time: 0.0254  time: 0.2505\n",
            "02/09 14:45:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][100/332]  base_lr: 7.3394e-06 lr: 2.2936e-07  eta: 2:36:20  time: 0.8863  data_time: 0.0116  memory: 11652  grad_norm: 141.5775  loss: 0.3996  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3996\n",
            "02/09 14:46:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][200/332]  base_lr: 7.2613e-06 lr: 2.2692e-07  eta: 2:34:51  time: 0.8870  data_time: 0.0114  memory: 11652  grad_norm: 170.4944  loss: 0.4879  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4879\n",
            "02/09 14:48:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][300/332]  base_lr: 7.1827e-06 lr: 2.2446e-07  eta: 2:33:21  time: 0.8893  data_time: 0.0112  memory: 11652  grad_norm: 130.3166  loss: 0.5351  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5351\n",
            "02/09 14:48:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:48:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [24][332/332]  base_lr: 7.1574e-06 lr: 2.2367e-07  eta: 2:32:52  time: 0.8797  data_time: 0.0110  memory: 11652  grad_norm: 202.4300  loss: 0.4597  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.4597\n",
            "02/09 14:48:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 24 epochs\n",
            "02/09 14:48:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [24][42/42]    acc/top1: 0.7018  acc/top5: 1.0000  acc/mean1: 0.7023  data_time: 0.0277  time: 0.2545\n",
            "02/09 14:49:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:50:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][100/332]  base_lr: 7.0779e-06 lr: 2.2118e-07  eta: 2:31:24  time: 0.8877  data_time: 0.0111  memory: 11652  grad_norm: 141.1359  loss: 0.4724  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4724\n",
            "02/09 14:51:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][200/332]  base_lr: 6.9978e-06 lr: 2.1868e-07  eta: 2:29:55  time: 0.8889  data_time: 0.0124  memory: 11652  grad_norm: 150.9139  loss: 0.4624  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.4624\n",
            "02/09 14:53:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][300/332]  base_lr: 6.9173e-06 lr: 2.1616e-07  eta: 2:28:25  time: 0.8882  data_time: 0.0115  memory: 11652  grad_norm: 210.9499  loss: 0.5561  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5561\n",
            "02/09 14:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [25][332/332]  base_lr: 6.8914e-06 lr: 2.1536e-07  eta: 2:27:56  time: 0.8781  data_time: 0.0110  memory: 11652  grad_norm: 181.9569  loss: 0.6066  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6066\n",
            "02/09 14:54:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][42/42]    acc/top1: 0.7199  acc/top5: 1.0000  acc/mean1: 0.7168  data_time: 0.0228  time: 0.2482\n",
            "02/09 14:55:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][100/332]  base_lr: 6.8102e-06 lr: 2.1282e-07  eta: 2:26:28  time: 0.8887  data_time: 0.0119  memory: 11652  grad_norm: 135.2643  loss: 0.5183  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5183\n",
            "02/09 14:57:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][200/332]  base_lr: 6.7284e-06 lr: 2.1026e-07  eta: 2:24:59  time: 0.8889  data_time: 0.0109  memory: 11652  grad_norm: 194.4451  loss: 0.5942  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5942\n",
            "02/09 14:58:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][300/332]  base_lr: 6.6463e-06 lr: 2.0770e-07  eta: 2:23:30  time: 0.8879  data_time: 0.0115  memory: 11652  grad_norm: 205.9375  loss: 0.5231  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5231\n",
            "02/09 14:59:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 14:59:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [26][332/332]  base_lr: 6.6199e-06 lr: 2.0687e-07  eta: 2:23:01  time: 0.8797  data_time: 0.0109  memory: 11652  grad_norm: 181.9899  loss: 0.4195  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4195\n",
            "02/09 14:59:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [26][42/42]    acc/top1: 0.7259  acc/top5: 1.0000  acc/mean1: 0.7193  data_time: 0.0253  time: 0.2510\n",
            "02/09 15:00:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][100/332]  base_lr: 6.5372e-06 lr: 2.0429e-07  eta: 2:21:32  time: 0.8865  data_time: 0.0109  memory: 11652  grad_norm: 170.2380  loss: 0.5252  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5252\n",
            "02/09 15:02:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][200/332]  base_lr: 6.4542e-06 lr: 2.0169e-07  eta: 2:20:03  time: 0.8854  data_time: 0.0112  memory: 11652  grad_norm: 156.1641  loss: 0.5488  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5488\n",
            "02/09 15:03:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][300/332]  base_lr: 6.3708e-06 lr: 1.9909e-07  eta: 2:18:33  time: 0.8866  data_time: 0.0117  memory: 11652  grad_norm: 163.2212  loss: 0.5334  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5334\n",
            "02/09 15:04:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:04:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [27][332/332]  base_lr: 6.3441e-06 lr: 1.9825e-07  eta: 2:18:04  time: 0.8747  data_time: 0.0109  memory: 11652  grad_norm: 144.1163  loss: 0.4791  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.4791\n",
            "02/09 15:04:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 27 epochs\n",
            "02/09 15:04:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [27][42/42]    acc/top1: 0.7199  acc/top5: 1.0000  acc/mean1: 0.7112  data_time: 0.0235  time: 0.2490\n",
            "02/09 15:04:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:05:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][100/332]  base_lr: 6.2603e-06 lr: 1.9563e-07  eta: 2:16:36  time: 0.8869  data_time: 0.0116  memory: 11652  grad_norm: 165.1200  loss: 0.6169  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6169\n",
            "02/09 15:07:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][200/332]  base_lr: 6.1762e-06 lr: 1.9301e-07  eta: 2:15:06  time: 0.8880  data_time: 0.0113  memory: 11652  grad_norm: 149.8946  loss: 0.4764  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.4764\n",
            "02/09 15:08:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][300/332]  base_lr: 6.0919e-06 lr: 1.9037e-07  eta: 2:13:37  time: 0.8895  data_time: 0.0116  memory: 11652  grad_norm: 161.1103  loss: 0.5990  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5990\n",
            "02/09 15:09:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:09:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [28][332/332]  base_lr: 6.0648e-06 lr: 1.8953e-07  eta: 2:13:08  time: 0.8779  data_time: 0.0115  memory: 11652  grad_norm: 143.0537  loss: 0.5129  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.5129\n",
            "02/09 15:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [28][42/42]    acc/top1: 0.7349  acc/top5: 1.0000  acc/mean1: 0.7245  data_time: 0.0249  time: 0.2508\n",
            "02/09 15:09:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_16.pth is removed\n",
            "02/09 15:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7349 acc/top1 at 28 epoch is saved to best_acc_top1_epoch_28.pth.\n",
            "02/09 15:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][100/332]  base_lr: 5.9803e-06 lr: 1.8688e-07  eta: 2:11:40  time: 0.8878  data_time: 0.0113  memory: 11652  grad_norm: 141.0951  loss: 0.4578  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4578\n",
            "02/09 15:12:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][200/332]  base_lr: 5.8955e-06 lr: 1.8423e-07  eta: 2:10:10  time: 0.8873  data_time: 0.0113  memory: 11652  grad_norm: 245.3995  loss: 0.4960  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4960\n",
            "02/09 15:14:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][300/332]  base_lr: 5.8106e-06 lr: 1.8158e-07  eta: 2:08:41  time: 0.8891  data_time: 0.0115  memory: 11652  grad_norm: 157.1230  loss: 0.4739  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4739\n",
            "02/09 15:14:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:14:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [29][332/332]  base_lr: 5.7834e-06 lr: 1.8073e-07  eta: 2:08:12  time: 0.8774  data_time: 0.0108  memory: 11652  grad_norm: 165.4956  loss: 0.5308  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.5308\n",
            "02/09 15:14:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [29][42/42]    acc/top1: 0.7410  acc/top5: 1.0000  acc/mean1: 0.7350  data_time: 0.0241  time: 0.2495\n",
            "02/09 15:14:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_28.pth is removed\n",
            "02/09 15:14:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7410 acc/top1 at 29 epoch is saved to best_acc_top1_epoch_29.pth.\n",
            "02/09 15:16:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][100/332]  base_lr: 5.6984e-06 lr: 1.7807e-07  eta: 2:06:44  time: 0.8876  data_time: 0.0112  memory: 11652  grad_norm: 196.2776  loss: 0.4686  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4686\n",
            "02/09 15:17:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][200/332]  base_lr: 5.6133e-06 lr: 1.7541e-07  eta: 2:05:14  time: 0.8878  data_time: 0.0116  memory: 11652  grad_norm: 154.0246  loss: 0.5030  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5030\n",
            "02/09 15:19:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][300/332]  base_lr: 5.5281e-06 lr: 1.7275e-07  eta: 2:03:45  time: 0.8902  data_time: 0.0115  memory: 11652  grad_norm: 194.7946  loss: 0.5610  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5610\n",
            "02/09 15:19:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:19:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [30][332/332]  base_lr: 5.5009e-06 lr: 1.7190e-07  eta: 2:03:16  time: 0.8770  data_time: 0.0114  memory: 11652  grad_norm: 173.1264  loss: 0.4779  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.4779\n",
            "02/09 15:19:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 30 epochs\n",
            "02/09 15:20:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][42/42]    acc/top1: 0.7380  acc/top5: 1.0000  acc/mean1: 0.7274  data_time: 0.0247  time: 0.2495\n",
            "02/09 15:20:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:21:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][100/332]  base_lr: 5.4157e-06 lr: 1.6924e-07  eta: 2:01:48  time: 0.8878  data_time: 0.0117  memory: 11652  grad_norm: 156.2167  loss: 0.3951  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3951\n",
            "02/09 15:23:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][200/332]  base_lr: 5.3306e-06 lr: 1.6658e-07  eta: 2:00:19  time: 0.8865  data_time: 0.0112  memory: 11652  grad_norm: 134.3392  loss: 0.4653  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4653\n",
            "02/09 15:24:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][300/332]  base_lr: 5.2455e-06 lr: 1.6392e-07  eta: 1:58:49  time: 0.8898  data_time: 0.0113  memory: 11652  grad_norm: 149.8042  loss: 0.4609  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4609\n",
            "02/09 15:24:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:24:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [31][332/332]  base_lr: 5.2183e-06 lr: 1.6307e-07  eta: 1:58:21  time: 0.8764  data_time: 0.0108  memory: 11652  grad_norm: 148.0480  loss: 0.5160  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.5160\n",
            "02/09 15:25:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [31][42/42]    acc/top1: 0.7440  acc/top5: 1.0000  acc/mean1: 0.7382  data_time: 0.0255  time: 0.2509\n",
            "02/09 15:25:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_29.pth is removed\n",
            "02/09 15:25:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7440 acc/top1 at 31 epoch is saved to best_acc_top1_epoch_31.pth.\n",
            "02/09 15:26:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][100/332]  base_lr: 5.1334e-06 lr: 1.6042e-07  eta: 1:56:52  time: 0.8880  data_time: 0.0117  memory: 11652  grad_norm: 176.3481  loss: 0.5215  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5215\n",
            "02/09 15:28:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][200/332]  base_lr: 5.0485e-06 lr: 1.5777e-07  eta: 1:55:23  time: 0.8903  data_time: 0.0115  memory: 11652  grad_norm: 155.6577  loss: 0.5038  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5038\n",
            "02/09 15:29:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][300/332]  base_lr: 4.9639e-06 lr: 1.5512e-07  eta: 1:53:54  time: 0.8896  data_time: 0.0117  memory: 11652  grad_norm: 156.0869  loss: 0.5285  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5285\n",
            "02/09 15:30:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:30:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [32][332/332]  base_lr: 4.9368e-06 lr: 1.5428e-07  eta: 1:53:25  time: 0.8783  data_time: 0.0111  memory: 11652  grad_norm: 160.2718  loss: 0.4937  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.4937\n",
            "02/09 15:30:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [32][42/42]    acc/top1: 0.7319  acc/top5: 1.0000  acc/mean1: 0.7233  data_time: 0.0251  time: 0.2505\n",
            "02/09 15:31:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][100/332]  base_lr: 4.8525e-06 lr: 1.5164e-07  eta: 1:51:57  time: 0.8906  data_time: 0.0120  memory: 11652  grad_norm: 215.3724  loss: 0.4643  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4643\n",
            "02/09 15:33:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][200/332]  base_lr: 4.7683e-06 lr: 1.4901e-07  eta: 1:50:28  time: 0.8909  data_time: 0.0114  memory: 11652  grad_norm: 180.0682  loss: 0.5107  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5107\n",
            "02/09 15:34:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][300/332]  base_lr: 4.6844e-06 lr: 1.4639e-07  eta: 1:48:58  time: 0.8876  data_time: 0.0112  memory: 11652  grad_norm: 156.5491  loss: 0.5149  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5149\n",
            "02/09 15:35:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:35:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [33][332/332]  base_lr: 4.6576e-06 lr: 1.4555e-07  eta: 1:48:30  time: 0.8775  data_time: 0.0111  memory: 11652  grad_norm: 162.0490  loss: 0.5246  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.5246\n",
            "02/09 15:35:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 33 epochs\n",
            "02/09 15:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [33][42/42]    acc/top1: 0.7530  acc/top5: 1.0000  acc/mean1: 0.7411  data_time: 0.0250  time: 0.2511\n",
            "02/09 15:35:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_31.pth is removed\n",
            "02/09 15:35:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7530 acc/top1 at 33 epoch is saved to best_acc_top1_epoch_33.pth.\n",
            "02/09 15:36:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:37:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][100/332]  base_lr: 4.5741e-06 lr: 1.4294e-07  eta: 1:47:01  time: 0.8893  data_time: 0.0115  memory: 11652  grad_norm: 130.4847  loss: 0.4510  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4510\n",
            "02/09 15:38:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][200/332]  base_lr: 4.4909e-06 lr: 1.4034e-07  eta: 1:45:32  time: 0.8888  data_time: 0.0122  memory: 11652  grad_norm: 192.9777  loss: 0.4918  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4918\n",
            "02/09 15:40:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][300/332]  base_lr: 4.4081e-06 lr: 1.3775e-07  eta: 1:44:03  time: 0.8871  data_time: 0.0113  memory: 11652  grad_norm: 210.9265  loss: 0.5429  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5429\n",
            "02/09 15:40:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:40:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [34][332/332]  base_lr: 4.3817e-06 lr: 1.3693e-07  eta: 1:43:34  time: 0.8767  data_time: 0.0112  memory: 11652  grad_norm: 172.3326  loss: 0.4827  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.4827\n",
            "02/09 15:40:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [34][42/42]    acc/top1: 0.7380  acc/top5: 1.0000  acc/mean1: 0.7350  data_time: 0.0252  time: 0.2507\n",
            "02/09 15:42:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][100/332]  base_lr: 4.2994e-06 lr: 1.3436e-07  eta: 1:42:05  time: 0.8888  data_time: 0.0114  memory: 11652  grad_norm: 167.5376  loss: 0.4885  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4885\n",
            "02/09 15:43:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][200/332]  base_lr: 4.2176e-06 lr: 1.3180e-07  eta: 1:40:36  time: 0.8887  data_time: 0.0120  memory: 11652  grad_norm: 186.8901  loss: 0.4674  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.4674\n",
            "02/09 15:45:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][300/332]  base_lr: 4.1362e-06 lr: 1.2926e-07  eta: 1:39:07  time: 0.8871  data_time: 0.0116  memory: 11652  grad_norm: 166.9573  loss: 0.5118  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5118\n",
            "02/09 15:45:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:45:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [35][332/332]  base_lr: 4.1102e-06 lr: 1.2844e-07  eta: 1:38:38  time: 0.8780  data_time: 0.0112  memory: 11652  grad_norm: 128.7265  loss: 0.4562  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4562\n",
            "02/09 15:45:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][42/42]    acc/top1: 0.7470  acc/top5: 1.0000  acc/mean1: 0.7338  data_time: 0.0256  time: 0.2512\n",
            "02/09 15:47:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][100/332]  base_lr: 4.0295e-06 lr: 1.2592e-07  eta: 1:37:09  time: 0.8861  data_time: 0.0111  memory: 11652  grad_norm: 199.2640  loss: 0.4371  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4371\n",
            "02/09 15:48:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][200/332]  base_lr: 3.9493e-06 lr: 1.2341e-07  eta: 1:35:40  time: 0.8876  data_time: 0.0112  memory: 11652  grad_norm: 141.3122  loss: 0.4733  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4733\n",
            "02/09 15:50:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][300/332]  base_lr: 3.8696e-06 lr: 1.2093e-07  eta: 1:34:11  time: 0.8880  data_time: 0.0114  memory: 11652  grad_norm: 177.7040  loss: 0.4578  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4578\n",
            "02/09 15:50:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:50:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [36][332/332]  base_lr: 3.8442e-06 lr: 1.2013e-07  eta: 1:33:42  time: 0.8762  data_time: 0.0107  memory: 11652  grad_norm: 235.8561  loss: 0.5531  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.5531\n",
            "02/09 15:50:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 36 epochs\n",
            "02/09 15:51:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [36][42/42]    acc/top1: 0.7349  acc/top5: 1.0000  acc/mean1: 0.7286  data_time: 0.0275  time: 0.2528\n",
            "02/09 15:51:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][100/332]  base_lr: 3.7653e-06 lr: 1.1767e-07  eta: 1:32:13  time: 0.8870  data_time: 0.0113  memory: 11652  grad_norm: 233.9197  loss: 0.4461  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4461\n",
            "02/09 15:54:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][200/332]  base_lr: 3.6871e-06 lr: 1.1522e-07  eta: 1:30:44  time: 0.8873  data_time: 0.0115  memory: 11652  grad_norm: 212.3070  loss: 0.4667  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.4667\n",
            "02/09 15:55:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][300/332]  base_lr: 3.6095e-06 lr: 1.1280e-07  eta: 1:29:15  time: 0.8872  data_time: 0.0112  memory: 11652  grad_norm: 221.8089  loss: 0.5786  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5786\n",
            "02/09 15:56:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 15:56:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [37][332/332]  base_lr: 3.5848e-06 lr: 1.1202e-07  eta: 1:28:46  time: 0.8773  data_time: 0.0110  memory: 11652  grad_norm: 181.0990  loss: 0.4529  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.4529\n",
            "02/09 15:56:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [37][42/42]    acc/top1: 0.7530  acc/top5: 1.0000  acc/mean1: 0.7511  data_time: 0.0272  time: 0.2526\n",
            "02/09 15:57:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][100/332]  base_lr: 3.5080e-06 lr: 1.0963e-07  eta: 1:27:17  time: 0.8865  data_time: 0.0112  memory: 11652  grad_norm: 169.0711  loss: 0.5420  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5420\n",
            "02/09 15:59:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][200/332]  base_lr: 3.4320e-06 lr: 1.0725e-07  eta: 1:25:48  time: 0.8876  data_time: 0.0115  memory: 11652  grad_norm: 141.1869  loss: 0.4445  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4445\n",
            "02/09 16:00:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][300/332]  base_lr: 3.3568e-06 lr: 1.0490e-07  eta: 1:24:19  time: 0.8892  data_time: 0.0118  memory: 11652  grad_norm: 142.1328  loss: 0.4909  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4909\n",
            "02/09 16:01:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:01:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [38][332/332]  base_lr: 3.3329e-06 lr: 1.0415e-07  eta: 1:23:50  time: 0.8774  data_time: 0.0112  memory: 11652  grad_norm: 177.3966  loss: 0.4878  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.4878\n",
            "02/09 16:01:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [38][42/42]    acc/top1: 0.7380  acc/top5: 1.0000  acc/mean1: 0.7362  data_time: 0.0250  time: 0.2504\n",
            "02/09 16:02:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][100/332]  base_lr: 3.2586e-06 lr: 1.0183e-07  eta: 1:22:21  time: 0.8870  data_time: 0.0116  memory: 11652  grad_norm: 164.9304  loss: 0.5091  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5091\n",
            "02/09 16:04:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][200/332]  base_lr: 3.1852e-06 lr: 9.9537e-08  eta: 1:20:52  time: 0.8860  data_time: 0.0114  memory: 11652  grad_norm: 135.8918  loss: 0.4079  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4079\n",
            "02/09 16:05:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][300/332]  base_lr: 3.1126e-06 lr: 9.7267e-08  eta: 1:19:23  time: 0.8882  data_time: 0.0119  memory: 11652  grad_norm: 185.1427  loss: 0.4541  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4541\n",
            "02/09 16:06:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:06:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [39][332/332]  base_lr: 3.0895e-06 lr: 9.6547e-08  eta: 1:18:54  time: 0.8771  data_time: 0.0110  memory: 11652  grad_norm: 151.3838  loss: 0.4663  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.4663\n",
            "02/09 16:06:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 39 epochs\n",
            "02/09 16:06:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [39][42/42]    acc/top1: 0.7530  acc/top5: 1.0000  acc/mean1: 0.7447  data_time: 0.0240  time: 0.2495\n",
            "02/09 16:07:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:08:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][100/332]  base_lr: 3.0180e-06 lr: 9.4313e-08  eta: 1:17:25  time: 0.8896  data_time: 0.0122  memory: 11652  grad_norm: 191.1707  loss: 0.5634  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5634\n",
            "02/09 16:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][200/332]  base_lr: 2.9474e-06 lr: 9.2107e-08  eta: 1:15:56  time: 0.8875  data_time: 0.0117  memory: 11652  grad_norm: 194.4955  loss: 0.4623  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4623\n",
            "02/09 16:10:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][300/332]  base_lr: 2.8778e-06 lr: 8.9930e-08  eta: 1:14:27  time: 0.8894  data_time: 0.0115  memory: 11652  grad_norm: 176.9608  loss: 0.4740  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4740\n",
            "02/09 16:11:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:11:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [40][332/332]  base_lr: 2.8557e-06 lr: 8.9239e-08  eta: 1:13:58  time: 0.8780  data_time: 0.0113  memory: 11652  grad_norm: 225.4452  loss: 0.5630  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5630\n",
            "02/09 16:11:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][42/42]    acc/top1: 0.7500  acc/top5: 1.0000  acc/mean1: 0.7415  data_time: 0.0238  time: 0.2496\n",
            "02/09 16:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][100/332]  base_lr: 2.7872e-06 lr: 8.7101e-08  eta: 1:12:29  time: 0.8869  data_time: 0.0115  memory: 11652  grad_norm: 183.5911  loss: 0.4248  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4248\n",
            "02/09 16:14:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][200/332]  base_lr: 2.7198e-06 lr: 8.4993e-08  eta: 1:11:00  time: 0.8878  data_time: 0.0117  memory: 11652  grad_norm: 200.0136  loss: 0.5215  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5215\n",
            "02/09 16:16:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][300/332]  base_lr: 2.6533e-06 lr: 8.2916e-08  eta: 1:09:31  time: 0.8881  data_time: 0.0115  memory: 11652  grad_norm: 183.0923  loss: 0.4769  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4769\n",
            "02/09 16:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [41][332/332]  base_lr: 2.6322e-06 lr: 8.2258e-08  eta: 1:09:02  time: 0.8770  data_time: 0.0107  memory: 11652  grad_norm: 200.0787  loss: 0.5189  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.5189\n",
            "02/09 16:16:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [41][42/42]    acc/top1: 0.7470  acc/top5: 1.0000  acc/mean1: 0.7419  data_time: 0.0252  time: 0.2501\n",
            "02/09 16:18:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][100/332]  base_lr: 2.5671e-06 lr: 8.0223e-08  eta: 1:07:33  time: 0.8866  data_time: 0.0114  memory: 11652  grad_norm: 215.4358  loss: 0.5243  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5243\n",
            "02/09 16:19:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][200/332]  base_lr: 2.5031e-06 lr: 7.8221e-08  eta: 1:06:04  time: 0.8886  data_time: 0.0116  memory: 11652  grad_norm: 224.6138  loss: 0.5449  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5449\n",
            "02/09 16:21:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][300/332]  base_lr: 2.4401e-06 lr: 7.6253e-08  eta: 1:04:35  time: 0.8907  data_time: 0.0115  memory: 11652  grad_norm: 197.2341  loss: 0.4994  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4994\n",
            "02/09 16:21:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:21:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [42][332/332]  base_lr: 2.4202e-06 lr: 7.5630e-08  eta: 1:04:06  time: 0.8779  data_time: 0.0108  memory: 11652  grad_norm: 204.3197  loss: 0.5406  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.5406\n",
            "02/09 16:21:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 42 epochs\n",
            "02/09 16:21:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [42][42/42]    acc/top1: 0.7530  acc/top5: 1.0000  acc/mean1: 0.7459  data_time: 0.0259  time: 0.2515\n",
            "02/09 16:22:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:23:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][100/332]  base_lr: 2.3586e-06 lr: 7.3707e-08  eta: 1:02:37  time: 0.8888  data_time: 0.0111  memory: 11652  grad_norm: 161.3256  loss: 0.4343  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4343\n",
            "02/09 16:24:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][200/332]  base_lr: 2.2982e-06 lr: 7.1819e-08  eta: 1:01:08  time: 0.8894  data_time: 0.0116  memory: 11652  grad_norm: 142.8812  loss: 0.4593  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4593\n",
            "02/09 16:26:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][300/332]  base_lr: 2.2389e-06 lr: 6.9967e-08  eta: 0:59:39  time: 0.8873  data_time: 0.0115  memory: 11652  grad_norm: 175.7174  loss: 0.4696  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4696\n",
            "02/09 16:26:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:26:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [43][332/332]  base_lr: 2.2202e-06 lr: 6.9382e-08  eta: 0:59:10  time: 0.8774  data_time: 0.0113  memory: 11652  grad_norm: 169.1867  loss: 0.4476  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4476\n",
            "02/09 16:27:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [43][42/42]    acc/top1: 0.7530  acc/top5: 1.0000  acc/mean1: 0.7459  data_time: 0.0276  time: 0.2539\n",
            "02/09 16:28:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][100/332]  base_lr: 2.1625e-06 lr: 6.7578e-08  eta: 0:57:42  time: 0.8887  data_time: 0.0116  memory: 11652  grad_norm: 159.5846  loss: 0.4326  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.4326\n",
            "02/09 16:30:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][200/332]  base_lr: 2.1060e-06 lr: 6.5812e-08  eta: 0:56:12  time: 0.8896  data_time: 0.0115  memory: 11652  grad_norm: 180.6682  loss: 0.4406  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4406\n",
            "02/09 16:31:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][300/332]  base_lr: 2.0507e-06 lr: 6.4084e-08  eta: 0:54:43  time: 0.8880  data_time: 0.0115  memory: 11652  grad_norm: 175.4159  loss: 0.4061  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.4061\n",
            "02/09 16:31:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:31:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [44][332/332]  base_lr: 2.0332e-06 lr: 6.3539e-08  eta: 0:54:15  time: 0.8784  data_time: 0.0110  memory: 11652  grad_norm: 178.2940  loss: 0.4347  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.4347\n",
            "02/09 16:32:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [44][42/42]    acc/top1: 0.7530  acc/top5: 1.0000  acc/mean1: 0.7447  data_time: 0.0246  time: 0.2507\n",
            "02/09 16:33:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][100/332]  base_lr: 1.9796e-06 lr: 6.1861e-08  eta: 0:52:46  time: 0.8889  data_time: 0.0114  memory: 11652  grad_norm: 200.8422  loss: 0.5084  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5084\n",
            "02/09 16:35:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][200/332]  base_lr: 1.9271e-06 lr: 6.0223e-08  eta: 0:51:17  time: 0.8863  data_time: 0.0111  memory: 11652  grad_norm: 188.4519  loss: 0.5074  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5074\n",
            "02/09 16:36:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][300/332]  base_lr: 1.8760e-06 lr: 5.8625e-08  eta: 0:49:47  time: 0.8881  data_time: 0.0119  memory: 11652  grad_norm: 243.1511  loss: 0.5478  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5478\n",
            "02/09 16:37:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:37:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [45][332/332]  base_lr: 1.8599e-06 lr: 5.8123e-08  eta: 0:49:19  time: 0.8790  data_time: 0.0110  memory: 11652  grad_norm: 168.8430  loss: 0.4532  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.4532\n",
            "02/09 16:37:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 45 epochs\n",
            "02/09 16:37:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [45][42/42]    acc/top1: 0.7590  acc/top5: 1.0000  acc/mean1: 0.7479  data_time: 0.0243  time: 0.2500\n",
            "02/09 16:37:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_33.pth is removed\n",
            "02/09 16:37:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7590 acc/top1 at 45 epoch is saved to best_acc_top1_epoch_45.pth.\n",
            "02/09 16:38:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:38:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][100/332]  base_lr: 1.8105e-06 lr: 5.6578e-08  eta: 0:47:50  time: 0.8874  data_time: 0.0112  memory: 11652  grad_norm: 208.4124  loss: 0.5047  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5047\n",
            "02/09 16:40:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][200/332]  base_lr: 1.7624e-06 lr: 5.5075e-08  eta: 0:46:21  time: 0.8879  data_time: 0.0116  memory: 11652  grad_norm: 192.1498  loss: 0.5444  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5444\n",
            "02/09 16:41:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][300/332]  base_lr: 1.7157e-06 lr: 5.3614e-08  eta: 0:44:51  time: 0.8880  data_time: 0.0117  memory: 11652  grad_norm: 219.4367  loss: 0.5353  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5353\n",
            "02/09 16:42:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:42:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [46][332/332]  base_lr: 1.7010e-06 lr: 5.3156e-08  eta: 0:44:23  time: 0.8773  data_time: 0.0107  memory: 11652  grad_norm: 228.5405  loss: 0.5027  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.5027\n",
            "02/09 16:42:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [46][42/42]    acc/top1: 0.7410  acc/top5: 1.0000  acc/mean1: 0.7354  data_time: 0.0233  time: 0.2494\n",
            "02/09 16:44:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][100/332]  base_lr: 1.6560e-06 lr: 5.1751e-08  eta: 0:42:54  time: 0.8870  data_time: 0.0111  memory: 11652  grad_norm: 151.6636  loss: 0.3986  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3986\n",
            "02/09 16:45:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][200/332]  base_lr: 1.6124e-06 lr: 5.0388e-08  eta: 0:41:25  time: 0.8886  data_time: 0.0117  memory: 11652  grad_norm: 205.7409  loss: 0.5035  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5035\n",
            "02/09 16:46:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][300/332]  base_lr: 1.5702e-06 lr: 4.9070e-08  eta: 0:39:55  time: 0.8888  data_time: 0.0117  memory: 11652  grad_norm: 139.7871  loss: 0.3472  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3472\n",
            "02/09 16:47:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:47:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [47][332/332]  base_lr: 1.5570e-06 lr: 4.8657e-08  eta: 0:39:27  time: 0.8765  data_time: 0.0106  memory: 11652  grad_norm: 176.7818  loss: 0.5072  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5072\n",
            "02/09 16:47:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [47][42/42]    acc/top1: 0.7560  acc/top5: 1.0000  acc/mean1: 0.7475  data_time: 0.0228  time: 0.2488\n",
            "02/09 16:49:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][100/332]  base_lr: 1.5167e-06 lr: 4.7397e-08  eta: 0:37:58  time: 0.8877  data_time: 0.0114  memory: 11652  grad_norm: 179.9501  loss: 0.4331  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4331\n",
            "02/09 16:50:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][200/332]  base_lr: 1.4778e-06 lr: 4.6181e-08  eta: 0:36:29  time: 0.8875  data_time: 0.0117  memory: 11652  grad_norm: 216.0498  loss: 0.4207  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4207\n",
            "02/09 16:52:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][300/332]  base_lr: 1.4403e-06 lr: 4.5010e-08  eta: 0:34:59  time: 0.8886  data_time: 0.0111  memory: 11652  grad_norm: 192.1035  loss: 0.4813  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4813\n",
            "02/09 16:52:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:52:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [48][332/332]  base_lr: 1.4286e-06 lr: 4.4645e-08  eta: 0:34:31  time: 0.8774  data_time: 0.0111  memory: 11652  grad_norm: 185.4189  loss: 0.3843  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3843\n",
            "02/09 16:52:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 48 epochs\n",
            "02/09 16:52:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [48][42/42]    acc/top1: 0.7530  acc/top5: 1.0000  acc/mean1: 0.7443  data_time: 0.0242  time: 0.2498\n",
            "02/09 16:53:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:54:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][100/332]  base_lr: 1.3931e-06 lr: 4.3534e-08  eta: 0:33:02  time: 0.8858  data_time: 0.0117  memory: 11652  grad_norm: 180.6643  loss: 0.4144  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4144\n",
            "02/09 16:55:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][200/332]  base_lr: 1.3590e-06 lr: 4.2469e-08  eta: 0:31:33  time: 0.8880  data_time: 0.0112  memory: 11652  grad_norm: 197.6521  loss: 0.4392  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4392\n",
            "02/09 16:57:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][300/332]  base_lr: 1.3264e-06 lr: 4.1451e-08  eta: 0:30:03  time: 0.8890  data_time: 0.0116  memory: 11652  grad_norm: 166.8378  loss: 0.4204  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4204\n",
            "02/09 16:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 16:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [49][332/332]  base_lr: 1.3163e-06 lr: 4.1135e-08  eta: 0:29:35  time: 0.8760  data_time: 0.0109  memory: 11652  grad_norm: 189.7306  loss: 0.4804  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.4804\n",
            "02/09 16:57:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [49][42/42]    acc/top1: 0.7470  acc/top5: 1.0000  acc/mean1: 0.7407  data_time: 0.0236  time: 0.2492\n",
            "02/09 16:59:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][100/332]  base_lr: 1.2857e-06 lr: 4.0178e-08  eta: 0:28:06  time: 0.8888  data_time: 0.0118  memory: 11652  grad_norm: 204.2279  loss: 0.3776  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3776\n",
            "02/09 17:00:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][200/332]  base_lr: 1.2566e-06 lr: 3.9269e-08  eta: 0:26:37  time: 0.8877  data_time: 0.0114  memory: 11652  grad_norm: 211.3708  loss: 0.5289  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5289\n",
            "02/09 17:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][300/332]  base_lr: 1.2290e-06 lr: 3.8407e-08  eta: 0:25:08  time: 0.8866  data_time: 0.0114  memory: 11652  grad_norm: 208.2091  loss: 0.5001  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5001\n",
            "02/09 17:02:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 17:02:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [50][332/332]  base_lr: 1.2205e-06 lr: 3.8141e-08  eta: 0:24:39  time: 0.8787  data_time: 0.0109  memory: 11652  grad_norm: 187.1475  loss: 0.5068  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.5068\n",
            "02/09 17:03:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][42/42]    acc/top1: 0.7500  acc/top5: 1.0000  acc/mean1: 0.7411  data_time: 0.0271  time: 0.2530\n",
            "02/09 17:04:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [51][100/332]  base_lr: 1.1949e-06 lr: 3.7342e-08  eta: 0:23:10  time: 0.8873  data_time: 0.0116  memory: 11652  grad_norm: 175.6858  loss: 0.3643  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3643\n",
            "02/09 17:06:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [51][200/332]  base_lr: 1.1709e-06 lr: 3.6591e-08  eta: 0:21:41  time: 0.8880  data_time: 0.0118  memory: 11652  grad_norm: 211.7778  loss: 0.4482  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4482\n",
            "02/09 17:07:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [51][300/332]  base_lr: 1.1484e-06 lr: 3.5889e-08  eta: 0:20:12  time: 0.8886  data_time: 0.0116  memory: 11652  grad_norm: 205.9541  loss: 0.4166  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4166\n",
            "02/09 17:07:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 17:07:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [51][332/332]  base_lr: 1.1416e-06 lr: 3.5675e-08  eta: 0:19:43  time: 0.8780  data_time: 0.0114  memory: 11652  grad_norm: 180.7766  loss: 0.4131  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.4131\n",
            "02/09 17:07:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 51 epochs\n",
            "02/09 17:08:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [51][42/42]    acc/top1: 0.7470  acc/top5: 1.0000  acc/mean1: 0.7399  data_time: 0.0230  time: 0.2484\n",
            "02/09 17:09:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 17:09:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [52][100/332]  base_lr: 1.1212e-06 lr: 3.5037e-08  eta: 0:18:14  time: 0.8876  data_time: 0.0117  memory: 11652  grad_norm: 175.8223  loss: 0.4161  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4161\n",
            "02/09 17:11:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [52][200/332]  base_lr: 1.1023e-06 lr: 3.4448e-08  eta: 0:16:45  time: 0.8888  data_time: 0.0112  memory: 11652  grad_norm: 194.0235  loss: 0.3938  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3938\n",
            "02/09 17:12:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [52][300/332]  base_lr: 1.0851e-06 lr: 3.3908e-08  eta: 0:15:16  time: 0.8891  data_time: 0.0117  memory: 11652  grad_norm: 177.2660  loss: 0.4980  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4980\n",
            "02/09 17:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 17:13:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [52][332/332]  base_lr: 1.0799e-06 lr: 3.3746e-08  eta: 0:14:47  time: 0.8747  data_time: 0.0108  memory: 11652  grad_norm: 193.1456  loss: 0.4273  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4273\n",
            "02/09 17:13:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [52][42/42]    acc/top1: 0.7560  acc/top5: 1.0000  acc/mean1: 0.7511  data_time: 0.0247  time: 0.2503\n",
            "02/09 17:14:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [53][100/332]  base_lr: 1.0647e-06 lr: 3.3271e-08  eta: 0:13:18  time: 0.8867  data_time: 0.0111  memory: 11652  grad_norm: 182.2962  loss: 0.4029  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4029\n",
            "02/09 17:16:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [53][200/332]  base_lr: 1.0511e-06 lr: 3.2847e-08  eta: 0:11:49  time: 0.8872  data_time: 0.0116  memory: 11652  grad_norm: 214.0891  loss: 0.5372  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.5372\n",
            "02/09 17:17:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [53][300/332]  base_lr: 1.0391e-06 lr: 3.2472e-08  eta: 0:10:20  time: 0.8862  data_time: 0.0113  memory: 11652  grad_norm: 203.0740  loss: 0.3844  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3844\n",
            "02/09 17:18:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 17:18:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [53][332/332]  base_lr: 1.0356e-06 lr: 3.2362e-08  eta: 0:09:51  time: 0.8771  data_time: 0.0106  memory: 11652  grad_norm: 179.4255  loss: 0.4356  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.4356\n",
            "02/09 17:18:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [53][42/42]    acc/top1: 0.7530  acc/top5: 1.0000  acc/mean1: 0.7483  data_time: 0.0256  time: 0.2511\n",
            "02/09 17:19:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [54][100/332]  base_lr: 1.0257e-06 lr: 3.2053e-08  eta: 0:08:22  time: 0.8870  data_time: 0.0112  memory: 11652  grad_norm: 200.7396  loss: 0.5442  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5442\n",
            "02/09 17:21:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [54][200/332]  base_lr: 1.0174e-06 lr: 3.1794e-08  eta: 0:06:53  time: 0.8877  data_time: 0.0115  memory: 11652  grad_norm: 204.9333  loss: 0.5160  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5160\n",
            "02/09 17:22:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [54][300/332]  base_lr: 1.0107e-06 lr: 3.1585e-08  eta: 0:05:24  time: 0.8858  data_time: 0.0114  memory: 11652  grad_norm: 151.4934  loss: 0.4771  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4771\n",
            "02/09 17:23:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 17:23:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [54][332/332]  base_lr: 1.0089e-06 lr: 3.1529e-08  eta: 0:04:55  time: 0.8773  data_time: 0.0110  memory: 11652  grad_norm: 208.7927  loss: 0.4497  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.4497\n",
            "02/09 17:23:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 54 epochs\n",
            "02/09 17:23:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [54][42/42]    acc/top1: 0.7470  acc/top5: 1.0000  acc/mean1: 0.7383  data_time: 0.0236  time: 0.2491\n",
            "02/09 17:24:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 17:25:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [55][100/332]  base_lr: 1.0044e-06 lr: 3.1387e-08  eta: 0:03:26  time: 0.8874  data_time: 0.0118  memory: 11652  grad_norm: 143.9910  loss: 0.3981  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3981\n",
            "02/09 17:26:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [55][200/332]  base_lr: 1.0014e-06 lr: 3.1295e-08  eta: 0:01:57  time: 0.8884  data_time: 0.0119  memory: 11652  grad_norm: 191.1172  loss: 0.5166  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5166\n",
            "02/09 17:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [55][300/332]  base_lr: 1.0001e-06 lr: 3.1253e-08  eta: 0:00:28  time: 0.8842  data_time: 0.0111  memory: 11652  grad_norm: 188.7361  loss: 0.3749  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3749\n",
            "02/09 17:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb_20240209_124406\n",
            "02/09 17:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [55][332/332]  base_lr: 1.0000e-06 lr: 3.1250e-08  eta: 0:00:00  time: 0.8773  data_time: 0.0114  memory: 11652  grad_norm: 213.9618  loss: 0.4695  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4695\n",
            "02/09 17:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 55 epochs\n",
            "02/09 17:28:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [55][42/42]    acc/top1: 0.7620  acc/top5: 1.0000  acc/mean1: 0.7568  data_time: 0.0252  time: 0.2501\n",
            "02/09 17:28:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb/best_acc_top1_epoch_45.pth is removed\n",
            "02/09 17:28:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7620 acc/top1 at 55 epoch is saved to best_acc_top1_epoch_55.pth.\n"
          ]
        }
      ],
      "source": [
        "!python ./tools/train.py ./cuny/configs/uniformerv2/no_pretrain_uniformerv2-base-p16-res224_clip_8xb32-u8-rgb.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TsVCPys7dO1d"
      },
      "outputs": [],
      "source": [
        "!cp -r work_dirs /content/drive/MyDrive/cuny_dataset/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Ykj0I2v7v5ao"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}