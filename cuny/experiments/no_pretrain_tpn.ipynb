{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vfrantc/mmaction2/blob/main/cuny/experiments/no_pretrain_tpn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIT8tO-DStuc",
        "outputId": "06ccbd1e-e78a-4e8f-a798-b21ceb6dc806"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cvxpy 1.3.3 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.36 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.1/94.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.0/436.0 kB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n",
            "rm: cannot remove '/content/mmaction2/': No such file or directory\n",
            "Cloning into 'mmaction2'...\n",
            "remote: Enumerating objects: 22476, done.\u001b[K\n",
            "remote: Counting objects: 100% (390/390), done.\u001b[K\n",
            "remote: Compressing objects: 100% (195/195), done.\u001b[K\n",
            "remote: Total 22476 (delta 224), reused 340 (delta 189), pack-reused 22086\u001b[K\n",
            "Receiving objects: 100% (22476/22476), 65.55 MiB | 22.92 MiB/s, done.\n",
            "Resolving deltas: 100% (15768/15768), done.\n",
            "/content/mmaction2\n",
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Obtaining file:///content/mmaction2\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-weimeib6/mmaction2.egg-info\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-weimeib6/mmaction2.egg-info/SOURCES.txt'\n",
            "  warning: no files found matching 'mmaction/.mim/model-index.yml'\n",
            "  warning: no files found matching 'mmaction/.mim/dataset-index.yml'\n",
            "  warning: no files found matching '*.py' under directory 'mmaction/.mim/configs'\n",
            "  warning: no files found matching '*.yml' under directory 'mmaction/.mim/configs'\n",
            "  warning: no files found matching '*.sh' under directory 'mmaction/.mim/tools'\n",
            "  warning: no files found matching '*.py' under directory 'mmaction/.mim/tools'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-weimeib6/mmaction2.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting decord>=0.4.1 (from mmaction2==1.2.0)\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from mmaction2==1.2.0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmaction2==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->mmaction2==1.2.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->mmaction2==1.2.0) (1.3.0)\n",
            "Installing collected packages: einops, decord, mmaction2\n",
            "  Running setup.py develop for mmaction2\n",
            "    Running command python setup.py develop\n",
            "    running develop\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    running egg_info\n",
            "    creating mmaction2.egg-info\n",
            "    writing manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "Successfully installed decord-0.6.0 einops-0.7.0 mmaction2-1.2.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# INSTALL REQUIREMENTS AND MMACTION\n",
        "!pip install pytorchvideo --quiet\n",
        "!pip install timm --quiet\n",
        "!pip install -U openmim --quiet\n",
        "!mim install mmengine --quiet\n",
        "!mim install mmcv --quiet\n",
        "!mim install mmdet --quiet\n",
        "!mim install mmpose --quiet\n",
        "\n",
        "# INSTALL MMACTION, OUR CONFIGS ARE THERE AS WELL\n",
        "%cd /content/\n",
        "!rm -r /content/mmaction2/\n",
        "!git clone https://github.com/vfrantc/mmaction2.git\n",
        "%cd mmaction2\n",
        "!pip install -v -e .\n",
        "\n",
        "# COPY DATASET\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!cp /content/drive/MyDrive/cuny_dataset/cuny_dataset.zip .\n",
        "!unzip -qq cuny_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv content/mmaction2/data ."
      ],
      "metadata": {
        "id": "p-HNQ4rOzZf1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYI5XnUtioeV"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E-8hE5fOhTMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d8fabed-fef0-469e-b1ce-9d534e962879"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/09 15:32:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 740335828\n",
            "    GPU 0: Tesla V100-SXM2-16GB\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.1.0+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX512\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.0+cu121\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.3\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 740335828\n",
            "    diff_rank_seed: False\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "02/09 15:32:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "ann_file_test = 'data/kinetics400/kinetics400_val_list_videos.txt'\n",
            "ann_file_train = 'data/kinetics400/kinetics400_train_list_videos.txt'\n",
            "ann_file_val = 'data/kinetics400/kinetics400_val_list_videos.txt'\n",
            "data_root = 'data/kinetics400/videos_train'\n",
            "data_root_val = 'data/kinetics400/videos_val'\n",
            "dataset_type = 'VideoDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=1, max_keep_ckpts=5, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'),\n",
            "    timer=dict(type='IterTimerHook'))\n",
            "default_scope = 'mmaction'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "launcher = 'none'\n",
            "load_from = None\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        conv1_kernel=(\n",
            "            1,\n",
            "            7,\n",
            "            7,\n",
            "        ),\n",
            "        conv1_stride_t=1,\n",
            "        depth=50,\n",
            "        inflate=(\n",
            "            0,\n",
            "            0,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        lateral=False,\n",
            "        norm_eval=False,\n",
            "        out_indices=(\n",
            "            2,\n",
            "            3,\n",
            "        ),\n",
            "        pool1_stride_t=1,\n",
            "        pretrained='torchvision://resnet50',\n",
            "        type='ResNet3dSlowOnly'),\n",
            "    cls_head=dict(\n",
            "        average_clips='prob',\n",
            "        consensus=dict(dim=1, type='AvgConsensus'),\n",
            "        dropout_ratio=0.5,\n",
            "        in_channels=2048,\n",
            "        init_std=0.01,\n",
            "        num_classes=400,\n",
            "        spatial_type='avg',\n",
            "        type='TPNHead'),\n",
            "    data_preprocessor=dict(\n",
            "        format_shape='NCTHW',\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='ActionDataPreprocessor'),\n",
            "    neck=dict(\n",
            "        aux_head_cfg=dict(loss_weight=0.5, out_channels=400),\n",
            "        downsample_cfg=dict(downsample_scale=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        )),\n",
            "        in_channels=(\n",
            "            1024,\n",
            "            2048,\n",
            "        ),\n",
            "        level_fusion_cfg=dict(\n",
            "            downsample_scales=(\n",
            "                (\n",
            "                    1,\n",
            "                    1,\n",
            "                    1,\n",
            "                ),\n",
            "                (\n",
            "                    1,\n",
            "                    1,\n",
            "                    1,\n",
            "                ),\n",
            "            ),\n",
            "            in_channels=(\n",
            "                1024,\n",
            "                1024,\n",
            "            ),\n",
            "            mid_channels=(\n",
            "                1024,\n",
            "                1024,\n",
            "            ),\n",
            "            out_channels=2048),\n",
            "        out_channels=1024,\n",
            "        spatial_modulation_cfg=dict(\n",
            "            in_channels=(\n",
            "                1024,\n",
            "                2048,\n",
            "            ), out_channels=2048),\n",
            "        temporal_modulation_cfg=dict(downsample_scales=(\n",
            "            8,\n",
            "            8,\n",
            "        )),\n",
            "        type='TPN',\n",
            "        upsample_cfg=dict(scale_factor=(\n",
            "            1,\n",
            "            1,\n",
            "            1,\n",
            "        ))),\n",
            "    test_cfg=dict(fcn_test=True),\n",
            "    train_cfg=None,\n",
            "    type='Recognizer3D')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=dict(max_norm=40, norm_type=2),\n",
            "    optimizer=dict(\n",
            "        lr=0.01, momentum=0.9, nesterov=True, type='SGD', weight_decay=0.0001))\n",
            "param_scheduler = [\n",
            "    dict(\n",
            "        begin=0,\n",
            "        by_epoch=True,\n",
            "        end=150,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            75,\n",
            "            125,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "randomness = dict(deterministic=False, diff_rank_seed=False, seed=None)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='data/kinetics400/kinetics400_val_list_videos.txt',\n",
            "        data_prefix=dict(video='data/kinetics400/videos_val'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=8,\n",
            "                frame_interval=8,\n",
            "                num_clips=10,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=256, type='ThreeCrop'),\n",
            "            dict(input_format='NCTHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "test_pipeline = [\n",
            "    dict(type='DecordInit'),\n",
            "    dict(\n",
            "        clip_len=8,\n",
            "        frame_interval=8,\n",
            "        num_clips=10,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=256, type='ThreeCrop'),\n",
            "    dict(input_format='NCTHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "train_cfg = dict(\n",
            "    max_epochs=150, type='EpochBasedTrainLoop', val_begin=1, val_interval=10)\n",
            "train_dataloader = dict(\n",
            "    batch_size=8,\n",
            "    dataset=dict(\n",
            "        ann_file='data/kinetics400/kinetics400_train_list_videos.txt',\n",
            "        data_prefix=dict(video='data/kinetics400/videos_train'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=8, frame_interval=8, num_clips=1,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(type='RandomResizedCrop'),\n",
            "            dict(keep_ratio=False, scale=(\n",
            "                224,\n",
            "                224,\n",
            "            ), type='Resize'),\n",
            "            dict(flip_ratio=0.5, type='Flip'),\n",
            "            dict(type='ColorJitter'),\n",
            "            dict(input_format='NCTHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(type='DecordInit'),\n",
            "    dict(clip_len=8, frame_interval=8, num_clips=1, type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(type='RandomResizedCrop'),\n",
            "    dict(keep_ratio=False, scale=(\n",
            "        224,\n",
            "        224,\n",
            "    ), type='Resize'),\n",
            "    dict(flip_ratio=0.5, type='Flip'),\n",
            "    dict(type='ColorJitter'),\n",
            "    dict(input_format='NCTHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=8,\n",
            "    dataset=dict(\n",
            "        ann_file='data/kinetics400/kinetics400_val_list_videos.txt',\n",
            "        data_prefix=dict(video='data/kinetics400/videos_val'),\n",
            "        pipeline=[\n",
            "            dict(type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=8,\n",
            "                frame_interval=8,\n",
            "                num_clips=1,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='CenterCrop'),\n",
            "            dict(type='ColorJitter'),\n",
            "            dict(input_format='NCTHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "val_pipeline = [\n",
            "    dict(type='DecordInit'),\n",
            "    dict(\n",
            "        clip_len=8,\n",
            "        frame_interval=8,\n",
            "        num_clips=1,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='CenterCrop'),\n",
            "    dict(type='ColorJitter'),\n",
            "    dict(input_format='NCTHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb'\n",
            "\n",
            "02/09 15:32:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "02/09 15:32:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "02/09 15:32:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: torchvision://resnet50\n",
            "Loads checkpoint by torchvision backend from path: torchvision://resnet50\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n",
            "100% 97.8M/97.8M [00:00<00:00, 408MB/s]\n",
            "02/09 15:32:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - These parameters in the 2d checkpoint are not loaded: {'fc.weight', 'fc.bias'}\n",
            "02/09 15:32:54 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "02/09 15:32:54 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "02/09 15:32:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmaction2/work_dirs/no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb.\n",
            "02/09 15:33:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][ 20/332]  lr: 1.0000e-02  eta: 7:32:38  time: 0.5456  data_time: 0.0697  memory: 6613  grad_norm: 24.6125  loss: 2.0797  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.4373  loss_aux: 0.6423\n",
            "02/09 15:33:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][ 40/332]  lr: 1.0000e-02  eta: 6:30:35  time: 0.3964  data_time: 0.0107  memory: 6613  grad_norm: 22.4268  loss: 2.0813  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 1.5058  loss_aux: 0.5755\n",
            "02/09 15:33:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][ 60/332]  lr: 1.0000e-02  eta: 6:09:20  time: 0.3946  data_time: 0.0099  memory: 6613  grad_norm: 12.4286  loss: 1.6589  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.1483  loss_aux: 0.5105\n",
            "02/09 15:33:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][ 80/332]  lr: 1.0000e-02  eta: 5:58:35  time: 0.3944  data_time: 0.0101  memory: 6613  grad_norm: 7.9048  loss: 1.4419  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9697  loss_aux: 0.4722\n",
            "02/09 15:33:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][100/332]  lr: 1.0000e-02  eta: 5:52:02  time: 0.3941  data_time: 0.0096  memory: 6613  grad_norm: 6.1565  loss: 1.4404  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0537  loss_aux: 0.3868\n",
            "02/09 15:33:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][120/332]  lr: 1.0000e-02  eta: 5:47:44  time: 0.3948  data_time: 0.0102  memory: 6613  grad_norm: 6.6019  loss: 1.5609  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 1.1030  loss_aux: 0.4578\n",
            "02/09 15:33:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][140/332]  lr: 1.0000e-02  eta: 5:44:33  time: 0.3944  data_time: 0.0098  memory: 6613  grad_norm: 4.9189  loss: 1.2225  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8264  loss_aux: 0.3961\n",
            "02/09 15:34:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][160/332]  lr: 1.0000e-02  eta: 5:42:14  time: 0.3951  data_time: 0.0098  memory: 6613  grad_norm: 5.1227  loss: 1.3092  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.8707  loss_aux: 0.4385\n",
            "02/09 15:34:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][180/332]  lr: 1.0000e-02  eta: 5:40:21  time: 0.3948  data_time: 0.0098  memory: 6613  grad_norm: 4.5698  loss: 1.2450  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8445  loss_aux: 0.4005\n",
            "02/09 15:34:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][200/332]  lr: 1.0000e-02  eta: 5:38:52  time: 0.3953  data_time: 0.0101  memory: 6613  grad_norm: 4.8759  loss: 1.2749  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8779  loss_aux: 0.3970\n",
            "02/09 15:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][220/332]  lr: 1.0000e-02  eta: 5:37:34  time: 0.3945  data_time: 0.0100  memory: 6613  grad_norm: 4.2840  loss: 1.2838  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8458  loss_aux: 0.4380\n",
            "02/09 15:34:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][240/332]  lr: 1.0000e-02  eta: 5:36:30  time: 0.3948  data_time: 0.0097  memory: 6613  grad_norm: 4.2550  loss: 1.1844  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7603  loss_aux: 0.4241\n",
            "02/09 15:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][260/332]  lr: 1.0000e-02  eta: 5:35:40  time: 0.3964  data_time: 0.0106  memory: 6613  grad_norm: 4.5044  loss: 1.3035  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8053  loss_aux: 0.4982\n",
            "02/09 15:34:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][280/332]  lr: 1.0000e-02  eta: 5:34:51  time: 0.3951  data_time: 0.0099  memory: 6613  grad_norm: 4.4832  loss: 1.2159  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8074  loss_aux: 0.4085\n",
            "02/09 15:34:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][300/332]  lr: 1.0000e-02  eta: 5:34:10  time: 0.3958  data_time: 0.0104  memory: 6613  grad_norm: 4.0976  loss: 1.2547  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7884  loss_aux: 0.4663\n",
            "02/09 15:35:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][320/332]  lr: 1.0000e-02  eta: 5:33:32  time: 0.3952  data_time: 0.0098  memory: 6613  grad_norm: 4.1818  loss: 1.1988  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7728  loss_aux: 0.4260\n",
            "02/09 15:35:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:35:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][332/332]  lr: 1.0000e-02  eta: 5:33:00  time: 0.3919  data_time: 0.0095  memory: 6613  grad_norm: 4.6075  loss: 1.1651  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6899  loss_aux: 0.4752\n",
            "02/09 15:35:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 1 epochs\n",
            "02/09 15:35:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][ 20/332]  lr: 1.0000e-02  eta: 5:34:40  time: 0.4426  data_time: 0.0503  memory: 6613  grad_norm: 4.2279  loss: 1.2190  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7782  loss_aux: 0.4408\n",
            "02/09 15:35:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][ 40/332]  lr: 1.0000e-02  eta: 5:34:04  time: 0.3956  data_time: 0.0101  memory: 6613  grad_norm: 4.1961  loss: 1.2390  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7934  loss_aux: 0.4456\n",
            "02/09 15:35:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][ 60/332]  lr: 1.0000e-02  eta: 5:33:28  time: 0.3945  data_time: 0.0098  memory: 6613  grad_norm: 3.5530  loss: 1.1741  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7720  loss_aux: 0.4021\n",
            "02/09 15:35:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][ 80/332]  lr: 1.0000e-02  eta: 5:32:58  time: 0.3956  data_time: 0.0102  memory: 6613  grad_norm: 3.8233  loss: 1.2450  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7842  loss_aux: 0.4608\n",
            "02/09 15:35:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][100/332]  lr: 1.0000e-02  eta: 5:32:32  time: 0.3967  data_time: 0.0112  memory: 6613  grad_norm: 3.9747  loss: 1.2663  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8312  loss_aux: 0.4351\n",
            "02/09 15:35:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][120/332]  lr: 1.0000e-02  eta: 5:32:03  time: 0.3948  data_time: 0.0101  memory: 6613  grad_norm: 3.5489  loss: 1.2190  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7978  loss_aux: 0.4212\n",
            "02/09 15:36:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][140/332]  lr: 1.0000e-02  eta: 5:31:39  time: 0.3959  data_time: 0.0108  memory: 6613  grad_norm: 3.1929  loss: 1.1588  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7934  loss_aux: 0.3655\n",
            "02/09 15:36:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][160/332]  lr: 1.0000e-02  eta: 5:31:14  time: 0.3951  data_time: 0.0100  memory: 6613  grad_norm: 3.6253  loss: 1.2647  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8484  loss_aux: 0.4164\n",
            "02/09 15:36:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][180/332]  lr: 1.0000e-02  eta: 5:30:51  time: 0.3952  data_time: 0.0101  memory: 6613  grad_norm: 3.6008  loss: 1.1450  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7678  loss_aux: 0.3772\n",
            "02/09 15:36:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][200/332]  lr: 1.0000e-02  eta: 5:30:29  time: 0.3955  data_time: 0.0105  memory: 6613  grad_norm: 3.5220  loss: 1.1586  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7849  loss_aux: 0.3738\n",
            "02/09 15:36:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][220/332]  lr: 1.0000e-02  eta: 5:30:08  time: 0.3949  data_time: 0.0097  memory: 6613  grad_norm: 3.8184  loss: 1.2204  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8199  loss_aux: 0.4005\n",
            "02/09 15:36:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][240/332]  lr: 1.0000e-02  eta: 5:29:49  time: 0.3961  data_time: 0.0104  memory: 6613  grad_norm: 3.7322  loss: 1.2270  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8065  loss_aux: 0.4205\n",
            "02/09 15:36:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][260/332]  lr: 1.0000e-02  eta: 5:29:33  time: 0.3969  data_time: 0.0110  memory: 6613  grad_norm: 3.7963  loss: 1.0842  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6917  loss_aux: 0.3925\n",
            "02/09 15:37:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][280/332]  lr: 1.0000e-02  eta: 5:29:13  time: 0.3948  data_time: 0.0100  memory: 6613  grad_norm: 3.8710  loss: 1.1716  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7435  loss_aux: 0.4281\n",
            "02/09 15:37:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][300/332]  lr: 1.0000e-02  eta: 5:28:55  time: 0.3954  data_time: 0.0101  memory: 6613  grad_norm: 4.1027  loss: 1.3064  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.8750  loss_aux: 0.4314\n",
            "02/09 15:37:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][320/332]  lr: 1.0000e-02  eta: 5:28:39  time: 0.3958  data_time: 0.0106  memory: 6613  grad_norm: 3.3421  loss: 1.1851  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7557  loss_aux: 0.4294\n",
            "02/09 15:37:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:37:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][332/332]  lr: 1.0000e-02  eta: 5:28:20  time: 0.3895  data_time: 0.0095  memory: 6613  grad_norm: 3.3557  loss: 1.1930  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7843  loss_aux: 0.4087\n",
            "02/09 15:37:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 2 epochs\n",
            "02/09 15:37:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][ 20/332]  lr: 1.0000e-02  eta: 5:29:00  time: 0.4340  data_time: 0.0463  memory: 6613  grad_norm: 3.1463  loss: 1.1054  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7275  loss_aux: 0.3779\n",
            "02/09 15:37:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][ 40/332]  lr: 1.0000e-02  eta: 5:28:43  time: 0.3956  data_time: 0.0102  memory: 6613  grad_norm: 3.1423  loss: 1.1339  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7494  loss_aux: 0.3845\n",
            "02/09 15:37:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][ 60/332]  lr: 1.0000e-02  eta: 5:28:25  time: 0.3946  data_time: 0.0096  memory: 6613  grad_norm: 4.0729  loss: 1.2456  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8049  loss_aux: 0.4407\n",
            "02/09 15:37:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][ 80/332]  lr: 1.0000e-02  eta: 5:28:10  time: 0.3962  data_time: 0.0105  memory: 6613  grad_norm: 3.5370  loss: 1.2079  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7943  loss_aux: 0.4136\n",
            "02/09 15:38:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][100/332]  lr: 1.0000e-02  eta: 5:27:54  time: 0.3950  data_time: 0.0100  memory: 6613  grad_norm: 2.9394  loss: 1.1970  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8344  loss_aux: 0.3626\n",
            "02/09 15:38:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][120/332]  lr: 1.0000e-02  eta: 5:27:39  time: 0.3955  data_time: 0.0104  memory: 6613  grad_norm: 3.0659  loss: 1.1710  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7612  loss_aux: 0.4097\n",
            "02/09 15:38:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][140/332]  lr: 1.0000e-02  eta: 5:27:23  time: 0.3951  data_time: 0.0101  memory: 6613  grad_norm: 3.4548  loss: 1.1242  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7420  loss_aux: 0.3822\n",
            "02/09 15:38:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][160/332]  lr: 1.0000e-02  eta: 5:27:09  time: 0.3956  data_time: 0.0103  memory: 6613  grad_norm: 4.0494  loss: 1.1822  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8114  loss_aux: 0.3708\n",
            "02/09 15:38:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][180/332]  lr: 1.0000e-02  eta: 5:26:55  time: 0.3958  data_time: 0.0104  memory: 6613  grad_norm: 3.8325  loss: 1.1694  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8026  loss_aux: 0.3668\n",
            "02/09 15:38:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][200/332]  lr: 1.0000e-02  eta: 5:26:42  time: 0.3963  data_time: 0.0106  memory: 6613  grad_norm: 3.5154  loss: 1.2776  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8174  loss_aux: 0.4601\n",
            "02/09 15:38:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][220/332]  lr: 1.0000e-02  eta: 5:26:26  time: 0.3935  data_time: 0.0093  memory: 6613  grad_norm: 2.9441  loss: 1.2032  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7903  loss_aux: 0.4130\n",
            "02/09 15:39:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][240/332]  lr: 1.0000e-02  eta: 5:26:13  time: 0.3956  data_time: 0.0104  memory: 6613  grad_norm: 3.0211  loss: 1.2119  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7948  loss_aux: 0.4171\n",
            "02/09 15:39:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][260/332]  lr: 1.0000e-02  eta: 5:26:01  time: 0.3961  data_time: 0.0107  memory: 6613  grad_norm: 3.3172  loss: 1.2387  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8501  loss_aux: 0.3885\n",
            "02/09 15:39:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][280/332]  lr: 1.0000e-02  eta: 5:25:47  time: 0.3946  data_time: 0.0098  memory: 6613  grad_norm: 3.2181  loss: 1.1339  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7544  loss_aux: 0.3795\n",
            "02/09 15:39:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][300/332]  lr: 1.0000e-02  eta: 5:25:34  time: 0.3950  data_time: 0.0100  memory: 6613  grad_norm: 3.1730  loss: 1.2394  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.8674  loss_aux: 0.3720\n",
            "02/09 15:39:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][320/332]  lr: 1.0000e-02  eta: 5:25:21  time: 0.3948  data_time: 0.0098  memory: 6613  grad_norm: 3.0322  loss: 1.1680  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8021  loss_aux: 0.3659\n",
            "02/09 15:39:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:39:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][332/332]  lr: 1.0000e-02  eta: 5:25:08  time: 0.3903  data_time: 0.0097  memory: 6613  grad_norm: 3.3854  loss: 1.1884  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8154  loss_aux: 0.3731\n",
            "02/09 15:39:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 3 epochs\n",
            "02/09 15:39:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:39:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][ 20/332]  lr: 1.0000e-02  eta: 5:25:49  time: 0.4502  data_time: 0.0623  memory: 6613  grad_norm: 3.2047  loss: 1.1006  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7278  loss_aux: 0.3728\n",
            "02/09 15:39:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][ 40/332]  lr: 1.0000e-02  eta: 5:25:36  time: 0.3957  data_time: 0.0103  memory: 6613  grad_norm: 2.9713  loss: 1.1217  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7412  loss_aux: 0.3806\n",
            "02/09 15:40:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][ 60/332]  lr: 1.0000e-02  eta: 5:25:23  time: 0.3957  data_time: 0.0107  memory: 6613  grad_norm: 2.9007  loss: 1.0804  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6948  loss_aux: 0.3856\n",
            "02/09 15:40:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][ 80/332]  lr: 1.0000e-02  eta: 5:25:10  time: 0.3950  data_time: 0.0099  memory: 6613  grad_norm: 3.5548  loss: 1.1284  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7636  loss_aux: 0.3648\n",
            "02/09 15:40:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][100/332]  lr: 1.0000e-02  eta: 5:24:58  time: 0.3949  data_time: 0.0099  memory: 6613  grad_norm: 3.0132  loss: 1.1099  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7362  loss_aux: 0.3737\n",
            "02/09 15:40:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][120/332]  lr: 1.0000e-02  eta: 5:24:45  time: 0.3952  data_time: 0.0098  memory: 6613  grad_norm: 3.3822  loss: 1.0433  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6951  loss_aux: 0.3482\n",
            "02/09 15:40:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][140/332]  lr: 1.0000e-02  eta: 5:24:33  time: 0.3959  data_time: 0.0100  memory: 6613  grad_norm: 3.7423  loss: 1.1272  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7413  loss_aux: 0.3860\n",
            "02/09 15:40:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][160/332]  lr: 1.0000e-02  eta: 5:24:21  time: 0.3947  data_time: 0.0097  memory: 6613  grad_norm: 4.2244  loss: 1.1891  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8168  loss_aux: 0.3724\n",
            "02/09 15:40:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][180/332]  lr: 1.0000e-02  eta: 5:24:09  time: 0.3958  data_time: 0.0103  memory: 6613  grad_norm: 3.9205  loss: 1.1651  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.8021  loss_aux: 0.3630\n",
            "02/09 15:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][200/332]  lr: 1.0000e-02  eta: 5:23:58  time: 0.3955  data_time: 0.0104  memory: 6613  grad_norm: 2.9207  loss: 1.0892  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7144  loss_aux: 0.3748\n",
            "02/09 15:41:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][220/332]  lr: 1.0000e-02  eta: 5:23:45  time: 0.3948  data_time: 0.0096  memory: 6613  grad_norm: 3.4175  loss: 1.1673  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8051  loss_aux: 0.3623\n",
            "02/09 15:41:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][240/332]  lr: 1.0000e-02  eta: 5:23:34  time: 0.3955  data_time: 0.0099  memory: 6613  grad_norm: 3.2977  loss: 1.1422  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7423  loss_aux: 0.3999\n",
            "02/09 15:41:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][260/332]  lr: 1.0000e-02  eta: 5:23:22  time: 0.3949  data_time: 0.0100  memory: 6613  grad_norm: 3.0946  loss: 1.0705  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7270  loss_aux: 0.3435\n",
            "02/09 15:41:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][280/332]  lr: 1.0000e-02  eta: 5:23:11  time: 0.3954  data_time: 0.0105  memory: 6613  grad_norm: 3.3351  loss: 1.1598  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7441  loss_aux: 0.4157\n",
            "02/09 15:41:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][300/332]  lr: 1.0000e-02  eta: 5:22:59  time: 0.3948  data_time: 0.0098  memory: 6613  grad_norm: 3.5165  loss: 1.0394  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6840  loss_aux: 0.3554\n",
            "02/09 15:41:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][320/332]  lr: 1.0000e-02  eta: 5:22:48  time: 0.3953  data_time: 0.0101  memory: 6613  grad_norm: 3.5215  loss: 1.0963  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7268  loss_aux: 0.3695\n",
            "02/09 15:41:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:41:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][332/332]  lr: 1.0000e-02  eta: 5:22:38  time: 0.3911  data_time: 0.0103  memory: 6613  grad_norm: 3.5544  loss: 1.0570  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6961  loss_aux: 0.3610\n",
            "02/09 15:41:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
            "02/09 15:42:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][ 20/332]  lr: 1.0000e-02  eta: 5:23:07  time: 0.4508  data_time: 0.0627  memory: 6613  grad_norm: 5.5318  loss: 1.2164  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8274  loss_aux: 0.3890\n",
            "02/09 15:42:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][ 40/332]  lr: 1.0000e-02  eta: 5:22:56  time: 0.3956  data_time: 0.0101  memory: 6613  grad_norm: 5.2993  loss: 1.1402  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7581  loss_aux: 0.3822\n",
            "02/09 15:42:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][ 60/332]  lr: 1.0000e-02  eta: 5:22:44  time: 0.3944  data_time: 0.0094  memory: 6613  grad_norm: 4.5359  loss: 1.0970  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7536  loss_aux: 0.3434\n",
            "02/09 15:42:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][ 80/332]  lr: 1.0000e-02  eta: 5:22:33  time: 0.3955  data_time: 0.0104  memory: 6613  grad_norm: 4.4988  loss: 1.1106  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7237  loss_aux: 0.3869\n",
            "02/09 15:42:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][100/332]  lr: 1.0000e-02  eta: 5:22:22  time: 0.3955  data_time: 0.0103  memory: 6613  grad_norm: 4.0050  loss: 1.1264  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7426  loss_aux: 0.3838\n",
            "02/09 15:42:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][120/332]  lr: 1.0000e-02  eta: 5:22:10  time: 0.3948  data_time: 0.0099  memory: 6613  grad_norm: 3.8774  loss: 1.1526  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7805  loss_aux: 0.3721\n",
            "02/09 15:42:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][140/332]  lr: 1.0000e-02  eta: 5:22:00  time: 0.3957  data_time: 0.0106  memory: 6613  grad_norm: 3.7157  loss: 1.0959  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7036  loss_aux: 0.3924\n",
            "02/09 15:42:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][160/332]  lr: 1.0000e-02  eta: 5:21:48  time: 0.3943  data_time: 0.0095  memory: 6613  grad_norm: 3.7414  loss: 1.1429  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7630  loss_aux: 0.3799\n",
            "02/09 15:43:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][180/332]  lr: 1.0000e-02  eta: 5:21:37  time: 0.3953  data_time: 0.0104  memory: 6613  grad_norm: 3.5446  loss: 1.1094  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7269  loss_aux: 0.3824\n",
            "02/09 15:43:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][200/332]  lr: 1.0000e-02  eta: 5:21:27  time: 0.3955  data_time: 0.0105  memory: 6613  grad_norm: 4.0305  loss: 1.2329  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8354  loss_aux: 0.3975\n",
            "02/09 15:43:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][220/332]  lr: 1.0000e-02  eta: 5:21:16  time: 0.3952  data_time: 0.0101  memory: 6613  grad_norm: 3.9588  loss: 1.3064  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.9173  loss_aux: 0.3891\n",
            "02/09 15:43:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][240/332]  lr: 1.0000e-02  eta: 5:21:06  time: 0.3960  data_time: 0.0108  memory: 6613  grad_norm: 4.4686  loss: 1.2859  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8600  loss_aux: 0.4259\n",
            "02/09 15:43:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][260/332]  lr: 1.0000e-02  eta: 5:20:55  time: 0.3952  data_time: 0.0104  memory: 6613  grad_norm: 4.6674  loss: 1.2381  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8653  loss_aux: 0.3728\n",
            "02/09 15:43:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][280/332]  lr: 1.0000e-02  eta: 5:20:45  time: 0.3951  data_time: 0.0105  memory: 6613  grad_norm: 3.4161  loss: 1.1826  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8012  loss_aux: 0.3813\n",
            "02/09 15:43:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][300/332]  lr: 1.0000e-02  eta: 5:20:34  time: 0.3950  data_time: 0.0101  memory: 6613  grad_norm: 3.1140  loss: 1.1311  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7598  loss_aux: 0.3713\n",
            "02/09 15:44:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][320/332]  lr: 1.0000e-02  eta: 5:20:24  time: 0.3950  data_time: 0.0102  memory: 6613  grad_norm: 3.3532  loss: 1.0775  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7104  loss_aux: 0.3671\n",
            "02/09 15:44:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:44:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][332/332]  lr: 1.0000e-02  eta: 5:20:14  time: 0.3898  data_time: 0.0096  memory: 6613  grad_norm: 3.4345  loss: 1.0712  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7243  loss_aux: 0.3469\n",
            "02/09 15:44:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 5 epochs\n",
            "02/09 15:44:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][ 20/332]  lr: 1.0000e-02  eta: 5:20:31  time: 0.4426  data_time: 0.0536  memory: 6613  grad_norm: 3.1600  loss: 1.0889  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7156  loss_aux: 0.3733\n",
            "02/09 15:44:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][ 40/332]  lr: 1.0000e-02  eta: 5:20:20  time: 0.3942  data_time: 0.0096  memory: 6613  grad_norm: 3.3650  loss: 1.1648  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7785  loss_aux: 0.3863\n",
            "02/09 15:44:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][ 60/332]  lr: 1.0000e-02  eta: 5:20:09  time: 0.3938  data_time: 0.0097  memory: 6613  grad_norm: 3.7276  loss: 1.2131  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8155  loss_aux: 0.3977\n",
            "02/09 15:44:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][ 80/332]  lr: 1.0000e-02  eta: 5:19:58  time: 0.3946  data_time: 0.0104  memory: 6613  grad_norm: 4.0837  loss: 1.3116  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8612  loss_aux: 0.4504\n",
            "02/09 15:44:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][100/332]  lr: 1.0000e-02  eta: 5:19:48  time: 0.3944  data_time: 0.0100  memory: 6613  grad_norm: 3.8852  loss: 1.1239  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7481  loss_aux: 0.3758\n",
            "02/09 15:44:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][120/332]  lr: 1.0000e-02  eta: 5:19:37  time: 0.3954  data_time: 0.0104  memory: 6613  grad_norm: 6.1752  loss: 1.3196  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9025  loss_aux: 0.4171\n",
            "02/09 15:45:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][140/332]  lr: 1.0000e-02  eta: 5:19:27  time: 0.3950  data_time: 0.0102  memory: 6613  grad_norm: 4.1581  loss: 1.2233  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8408  loss_aux: 0.3826\n",
            "02/09 15:45:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][160/332]  lr: 1.0000e-02  eta: 5:19:16  time: 0.3939  data_time: 0.0095  memory: 6613  grad_norm: 3.9838  loss: 1.0982  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7432  loss_aux: 0.3550\n",
            "02/09 15:45:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][180/332]  lr: 1.0000e-02  eta: 5:19:06  time: 0.3950  data_time: 0.0104  memory: 6613  grad_norm: 4.2465  loss: 1.1981  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8192  loss_aux: 0.3789\n",
            "02/09 15:45:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][200/332]  lr: 1.0000e-02  eta: 5:18:56  time: 0.3947  data_time: 0.0096  memory: 6613  grad_norm: 5.7680  loss: 1.1163  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7669  loss_aux: 0.3494\n",
            "02/09 15:45:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][220/332]  lr: 1.0000e-02  eta: 5:18:45  time: 0.3937  data_time: 0.0090  memory: 6613  grad_norm: 6.5680  loss: 1.2641  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8751  loss_aux: 0.3890\n",
            "02/09 15:45:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][240/332]  lr: 1.0000e-02  eta: 5:18:35  time: 0.3954  data_time: 0.0104  memory: 6613  grad_norm: 7.3348  loss: 1.1767  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7510  loss_aux: 0.4257\n",
            "02/09 15:45:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][260/332]  lr: 1.0000e-02  eta: 5:18:25  time: 0.3952  data_time: 0.0099  memory: 6613  grad_norm: 5.7927  loss: 1.2604  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8220  loss_aux: 0.4384\n",
            "02/09 15:46:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][280/332]  lr: 1.0000e-02  eta: 5:18:15  time: 0.3943  data_time: 0.0095  memory: 6613  grad_norm: 5.3032  loss: 1.2024  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8006  loss_aux: 0.4018\n",
            "02/09 15:46:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][300/332]  lr: 1.0000e-02  eta: 5:18:05  time: 0.3952  data_time: 0.0103  memory: 6613  grad_norm: 4.0401  loss: 1.1316  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7010  loss_aux: 0.4306\n",
            "02/09 15:46:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][320/332]  lr: 1.0000e-02  eta: 5:17:55  time: 0.3951  data_time: 0.0104  memory: 6613  grad_norm: 5.3226  loss: 1.2094  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7998  loss_aux: 0.4096\n",
            "02/09 15:46:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:46:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][332/332]  lr: 1.0000e-02  eta: 5:17:47  time: 0.3895  data_time: 0.0099  memory: 6613  grad_norm: 3.8319  loss: 1.2410  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8649  loss_aux: 0.3761\n",
            "02/09 15:46:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 6 epochs\n",
            "02/09 15:46:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:46:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][ 20/332]  lr: 1.0000e-02  eta: 5:17:54  time: 0.4319  data_time: 0.0442  memory: 6613  grad_norm: 3.6628  loss: 1.1656  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7836  loss_aux: 0.3820\n",
            "02/09 15:46:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][ 40/332]  lr: 1.0000e-02  eta: 5:17:45  time: 0.3953  data_time: 0.0106  memory: 6613  grad_norm: 4.1379  loss: 1.1791  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7808  loss_aux: 0.3983\n",
            "02/09 15:46:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][ 60/332]  lr: 1.0000e-02  eta: 5:17:36  time: 0.3981  data_time: 0.0126  memory: 6613  grad_norm: 3.9850  loss: 1.1829  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7786  loss_aux: 0.4044\n",
            "02/09 15:46:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][ 80/332]  lr: 1.0000e-02  eta: 5:17:27  time: 0.3958  data_time: 0.0106  memory: 6613  grad_norm: 3.6518  loss: 1.1098  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7487  loss_aux: 0.3610\n",
            "02/09 15:47:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][100/332]  lr: 1.0000e-02  eta: 5:17:17  time: 0.3947  data_time: 0.0102  memory: 6613  grad_norm: 3.3087  loss: 1.0896  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7005  loss_aux: 0.3890\n",
            "02/09 15:47:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][120/332]  lr: 1.0000e-02  eta: 5:17:06  time: 0.3942  data_time: 0.0100  memory: 6613  grad_norm: 3.4180  loss: 1.2357  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7928  loss_aux: 0.4429\n",
            "02/09 15:47:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][140/332]  lr: 1.0000e-02  eta: 5:16:56  time: 0.3941  data_time: 0.0100  memory: 6613  grad_norm: 3.0281  loss: 1.1416  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7535  loss_aux: 0.3881\n",
            "02/09 15:47:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][160/332]  lr: 1.0000e-02  eta: 5:16:46  time: 0.3937  data_time: 0.0098  memory: 6613  grad_norm: 3.0223  loss: 1.1737  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8000  loss_aux: 0.3737\n",
            "02/09 15:47:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][180/332]  lr: 1.0000e-02  eta: 5:16:36  time: 0.3940  data_time: 0.0099  memory: 6613  grad_norm: 2.9399  loss: 1.1136  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7485  loss_aux: 0.3651\n",
            "02/09 15:47:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][200/332]  lr: 1.0000e-02  eta: 5:16:26  time: 0.3952  data_time: 0.0103  memory: 6613  grad_norm: 3.1156  loss: 1.1491  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7939  loss_aux: 0.3552\n",
            "02/09 15:47:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][220/332]  lr: 1.0000e-02  eta: 5:16:16  time: 0.3944  data_time: 0.0099  memory: 6613  grad_norm: 3.3667  loss: 1.2181  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8410  loss_aux: 0.3771\n",
            "02/09 15:47:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][240/332]  lr: 1.0000e-02  eta: 5:16:07  time: 0.3946  data_time: 0.0100  memory: 6613  grad_norm: 3.1183  loss: 1.1192  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7725  loss_aux: 0.3468\n",
            "02/09 15:48:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][260/332]  lr: 1.0000e-02  eta: 5:15:57  time: 0.3949  data_time: 0.0101  memory: 6613  grad_norm: 2.9245  loss: 1.0407  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6661  loss_aux: 0.3745\n",
            "02/09 15:48:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][280/332]  lr: 1.0000e-02  eta: 5:15:47  time: 0.3935  data_time: 0.0095  memory: 6613  grad_norm: 4.1884  loss: 1.2199  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8063  loss_aux: 0.4136\n",
            "02/09 15:48:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][300/332]  lr: 1.0000e-02  eta: 5:15:37  time: 0.3937  data_time: 0.0097  memory: 6613  grad_norm: 4.1884  loss: 1.1463  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7619  loss_aux: 0.3843\n",
            "02/09 15:48:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][320/332]  lr: 1.0000e-02  eta: 5:15:27  time: 0.3943  data_time: 0.0098  memory: 6613  grad_norm: 3.9030  loss: 1.2434  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8407  loss_aux: 0.4027\n",
            "02/09 15:48:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:48:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][332/332]  lr: 1.0000e-02  eta: 5:15:19  time: 0.3894  data_time: 0.0099  memory: 6613  grad_norm: 4.1694  loss: 1.1846  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.7740  loss_aux: 0.4107\n",
            "02/09 15:48:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 7 epochs\n",
            "02/09 15:48:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][ 20/332]  lr: 1.0000e-02  eta: 5:15:29  time: 0.4423  data_time: 0.0544  memory: 6613  grad_norm: 3.5792  loss: 1.1944  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8035  loss_aux: 0.3909\n",
            "02/09 15:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][ 40/332]  lr: 1.0000e-02  eta: 5:15:19  time: 0.3944  data_time: 0.0101  memory: 6613  grad_norm: 3.2221  loss: 1.1174  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7723  loss_aux: 0.3451\n",
            "02/09 15:49:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][ 60/332]  lr: 1.0000e-02  eta: 5:15:09  time: 0.3941  data_time: 0.0100  memory: 6613  grad_norm: 2.6641  loss: 1.0573  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7032  loss_aux: 0.3541\n",
            "02/09 15:49:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][ 80/332]  lr: 1.0000e-02  eta: 5:14:59  time: 0.3938  data_time: 0.0093  memory: 6613  grad_norm: 3.3572  loss: 1.1733  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7949  loss_aux: 0.3784\n",
            "02/09 15:49:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][100/332]  lr: 1.0000e-02  eta: 5:14:49  time: 0.3932  data_time: 0.0097  memory: 6613  grad_norm: 2.8127  loss: 1.1053  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7295  loss_aux: 0.3757\n",
            "02/09 15:49:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][120/332]  lr: 1.0000e-02  eta: 5:14:39  time: 0.3932  data_time: 0.0096  memory: 6613  grad_norm: 3.5027  loss: 1.1838  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7827  loss_aux: 0.4010\n",
            "02/09 15:49:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][140/332]  lr: 1.0000e-02  eta: 5:14:29  time: 0.3941  data_time: 0.0100  memory: 6613  grad_norm: 3.4331  loss: 1.1414  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7736  loss_aux: 0.3678\n",
            "02/09 15:49:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][160/332]  lr: 1.0000e-02  eta: 5:14:19  time: 0.3932  data_time: 0.0095  memory: 6613  grad_norm: 3.1601  loss: 1.1504  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7803  loss_aux: 0.3702\n",
            "02/09 15:49:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][180/332]  lr: 1.0000e-02  eta: 5:14:10  time: 0.3941  data_time: 0.0100  memory: 6613  grad_norm: 3.0956  loss: 1.1808  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7843  loss_aux: 0.3965\n",
            "02/09 15:49:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][200/332]  lr: 1.0000e-02  eta: 5:14:00  time: 0.3946  data_time: 0.0102  memory: 6613  grad_norm: 3.1272  loss: 1.1544  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7228  loss_aux: 0.4316\n",
            "02/09 15:50:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][220/332]  lr: 1.0000e-02  eta: 5:13:50  time: 0.3934  data_time: 0.0095  memory: 6613  grad_norm: 2.2881  loss: 1.0020  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6639  loss_aux: 0.3381\n",
            "02/09 15:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][240/332]  lr: 1.0000e-02  eta: 5:13:41  time: 0.3944  data_time: 0.0103  memory: 6613  grad_norm: 3.0439  loss: 1.2433  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8476  loss_aux: 0.3957\n",
            "02/09 15:50:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][260/332]  lr: 1.0000e-02  eta: 5:13:31  time: 0.3944  data_time: 0.0103  memory: 6613  grad_norm: 2.6823  loss: 1.0901  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7282  loss_aux: 0.3619\n",
            "02/09 15:50:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][280/332]  lr: 1.0000e-02  eta: 5:13:22  time: 0.3936  data_time: 0.0096  memory: 6613  grad_norm: 2.9544  loss: 1.1713  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7882  loss_aux: 0.3832\n",
            "02/09 15:50:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][300/332]  lr: 1.0000e-02  eta: 5:13:12  time: 0.3943  data_time: 0.0099  memory: 6613  grad_norm: 2.9427  loss: 1.1573  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7726  loss_aux: 0.3847\n",
            "02/09 15:50:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][320/332]  lr: 1.0000e-02  eta: 5:13:03  time: 0.3941  data_time: 0.0099  memory: 6613  grad_norm: 2.6788  loss: 1.1585  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7739  loss_aux: 0.3847\n",
            "02/09 15:50:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:50:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][332/332]  lr: 1.0000e-02  eta: 5:12:55  time: 0.3895  data_time: 0.0098  memory: 6613  grad_norm: 3.1692  loss: 1.1029  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.7316  loss_aux: 0.3712\n",
            "02/09 15:50:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 8 epochs\n",
            "02/09 15:50:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][ 20/332]  lr: 1.0000e-02  eta: 5:13:00  time: 0.4334  data_time: 0.0452  memory: 6613  grad_norm: 3.1994  loss: 1.1905  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8086  loss_aux: 0.3819\n",
            "02/09 15:51:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][ 40/332]  lr: 1.0000e-02  eta: 5:12:50  time: 0.3939  data_time: 0.0097  memory: 6613  grad_norm: 3.0106  loss: 1.1053  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7498  loss_aux: 0.3555\n",
            "02/09 15:51:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][ 60/332]  lr: 1.0000e-02  eta: 5:12:41  time: 0.3947  data_time: 0.0108  memory: 6613  grad_norm: 2.6943  loss: 1.1963  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8226  loss_aux: 0.3737\n",
            "02/09 15:51:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][ 80/332]  lr: 1.0000e-02  eta: 5:12:31  time: 0.3942  data_time: 0.0104  memory: 6613  grad_norm: 3.0330  loss: 1.1852  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7963  loss_aux: 0.3889\n",
            "02/09 15:51:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][100/332]  lr: 1.0000e-02  eta: 5:12:22  time: 0.3939  data_time: 0.0098  memory: 6613  grad_norm: 2.9400  loss: 1.1116  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7307  loss_aux: 0.3809\n",
            "02/09 15:51:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][120/332]  lr: 1.0000e-02  eta: 5:12:13  time: 0.3945  data_time: 0.0102  memory: 6613  grad_norm: 3.3007  loss: 1.0946  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7488  loss_aux: 0.3458\n",
            "02/09 15:51:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][140/332]  lr: 1.0000e-02  eta: 5:12:03  time: 0.3944  data_time: 0.0102  memory: 6613  grad_norm: 3.1531  loss: 1.1277  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7622  loss_aux: 0.3655\n",
            "02/09 15:51:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][160/332]  lr: 1.0000e-02  eta: 5:11:54  time: 0.3940  data_time: 0.0098  memory: 6613  grad_norm: 2.8878  loss: 1.1112  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7384  loss_aux: 0.3728\n",
            "02/09 15:52:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][180/332]  lr: 1.0000e-02  eta: 5:11:45  time: 0.3944  data_time: 0.0103  memory: 6613  grad_norm: 2.6371  loss: 1.0785  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7056  loss_aux: 0.3729\n",
            "02/09 15:52:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][200/332]  lr: 1.0000e-02  eta: 5:11:36  time: 0.3956  data_time: 0.0108  memory: 6613  grad_norm: 4.0144  loss: 1.0486  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7050  loss_aux: 0.3436\n",
            "02/09 15:52:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][220/332]  lr: 1.0000e-02  eta: 5:11:26  time: 0.3938  data_time: 0.0093  memory: 6613  grad_norm: 4.4920  loss: 1.1264  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8034  loss_aux: 0.3229\n",
            "02/09 15:52:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][240/332]  lr: 1.0000e-02  eta: 5:11:17  time: 0.3941  data_time: 0.0097  memory: 6613  grad_norm: 3.1342  loss: 1.0646  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7354  loss_aux: 0.3292\n",
            "02/09 15:52:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][260/332]  lr: 1.0000e-02  eta: 5:11:09  time: 0.3962  data_time: 0.0111  memory: 6613  grad_norm: 3.1698  loss: 1.0029  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6945  loss_aux: 0.3083\n",
            "02/09 15:52:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][280/332]  lr: 1.0000e-02  eta: 5:10:59  time: 0.3939  data_time: 0.0095  memory: 6613  grad_norm: 4.6200  loss: 1.3063  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8858  loss_aux: 0.4205\n",
            "02/09 15:52:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][300/332]  lr: 1.0000e-02  eta: 5:10:50  time: 0.3946  data_time: 0.0101  memory: 6613  grad_norm: 3.2808  loss: 1.2354  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8164  loss_aux: 0.4190\n",
            "02/09 15:52:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][320/332]  lr: 1.0000e-02  eta: 5:10:41  time: 0.3947  data_time: 0.0104  memory: 6613  grad_norm: 4.2166  loss: 1.1578  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7755  loss_aux: 0.3823\n",
            "02/09 15:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][332/332]  lr: 1.0000e-02  eta: 5:10:34  time: 0.3892  data_time: 0.0096  memory: 6613  grad_norm: 5.3161  loss: 1.1954  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.8232  loss_aux: 0.3722\n",
            "02/09 15:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 9 epochs\n",
            "02/09 15:53:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:53:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][ 20/332]  lr: 1.0000e-02  eta: 5:10:39  time: 0.4396  data_time: 0.0523  memory: 6613  grad_norm: 4.1013  loss: 1.1048  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7112  loss_aux: 0.3936\n",
            "02/09 15:53:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][ 40/332]  lr: 1.0000e-02  eta: 5:10:30  time: 0.3950  data_time: 0.0102  memory: 6613  grad_norm: 3.0045  loss: 1.0979  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7272  loss_aux: 0.3707\n",
            "02/09 15:53:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][ 60/332]  lr: 1.0000e-02  eta: 5:10:21  time: 0.3946  data_time: 0.0097  memory: 6613  grad_norm: 4.0902  loss: 1.2198  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.8330  loss_aux: 0.3867\n",
            "02/09 15:53:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][ 80/332]  lr: 1.0000e-02  eta: 5:10:12  time: 0.3953  data_time: 0.0104  memory: 6613  grad_norm: 6.4164  loss: 1.1423  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7914  loss_aux: 0.3509\n",
            "02/09 15:53:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][100/332]  lr: 1.0000e-02  eta: 5:10:03  time: 0.3946  data_time: 0.0099  memory: 6613  grad_norm: 4.6585  loss: 1.1605  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7364  loss_aux: 0.4241\n",
            "02/09 15:53:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][120/332]  lr: 1.0000e-02  eta: 5:09:54  time: 0.3951  data_time: 0.0101  memory: 6613  grad_norm: 5.6376  loss: 1.2162  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7797  loss_aux: 0.4366\n",
            "02/09 15:54:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][140/332]  lr: 1.0000e-02  eta: 5:09:45  time: 0.3965  data_time: 0.0113  memory: 6613  grad_norm: 3.4054  loss: 1.1342  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7775  loss_aux: 0.3567\n",
            "02/09 15:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][160/332]  lr: 1.0000e-02  eta: 5:09:36  time: 0.3940  data_time: 0.0097  memory: 6613  grad_norm: 3.7095  loss: 1.3035  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.8795  loss_aux: 0.4239\n",
            "02/09 15:54:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][180/332]  lr: 1.0000e-02  eta: 5:09:28  time: 0.3962  data_time: 0.0112  memory: 6613  grad_norm: 4.9535  loss: 1.1764  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.7541  loss_aux: 0.4223\n",
            "02/09 15:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][200/332]  lr: 1.0000e-02  eta: 5:09:19  time: 0.3947  data_time: 0.0103  memory: 6613  grad_norm: 4.2105  loss: 1.1185  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7032  loss_aux: 0.4154\n",
            "02/09 15:54:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][220/332]  lr: 1.0000e-02  eta: 5:09:10  time: 0.3945  data_time: 0.0098  memory: 6613  grad_norm: 3.1820  loss: 1.1216  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7329  loss_aux: 0.3886\n",
            "02/09 15:54:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][240/332]  lr: 1.0000e-02  eta: 5:09:01  time: 0.3942  data_time: 0.0096  memory: 6613  grad_norm: 3.9651  loss: 1.1815  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7682  loss_aux: 0.4133\n",
            "02/09 15:54:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][260/332]  lr: 1.0000e-02  eta: 5:08:51  time: 0.3937  data_time: 0.0096  memory: 6613  grad_norm: 7.3720  loss: 1.5315  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 1.0915  loss_aux: 0.4401\n",
            "02/09 15:54:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][280/332]  lr: 1.0000e-02  eta: 5:08:42  time: 0.3936  data_time: 0.0095  memory: 6613  grad_norm: 3.3908  loss: 1.2126  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8200  loss_aux: 0.3926\n",
            "02/09 15:55:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][300/332]  lr: 1.0000e-02  eta: 5:08:33  time: 0.3942  data_time: 0.0098  memory: 6613  grad_norm: 5.4568  loss: 1.3375  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.9582  loss_aux: 0.3793\n",
            "02/09 15:55:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][320/332]  lr: 1.0000e-02  eta: 5:08:24  time: 0.3937  data_time: 0.0097  memory: 6613  grad_norm: 4.2023  loss: 1.2101  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8097  loss_aux: 0.4004\n",
            "02/09 15:55:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:55:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][332/332]  lr: 1.0000e-02  eta: 5:08:17  time: 0.3887  data_time: 0.0092  memory: 6613  grad_norm: 6.1121  loss: 1.1887  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8160  loss_aux: 0.3727\n",
            "02/09 15:55:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 10 epochs\n",
            "02/09 15:55:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [10][20/42]    eta: 0:00:04  time: 0.2045  data_time: 0.0944  memory: 1447  \n",
            "02/09 15:55:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [10][40/42]    eta: 0:00:00  time: 0.1289  data_time: 0.0270  memory: 1447  \n",
            "02/09 15:55:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][42/42]    acc/top1: 0.5331  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0581  time: 0.1626\n",
            "02/09 15:55:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.5331 acc/top1 at 10 epoch is saved to best_acc_top1_epoch_10.pth.\n",
            "02/09 15:55:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][ 20/332]  lr: 1.0000e-02  eta: 5:08:23  time: 0.4476  data_time: 0.0606  memory: 6616  grad_norm: 4.1373  loss: 1.3182  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8639  loss_aux: 0.4543\n",
            "02/09 15:55:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][ 40/332]  lr: 1.0000e-02  eta: 5:08:14  time: 0.3934  data_time: 0.0094  memory: 6616  grad_norm: 4.5968  loss: 1.2047  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8030  loss_aux: 0.4018\n",
            "02/09 15:55:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][ 60/332]  lr: 1.0000e-02  eta: 5:08:04  time: 0.3936  data_time: 0.0095  memory: 6616  grad_norm: 4.4645  loss: 1.2479  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8095  loss_aux: 0.4384\n",
            "02/09 15:56:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][ 80/332]  lr: 1.0000e-02  eta: 5:07:55  time: 0.3946  data_time: 0.0104  memory: 6616  grad_norm: 3.6223  loss: 1.1895  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7884  loss_aux: 0.4012\n",
            "02/09 15:56:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][100/332]  lr: 1.0000e-02  eta: 5:07:46  time: 0.3946  data_time: 0.0103  memory: 6616  grad_norm: 4.4566  loss: 1.1455  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7817  loss_aux: 0.3639\n",
            "02/09 15:56:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][120/332]  lr: 1.0000e-02  eta: 5:07:38  time: 0.3946  data_time: 0.0099  memory: 6616  grad_norm: 3.5707  loss: 1.2173  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7639  loss_aux: 0.4533\n",
            "02/09 15:56:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][140/332]  lr: 1.0000e-02  eta: 5:07:29  time: 0.3945  data_time: 0.0102  memory: 6616  grad_norm: 6.3050  loss: 1.2199  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7821  loss_aux: 0.4379\n",
            "02/09 15:56:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][160/332]  lr: 1.0000e-02  eta: 5:07:20  time: 0.3944  data_time: 0.0098  memory: 6616  grad_norm: 16.7589  loss: 1.2056  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7917  loss_aux: 0.4139\n",
            "02/09 15:56:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][180/332]  lr: 1.0000e-02  eta: 5:07:11  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 4.7777  loss: 1.0886  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7096  loss_aux: 0.3790\n",
            "02/09 15:56:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][200/332]  lr: 1.0000e-02  eta: 5:07:02  time: 0.3957  data_time: 0.0110  memory: 6616  grad_norm: 3.0486  loss: 1.1288  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7765  loss_aux: 0.3523\n",
            "02/09 15:56:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][220/332]  lr: 1.0000e-02  eta: 5:06:53  time: 0.3946  data_time: 0.0102  memory: 6616  grad_norm: 6.5432  loss: 1.2394  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8365  loss_aux: 0.4029\n",
            "02/09 15:57:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][240/332]  lr: 1.0000e-02  eta: 5:06:44  time: 0.3943  data_time: 0.0099  memory: 6616  grad_norm: 5.4502  loss: 1.2968  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8708  loss_aux: 0.4260\n",
            "02/09 15:57:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][260/332]  lr: 1.0000e-02  eta: 5:06:36  time: 0.3947  data_time: 0.0107  memory: 6616  grad_norm: 3.4133  loss: 1.0565  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6960  loss_aux: 0.3604\n",
            "02/09 15:57:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][280/332]  lr: 1.0000e-02  eta: 5:06:27  time: 0.3955  data_time: 0.0105  memory: 6616  grad_norm: 5.2199  loss: 1.1374  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7437  loss_aux: 0.3937\n",
            "02/09 15:57:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][300/332]  lr: 1.0000e-02  eta: 5:06:18  time: 0.3951  data_time: 0.0102  memory: 6616  grad_norm: 5.9807  loss: 1.1791  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7881  loss_aux: 0.3910\n",
            "02/09 15:57:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][320/332]  lr: 1.0000e-02  eta: 5:06:09  time: 0.3937  data_time: 0.0095  memory: 6616  grad_norm: 4.5938  loss: 1.2378  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8272  loss_aux: 0.4107\n",
            "02/09 15:57:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:57:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][332/332]  lr: 1.0000e-02  eta: 5:06:03  time: 0.3889  data_time: 0.0094  memory: 6616  grad_norm: 3.8446  loss: 1.1887  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8023  loss_aux: 0.3864\n",
            "02/09 15:57:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 11 epochs\n",
            "02/09 15:57:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][ 20/332]  lr: 1.0000e-02  eta: 5:06:04  time: 0.4369  data_time: 0.0483  memory: 6616  grad_norm: 3.7712  loss: 1.2036  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7827  loss_aux: 0.4209\n",
            "02/09 15:58:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][ 40/332]  lr: 1.0000e-02  eta: 5:05:55  time: 0.3934  data_time: 0.0094  memory: 6616  grad_norm: 4.4577  loss: 1.2048  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7833  loss_aux: 0.4215\n",
            "02/09 15:58:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][ 60/332]  lr: 1.0000e-02  eta: 5:05:46  time: 0.3941  data_time: 0.0098  memory: 6616  grad_norm: 2.8299  loss: 1.1155  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7422  loss_aux: 0.3733\n",
            "02/09 15:58:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][ 80/332]  lr: 1.0000e-02  eta: 5:05:37  time: 0.3937  data_time: 0.0095  memory: 6616  grad_norm: 4.9295  loss: 1.2160  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8059  loss_aux: 0.4102\n",
            "02/09 15:58:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][100/332]  lr: 1.0000e-02  eta: 5:05:29  time: 0.3947  data_time: 0.0107  memory: 6616  grad_norm: 2.9361  loss: 1.1694  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8049  loss_aux: 0.3645\n",
            "02/09 15:58:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][120/332]  lr: 1.0000e-02  eta: 5:05:20  time: 0.3957  data_time: 0.0111  memory: 6616  grad_norm: 2.6160  loss: 1.1294  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7407  loss_aux: 0.3888\n",
            "02/09 15:58:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][140/332]  lr: 1.0000e-02  eta: 5:05:11  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 5.7112  loss: 1.1038  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7225  loss_aux: 0.3813\n",
            "02/09 15:58:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][160/332]  lr: 1.0000e-02  eta: 5:05:02  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 3.0696  loss: 1.1716  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7340  loss_aux: 0.4376\n",
            "02/09 15:58:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][180/332]  lr: 1.0000e-02  eta: 5:04:54  time: 0.3951  data_time: 0.0106  memory: 6616  grad_norm: 3.9887  loss: 1.1299  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7208  loss_aux: 0.4091\n",
            "02/09 15:59:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][200/332]  lr: 1.0000e-02  eta: 5:04:45  time: 0.3940  data_time: 0.0100  memory: 6616  grad_norm: 4.4091  loss: 1.3041  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9220  loss_aux: 0.3821\n",
            "02/09 15:59:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][220/332]  lr: 1.0000e-02  eta: 5:04:36  time: 0.3950  data_time: 0.0108  memory: 6616  grad_norm: 4.0919  loss: 1.2155  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8268  loss_aux: 0.3887\n",
            "02/09 15:59:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][240/332]  lr: 1.0000e-02  eta: 5:04:28  time: 0.3954  data_time: 0.0109  memory: 6616  grad_norm: 2.7509  loss: 1.1630  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.7615  loss_aux: 0.4016\n",
            "02/09 15:59:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][260/332]  lr: 1.0000e-02  eta: 5:04:19  time: 0.3944  data_time: 0.0103  memory: 6616  grad_norm: 3.3945  loss: 1.2325  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8528  loss_aux: 0.3798\n",
            "02/09 15:59:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][280/332]  lr: 1.0000e-02  eta: 5:04:10  time: 0.3949  data_time: 0.0104  memory: 6616  grad_norm: 2.3627  loss: 1.1663  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8058  loss_aux: 0.3605\n",
            "02/09 15:59:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][300/332]  lr: 1.0000e-02  eta: 5:04:01  time: 0.3944  data_time: 0.0105  memory: 6616  grad_norm: 2.3982  loss: 1.0931  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6950  loss_aux: 0.3980\n",
            "02/09 15:59:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][320/332]  lr: 1.0000e-02  eta: 5:03:53  time: 0.3948  data_time: 0.0106  memory: 6616  grad_norm: 2.7486  loss: 1.2281  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8276  loss_aux: 0.4005\n",
            "02/09 15:59:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 15:59:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][332/332]  lr: 1.0000e-02  eta: 5:03:46  time: 0.3889  data_time: 0.0094  memory: 6616  grad_norm: 2.4038  loss: 1.1201  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7434  loss_aux: 0.3767\n",
            "02/09 15:59:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n",
            "02/09 16:00:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:00:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][ 20/332]  lr: 1.0000e-02  eta: 5:03:50  time: 0.4491  data_time: 0.0624  memory: 6616  grad_norm: 3.0810  loss: 1.2790  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8625  loss_aux: 0.4165\n",
            "02/09 16:00:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][ 40/332]  lr: 1.0000e-02  eta: 5:03:41  time: 0.3933  data_time: 0.0094  memory: 6616  grad_norm: 2.8620  loss: 1.1901  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8068  loss_aux: 0.3833\n",
            "02/09 16:00:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][ 60/332]  lr: 1.0000e-02  eta: 5:03:32  time: 0.3943  data_time: 0.0099  memory: 6616  grad_norm: 2.9997  loss: 1.1888  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7974  loss_aux: 0.3914\n",
            "02/09 16:00:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][ 80/332]  lr: 1.0000e-02  eta: 5:03:23  time: 0.3932  data_time: 0.0097  memory: 6616  grad_norm: 3.6426  loss: 1.2387  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8538  loss_aux: 0.3849\n",
            "02/09 16:00:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][100/332]  lr: 1.0000e-02  eta: 5:03:14  time: 0.3934  data_time: 0.0097  memory: 6616  grad_norm: 3.5395  loss: 1.1670  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8069  loss_aux: 0.3601\n",
            "02/09 16:00:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][120/332]  lr: 1.0000e-02  eta: 5:03:05  time: 0.3948  data_time: 0.0105  memory: 6616  grad_norm: 3.2854  loss: 1.2062  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8476  loss_aux: 0.3586\n",
            "02/09 16:00:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][140/332]  lr: 1.0000e-02  eta: 5:02:56  time: 0.3933  data_time: 0.0096  memory: 6616  grad_norm: 2.7116  loss: 1.2221  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8577  loss_aux: 0.3644\n",
            "02/09 16:01:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][160/332]  lr: 1.0000e-02  eta: 5:02:48  time: 0.3944  data_time: 0.0102  memory: 6616  grad_norm: 2.5291  loss: 1.1081  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7402  loss_aux: 0.3679\n",
            "02/09 16:01:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][180/332]  lr: 1.0000e-02  eta: 5:02:39  time: 0.3949  data_time: 0.0104  memory: 6616  grad_norm: 2.8169  loss: 1.1576  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7519  loss_aux: 0.4057\n",
            "02/09 16:01:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][200/332]  lr: 1.0000e-02  eta: 5:02:30  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 2.8975  loss: 1.1998  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8228  loss_aux: 0.3770\n",
            "02/09 16:01:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][220/332]  lr: 1.0000e-02  eta: 5:02:22  time: 0.3957  data_time: 0.0111  memory: 6616  grad_norm: 3.4441  loss: 1.0295  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6742  loss_aux: 0.3553\n",
            "02/09 16:01:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][240/332]  lr: 1.0000e-02  eta: 5:02:13  time: 0.3943  data_time: 0.0101  memory: 6616  grad_norm: 2.2661  loss: 1.1744  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7802  loss_aux: 0.3942\n",
            "02/09 16:01:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][260/332]  lr: 1.0000e-02  eta: 5:02:04  time: 0.3942  data_time: 0.0102  memory: 6616  grad_norm: 2.7080  loss: 1.1082  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7218  loss_aux: 0.3864\n",
            "02/09 16:01:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][280/332]  lr: 1.0000e-02  eta: 5:01:56  time: 0.3952  data_time: 0.0107  memory: 6616  grad_norm: 31.5096  loss: 1.1970  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7846  loss_aux: 0.4124\n",
            "02/09 16:02:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][300/332]  lr: 1.0000e-02  eta: 5:01:47  time: 0.3948  data_time: 0.0104  memory: 6616  grad_norm: 4.2257  loss: 1.2254  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8550  loss_aux: 0.3704\n",
            "02/09 16:02:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][320/332]  lr: 1.0000e-02  eta: 5:01:39  time: 0.3936  data_time: 0.0097  memory: 6616  grad_norm: 3.3767  loss: 1.1257  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7415  loss_aux: 0.3842\n",
            "02/09 16:02:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:02:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][332/332]  lr: 1.0000e-02  eta: 5:01:32  time: 0.3888  data_time: 0.0094  memory: 6616  grad_norm: 3.8802  loss: 1.0704  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6827  loss_aux: 0.3876\n",
            "02/09 16:02:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 13 epochs\n",
            "02/09 16:02:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][ 20/332]  lr: 1.0000e-02  eta: 5:01:32  time: 0.4368  data_time: 0.0489  memory: 6616  grad_norm: 4.3825  loss: 1.0566  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6917  loss_aux: 0.3649\n",
            "02/09 16:02:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][ 40/332]  lr: 1.0000e-02  eta: 5:01:24  time: 0.3936  data_time: 0.0098  memory: 6616  grad_norm: 3.4176  loss: 1.1989  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7994  loss_aux: 0.3995\n",
            "02/09 16:02:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][ 60/332]  lr: 1.0000e-02  eta: 5:01:15  time: 0.3939  data_time: 0.0101  memory: 6616  grad_norm: 3.2509  loss: 1.0948  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7118  loss_aux: 0.3830\n",
            "02/09 16:02:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][ 80/332]  lr: 1.0000e-02  eta: 5:01:06  time: 0.3927  data_time: 0.0092  memory: 6616  grad_norm: 3.4030  loss: 1.1689  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8069  loss_aux: 0.3620\n",
            "02/09 16:02:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][100/332]  lr: 1.0000e-02  eta: 5:00:57  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 3.3876  loss: 1.1587  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7496  loss_aux: 0.4091\n",
            "02/09 16:03:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][120/332]  lr: 1.0000e-02  eta: 5:00:49  time: 0.3951  data_time: 0.0107  memory: 6616  grad_norm: 3.3127  loss: 1.1713  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8089  loss_aux: 0.3624\n",
            "02/09 16:03:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][140/332]  lr: 1.0000e-02  eta: 5:00:40  time: 0.3937  data_time: 0.0099  memory: 6616  grad_norm: 3.5676  loss: 1.1997  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8084  loss_aux: 0.3913\n",
            "02/09 16:03:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][160/332]  lr: 1.0000e-02  eta: 5:00:31  time: 0.3946  data_time: 0.0103  memory: 6616  grad_norm: 3.3283  loss: 1.2334  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.8385  loss_aux: 0.3949\n",
            "02/09 16:03:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][180/332]  lr: 1.0000e-02  eta: 5:00:23  time: 0.3942  data_time: 0.0105  memory: 6616  grad_norm: 6.7051  loss: 1.2943  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8773  loss_aux: 0.4171\n",
            "02/09 16:03:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][200/332]  lr: 1.0000e-02  eta: 5:00:14  time: 0.3946  data_time: 0.0104  memory: 6616  grad_norm: 3.4978  loss: 1.2725  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8776  loss_aux: 0.3949\n",
            "02/09 16:03:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][220/332]  lr: 1.0000e-02  eta: 5:00:05  time: 0.3941  data_time: 0.0100  memory: 6616  grad_norm: 2.7301  loss: 1.1263  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7409  loss_aux: 0.3854\n",
            "02/09 16:03:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][240/332]  lr: 1.0000e-02  eta: 4:59:57  time: 0.3946  data_time: 0.0104  memory: 6616  grad_norm: 3.2339  loss: 1.1183  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7632  loss_aux: 0.3551\n",
            "02/09 16:03:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][260/332]  lr: 1.0000e-02  eta: 4:59:48  time: 0.3940  data_time: 0.0102  memory: 6616  grad_norm: 4.6799  loss: 1.2222  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8696  loss_aux: 0.3526\n",
            "02/09 16:04:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][280/332]  lr: 1.0000e-02  eta: 4:59:39  time: 0.3945  data_time: 0.0100  memory: 6616  grad_norm: 3.3153  loss: 1.1775  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7732  loss_aux: 0.4043\n",
            "02/09 16:04:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][300/332]  lr: 1.0000e-02  eta: 4:59:31  time: 0.3947  data_time: 0.0104  memory: 6616  grad_norm: 3.3598  loss: 1.1556  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8024  loss_aux: 0.3532\n",
            "02/09 16:04:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][320/332]  lr: 1.0000e-02  eta: 4:59:22  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 3.7618  loss: 1.2547  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.8315  loss_aux: 0.4232\n",
            "02/09 16:04:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:04:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][332/332]  lr: 1.0000e-02  eta: 4:59:16  time: 0.3893  data_time: 0.0095  memory: 6616  grad_norm: 3.5495  loss: 1.2698  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8837  loss_aux: 0.3861\n",
            "02/09 16:04:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 14 epochs\n",
            "02/09 16:04:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][ 20/332]  lr: 1.0000e-02  eta: 4:59:16  time: 0.4362  data_time: 0.0493  memory: 6616  grad_norm: 3.4230  loss: 1.1739  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7803  loss_aux: 0.3936\n",
            "02/09 16:04:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][ 40/332]  lr: 1.0000e-02  eta: 4:59:07  time: 0.3937  data_time: 0.0096  memory: 6616  grad_norm: 3.4571  loss: 1.1861  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7887  loss_aux: 0.3973\n",
            "02/09 16:04:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][ 60/332]  lr: 1.0000e-02  eta: 4:58:58  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 3.5285  loss: 1.1547  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7947  loss_aux: 0.3600\n",
            "02/09 16:05:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][ 80/332]  lr: 1.0000e-02  eta: 4:58:50  time: 0.3944  data_time: 0.0102  memory: 6616  grad_norm: 2.6952  loss: 1.1588  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7818  loss_aux: 0.3771\n",
            "02/09 16:05:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][100/332]  lr: 1.0000e-02  eta: 4:58:41  time: 0.3945  data_time: 0.0100  memory: 6616  grad_norm: 4.9246  loss: 1.2045  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7957  loss_aux: 0.4088\n",
            "02/09 16:05:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][120/332]  lr: 1.0000e-02  eta: 4:58:33  time: 0.3939  data_time: 0.0100  memory: 6616  grad_norm: 3.4120  loss: 1.2274  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8503  loss_aux: 0.3771\n",
            "02/09 16:05:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][140/332]  lr: 1.0000e-02  eta: 4:58:24  time: 0.3934  data_time: 0.0096  memory: 6616  grad_norm: 2.6742  loss: 1.0969  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7395  loss_aux: 0.3574\n",
            "02/09 16:05:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][160/332]  lr: 1.0000e-02  eta: 4:58:15  time: 0.3957  data_time: 0.0108  memory: 6616  grad_norm: 3.5136  loss: 1.1459  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7796  loss_aux: 0.3663\n",
            "02/09 16:05:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][180/332]  lr: 1.0000e-02  eta: 4:58:07  time: 0.3942  data_time: 0.0099  memory: 6616  grad_norm: 3.6013  loss: 1.1722  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7818  loss_aux: 0.3904\n",
            "02/09 16:05:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][200/332]  lr: 1.0000e-02  eta: 4:57:58  time: 0.3942  data_time: 0.0102  memory: 6616  grad_norm: 3.8382  loss: 1.1727  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7871  loss_aux: 0.3856\n",
            "02/09 16:05:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][220/332]  lr: 1.0000e-02  eta: 4:57:50  time: 0.3956  data_time: 0.0107  memory: 6616  grad_norm: 3.4987  loss: 1.1100  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7345  loss_aux: 0.3756\n",
            "02/09 16:06:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][240/332]  lr: 1.0000e-02  eta: 4:57:41  time: 0.3937  data_time: 0.0097  memory: 6616  grad_norm: 5.0308  loss: 1.1222  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7549  loss_aux: 0.3673\n",
            "02/09 16:06:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][260/332]  lr: 1.0000e-02  eta: 4:57:33  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 3.8746  loss: 1.1951  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8007  loss_aux: 0.3944\n",
            "02/09 16:06:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][280/332]  lr: 1.0000e-02  eta: 4:57:24  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 3.2099  loss: 1.2081  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8282  loss_aux: 0.3799\n",
            "02/09 16:06:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][300/332]  lr: 1.0000e-02  eta: 4:57:16  time: 0.3940  data_time: 0.0102  memory: 6616  grad_norm: 2.7276  loss: 1.1103  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7515  loss_aux: 0.3588\n",
            "02/09 16:06:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][320/332]  lr: 1.0000e-02  eta: 4:57:07  time: 0.3943  data_time: 0.0100  memory: 6616  grad_norm: 3.6573  loss: 1.1798  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7927  loss_aux: 0.3870\n",
            "02/09 16:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][332/332]  lr: 1.0000e-02  eta: 4:57:01  time: 0.3893  data_time: 0.0095  memory: 6616  grad_norm: 2.9639  loss: 1.1689  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7611  loss_aux: 0.4078\n",
            "02/09 16:06:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 15 epochs\n",
            "02/09 16:06:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:06:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][ 20/332]  lr: 1.0000e-02  eta: 4:57:02  time: 0.4486  data_time: 0.0630  memory: 6616  grad_norm: 5.5322  loss: 1.1625  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7981  loss_aux: 0.3644\n",
            "02/09 16:07:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][ 40/332]  lr: 1.0000e-02  eta: 4:56:54  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 2.9957  loss: 1.2194  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8203  loss_aux: 0.3991\n",
            "02/09 16:07:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][ 60/332]  lr: 1.0000e-02  eta: 4:56:45  time: 0.3954  data_time: 0.0104  memory: 6616  grad_norm: 2.7316  loss: 1.1224  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7567  loss_aux: 0.3656\n",
            "02/09 16:07:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][ 80/332]  lr: 1.0000e-02  eta: 4:56:37  time: 0.3940  data_time: 0.0098  memory: 6616  grad_norm: 3.1498  loss: 1.1409  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7556  loss_aux: 0.3854\n",
            "02/09 16:07:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][100/332]  lr: 1.0000e-02  eta: 4:56:28  time: 0.3938  data_time: 0.0097  memory: 6616  grad_norm: 3.4926  loss: 1.1681  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8001  loss_aux: 0.3680\n",
            "02/09 16:07:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][120/332]  lr: 1.0000e-02  eta: 4:56:19  time: 0.3941  data_time: 0.0100  memory: 6616  grad_norm: 3.5272  loss: 1.1445  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7465  loss_aux: 0.3980\n",
            "02/09 16:07:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][140/332]  lr: 1.0000e-02  eta: 4:56:11  time: 0.3954  data_time: 0.0106  memory: 6616  grad_norm: 3.0633  loss: 1.1261  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7525  loss_aux: 0.3736\n",
            "02/09 16:07:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][160/332]  lr: 1.0000e-02  eta: 4:56:03  time: 0.3947  data_time: 0.0105  memory: 6616  grad_norm: 3.3415  loss: 1.1415  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7508  loss_aux: 0.3907\n",
            "02/09 16:07:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][180/332]  lr: 1.0000e-02  eta: 4:55:54  time: 0.3948  data_time: 0.0098  memory: 6616  grad_norm: 2.8063  loss: 1.1541  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7804  loss_aux: 0.3737\n",
            "02/09 16:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][200/332]  lr: 1.0000e-02  eta: 4:55:46  time: 0.3950  data_time: 0.0101  memory: 6616  grad_norm: 4.6257  loss: 1.2450  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8674  loss_aux: 0.3776\n",
            "02/09 16:08:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][220/332]  lr: 1.0000e-02  eta: 4:55:37  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 3.7212  loss: 1.2263  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8345  loss_aux: 0.3918\n",
            "02/09 16:08:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][240/332]  lr: 1.0000e-02  eta: 4:55:29  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 3.9010  loss: 1.2154  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8149  loss_aux: 0.4005\n",
            "02/09 16:08:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][260/332]  lr: 1.0000e-02  eta: 4:55:21  time: 0.3946  data_time: 0.0103  memory: 6616  grad_norm: 3.3472  loss: 1.0749  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7148  loss_aux: 0.3601\n",
            "02/09 16:08:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][280/332]  lr: 1.0000e-02  eta: 4:55:12  time: 0.3950  data_time: 0.0107  memory: 6616  grad_norm: 4.1579  loss: 1.1145  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7566  loss_aux: 0.3579\n",
            "02/09 16:08:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][300/332]  lr: 1.0000e-02  eta: 4:55:04  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 4.4182  loss: 1.2531  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8673  loss_aux: 0.3858\n",
            "02/09 16:08:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][320/332]  lr: 1.0000e-02  eta: 4:54:55  time: 0.3934  data_time: 0.0095  memory: 6616  grad_norm: 2.5916  loss: 1.1008  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7546  loss_aux: 0.3462\n",
            "02/09 16:08:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:08:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][332/332]  lr: 1.0000e-02  eta: 4:54:49  time: 0.3885  data_time: 0.0091  memory: 6616  grad_norm: 3.6935  loss: 1.1744  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8253  loss_aux: 0.3492\n",
            "02/09 16:08:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 16 epochs\n",
            "02/09 16:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][ 20/332]  lr: 1.0000e-02  eta: 4:54:47  time: 0.4343  data_time: 0.0475  memory: 6616  grad_norm: 3.0526  loss: 1.1628  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7942  loss_aux: 0.3686\n",
            "02/09 16:09:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][ 40/332]  lr: 1.0000e-02  eta: 4:54:39  time: 0.3943  data_time: 0.0098  memory: 6616  grad_norm: 2.9356  loss: 1.2133  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8261  loss_aux: 0.3872\n",
            "02/09 16:09:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][ 60/332]  lr: 1.0000e-02  eta: 4:54:30  time: 0.3943  data_time: 0.0097  memory: 6616  grad_norm: 4.6423  loss: 1.0810  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7281  loss_aux: 0.3530\n",
            "02/09 16:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][ 80/332]  lr: 1.0000e-02  eta: 4:54:22  time: 0.3945  data_time: 0.0100  memory: 6616  grad_norm: 3.8285  loss: 1.2279  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8258  loss_aux: 0.4021\n",
            "02/09 16:09:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][100/332]  lr: 1.0000e-02  eta: 4:54:13  time: 0.3954  data_time: 0.0104  memory: 6616  grad_norm: 4.1644  loss: 1.1746  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8219  loss_aux: 0.3527\n",
            "02/09 16:09:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][120/332]  lr: 1.0000e-02  eta: 4:54:05  time: 0.3944  data_time: 0.0097  memory: 6616  grad_norm: 3.2561  loss: 1.1507  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7664  loss_aux: 0.3843\n",
            "02/09 16:09:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][140/332]  lr: 1.0000e-02  eta: 4:53:56  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 3.3358  loss: 1.1402  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7541  loss_aux: 0.3862\n",
            "02/09 16:10:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][160/332]  lr: 1.0000e-02  eta: 4:53:48  time: 0.3952  data_time: 0.0105  memory: 6616  grad_norm: 3.2842  loss: 1.1746  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8187  loss_aux: 0.3559\n",
            "02/09 16:10:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][180/332]  lr: 1.0000e-02  eta: 4:53:39  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 4.3945  loss: 1.2342  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8487  loss_aux: 0.3855\n",
            "02/09 16:10:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][200/332]  lr: 1.0000e-02  eta: 4:53:31  time: 0.3959  data_time: 0.0108  memory: 6616  grad_norm: 2.9728  loss: 1.1378  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7807  loss_aux: 0.3570\n",
            "02/09 16:10:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][220/332]  lr: 1.0000e-02  eta: 4:53:23  time: 0.3943  data_time: 0.0098  memory: 6616  grad_norm: 3.7157  loss: 1.1964  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8099  loss_aux: 0.3865\n",
            "02/09 16:10:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][240/332]  lr: 1.0000e-02  eta: 4:53:14  time: 0.3944  data_time: 0.0097  memory: 6616  grad_norm: 3.0011  loss: 1.1166  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7497  loss_aux: 0.3670\n",
            "02/09 16:10:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][260/332]  lr: 1.0000e-02  eta: 4:53:06  time: 0.3943  data_time: 0.0102  memory: 6616  grad_norm: 3.4176  loss: 1.1579  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7922  loss_aux: 0.3657\n",
            "02/09 16:10:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][280/332]  lr: 1.0000e-02  eta: 4:52:57  time: 0.3952  data_time: 0.0103  memory: 6616  grad_norm: 4.2825  loss: 1.1696  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7837  loss_aux: 0.3858\n",
            "02/09 16:10:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][300/332]  lr: 1.0000e-02  eta: 4:52:49  time: 0.3951  data_time: 0.0098  memory: 6616  grad_norm: 3.7753  loss: 1.1698  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7895  loss_aux: 0.3803\n",
            "02/09 16:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][320/332]  lr: 1.0000e-02  eta: 4:52:41  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 3.0026  loss: 1.0738  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7241  loss_aux: 0.3496\n",
            "02/09 16:11:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:11:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][332/332]  lr: 1.0000e-02  eta: 4:52:35  time: 0.3893  data_time: 0.0094  memory: 6616  grad_norm: 3.1434  loss: 1.0833  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.7278  loss_aux: 0.3556\n",
            "02/09 16:11:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 17 epochs\n",
            "02/09 16:11:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][ 20/332]  lr: 1.0000e-02  eta: 4:52:35  time: 0.4465  data_time: 0.0569  memory: 6616  grad_norm: 3.1529  loss: 1.1278  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7611  loss_aux: 0.3667\n",
            "02/09 16:11:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][ 40/332]  lr: 1.0000e-02  eta: 4:52:26  time: 0.3963  data_time: 0.0107  memory: 6616  grad_norm: 2.9141  loss: 1.1763  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7862  loss_aux: 0.3900\n",
            "02/09 16:11:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][ 60/332]  lr: 1.0000e-02  eta: 4:52:18  time: 0.3949  data_time: 0.0097  memory: 6616  grad_norm: 2.9955  loss: 1.1917  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7980  loss_aux: 0.3937\n",
            "02/09 16:11:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][ 80/332]  lr: 1.0000e-02  eta: 4:52:10  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 3.5619  loss: 1.0865  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7275  loss_aux: 0.3591\n",
            "02/09 16:11:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][100/332]  lr: 1.0000e-02  eta: 4:52:01  time: 0.3959  data_time: 0.0104  memory: 6616  grad_norm: 2.3619  loss: 1.0563  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7200  loss_aux: 0.3363\n",
            "02/09 16:12:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][120/332]  lr: 1.0000e-02  eta: 4:51:53  time: 0.3943  data_time: 0.0097  memory: 6616  grad_norm: 3.2692  loss: 1.1936  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8035  loss_aux: 0.3901\n",
            "02/09 16:12:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][140/332]  lr: 1.0000e-02  eta: 4:51:45  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 3.4972  loss: 1.1212  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7530  loss_aux: 0.3682\n",
            "02/09 16:12:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][160/332]  lr: 1.0000e-02  eta: 4:51:36  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 2.7756  loss: 1.1384  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7870  loss_aux: 0.3513\n",
            "02/09 16:12:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][180/332]  lr: 1.0000e-02  eta: 4:51:28  time: 0.3933  data_time: 0.0094  memory: 6616  grad_norm: 3.3755  loss: 1.2003  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8163  loss_aux: 0.3839\n",
            "02/09 16:12:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][200/332]  lr: 1.0000e-02  eta: 4:51:19  time: 0.3936  data_time: 0.0095  memory: 6616  grad_norm: 3.4924  loss: 1.1621  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8181  loss_aux: 0.3440\n",
            "02/09 16:12:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][220/332]  lr: 1.0000e-02  eta: 4:51:10  time: 0.3939  data_time: 0.0099  memory: 6616  grad_norm: 2.7063  loss: 1.1740  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7691  loss_aux: 0.4049\n",
            "02/09 16:12:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][240/332]  lr: 1.0000e-02  eta: 4:51:02  time: 0.3940  data_time: 0.0099  memory: 6616  grad_norm: 2.7141  loss: 1.1753  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8111  loss_aux: 0.3642\n",
            "02/09 16:12:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][260/332]  lr: 1.0000e-02  eta: 4:50:53  time: 0.3940  data_time: 0.0103  memory: 6616  grad_norm: 2.7250  loss: 1.1801  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8007  loss_aux: 0.3795\n",
            "02/09 16:13:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][280/332]  lr: 1.0000e-02  eta: 4:50:45  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 3.2352  loss: 1.1756  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.8066  loss_aux: 0.3690\n",
            "02/09 16:13:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][300/332]  lr: 1.0000e-02  eta: 4:50:37  time: 0.3933  data_time: 0.0096  memory: 6616  grad_norm: 2.8725  loss: 1.0783  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7390  loss_aux: 0.3393\n",
            "02/09 16:13:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][320/332]  lr: 1.0000e-02  eta: 4:50:28  time: 0.3936  data_time: 0.0095  memory: 6616  grad_norm: 4.0380  loss: 1.1991  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8055  loss_aux: 0.3936\n",
            "02/09 16:13:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:13:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][332/332]  lr: 1.0000e-02  eta: 4:50:22  time: 0.3891  data_time: 0.0092  memory: 6616  grad_norm: 4.2847  loss: 1.1843  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.8006  loss_aux: 0.3837\n",
            "02/09 16:13:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 18 epochs\n",
            "02/09 16:13:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][ 20/332]  lr: 1.0000e-02  eta: 4:50:21  time: 0.4464  data_time: 0.0578  memory: 6616  grad_norm: 3.3287  loss: 1.1450  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7916  loss_aux: 0.3535\n",
            "02/09 16:13:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:13:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][ 40/332]  lr: 1.0000e-02  eta: 4:50:13  time: 0.3965  data_time: 0.0111  memory: 6616  grad_norm: 2.2470  loss: 0.9847  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6501  loss_aux: 0.3345\n",
            "02/09 16:13:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][ 60/332]  lr: 1.0000e-02  eta: 4:50:05  time: 0.3942  data_time: 0.0096  memory: 6616  grad_norm: 2.5743  loss: 1.1154  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7677  loss_aux: 0.3477\n",
            "02/09 16:13:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][ 80/332]  lr: 1.0000e-02  eta: 4:49:57  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 2.4016  loss: 1.1663  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7905  loss_aux: 0.3758\n",
            "02/09 16:14:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][100/332]  lr: 1.0000e-02  eta: 4:49:48  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 3.0582  loss: 1.1539  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7843  loss_aux: 0.3696\n",
            "02/09 16:14:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][120/332]  lr: 1.0000e-02  eta: 4:49:40  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 2.8317  loss: 1.1452  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7655  loss_aux: 0.3797\n",
            "02/09 16:14:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][140/332]  lr: 1.0000e-02  eta: 4:49:31  time: 0.3944  data_time: 0.0096  memory: 6616  grad_norm: 2.8428  loss: 1.1315  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7645  loss_aux: 0.3670\n",
            "02/09 16:14:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][160/332]  lr: 1.0000e-02  eta: 4:49:23  time: 0.3961  data_time: 0.0107  memory: 6616  grad_norm: 4.3963  loss: 1.1866  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8189  loss_aux: 0.3677\n",
            "02/09 16:14:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][180/332]  lr: 1.0000e-02  eta: 4:49:15  time: 0.3935  data_time: 0.0095  memory: 6616  grad_norm: 2.8759  loss: 1.1002  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7343  loss_aux: 0.3658\n",
            "02/09 16:14:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][200/332]  lr: 1.0000e-02  eta: 4:49:06  time: 0.3942  data_time: 0.0098  memory: 6616  grad_norm: 2.7573  loss: 1.2504  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8580  loss_aux: 0.3924\n",
            "02/09 16:14:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][220/332]  lr: 1.0000e-02  eta: 4:48:58  time: 0.3942  data_time: 0.0098  memory: 6616  grad_norm: 2.5153  loss: 1.1226  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7416  loss_aux: 0.3810\n",
            "02/09 16:15:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][240/332]  lr: 1.0000e-02  eta: 4:48:50  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 2.9138  loss: 1.1014  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7505  loss_aux: 0.3509\n",
            "02/09 16:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][260/332]  lr: 1.0000e-02  eta: 4:48:41  time: 0.3956  data_time: 0.0105  memory: 6616  grad_norm: 6.4121  loss: 1.1666  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7686  loss_aux: 0.3980\n",
            "02/09 16:15:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][280/332]  lr: 1.0000e-02  eta: 4:48:33  time: 0.3947  data_time: 0.0097  memory: 6616  grad_norm: 9.2538  loss: 1.1797  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8152  loss_aux: 0.3645\n",
            "02/09 16:15:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][300/332]  lr: 1.0000e-02  eta: 4:48:25  time: 0.3945  data_time: 0.0098  memory: 6616  grad_norm: 4.0327  loss: 1.2459  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8783  loss_aux: 0.3677\n",
            "02/09 16:15:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][320/332]  lr: 1.0000e-02  eta: 4:48:16  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 3.6334  loss: 1.2958  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.9124  loss_aux: 0.3833\n",
            "02/09 16:15:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:15:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][332/332]  lr: 1.0000e-02  eta: 4:48:10  time: 0.3894  data_time: 0.0093  memory: 6616  grad_norm: 3.9632  loss: 1.1891  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.8288  loss_aux: 0.3603\n",
            "02/09 16:15:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 19 epochs\n",
            "02/09 16:15:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][ 20/332]  lr: 1.0000e-02  eta: 4:48:12  time: 0.4693  data_time: 0.0819  memory: 6616  grad_norm: 2.7238  loss: 1.0730  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7224  loss_aux: 0.3506\n",
            "02/09 16:15:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][ 40/332]  lr: 1.0000e-02  eta: 4:48:04  time: 0.3964  data_time: 0.0110  memory: 6616  grad_norm: 3.3494  loss: 1.1635  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7695  loss_aux: 0.3940\n",
            "02/09 16:16:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][ 60/332]  lr: 1.0000e-02  eta: 4:47:56  time: 0.3946  data_time: 0.0100  memory: 6616  grad_norm: 2.6606  loss: 1.0723  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7173  loss_aux: 0.3550\n",
            "02/09 16:16:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][ 80/332]  lr: 1.0000e-02  eta: 4:47:48  time: 0.3949  data_time: 0.0105  memory: 6616  grad_norm: 2.8726  loss: 1.1087  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7131  loss_aux: 0.3955\n",
            "02/09 16:16:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][100/332]  lr: 1.0000e-02  eta: 4:47:39  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 3.9601  loss: 1.1882  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8050  loss_aux: 0.3833\n",
            "02/09 16:16:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][120/332]  lr: 1.0000e-02  eta: 4:47:31  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 3.3596  loss: 1.1371  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7556  loss_aux: 0.3815\n",
            "02/09 16:16:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][140/332]  lr: 1.0000e-02  eta: 4:47:23  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 4.4032  loss: 1.1073  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7400  loss_aux: 0.3673\n",
            "02/09 16:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][160/332]  lr: 1.0000e-02  eta: 4:47:14  time: 0.3944  data_time: 0.0095  memory: 6616  grad_norm: 4.2597  loss: 1.0805  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6884  loss_aux: 0.3921\n",
            "02/09 16:16:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][180/332]  lr: 1.0000e-02  eta: 4:47:06  time: 0.3956  data_time: 0.0108  memory: 6616  grad_norm: 3.1225  loss: 1.0869  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7353  loss_aux: 0.3516\n",
            "02/09 16:17:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][200/332]  lr: 1.0000e-02  eta: 4:46:58  time: 0.3951  data_time: 0.0106  memory: 6616  grad_norm: 2.9848  loss: 1.1207  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7697  loss_aux: 0.3510\n",
            "02/09 16:17:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][220/332]  lr: 1.0000e-02  eta: 4:46:49  time: 0.3952  data_time: 0.0106  memory: 6616  grad_norm: 3.7463  loss: 1.2953  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9127  loss_aux: 0.3826\n",
            "02/09 16:17:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][240/332]  lr: 1.0000e-02  eta: 4:46:41  time: 0.3950  data_time: 0.0103  memory: 6616  grad_norm: 3.0032  loss: 1.2029  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8147  loss_aux: 0.3882\n",
            "02/09 16:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][260/332]  lr: 1.0000e-02  eta: 4:46:33  time: 0.3953  data_time: 0.0106  memory: 6616  grad_norm: 5.7652  loss: 1.1906  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8152  loss_aux: 0.3753\n",
            "02/09 16:17:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][280/332]  lr: 1.0000e-02  eta: 4:46:24  time: 0.3940  data_time: 0.0098  memory: 6616  grad_norm: 2.8374  loss: 1.0990  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7397  loss_aux: 0.3593\n",
            "02/09 16:17:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][300/332]  lr: 1.0000e-02  eta: 4:46:16  time: 0.3951  data_time: 0.0104  memory: 6616  grad_norm: 2.6677  loss: 1.0950  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7400  loss_aux: 0.3551\n",
            "02/09 16:17:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][320/332]  lr: 1.0000e-02  eta: 4:46:08  time: 0.3950  data_time: 0.0101  memory: 6616  grad_norm: 4.7731  loss: 1.1983  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8009  loss_aux: 0.3975\n",
            "02/09 16:17:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:17:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][332/332]  lr: 1.0000e-02  eta: 4:46:02  time: 0.3889  data_time: 0.0092  memory: 6616  grad_norm: 3.9801  loss: 1.1879  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.7935  loss_aux: 0.3944\n",
            "02/09 16:17:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 20 epochs\n",
            "02/09 16:18:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [20][20/42]    eta: 0:00:04  time: 0.1881  data_time: 0.0812  memory: 1447  \n",
            "02/09 16:18:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [20][40/42]    eta: 0:00:00  time: 0.1208  data_time: 0.0199  memory: 1447  \n",
            "02/09 16:18:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][42/42]    acc/top1: 0.5331  acc/top5: 1.0000  acc/mean1: 0.5000  data_time: 0.0474  time: 0.1488\n",
            "02/09 16:18:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][ 20/332]  lr: 1.0000e-02  eta: 4:46:00  time: 0.4458  data_time: 0.0598  memory: 6616  grad_norm: 2.5108  loss: 1.0879  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7374  loss_aux: 0.3505\n",
            "02/09 16:18:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][ 40/332]  lr: 1.0000e-02  eta: 4:45:52  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 4.9978  loss: 1.2604  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8523  loss_aux: 0.4081\n",
            "02/09 16:18:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][ 60/332]  lr: 1.0000e-02  eta: 4:45:44  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 2.8977  loss: 1.1749  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8189  loss_aux: 0.3559\n",
            "02/09 16:18:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][ 80/332]  lr: 1.0000e-02  eta: 4:45:35  time: 0.3943  data_time: 0.0096  memory: 6616  grad_norm: 2.2025  loss: 1.0250  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6709  loss_aux: 0.3541\n",
            "02/09 16:18:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][100/332]  lr: 1.0000e-02  eta: 4:45:27  time: 0.3961  data_time: 0.0111  memory: 6616  grad_norm: 3.7347  loss: 1.1611  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7810  loss_aux: 0.3801\n",
            "02/09 16:18:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][120/332]  lr: 1.0000e-02  eta: 4:45:19  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 2.5348  loss: 1.0964  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7075  loss_aux: 0.3889\n",
            "02/09 16:18:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][140/332]  lr: 1.0000e-02  eta: 4:45:10  time: 0.3944  data_time: 0.0097  memory: 6616  grad_norm: 3.0808  loss: 1.1296  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7574  loss_aux: 0.3722\n",
            "02/09 16:19:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][160/332]  lr: 1.0000e-02  eta: 4:45:02  time: 0.3964  data_time: 0.0108  memory: 6616  grad_norm: 3.4571  loss: 1.1295  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7364  loss_aux: 0.3931\n",
            "02/09 16:19:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][180/332]  lr: 1.0000e-02  eta: 4:44:54  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 3.8626  loss: 1.1828  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8246  loss_aux: 0.3582\n",
            "02/09 16:19:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][200/332]  lr: 1.0000e-02  eta: 4:44:46  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 2.9860  loss: 1.1394  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7606  loss_aux: 0.3788\n",
            "02/09 16:19:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][220/332]  lr: 1.0000e-02  eta: 4:44:37  time: 0.3953  data_time: 0.0104  memory: 6616  grad_norm: 2.6449  loss: 1.0803  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7252  loss_aux: 0.3552\n",
            "02/09 16:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][240/332]  lr: 1.0000e-02  eta: 4:44:29  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 3.3356  loss: 1.2036  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8219  loss_aux: 0.3817\n",
            "02/09 16:19:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][260/332]  lr: 1.0000e-02  eta: 4:44:21  time: 0.3959  data_time: 0.0108  memory: 6616  grad_norm: 2.9460  loss: 1.1733  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8210  loss_aux: 0.3523\n",
            "02/09 16:19:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][280/332]  lr: 1.0000e-02  eta: 4:44:13  time: 0.3946  data_time: 0.0102  memory: 6616  grad_norm: 2.5917  loss: 1.0933  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7419  loss_aux: 0.3514\n",
            "02/09 16:20:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][300/332]  lr: 1.0000e-02  eta: 4:44:04  time: 0.3945  data_time: 0.0098  memory: 6616  grad_norm: 2.6947  loss: 1.1625  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7758  loss_aux: 0.3866\n",
            "02/09 16:20:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][320/332]  lr: 1.0000e-02  eta: 4:43:56  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 2.8280  loss: 1.1717  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7807  loss_aux: 0.3911\n",
            "02/09 16:20:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:20:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][332/332]  lr: 1.0000e-02  eta: 4:43:51  time: 0.3898  data_time: 0.0097  memory: 6616  grad_norm: 3.0436  loss: 1.1190  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7566  loss_aux: 0.3625\n",
            "02/09 16:20:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 21 epochs\n",
            "02/09 16:20:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][ 20/332]  lr: 1.0000e-02  eta: 4:43:48  time: 0.4410  data_time: 0.0541  memory: 6616  grad_norm: 4.1079  loss: 1.1267  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7788  loss_aux: 0.3480\n",
            "02/09 16:20:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:20:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][ 40/332]  lr: 1.0000e-02  eta: 4:43:40  time: 0.3959  data_time: 0.0110  memory: 6616  grad_norm: 2.8130  loss: 1.0878  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7312  loss_aux: 0.3566\n",
            "02/09 16:20:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][ 60/332]  lr: 1.0000e-02  eta: 4:43:31  time: 0.3943  data_time: 0.0102  memory: 6616  grad_norm: 2.6320  loss: 1.0969  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7250  loss_aux: 0.3719\n",
            "02/09 16:20:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][ 80/332]  lr: 1.0000e-02  eta: 4:43:23  time: 0.3943  data_time: 0.0104  memory: 6616  grad_norm: 3.0419  loss: 1.2204  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8050  loss_aux: 0.4154\n",
            "02/09 16:20:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][100/332]  lr: 1.0000e-02  eta: 4:43:15  time: 0.3945  data_time: 0.0102  memory: 6616  grad_norm: 2.6860  loss: 1.1573  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8027  loss_aux: 0.3546\n",
            "02/09 16:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][120/332]  lr: 1.0000e-02  eta: 4:43:06  time: 0.3942  data_time: 0.0099  memory: 6616  grad_norm: 2.4973  loss: 1.2146  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8512  loss_aux: 0.3634\n",
            "02/09 16:21:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][140/332]  lr: 1.0000e-02  eta: 4:42:58  time: 0.3959  data_time: 0.0108  memory: 6616  grad_norm: 2.6414  loss: 1.1393  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7894  loss_aux: 0.3499\n",
            "02/09 16:21:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][160/332]  lr: 1.0000e-02  eta: 4:42:50  time: 0.3963  data_time: 0.0110  memory: 6616  grad_norm: 2.6179  loss: 1.0915  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7370  loss_aux: 0.3545\n",
            "02/09 16:21:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][180/332]  lr: 1.0000e-02  eta: 4:42:41  time: 0.3938  data_time: 0.0097  memory: 6616  grad_norm: 3.2412  loss: 1.1533  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7980  loss_aux: 0.3553\n",
            "02/09 16:21:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][200/332]  lr: 1.0000e-02  eta: 4:42:33  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 2.7476  loss: 1.1113  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7190  loss_aux: 0.3923\n",
            "02/09 16:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][220/332]  lr: 1.0000e-02  eta: 4:42:25  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 2.5835  loss: 1.2216  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8115  loss_aux: 0.4101\n",
            "02/09 16:21:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][240/332]  lr: 1.0000e-02  eta: 4:42:16  time: 0.3941  data_time: 0.0096  memory: 6616  grad_norm: 4.7955  loss: 1.2187  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8498  loss_aux: 0.3689\n",
            "02/09 16:22:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][260/332]  lr: 1.0000e-02  eta: 4:42:08  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 2.2062  loss: 1.0700  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7019  loss_aux: 0.3681\n",
            "02/09 16:22:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][280/332]  lr: 1.0000e-02  eta: 4:42:00  time: 0.3954  data_time: 0.0106  memory: 6616  grad_norm: 2.5928  loss: 1.1495  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7727  loss_aux: 0.3768\n",
            "02/09 16:22:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][300/332]  lr: 1.0000e-02  eta: 4:41:52  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 2.0477  loss: 1.0437  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6596  loss_aux: 0.3840\n",
            "02/09 16:22:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][320/332]  lr: 1.0000e-02  eta: 4:41:43  time: 0.3939  data_time: 0.0096  memory: 6616  grad_norm: 2.6818  loss: 1.1291  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7688  loss_aux: 0.3603\n",
            "02/09 16:22:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:22:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][332/332]  lr: 1.0000e-02  eta: 4:41:38  time: 0.3886  data_time: 0.0090  memory: 6616  grad_norm: 2.4834  loss: 1.1486  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7645  loss_aux: 0.3842\n",
            "02/09 16:22:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 22 epochs\n",
            "02/09 16:22:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][ 20/332]  lr: 1.0000e-02  eta: 4:41:36  time: 0.4524  data_time: 0.0657  memory: 6616  grad_norm: 2.9221  loss: 1.1773  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8018  loss_aux: 0.3755\n",
            "02/09 16:22:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][ 40/332]  lr: 1.0000e-02  eta: 4:41:28  time: 0.3948  data_time: 0.0099  memory: 6616  grad_norm: 2.5462  loss: 1.1432  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7752  loss_aux: 0.3679\n",
            "02/09 16:22:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][ 60/332]  lr: 1.0000e-02  eta: 4:41:19  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 2.6929  loss: 1.1068  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7575  loss_aux: 0.3493\n",
            "02/09 16:23:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][ 80/332]  lr: 1.0000e-02  eta: 4:41:11  time: 0.3957  data_time: 0.0108  memory: 6616  grad_norm: 2.6075  loss: 1.1387  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7726  loss_aux: 0.3660\n",
            "02/09 16:23:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][100/332]  lr: 1.0000e-02  eta: 4:41:03  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 2.4829  loss: 1.1062  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7679  loss_aux: 0.3383\n",
            "02/09 16:23:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][120/332]  lr: 1.0000e-02  eta: 4:40:55  time: 0.3946  data_time: 0.0103  memory: 6616  grad_norm: 2.5732  loss: 1.1301  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7587  loss_aux: 0.3714\n",
            "02/09 16:23:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][140/332]  lr: 1.0000e-02  eta: 4:40:46  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 2.5611  loss: 1.1014  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7426  loss_aux: 0.3588\n",
            "02/09 16:23:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][160/332]  lr: 1.0000e-02  eta: 4:40:38  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 3.2068  loss: 1.0907  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7304  loss_aux: 0.3603\n",
            "02/09 16:23:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][180/332]  lr: 1.0000e-02  eta: 4:40:30  time: 0.3949  data_time: 0.0104  memory: 6616  grad_norm: 2.9249  loss: 1.1192  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7576  loss_aux: 0.3616\n",
            "02/09 16:23:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][200/332]  lr: 1.0000e-02  eta: 4:40:22  time: 0.3958  data_time: 0.0108  memory: 6616  grad_norm: 2.7213  loss: 1.1855  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8019  loss_aux: 0.3835\n",
            "02/09 16:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][220/332]  lr: 1.0000e-02  eta: 4:40:13  time: 0.3946  data_time: 0.0100  memory: 6616  grad_norm: 2.6361  loss: 1.1687  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7895  loss_aux: 0.3793\n",
            "02/09 16:24:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][240/332]  lr: 1.0000e-02  eta: 4:40:05  time: 0.3951  data_time: 0.0104  memory: 6616  grad_norm: 2.1472  loss: 1.0872  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7235  loss_aux: 0.3637\n",
            "02/09 16:24:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][260/332]  lr: 1.0000e-02  eta: 4:39:57  time: 0.3953  data_time: 0.0104  memory: 6616  grad_norm: 2.4651  loss: 1.1747  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8137  loss_aux: 0.3610\n",
            "02/09 16:24:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][280/332]  lr: 1.0000e-02  eta: 4:39:49  time: 0.3941  data_time: 0.0098  memory: 6616  grad_norm: 2.8290  loss: 1.0540  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7168  loss_aux: 0.3372\n",
            "02/09 16:24:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][300/332]  lr: 1.0000e-02  eta: 4:39:40  time: 0.3948  data_time: 0.0105  memory: 6616  grad_norm: 3.7690  loss: 1.2721  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8818  loss_aux: 0.3903\n",
            "02/09 16:24:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][320/332]  lr: 1.0000e-02  eta: 4:39:32  time: 0.3948  data_time: 0.0101  memory: 6616  grad_norm: 2.7704  loss: 1.1368  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7618  loss_aux: 0.3750\n",
            "02/09 16:24:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:24:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][332/332]  lr: 1.0000e-02  eta: 4:39:27  time: 0.3902  data_time: 0.0095  memory: 6616  grad_norm: 2.9978  loss: 1.0927  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7225  loss_aux: 0.3701\n",
            "02/09 16:24:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 23 epochs\n",
            "02/09 16:24:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][ 20/332]  lr: 1.0000e-02  eta: 4:39:23  time: 0.4405  data_time: 0.0523  memory: 6616  grad_norm: 3.7926  loss: 1.1680  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7908  loss_aux: 0.3772\n",
            "02/09 16:25:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][ 40/332]  lr: 1.0000e-02  eta: 4:39:15  time: 0.3963  data_time: 0.0112  memory: 6616  grad_norm: 3.2547  loss: 1.1660  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7892  loss_aux: 0.3768\n",
            "02/09 16:25:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][ 60/332]  lr: 1.0000e-02  eta: 4:39:07  time: 0.3946  data_time: 0.0099  memory: 6616  grad_norm: 2.6992  loss: 1.1725  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7837  loss_aux: 0.3888\n",
            "02/09 16:25:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][ 80/332]  lr: 1.0000e-02  eta: 4:38:59  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 2.8425  loss: 1.2332  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8475  loss_aux: 0.3857\n",
            "02/09 16:25:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][100/332]  lr: 1.0000e-02  eta: 4:38:51  time: 0.3957  data_time: 0.0107  memory: 6616  grad_norm: 2.6028  loss: 1.0843  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7067  loss_aux: 0.3776\n",
            "02/09 16:25:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][120/332]  lr: 1.0000e-02  eta: 4:38:42  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 2.7491  loss: 1.1235  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7436  loss_aux: 0.3799\n",
            "02/09 16:25:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][140/332]  lr: 1.0000e-02  eta: 4:38:34  time: 0.3944  data_time: 0.0101  memory: 6616  grad_norm: 2.8839  loss: 1.1335  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7649  loss_aux: 0.3686\n",
            "02/09 16:25:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][160/332]  lr: 1.0000e-02  eta: 4:38:26  time: 0.3943  data_time: 0.0100  memory: 6616  grad_norm: 3.1145  loss: 1.1372  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7488  loss_aux: 0.3883\n",
            "02/09 16:25:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][180/332]  lr: 1.0000e-02  eta: 4:38:17  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 2.6578  loss: 1.1406  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7442  loss_aux: 0.3964\n",
            "02/09 16:26:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][200/332]  lr: 1.0000e-02  eta: 4:38:09  time: 0.3957  data_time: 0.0108  memory: 6616  grad_norm: 2.5019  loss: 1.1369  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7546  loss_aux: 0.3822\n",
            "02/09 16:26:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][220/332]  lr: 1.0000e-02  eta: 4:38:01  time: 0.3947  data_time: 0.0100  memory: 6616  grad_norm: 3.0161  loss: 1.1201  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7422  loss_aux: 0.3780\n",
            "02/09 16:26:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][240/332]  lr: 1.0000e-02  eta: 4:37:53  time: 0.3959  data_time: 0.0104  memory: 6616  grad_norm: 2.9824  loss: 1.1311  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7552  loss_aux: 0.3759\n",
            "02/09 16:26:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][260/332]  lr: 1.0000e-02  eta: 4:37:45  time: 0.3952  data_time: 0.0104  memory: 6616  grad_norm: 2.8826  loss: 1.1326  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7806  loss_aux: 0.3520\n",
            "02/09 16:26:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][280/332]  lr: 1.0000e-02  eta: 4:37:36  time: 0.3949  data_time: 0.0099  memory: 6616  grad_norm: 2.8584  loss: 1.0853  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7233  loss_aux: 0.3620\n",
            "02/09 16:26:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][300/332]  lr: 1.0000e-02  eta: 4:37:28  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 2.5355  loss: 1.0569  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7196  loss_aux: 0.3373\n",
            "02/09 16:26:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][320/332]  lr: 1.0000e-02  eta: 4:37:20  time: 0.3940  data_time: 0.0096  memory: 6616  grad_norm: 4.7888  loss: 1.1039  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7414  loss_aux: 0.3625\n",
            "02/09 16:26:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:26:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][332/332]  lr: 1.0000e-02  eta: 4:37:14  time: 0.3898  data_time: 0.0095  memory: 6616  grad_norm: 4.0461  loss: 1.0964  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7331  loss_aux: 0.3633\n",
            "02/09 16:26:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 24 epochs\n",
            "02/09 16:27:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][ 20/332]  lr: 1.0000e-02  eta: 4:37:11  time: 0.4415  data_time: 0.0541  memory: 6616  grad_norm: 3.0608  loss: 1.1263  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7911  loss_aux: 0.3353\n",
            "02/09 16:27:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:27:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][ 40/332]  lr: 1.0000e-02  eta: 4:37:03  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 2.9458  loss: 1.1361  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7662  loss_aux: 0.3699\n",
            "02/09 16:27:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][ 60/332]  lr: 1.0000e-02  eta: 4:36:54  time: 0.3938  data_time: 0.0095  memory: 6616  grad_norm: 3.2623  loss: 1.1015  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7467  loss_aux: 0.3549\n",
            "02/09 16:27:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][ 80/332]  lr: 1.0000e-02  eta: 4:36:46  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 2.7136  loss: 1.1275  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7478  loss_aux: 0.3797\n",
            "02/09 16:27:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][100/332]  lr: 1.0000e-02  eta: 4:36:38  time: 0.3940  data_time: 0.0097  memory: 6616  grad_norm: 2.6046  loss: 1.1449  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7866  loss_aux: 0.3583\n",
            "02/09 16:27:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][120/332]  lr: 1.0000e-02  eta: 4:36:29  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 2.4112  loss: 1.0791  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7108  loss_aux: 0.3683\n",
            "02/09 16:27:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][140/332]  lr: 1.0000e-02  eta: 4:36:21  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 2.6833  loss: 1.0833  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7307  loss_aux: 0.3526\n",
            "02/09 16:28:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][160/332]  lr: 1.0000e-02  eta: 4:36:13  time: 0.3943  data_time: 0.0099  memory: 6616  grad_norm: 2.4353  loss: 1.1398  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8020  loss_aux: 0.3378\n",
            "02/09 16:28:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][180/332]  lr: 1.0000e-02  eta: 4:36:05  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 2.4459  loss: 1.1584  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7811  loss_aux: 0.3773\n",
            "02/09 16:28:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][200/332]  lr: 1.0000e-02  eta: 4:35:57  time: 0.3948  data_time: 0.0098  memory: 6616  grad_norm: 2.4285  loss: 1.0714  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7093  loss_aux: 0.3620\n",
            "02/09 16:28:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][220/332]  lr: 1.0000e-02  eta: 4:35:48  time: 0.3946  data_time: 0.0097  memory: 6616  grad_norm: 2.5158  loss: 1.1297  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7459  loss_aux: 0.3838\n",
            "02/09 16:28:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][240/332]  lr: 1.0000e-02  eta: 4:35:40  time: 0.3966  data_time: 0.0109  memory: 6616  grad_norm: 2.0943  loss: 1.0915  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7287  loss_aux: 0.3628\n",
            "02/09 16:28:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][260/332]  lr: 1.0000e-02  eta: 4:35:32  time: 0.3941  data_time: 0.0096  memory: 6616  grad_norm: 4.0353  loss: 1.1975  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8180  loss_aux: 0.3794\n",
            "02/09 16:28:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][280/332]  lr: 1.0000e-02  eta: 4:35:24  time: 0.3946  data_time: 0.0099  memory: 6616  grad_norm: 3.5227  loss: 1.1697  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7972  loss_aux: 0.3726\n",
            "02/09 16:29:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][300/332]  lr: 1.0000e-02  eta: 4:35:15  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 3.4426  loss: 1.0798  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7197  loss_aux: 0.3601\n",
            "02/09 16:29:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][320/332]  lr: 1.0000e-02  eta: 4:35:07  time: 0.3941  data_time: 0.0098  memory: 6616  grad_norm: 2.8038  loss: 1.2008  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8317  loss_aux: 0.3692\n",
            "02/09 16:29:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:29:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][332/332]  lr: 1.0000e-02  eta: 4:35:02  time: 0.3898  data_time: 0.0097  memory: 6616  grad_norm: 2.8984  loss: 1.1942  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.8262  loss_aux: 0.3680\n",
            "02/09 16:29:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 25 epochs\n",
            "02/09 16:29:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][ 20/332]  lr: 1.0000e-02  eta: 4:34:58  time: 0.4373  data_time: 0.0500  memory: 6616  grad_norm: 2.8970  loss: 1.1816  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8129  loss_aux: 0.3688\n",
            "02/09 16:29:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][ 40/332]  lr: 1.0000e-02  eta: 4:34:49  time: 0.3943  data_time: 0.0096  memory: 6616  grad_norm: 2.4701  loss: 1.0984  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.7544  loss_aux: 0.3439\n",
            "02/09 16:29:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][ 60/332]  lr: 1.0000e-02  eta: 4:34:41  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 2.9344  loss: 1.0881  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7416  loss_aux: 0.3466\n",
            "02/09 16:29:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][ 80/332]  lr: 1.0000e-02  eta: 4:34:33  time: 0.3951  data_time: 0.0106  memory: 6616  grad_norm: 2.1908  loss: 1.0836  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7301  loss_aux: 0.3535\n",
            "02/09 16:29:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][100/332]  lr: 1.0000e-02  eta: 4:34:25  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 2.2780  loss: 1.0917  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7354  loss_aux: 0.3563\n",
            "02/09 16:30:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][120/332]  lr: 1.0000e-02  eta: 4:34:17  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 2.4235  loss: 1.1039  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7400  loss_aux: 0.3639\n",
            "02/09 16:30:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][140/332]  lr: 1.0000e-02  eta: 4:34:08  time: 0.3950  data_time: 0.0103  memory: 6616  grad_norm: 2.5068  loss: 1.0935  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7444  loss_aux: 0.3490\n",
            "02/09 16:30:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][160/332]  lr: 1.0000e-02  eta: 4:34:00  time: 0.3945  data_time: 0.0099  memory: 6616  grad_norm: 2.8313  loss: 1.1503  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7670  loss_aux: 0.3833\n",
            "02/09 16:30:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][180/332]  lr: 1.0000e-02  eta: 4:33:52  time: 0.3959  data_time: 0.0106  memory: 6616  grad_norm: 4.2088  loss: 1.1263  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7738  loss_aux: 0.3525\n",
            "02/09 16:30:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][200/332]  lr: 1.0000e-02  eta: 4:33:44  time: 0.3946  data_time: 0.0098  memory: 6616  grad_norm: 3.2754  loss: 1.1934  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8221  loss_aux: 0.3713\n",
            "02/09 16:30:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][220/332]  lr: 1.0000e-02  eta: 4:33:35  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 2.3294  loss: 1.0573  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7300  loss_aux: 0.3273\n",
            "02/09 16:30:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][240/332]  lr: 1.0000e-02  eta: 4:33:27  time: 0.3956  data_time: 0.0109  memory: 6616  grad_norm: 3.7780  loss: 1.1881  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8166  loss_aux: 0.3715\n",
            "02/09 16:30:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][260/332]  lr: 1.0000e-02  eta: 4:33:19  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 3.1489  loss: 1.2256  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.8324  loss_aux: 0.3933\n",
            "02/09 16:31:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][280/332]  lr: 1.0000e-02  eta: 4:33:11  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 4.1364  loss: 1.1757  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8097  loss_aux: 0.3660\n",
            "02/09 16:31:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][300/332]  lr: 1.0000e-02  eta: 4:33:03  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 2.4474  loss: 1.0923  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7580  loss_aux: 0.3343\n",
            "02/09 16:31:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][320/332]  lr: 1.0000e-02  eta: 4:32:54  time: 0.3940  data_time: 0.0097  memory: 6616  grad_norm: 2.6930  loss: 1.1259  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7459  loss_aux: 0.3800\n",
            "02/09 16:31:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:31:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][332/332]  lr: 1.0000e-02  eta: 4:32:49  time: 0.3886  data_time: 0.0091  memory: 6616  grad_norm: 3.8472  loss: 1.2038  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.8335  loss_aux: 0.3703\n",
            "02/09 16:31:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 26 epochs\n",
            "02/09 16:31:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][ 20/332]  lr: 1.0000e-02  eta: 4:32:45  time: 0.4416  data_time: 0.0540  memory: 6616  grad_norm: 2.4078  loss: 1.1712  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7913  loss_aux: 0.3798\n",
            "02/09 16:31:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][ 40/332]  lr: 1.0000e-02  eta: 4:32:37  time: 0.3942  data_time: 0.0100  memory: 6616  grad_norm: 2.6451  loss: 1.0945  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7236  loss_aux: 0.3709\n",
            "02/09 16:31:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][ 60/332]  lr: 1.0000e-02  eta: 4:32:29  time: 0.3949  data_time: 0.0104  memory: 6616  grad_norm: 2.1971  loss: 1.0865  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7355  loss_aux: 0.3510\n",
            "02/09 16:32:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][ 80/332]  lr: 1.0000e-02  eta: 4:32:20  time: 0.3953  data_time: 0.0104  memory: 6616  grad_norm: 2.5399  loss: 1.1817  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7980  loss_aux: 0.3837\n",
            "02/09 16:32:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][100/332]  lr: 1.0000e-02  eta: 4:32:12  time: 0.3946  data_time: 0.0102  memory: 6616  grad_norm: 2.1029  loss: 1.1156  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7381  loss_aux: 0.3775\n",
            "02/09 16:32:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][120/332]  lr: 1.0000e-02  eta: 4:32:04  time: 0.3955  data_time: 0.0108  memory: 6616  grad_norm: 2.2514  loss: 1.1266  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7809  loss_aux: 0.3458\n",
            "02/09 16:32:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][140/332]  lr: 1.0000e-02  eta: 4:31:56  time: 0.3954  data_time: 0.0110  memory: 6616  grad_norm: 2.1419  loss: 1.0803  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7285  loss_aux: 0.3518\n",
            "02/09 16:32:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][160/332]  lr: 1.0000e-02  eta: 4:31:48  time: 0.3948  data_time: 0.0107  memory: 6616  grad_norm: 2.3356  loss: 1.0519  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6846  loss_aux: 0.3674\n",
            "02/09 16:32:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][180/332]  lr: 1.0000e-02  eta: 4:31:39  time: 0.3959  data_time: 0.0108  memory: 6616  grad_norm: 2.5200  loss: 1.1836  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8063  loss_aux: 0.3773\n",
            "02/09 16:32:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][200/332]  lr: 1.0000e-02  eta: 4:31:31  time: 0.3955  data_time: 0.0109  memory: 6616  grad_norm: 2.3394  loss: 1.1082  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7598  loss_aux: 0.3484\n",
            "02/09 16:32:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][220/332]  lr: 1.0000e-02  eta: 4:31:23  time: 0.3964  data_time: 0.0110  memory: 6616  grad_norm: 2.3929  loss: 1.0490  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7068  loss_aux: 0.3423\n",
            "02/09 16:33:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][240/332]  lr: 1.0000e-02  eta: 4:31:15  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 2.2739  loss: 1.0932  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7247  loss_aux: 0.3684\n",
            "02/09 16:33:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][260/332]  lr: 1.0000e-02  eta: 4:31:07  time: 0.3948  data_time: 0.0101  memory: 6616  grad_norm: 2.3354  loss: 1.1370  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7610  loss_aux: 0.3760\n",
            "02/09 16:33:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][280/332]  lr: 1.0000e-02  eta: 4:30:59  time: 0.3942  data_time: 0.0098  memory: 6616  grad_norm: 3.1690  loss: 1.2626  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9014  loss_aux: 0.3612\n",
            "02/09 16:33:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][300/332]  lr: 1.0000e-02  eta: 4:30:50  time: 0.3954  data_time: 0.0110  memory: 6616  grad_norm: 2.8667  loss: 1.1826  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8170  loss_aux: 0.3655\n",
            "02/09 16:33:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][320/332]  lr: 1.0000e-02  eta: 4:30:42  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 2.4337  loss: 1.1472  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7837  loss_aux: 0.3635\n",
            "02/09 16:33:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:33:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][332/332]  lr: 1.0000e-02  eta: 4:30:37  time: 0.3893  data_time: 0.0094  memory: 6616  grad_norm: 3.0315  loss: 1.1530  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7796  loss_aux: 0.3734\n",
            "02/09 16:33:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 27 epochs\n",
            "02/09 16:33:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][ 20/332]  lr: 1.0000e-02  eta: 4:30:33  time: 0.4463  data_time: 0.0578  memory: 6616  grad_norm: 2.5277  loss: 1.1294  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7586  loss_aux: 0.3708\n",
            "02/09 16:34:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:34:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][ 40/332]  lr: 1.0000e-02  eta: 4:30:25  time: 0.3952  data_time: 0.0104  memory: 6616  grad_norm: 2.4780  loss: 1.0980  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7347  loss_aux: 0.3633\n",
            "02/09 16:34:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][ 60/332]  lr: 1.0000e-02  eta: 4:30:17  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 2.2746  loss: 1.0929  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7123  loss_aux: 0.3806\n",
            "02/09 16:34:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][ 80/332]  lr: 1.0000e-02  eta: 4:30:09  time: 0.3959  data_time: 0.0110  memory: 6616  grad_norm: 2.3320  loss: 1.1107  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7484  loss_aux: 0.3623\n",
            "02/09 16:34:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][100/332]  lr: 1.0000e-02  eta: 4:30:00  time: 0.3943  data_time: 0.0100  memory: 6616  grad_norm: 2.7592  loss: 1.1128  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7304  loss_aux: 0.3824\n",
            "02/09 16:34:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][120/332]  lr: 1.0000e-02  eta: 4:29:52  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 3.1159  loss: 1.0647  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6914  loss_aux: 0.3733\n",
            "02/09 16:34:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][140/332]  lr: 1.0000e-02  eta: 4:29:44  time: 0.3943  data_time: 0.0098  memory: 6616  grad_norm: 5.2989  loss: 1.0861  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7509  loss_aux: 0.3351\n",
            "02/09 16:34:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][160/332]  lr: 1.0000e-02  eta: 4:29:36  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 2.1275  loss: 1.1097  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7448  loss_aux: 0.3649\n",
            "02/09 16:34:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][180/332]  lr: 1.0000e-02  eta: 4:29:28  time: 0.3953  data_time: 0.0101  memory: 6616  grad_norm: 2.0689  loss: 1.1031  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7411  loss_aux: 0.3620\n",
            "02/09 16:35:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][200/332]  lr: 1.0000e-02  eta: 4:29:19  time: 0.3943  data_time: 0.0097  memory: 6616  grad_norm: 1.8215  loss: 1.0038  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6595  loss_aux: 0.3443\n",
            "02/09 16:35:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][220/332]  lr: 1.0000e-02  eta: 4:29:11  time: 0.3966  data_time: 0.0113  memory: 6616  grad_norm: 2.2337  loss: 1.1437  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7549  loss_aux: 0.3888\n",
            "02/09 16:35:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][240/332]  lr: 1.0000e-02  eta: 4:29:03  time: 0.3958  data_time: 0.0107  memory: 6616  grad_norm: 2.4484  loss: 1.1640  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7739  loss_aux: 0.3901\n",
            "02/09 16:35:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][260/332]  lr: 1.0000e-02  eta: 4:28:55  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 2.5403  loss: 1.1557  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7585  loss_aux: 0.3973\n",
            "02/09 16:35:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][280/332]  lr: 1.0000e-02  eta: 4:28:47  time: 0.3962  data_time: 0.0111  memory: 6616  grad_norm: 2.0955  loss: 1.1058  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7521  loss_aux: 0.3537\n",
            "02/09 16:35:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][300/332]  lr: 1.0000e-02  eta: 4:28:39  time: 0.3957  data_time: 0.0107  memory: 6616  grad_norm: 2.5219  loss: 1.1231  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7730  loss_aux: 0.3501\n",
            "02/09 16:35:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][320/332]  lr: 1.0000e-02  eta: 4:28:31  time: 0.3952  data_time: 0.0104  memory: 6616  grad_norm: 2.3361  loss: 1.1463  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7786  loss_aux: 0.3677\n",
            "02/09 16:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][332/332]  lr: 1.0000e-02  eta: 4:28:25  time: 0.3898  data_time: 0.0096  memory: 6616  grad_norm: 2.5762  loss: 1.1203  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.7770  loss_aux: 0.3433\n",
            "02/09 16:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 28 epochs\n",
            "02/09 16:36:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][ 20/332]  lr: 1.0000e-02  eta: 4:28:22  time: 0.4461  data_time: 0.0574  memory: 6616  grad_norm: 1.8883  loss: 1.0615  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.7038  loss_aux: 0.3577\n",
            "02/09 16:36:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][ 40/332]  lr: 1.0000e-02  eta: 4:28:13  time: 0.3942  data_time: 0.0094  memory: 6616  grad_norm: 2.4872  loss: 1.1376  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7664  loss_aux: 0.3712\n",
            "02/09 16:36:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][ 60/332]  lr: 1.0000e-02  eta: 4:28:05  time: 0.3948  data_time: 0.0101  memory: 6616  grad_norm: 2.2163  loss: 1.0837  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7016  loss_aux: 0.3821\n",
            "02/09 16:36:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][ 80/332]  lr: 1.0000e-02  eta: 4:27:57  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 2.7479  loss: 1.0470  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7093  loss_aux: 0.3377\n",
            "02/09 16:36:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][100/332]  lr: 1.0000e-02  eta: 4:27:49  time: 0.3935  data_time: 0.0096  memory: 6616  grad_norm: 3.0708  loss: 1.2233  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8215  loss_aux: 0.4018\n",
            "02/09 16:36:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][120/332]  lr: 1.0000e-02  eta: 4:27:41  time: 0.3971  data_time: 0.0112  memory: 6616  grad_norm: 2.8842  loss: 1.0776  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7320  loss_aux: 0.3456\n",
            "02/09 16:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][140/332]  lr: 1.0000e-02  eta: 4:27:32  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 2.2226  loss: 1.0465  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7096  loss_aux: 0.3369\n",
            "02/09 16:37:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][160/332]  lr: 1.0000e-02  eta: 4:27:24  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 3.7981  loss: 1.1267  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7642  loss_aux: 0.3625\n",
            "02/09 16:37:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][180/332]  lr: 1.0000e-02  eta: 4:27:16  time: 0.3955  data_time: 0.0107  memory: 6616  grad_norm: 2.3611  loss: 1.0563  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7008  loss_aux: 0.3555\n",
            "02/09 16:37:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][200/332]  lr: 1.0000e-02  eta: 4:27:08  time: 0.3949  data_time: 0.0104  memory: 6616  grad_norm: 2.9506  loss: 1.1127  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7506  loss_aux: 0.3621\n",
            "02/09 16:37:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][220/332]  lr: 1.0000e-02  eta: 4:27:00  time: 0.3944  data_time: 0.0101  memory: 6616  grad_norm: 2.7031  loss: 1.1374  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7489  loss_aux: 0.3884\n",
            "02/09 16:37:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][240/332]  lr: 1.0000e-02  eta: 4:26:52  time: 0.3951  data_time: 0.0102  memory: 6616  grad_norm: 2.3165  loss: 1.1254  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7476  loss_aux: 0.3778\n",
            "02/09 16:37:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][260/332]  lr: 1.0000e-02  eta: 4:26:43  time: 0.3943  data_time: 0.0100  memory: 6616  grad_norm: 3.3488  loss: 1.1724  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8002  loss_aux: 0.3722\n",
            "02/09 16:37:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][280/332]  lr: 1.0000e-02  eta: 4:26:35  time: 0.3951  data_time: 0.0106  memory: 6616  grad_norm: 2.5066  loss: 1.2086  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8427  loss_aux: 0.3658\n",
            "02/09 16:37:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][300/332]  lr: 1.0000e-02  eta: 4:26:27  time: 0.3958  data_time: 0.0104  memory: 6616  grad_norm: 3.6877  loss: 1.1092  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7547  loss_aux: 0.3544\n",
            "02/09 16:38:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][320/332]  lr: 1.0000e-02  eta: 4:26:19  time: 0.3941  data_time: 0.0098  memory: 6616  grad_norm: 2.3115  loss: 1.1402  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7733  loss_aux: 0.3670\n",
            "02/09 16:38:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:38:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][332/332]  lr: 1.0000e-02  eta: 4:26:14  time: 0.3897  data_time: 0.0092  memory: 6616  grad_norm: 2.3305  loss: 1.1235  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7718  loss_aux: 0.3517\n",
            "02/09 16:38:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 29 epochs\n",
            "02/09 16:38:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][ 20/332]  lr: 1.0000e-02  eta: 4:26:10  time: 0.4526  data_time: 0.0645  memory: 6616  grad_norm: 2.3079  loss: 1.1244  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7536  loss_aux: 0.3708\n",
            "02/09 16:38:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][ 40/332]  lr: 1.0000e-02  eta: 4:26:02  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 4.3582  loss: 1.0837  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7350  loss_aux: 0.3488\n",
            "02/09 16:38:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][ 60/332]  lr: 1.0000e-02  eta: 4:25:54  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 2.0546  loss: 1.0486  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7028  loss_aux: 0.3458\n",
            "02/09 16:38:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][ 80/332]  lr: 1.0000e-02  eta: 4:25:46  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 2.7243  loss: 1.0873  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7308  loss_aux: 0.3566\n",
            "02/09 16:38:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][100/332]  lr: 1.0000e-02  eta: 4:25:37  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 3.3152  loss: 1.1484  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7757  loss_aux: 0.3727\n",
            "02/09 16:39:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][120/332]  lr: 1.0000e-02  eta: 4:25:29  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 2.9346  loss: 1.0657  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6991  loss_aux: 0.3666\n",
            "02/09 16:39:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][140/332]  lr: 1.0000e-02  eta: 4:25:21  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 2.8316  loss: 1.0943  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7569  loss_aux: 0.3374\n",
            "02/09 16:39:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][160/332]  lr: 1.0000e-02  eta: 4:25:13  time: 0.3955  data_time: 0.0105  memory: 6616  grad_norm: 2.3141  loss: 1.0660  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7167  loss_aux: 0.3493\n",
            "02/09 16:39:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][180/332]  lr: 1.0000e-02  eta: 4:25:05  time: 0.3944  data_time: 0.0098  memory: 6616  grad_norm: 2.3728  loss: 1.0308  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6922  loss_aux: 0.3387\n",
            "02/09 16:39:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][200/332]  lr: 1.0000e-02  eta: 4:24:56  time: 0.3940  data_time: 0.0097  memory: 6616  grad_norm: 2.0961  loss: 1.0843  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7216  loss_aux: 0.3627\n",
            "02/09 16:39:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][220/332]  lr: 1.0000e-02  eta: 4:24:48  time: 0.3954  data_time: 0.0106  memory: 6616  grad_norm: 2.3887  loss: 1.1523  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7750  loss_aux: 0.3773\n",
            "02/09 16:39:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][240/332]  lr: 1.0000e-02  eta: 4:24:40  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 2.3039  loss: 1.1212  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7597  loss_aux: 0.3615\n",
            "02/09 16:39:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][260/332]  lr: 1.0000e-02  eta: 4:24:32  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 2.6703  loss: 1.1317  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7555  loss_aux: 0.3762\n",
            "02/09 16:40:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][280/332]  lr: 1.0000e-02  eta: 4:24:24  time: 0.3944  data_time: 0.0098  memory: 6616  grad_norm: 2.9809  loss: 1.1374  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7734  loss_aux: 0.3640\n",
            "02/09 16:40:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][300/332]  lr: 1.0000e-02  eta: 4:24:16  time: 0.3946  data_time: 0.0099  memory: 6616  grad_norm: 3.3430  loss: 1.1131  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7380  loss_aux: 0.3752\n",
            "02/09 16:40:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][320/332]  lr: 1.0000e-02  eta: 4:24:07  time: 0.3938  data_time: 0.0096  memory: 6616  grad_norm: 2.3805  loss: 1.1291  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7638  loss_aux: 0.3654\n",
            "02/09 16:40:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:40:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][332/332]  lr: 1.0000e-02  eta: 4:24:02  time: 0.3897  data_time: 0.0097  memory: 6616  grad_norm: 3.6393  loss: 1.0604  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7051  loss_aux: 0.3554\n",
            "02/09 16:40:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 30 epochs\n",
            "02/09 16:40:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [30][20/42]    eta: 0:00:03  time: 0.1779  data_time: 0.0723  memory: 1447  \n",
            "02/09 16:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [30][40/42]    eta: 0:00:00  time: 0.1164  data_time: 0.0142  memory: 1447  \n",
            "02/09 16:40:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][42/42]    acc/top1: 0.5151  acc/top5: 1.0000  acc/mean1: 0.4955  data_time: 0.0407  time: 0.1420\n",
            "02/09 16:40:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][ 20/332]  lr: 1.0000e-02  eta: 4:23:58  time: 0.4451  data_time: 0.0593  memory: 6616  grad_norm: 2.3401  loss: 1.0755  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7108  loss_aux: 0.3647\n",
            "02/09 16:40:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:40:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][ 40/332]  lr: 1.0000e-02  eta: 4:23:50  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 1.9586  loss: 1.0519  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6834  loss_aux: 0.3686\n",
            "02/09 16:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][ 60/332]  lr: 1.0000e-02  eta: 4:23:41  time: 0.3944  data_time: 0.0098  memory: 6616  grad_norm: 2.6080  loss: 1.1408  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7715  loss_aux: 0.3693\n",
            "02/09 16:41:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][ 80/332]  lr: 1.0000e-02  eta: 4:23:33  time: 0.3947  data_time: 0.0105  memory: 6616  grad_norm: 2.1745  loss: 1.1255  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7516  loss_aux: 0.3738\n",
            "02/09 16:41:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][100/332]  lr: 1.0000e-02  eta: 4:23:25  time: 0.3947  data_time: 0.0104  memory: 6616  grad_norm: 2.3831  loss: 1.0986  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7301  loss_aux: 0.3685\n",
            "02/09 16:41:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][120/332]  lr: 1.0000e-02  eta: 4:23:17  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 2.2912  loss: 1.0623  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7146  loss_aux: 0.3477\n",
            "02/09 16:41:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][140/332]  lr: 1.0000e-02  eta: 4:23:09  time: 0.3953  data_time: 0.0104  memory: 6616  grad_norm: 3.1223  loss: 1.2092  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8277  loss_aux: 0.3815\n",
            "02/09 16:41:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][160/332]  lr: 1.0000e-02  eta: 4:23:00  time: 0.3946  data_time: 0.0100  memory: 6616  grad_norm: 2.3367  loss: 1.1220  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7637  loss_aux: 0.3584\n",
            "02/09 16:41:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][180/332]  lr: 1.0000e-02  eta: 4:22:52  time: 0.3949  data_time: 0.0105  memory: 6616  grad_norm: 2.6750  loss: 1.0634  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7009  loss_aux: 0.3625\n",
            "02/09 16:41:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][200/332]  lr: 1.0000e-02  eta: 4:22:44  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 2.3410  loss: 1.1200  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7604  loss_aux: 0.3596\n",
            "02/09 16:42:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][220/332]  lr: 1.0000e-02  eta: 4:22:36  time: 0.3946  data_time: 0.0102  memory: 6616  grad_norm: 2.1317  loss: 1.0887  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7444  loss_aux: 0.3444\n",
            "02/09 16:42:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][240/332]  lr: 1.0000e-02  eta: 4:22:28  time: 0.3954  data_time: 0.0106  memory: 6616  grad_norm: 3.9885  loss: 1.2881  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.9057  loss_aux: 0.3824\n",
            "02/09 16:42:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][260/332]  lr: 1.0000e-02  eta: 4:22:20  time: 0.3956  data_time: 0.0109  memory: 6616  grad_norm: 2.1082  loss: 0.9988  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6495  loss_aux: 0.3493\n",
            "02/09 16:42:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][280/332]  lr: 1.0000e-02  eta: 4:22:11  time: 0.3941  data_time: 0.0100  memory: 6616  grad_norm: 2.4726  loss: 1.1165  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7673  loss_aux: 0.3492\n",
            "02/09 16:42:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][300/332]  lr: 1.0000e-02  eta: 4:22:04  time: 0.3992  data_time: 0.0108  memory: 6616  grad_norm: 2.3594  loss: 1.1222  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7576  loss_aux: 0.3646\n",
            "02/09 16:42:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][320/332]  lr: 1.0000e-02  eta: 4:21:55  time: 0.3943  data_time: 0.0103  memory: 6616  grad_norm: 2.1950  loss: 1.1183  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7462  loss_aux: 0.3721\n",
            "02/09 16:42:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:42:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][332/332]  lr: 1.0000e-02  eta: 4:21:50  time: 0.3896  data_time: 0.0098  memory: 6616  grad_norm: 2.2349  loss: 1.1703  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7951  loss_aux: 0.3752\n",
            "02/09 16:42:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 31 epochs\n",
            "02/09 16:42:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][ 20/332]  lr: 1.0000e-02  eta: 4:21:46  time: 0.4473  data_time: 0.0619  memory: 6616  grad_norm: 2.2846  loss: 1.1464  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8040  loss_aux: 0.3425\n",
            "02/09 16:43:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][ 40/332]  lr: 1.0000e-02  eta: 4:21:38  time: 0.3951  data_time: 0.0106  memory: 6616  grad_norm: 2.7065  loss: 1.2070  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8226  loss_aux: 0.3844\n",
            "02/09 16:43:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][ 60/332]  lr: 1.0000e-02  eta: 4:21:30  time: 0.3944  data_time: 0.0103  memory: 6616  grad_norm: 2.2929  loss: 1.1244  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7592  loss_aux: 0.3652\n",
            "02/09 16:43:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][ 80/332]  lr: 1.0000e-02  eta: 4:21:21  time: 0.3944  data_time: 0.0101  memory: 6616  grad_norm: 2.7358  loss: 1.0525  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7036  loss_aux: 0.3490\n",
            "02/09 16:43:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][100/332]  lr: 1.0000e-02  eta: 4:21:13  time: 0.3941  data_time: 0.0100  memory: 6616  grad_norm: 2.4470  loss: 1.1480  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7891  loss_aux: 0.3588\n",
            "02/09 16:43:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][120/332]  lr: 1.0000e-02  eta: 4:21:05  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 1.9310  loss: 1.0849  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7266  loss_aux: 0.3583\n",
            "02/09 16:43:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][140/332]  lr: 1.0000e-02  eta: 4:20:57  time: 0.3949  data_time: 0.0105  memory: 6616  grad_norm: 2.5311  loss: 1.1771  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.7938  loss_aux: 0.3833\n",
            "02/09 16:43:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][160/332]  lr: 1.0000e-02  eta: 4:20:49  time: 0.3940  data_time: 0.0100  memory: 6616  grad_norm: 2.2081  loss: 1.1363  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7580  loss_aux: 0.3783\n",
            "02/09 16:44:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][180/332]  lr: 1.0000e-02  eta: 4:20:40  time: 0.3952  data_time: 0.0105  memory: 6616  grad_norm: 2.1471  loss: 1.1216  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7446  loss_aux: 0.3771\n",
            "02/09 16:44:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][200/332]  lr: 1.0000e-02  eta: 4:20:32  time: 0.3941  data_time: 0.0103  memory: 6616  grad_norm: 2.0962  loss: 1.0554  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7079  loss_aux: 0.3475\n",
            "02/09 16:44:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][220/332]  lr: 1.0000e-02  eta: 4:20:24  time: 0.3949  data_time: 0.0103  memory: 6616  grad_norm: 2.9686  loss: 1.1481  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7643  loss_aux: 0.3837\n",
            "02/09 16:44:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][240/332]  lr: 1.0000e-02  eta: 4:20:16  time: 0.3948  data_time: 0.0104  memory: 6616  grad_norm: 2.2210  loss: 1.0895  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7168  loss_aux: 0.3727\n",
            "02/09 16:44:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][260/332]  lr: 1.0000e-02  eta: 4:20:08  time: 0.3948  data_time: 0.0104  memory: 6616  grad_norm: 2.1649  loss: 1.1199  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7391  loss_aux: 0.3808\n",
            "02/09 16:44:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][280/332]  lr: 1.0000e-02  eta: 4:20:00  time: 0.3949  data_time: 0.0104  memory: 6616  grad_norm: 1.9717  loss: 1.1114  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7354  loss_aux: 0.3760\n",
            "02/09 16:44:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][300/332]  lr: 1.0000e-02  eta: 4:19:51  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 1.8748  loss: 1.1054  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7450  loss_aux: 0.3604\n",
            "02/09 16:44:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][320/332]  lr: 1.0000e-02  eta: 4:19:43  time: 0.3944  data_time: 0.0098  memory: 6616  grad_norm: 2.0746  loss: 1.1256  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7841  loss_aux: 0.3415\n",
            "02/09 16:45:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:45:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][332/332]  lr: 1.0000e-02  eta: 4:19:38  time: 0.3891  data_time: 0.0092  memory: 6616  grad_norm: 2.9375  loss: 1.1395  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7724  loss_aux: 0.3671\n",
            "02/09 16:45:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 32 epochs\n",
            "02/09 16:45:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][ 20/332]  lr: 1.0000e-02  eta: 4:19:33  time: 0.4415  data_time: 0.0533  memory: 6616  grad_norm: 2.3223  loss: 1.1509  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7739  loss_aux: 0.3771\n",
            "02/09 16:45:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][ 40/332]  lr: 1.0000e-02  eta: 4:19:25  time: 0.3951  data_time: 0.0102  memory: 6616  grad_norm: 2.1314  loss: 1.1526  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7801  loss_aux: 0.3725\n",
            "02/09 16:45:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][ 60/332]  lr: 1.0000e-02  eta: 4:19:17  time: 0.3949  data_time: 0.0103  memory: 6616  grad_norm: 2.0471  loss: 1.1265  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7737  loss_aux: 0.3528\n",
            "02/09 16:45:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][ 80/332]  lr: 1.0000e-02  eta: 4:19:09  time: 0.3950  data_time: 0.0103  memory: 6616  grad_norm: 2.1262  loss: 1.1485  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7854  loss_aux: 0.3631\n",
            "02/09 16:45:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][100/332]  lr: 1.0000e-02  eta: 4:19:01  time: 0.3945  data_time: 0.0098  memory: 6616  grad_norm: 2.1043  loss: 1.1385  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7859  loss_aux: 0.3526\n",
            "02/09 16:45:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][120/332]  lr: 1.0000e-02  eta: 4:18:52  time: 0.3950  data_time: 0.0103  memory: 6616  grad_norm: 2.0346  loss: 1.0926  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7234  loss_aux: 0.3692\n",
            "02/09 16:46:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][140/332]  lr: 1.0000e-02  eta: 4:18:44  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 2.5623  loss: 1.1510  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7805  loss_aux: 0.3705\n",
            "02/09 16:46:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][160/332]  lr: 1.0000e-02  eta: 4:18:36  time: 0.3939  data_time: 0.0097  memory: 6616  grad_norm: 2.0598  loss: 1.1461  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7687  loss_aux: 0.3774\n",
            "02/09 16:46:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][180/332]  lr: 1.0000e-02  eta: 4:18:28  time: 0.3952  data_time: 0.0104  memory: 6616  grad_norm: 2.1462  loss: 1.1314  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7500  loss_aux: 0.3814\n",
            "02/09 16:46:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][200/332]  lr: 1.0000e-02  eta: 4:18:20  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 2.1062  loss: 1.0968  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7396  loss_aux: 0.3571\n",
            "02/09 16:46:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][220/332]  lr: 1.0000e-02  eta: 4:18:11  time: 0.3942  data_time: 0.0102  memory: 6616  grad_norm: 1.8589  loss: 1.0049  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6668  loss_aux: 0.3381\n",
            "02/09 16:46:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][240/332]  lr: 1.0000e-02  eta: 4:18:03  time: 0.3956  data_time: 0.0108  memory: 6616  grad_norm: 2.0859  loss: 1.1389  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7920  loss_aux: 0.3469\n",
            "02/09 16:46:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][260/332]  lr: 1.0000e-02  eta: 4:17:55  time: 0.3942  data_time: 0.0101  memory: 6616  grad_norm: 2.3979  loss: 1.1310  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7727  loss_aux: 0.3583\n",
            "02/09 16:46:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][280/332]  lr: 1.0000e-02  eta: 4:17:47  time: 0.3944  data_time: 0.0098  memory: 6616  grad_norm: 2.0790  loss: 1.0838  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7321  loss_aux: 0.3517\n",
            "02/09 16:47:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][300/332]  lr: 1.0000e-02  eta: 4:17:39  time: 0.3948  data_time: 0.0101  memory: 6616  grad_norm: 1.8404  loss: 1.0385  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6927  loss_aux: 0.3458\n",
            "02/09 16:47:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][320/332]  lr: 1.0000e-02  eta: 4:17:31  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 2.0510  loss: 1.0156  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6736  loss_aux: 0.3419\n",
            "02/09 16:47:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:47:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][332/332]  lr: 1.0000e-02  eta: 4:17:25  time: 0.3899  data_time: 0.0100  memory: 6616  grad_norm: 2.0931  loss: 1.0789  top1_acc: 0.1667  top5_acc: 1.0000  loss_cls: 0.7072  loss_aux: 0.3718\n",
            "02/09 16:47:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 33 epochs\n",
            "02/09 16:47:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][ 20/332]  lr: 1.0000e-02  eta: 4:17:20  time: 0.4363  data_time: 0.0482  memory: 6616  grad_norm: 2.0781  loss: 1.1082  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7527  loss_aux: 0.3555\n",
            "02/09 16:47:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][ 40/332]  lr: 1.0000e-02  eta: 4:17:12  time: 0.3936  data_time: 0.0095  memory: 6616  grad_norm: 1.9943  loss: 1.0581  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7064  loss_aux: 0.3517\n",
            "02/09 16:47:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:47:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][ 60/332]  lr: 1.0000e-02  eta: 4:17:04  time: 0.3951  data_time: 0.0102  memory: 6616  grad_norm: 2.0466  loss: 1.0888  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7379  loss_aux: 0.3509\n",
            "02/09 16:47:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][ 80/332]  lr: 1.0000e-02  eta: 4:16:56  time: 0.3942  data_time: 0.0100  memory: 6616  grad_norm: 1.9602  loss: 1.1061  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7393  loss_aux: 0.3668\n",
            "02/09 16:47:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][100/332]  lr: 1.0000e-02  eta: 4:16:47  time: 0.3936  data_time: 0.0095  memory: 6616  grad_norm: 1.8524  loss: 1.0486  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7035  loss_aux: 0.3451\n",
            "02/09 16:48:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][120/332]  lr: 1.0000e-02  eta: 4:16:39  time: 0.3943  data_time: 0.0099  memory: 6616  grad_norm: 2.1396  loss: 1.1348  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7536  loss_aux: 0.3812\n",
            "02/09 16:48:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][140/332]  lr: 1.0000e-02  eta: 4:16:31  time: 0.3945  data_time: 0.0102  memory: 6616  grad_norm: 2.1890  loss: 1.1463  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7873  loss_aux: 0.3589\n",
            "02/09 16:48:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][160/332]  lr: 1.0000e-02  eta: 4:16:23  time: 0.3940  data_time: 0.0097  memory: 6616  grad_norm: 1.9040  loss: 1.0678  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7169  loss_aux: 0.3509\n",
            "02/09 16:48:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][180/332]  lr: 1.0000e-02  eta: 4:16:15  time: 0.3954  data_time: 0.0106  memory: 6616  grad_norm: 2.0149  loss: 1.1107  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7571  loss_aux: 0.3537\n",
            "02/09 16:48:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][200/332]  lr: 1.0000e-02  eta: 4:16:07  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 1.7871  loss: 1.0375  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6854  loss_aux: 0.3520\n",
            "02/09 16:48:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][220/332]  lr: 1.0000e-02  eta: 4:15:58  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 2.3310  loss: 1.0768  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7226  loss_aux: 0.3542\n",
            "02/09 16:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][240/332]  lr: 1.0000e-02  eta: 4:15:50  time: 0.3947  data_time: 0.0104  memory: 6616  grad_norm: 1.9435  loss: 1.1309  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7747  loss_aux: 0.3562\n",
            "02/09 16:49:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][260/332]  lr: 1.0000e-02  eta: 4:15:42  time: 0.3944  data_time: 0.0098  memory: 6616  grad_norm: 2.1584  loss: 1.1178  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7434  loss_aux: 0.3744\n",
            "02/09 16:49:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][280/332]  lr: 1.0000e-02  eta: 4:15:34  time: 0.3961  data_time: 0.0109  memory: 6616  grad_norm: 2.2479  loss: 1.0776  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7168  loss_aux: 0.3608\n",
            "02/09 16:49:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][300/332]  lr: 1.0000e-02  eta: 4:15:26  time: 0.3953  data_time: 0.0108  memory: 6616  grad_norm: 2.2835  loss: 1.1699  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.8113  loss_aux: 0.3587\n",
            "02/09 16:49:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][320/332]  lr: 1.0000e-02  eta: 4:15:18  time: 0.3941  data_time: 0.0094  memory: 6616  grad_norm: 2.0177  loss: 1.1065  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7473  loss_aux: 0.3592\n",
            "02/09 16:49:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:49:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][332/332]  lr: 1.0000e-02  eta: 4:15:12  time: 0.3888  data_time: 0.0091  memory: 6616  grad_norm: 2.3983  loss: 1.1881  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8222  loss_aux: 0.3659\n",
            "02/09 16:49:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 34 epochs\n",
            "02/09 16:49:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][ 20/332]  lr: 1.0000e-02  eta: 4:15:07  time: 0.4370  data_time: 0.0486  memory: 6616  grad_norm: 2.1364  loss: 1.1306  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7680  loss_aux: 0.3625\n",
            "02/09 16:49:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][ 40/332]  lr: 1.0000e-02  eta: 4:14:59  time: 0.3934  data_time: 0.0095  memory: 6616  grad_norm: 2.2532  loss: 1.2160  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8535  loss_aux: 0.3625\n",
            "02/09 16:49:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][ 60/332]  lr: 1.0000e-02  eta: 4:14:51  time: 0.3946  data_time: 0.0102  memory: 6616  grad_norm: 1.9132  loss: 1.0974  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7410  loss_aux: 0.3564\n",
            "02/09 16:50:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][ 80/332]  lr: 1.0000e-02  eta: 4:14:43  time: 0.3950  data_time: 0.0103  memory: 6616  grad_norm: 1.7458  loss: 1.0874  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7287  loss_aux: 0.3586\n",
            "02/09 16:50:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][100/332]  lr: 1.0000e-02  eta: 4:14:34  time: 0.3938  data_time: 0.0097  memory: 6616  grad_norm: 1.9671  loss: 1.1568  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7956  loss_aux: 0.3613\n",
            "02/09 16:50:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][120/332]  lr: 1.0000e-02  eta: 4:14:26  time: 0.3945  data_time: 0.0102  memory: 6616  grad_norm: 1.8790  loss: 1.1072  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7519  loss_aux: 0.3553\n",
            "02/09 16:50:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][140/332]  lr: 1.0000e-02  eta: 4:14:18  time: 0.3939  data_time: 0.0097  memory: 6616  grad_norm: 2.3044  loss: 1.1387  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7876  loss_aux: 0.3511\n",
            "02/09 16:50:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][160/332]  lr: 1.0000e-02  eta: 4:14:10  time: 0.3945  data_time: 0.0102  memory: 6616  grad_norm: 2.1790  loss: 1.1093  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7488  loss_aux: 0.3606\n",
            "02/09 16:50:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][180/332]  lr: 1.0000e-02  eta: 4:14:02  time: 0.3953  data_time: 0.0105  memory: 6616  grad_norm: 1.8065  loss: 1.0074  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6568  loss_aux: 0.3506\n",
            "02/09 16:50:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][200/332]  lr: 1.0000e-02  eta: 4:13:54  time: 0.3953  data_time: 0.0105  memory: 6616  grad_norm: 2.0446  loss: 1.0777  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7358  loss_aux: 0.3419\n",
            "02/09 16:51:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][220/332]  lr: 1.0000e-02  eta: 4:13:46  time: 0.3958  data_time: 0.0108  memory: 6616  grad_norm: 2.2032  loss: 1.1220  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7767  loss_aux: 0.3453\n",
            "02/09 16:51:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][240/332]  lr: 1.0000e-02  eta: 4:13:38  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 2.6773  loss: 1.0870  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7502  loss_aux: 0.3368\n",
            "02/09 16:51:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][260/332]  lr: 1.0000e-02  eta: 4:13:29  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 2.3637  loss: 1.1007  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7480  loss_aux: 0.3527\n",
            "02/09 16:51:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][280/332]  lr: 1.0000e-02  eta: 4:13:21  time: 0.3943  data_time: 0.0098  memory: 6616  grad_norm: 2.1959  loss: 1.1082  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7421  loss_aux: 0.3661\n",
            "02/09 16:51:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][300/332]  lr: 1.0000e-02  eta: 4:13:13  time: 0.3963  data_time: 0.0109  memory: 6616  grad_norm: 1.7825  loss: 1.0645  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7006  loss_aux: 0.3639\n",
            "02/09 16:51:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][320/332]  lr: 1.0000e-02  eta: 4:13:05  time: 0.3939  data_time: 0.0095  memory: 6616  grad_norm: 1.9923  loss: 1.1270  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7710  loss_aux: 0.3560\n",
            "02/09 16:51:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:51:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][332/332]  lr: 1.0000e-02  eta: 4:13:00  time: 0.3894  data_time: 0.0093  memory: 6616  grad_norm: 1.9648  loss: 1.1150  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7684  loss_aux: 0.3466\n",
            "02/09 16:51:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 35 epochs\n",
            "02/09 16:51:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][ 20/332]  lr: 1.0000e-02  eta: 4:12:55  time: 0.4462  data_time: 0.0599  memory: 6616  grad_norm: 2.3594  loss: 1.1366  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7867  loss_aux: 0.3499\n",
            "02/09 16:52:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][ 40/332]  lr: 1.0000e-02  eta: 4:12:47  time: 0.3947  data_time: 0.0100  memory: 6616  grad_norm: 2.0225  loss: 1.1015  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7474  loss_aux: 0.3541\n",
            "02/09 16:52:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][ 60/332]  lr: 1.0000e-02  eta: 4:12:39  time: 0.3952  data_time: 0.0105  memory: 6616  grad_norm: 2.0474  loss: 1.1035  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7460  loss_aux: 0.3574\n",
            "02/09 16:52:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][ 80/332]  lr: 1.0000e-02  eta: 4:12:31  time: 0.3949  data_time: 0.0104  memory: 6616  grad_norm: 2.2228  loss: 1.0863  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7316  loss_aux: 0.3546\n",
            "02/09 16:52:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][100/332]  lr: 1.0000e-02  eta: 4:12:22  time: 0.3951  data_time: 0.0107  memory: 6616  grad_norm: 2.3902  loss: 1.0764  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7258  loss_aux: 0.3506\n",
            "02/09 16:52:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][120/332]  lr: 1.0000e-02  eta: 4:12:14  time: 0.3953  data_time: 0.0106  memory: 6616  grad_norm: 2.1217  loss: 1.0317  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6944  loss_aux: 0.3373\n",
            "02/09 16:52:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][140/332]  lr: 1.0000e-02  eta: 4:12:06  time: 0.3942  data_time: 0.0099  memory: 6616  grad_norm: 1.6864  loss: 1.0728  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7061  loss_aux: 0.3667\n",
            "02/09 16:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][160/332]  lr: 1.0000e-02  eta: 4:11:58  time: 0.3942  data_time: 0.0097  memory: 6616  grad_norm: 1.9159  loss: 1.0712  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7258  loss_aux: 0.3454\n",
            "02/09 16:52:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][180/332]  lr: 1.0000e-02  eta: 4:11:50  time: 0.3951  data_time: 0.0104  memory: 6616  grad_norm: 1.9921  loss: 1.1356  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7699  loss_aux: 0.3657\n",
            "02/09 16:53:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][200/332]  lr: 1.0000e-02  eta: 4:11:42  time: 0.3944  data_time: 0.0097  memory: 6616  grad_norm: 2.1914  loss: 1.1523  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7997  loss_aux: 0.3526\n",
            "02/09 16:53:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][220/332]  lr: 1.0000e-02  eta: 4:11:34  time: 0.3947  data_time: 0.0100  memory: 6616  grad_norm: 1.7305  loss: 1.0755  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7054  loss_aux: 0.3702\n",
            "02/09 16:53:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][240/332]  lr: 1.0000e-02  eta: 4:11:25  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 2.2654  loss: 1.1654  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.8122  loss_aux: 0.3532\n",
            "02/09 16:53:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][260/332]  lr: 1.0000e-02  eta: 4:11:17  time: 0.3938  data_time: 0.0097  memory: 6616  grad_norm: 1.9063  loss: 1.0547  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6940  loss_aux: 0.3607\n",
            "02/09 16:53:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][280/332]  lr: 1.0000e-02  eta: 4:11:09  time: 0.3946  data_time: 0.0104  memory: 6616  grad_norm: 2.1955  loss: 1.1495  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7616  loss_aux: 0.3879\n",
            "02/09 16:53:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][300/332]  lr: 1.0000e-02  eta: 4:11:01  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 2.4470  loss: 1.1370  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7845  loss_aux: 0.3526\n",
            "02/09 16:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][320/332]  lr: 1.0000e-02  eta: 4:10:53  time: 0.3943  data_time: 0.0101  memory: 6616  grad_norm: 2.3486  loss: 1.0706  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7349  loss_aux: 0.3357\n",
            "02/09 16:53:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:53:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][332/332]  lr: 1.0000e-02  eta: 4:10:48  time: 0.3893  data_time: 0.0094  memory: 6616  grad_norm: 2.4651  loss: 1.0871  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.7461  loss_aux: 0.3410\n",
            "02/09 16:53:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 36 epochs\n",
            "02/09 16:54:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][ 20/332]  lr: 1.0000e-02  eta: 4:10:42  time: 0.4390  data_time: 0.0524  memory: 6616  grad_norm: 2.4282  loss: 1.0920  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7452  loss_aux: 0.3468\n",
            "02/09 16:54:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][ 40/332]  lr: 1.0000e-02  eta: 4:10:34  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 1.9972  loss: 1.0841  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7358  loss_aux: 0.3483\n",
            "02/09 16:54:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][ 60/332]  lr: 1.0000e-02  eta: 4:10:26  time: 0.3941  data_time: 0.0096  memory: 6616  grad_norm: 2.2003  loss: 1.0960  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7177  loss_aux: 0.3783\n",
            "02/09 16:54:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][ 80/332]  lr: 1.0000e-02  eta: 4:10:18  time: 0.3935  data_time: 0.0094  memory: 6616  grad_norm: 2.0747  loss: 1.1225  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7706  loss_aux: 0.3519\n",
            "02/09 16:54:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][100/332]  lr: 1.0000e-02  eta: 4:10:10  time: 0.3946  data_time: 0.0104  memory: 6616  grad_norm: 1.9974  loss: 1.0341  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6789  loss_aux: 0.3552\n",
            "02/09 16:54:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][120/332]  lr: 1.0000e-02  eta: 4:10:02  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 2.3368  loss: 1.1025  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7498  loss_aux: 0.3527\n",
            "02/09 16:54:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][140/332]  lr: 1.0000e-02  eta: 4:09:53  time: 0.3937  data_time: 0.0096  memory: 6616  grad_norm: 2.0661  loss: 1.1235  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7545  loss_aux: 0.3690\n",
            "02/09 16:55:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][160/332]  lr: 1.0000e-02  eta: 4:09:45  time: 0.3950  data_time: 0.0106  memory: 6616  grad_norm: 1.9785  loss: 1.0984  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7560  loss_aux: 0.3424\n",
            "02/09 16:55:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][180/332]  lr: 1.0000e-02  eta: 4:09:37  time: 0.3954  data_time: 0.0109  memory: 6616  grad_norm: 2.0917  loss: 1.0743  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7341  loss_aux: 0.3402\n",
            "02/09 16:55:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][200/332]  lr: 1.0000e-02  eta: 4:09:29  time: 0.3938  data_time: 0.0095  memory: 6616  grad_norm: 2.2074  loss: 1.1333  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7753  loss_aux: 0.3580\n",
            "02/09 16:55:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][220/332]  lr: 1.0000e-02  eta: 4:09:21  time: 0.3942  data_time: 0.0103  memory: 6616  grad_norm: 2.1278  loss: 1.0655  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7053  loss_aux: 0.3602\n",
            "02/09 16:55:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][240/332]  lr: 1.0000e-02  eta: 4:09:13  time: 0.3944  data_time: 0.0098  memory: 6616  grad_norm: 2.4989  loss: 1.1676  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7996  loss_aux: 0.3680\n",
            "02/09 16:55:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][260/332]  lr: 1.0000e-02  eta: 4:09:04  time: 0.3941  data_time: 0.0100  memory: 6616  grad_norm: 2.4910  loss: 1.1718  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8146  loss_aux: 0.3571\n",
            "02/09 16:55:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][280/332]  lr: 1.0000e-02  eta: 4:08:56  time: 0.3947  data_time: 0.0104  memory: 6616  grad_norm: 2.3604  loss: 1.1324  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7766  loss_aux: 0.3558\n",
            "02/09 16:56:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][300/332]  lr: 1.0000e-02  eta: 4:08:48  time: 0.3948  data_time: 0.0105  memory: 6616  grad_norm: 2.1806  loss: 1.0816  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7290  loss_aux: 0.3526\n",
            "02/09 16:56:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][320/332]  lr: 1.0000e-02  eta: 4:08:40  time: 0.3944  data_time: 0.0105  memory: 6616  grad_norm: 2.1094  loss: 1.1251  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7674  loss_aux: 0.3577\n",
            "02/09 16:56:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:56:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][332/332]  lr: 1.0000e-02  eta: 4:08:35  time: 0.3901  data_time: 0.0103  memory: 6616  grad_norm: 1.9299  loss: 1.0889  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7217  loss_aux: 0.3672\n",
            "02/09 16:56:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 37 epochs\n",
            "02/09 16:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][ 20/332]  lr: 1.0000e-02  eta: 4:08:30  time: 0.4502  data_time: 0.0625  memory: 6616  grad_norm: 1.8241  loss: 1.0736  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7273  loss_aux: 0.3463\n",
            "02/09 16:56:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][ 40/332]  lr: 1.0000e-02  eta: 4:08:22  time: 0.3946  data_time: 0.0103  memory: 6616  grad_norm: 2.1297  loss: 1.1950  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8372  loss_aux: 0.3578\n",
            "02/09 16:56:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][ 60/332]  lr: 1.0000e-02  eta: 4:08:14  time: 0.3939  data_time: 0.0099  memory: 6616  grad_norm: 1.9180  loss: 1.0959  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7495  loss_aux: 0.3464\n",
            "02/09 16:56:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][ 80/332]  lr: 1.0000e-02  eta: 4:08:06  time: 0.3954  data_time: 0.0109  memory: 6616  grad_norm: 1.9887  loss: 1.1399  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7603  loss_aux: 0.3795\n",
            "02/09 16:56:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][100/332]  lr: 1.0000e-02  eta: 4:07:58  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 2.2915  loss: 1.2031  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8241  loss_aux: 0.3791\n",
            "02/09 16:57:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][120/332]  lr: 1.0000e-02  eta: 4:07:49  time: 0.3943  data_time: 0.0101  memory: 6616  grad_norm: 1.8377  loss: 1.0405  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6888  loss_aux: 0.3517\n",
            "02/09 16:57:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][140/332]  lr: 1.0000e-02  eta: 4:07:41  time: 0.3927  data_time: 0.0091  memory: 6616  grad_norm: 2.1606  loss: 1.1689  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8110  loss_aux: 0.3580\n",
            "02/09 16:57:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][160/332]  lr: 1.0000e-02  eta: 4:07:33  time: 0.3947  data_time: 0.0107  memory: 6616  grad_norm: 2.0605  loss: 1.0976  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7414  loss_aux: 0.3561\n",
            "02/09 16:57:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][180/332]  lr: 1.0000e-02  eta: 4:07:25  time: 0.3941  data_time: 0.0101  memory: 6616  grad_norm: 1.9469  loss: 1.1022  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7494  loss_aux: 0.3528\n",
            "02/09 16:57:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][200/332]  lr: 1.0000e-02  eta: 4:07:17  time: 0.3944  data_time: 0.0102  memory: 6616  grad_norm: 2.0579  loss: 1.1252  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7582  loss_aux: 0.3669\n",
            "02/09 16:57:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][220/332]  lr: 1.0000e-02  eta: 4:07:09  time: 0.3949  data_time: 0.0103  memory: 6616  grad_norm: 1.6838  loss: 1.0556  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6961  loss_aux: 0.3595\n",
            "02/09 16:57:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][240/332]  lr: 1.0000e-02  eta: 4:07:00  time: 0.3942  data_time: 0.0102  memory: 6616  grad_norm: 2.1783  loss: 1.1256  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7752  loss_aux: 0.3503\n",
            "02/09 16:57:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][260/332]  lr: 1.0000e-02  eta: 4:06:52  time: 0.3931  data_time: 0.0093  memory: 6616  grad_norm: 1.9219  loss: 1.1200  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7607  loss_aux: 0.3592\n",
            "02/09 16:58:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][280/332]  lr: 1.0000e-02  eta: 4:06:44  time: 0.3951  data_time: 0.0106  memory: 6616  grad_norm: 1.9075  loss: 1.0422  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7047  loss_aux: 0.3375\n",
            "02/09 16:58:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][300/332]  lr: 1.0000e-02  eta: 4:06:36  time: 0.3948  data_time: 0.0105  memory: 6616  grad_norm: 2.0623  loss: 1.1222  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7599  loss_aux: 0.3623\n",
            "02/09 16:58:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][320/332]  lr: 1.0000e-02  eta: 4:06:28  time: 0.3932  data_time: 0.0095  memory: 6616  grad_norm: 2.0345  loss: 1.1801  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8085  loss_aux: 0.3716\n",
            "02/09 16:58:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 16:58:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][332/332]  lr: 1.0000e-02  eta: 4:06:23  time: 0.3886  data_time: 0.0091  memory: 6616  grad_norm: 1.8896  loss: 1.0925  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.7350  loss_aux: 0.3575\n",
            "02/09 16:58:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 38 epochs\n",
            "02/09 16:58:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][ 20/332]  lr: 1.0000e-02  eta: 4:06:17  time: 0.4411  data_time: 0.0541  memory: 6616  grad_norm: 1.9659  loss: 1.0903  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7251  loss_aux: 0.3651\n",
            "02/09 16:58:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][ 40/332]  lr: 1.0000e-02  eta: 4:06:09  time: 0.3946  data_time: 0.0099  memory: 6616  grad_norm: 2.4770  loss: 1.1170  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7601  loss_aux: 0.3569\n",
            "02/09 16:58:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][ 60/332]  lr: 1.0000e-02  eta: 4:06:01  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 2.5702  loss: 1.1138  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7540  loss_aux: 0.3598\n",
            "02/09 16:59:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][ 80/332]  lr: 1.0000e-02  eta: 4:05:53  time: 0.3939  data_time: 0.0098  memory: 6616  grad_norm: 1.9091  loss: 1.0740  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7261  loss_aux: 0.3479\n",
            "02/09 16:59:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][100/332]  lr: 1.0000e-02  eta: 4:05:45  time: 0.3978  data_time: 0.0119  memory: 6616  grad_norm: 1.8516  loss: 1.0980  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7330  loss_aux: 0.3650\n",
            "02/09 16:59:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][120/332]  lr: 1.0000e-02  eta: 4:05:37  time: 0.3957  data_time: 0.0106  memory: 6616  grad_norm: 2.3496  loss: 1.0645  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6953  loss_aux: 0.3692\n",
            "02/09 16:59:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][140/332]  lr: 1.0000e-02  eta: 4:05:29  time: 0.3940  data_time: 0.0095  memory: 6616  grad_norm: 2.3719  loss: 1.1190  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7833  loss_aux: 0.3356\n",
            "02/09 16:59:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][160/332]  lr: 1.0000e-02  eta: 4:05:21  time: 0.3951  data_time: 0.0106  memory: 6616  grad_norm: 1.9248  loss: 1.1092  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7432  loss_aux: 0.3660\n",
            "02/09 16:59:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][180/332]  lr: 1.0000e-02  eta: 4:05:13  time: 0.3956  data_time: 0.0106  memory: 6616  grad_norm: 2.1489  loss: 1.0859  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7347  loss_aux: 0.3512\n",
            "02/09 16:59:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][200/332]  lr: 1.0000e-02  eta: 4:05:04  time: 0.3944  data_time: 0.0096  memory: 6616  grad_norm: 2.4277  loss: 1.0780  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7321  loss_aux: 0.3459\n",
            "02/09 16:59:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][220/332]  lr: 1.0000e-02  eta: 4:04:56  time: 0.3949  data_time: 0.0100  memory: 6616  grad_norm: 1.8583  loss: 1.0556  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7150  loss_aux: 0.3406\n",
            "02/09 17:00:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][240/332]  lr: 1.0000e-02  eta: 4:04:48  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 1.9577  loss: 1.1149  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7402  loss_aux: 0.3746\n",
            "02/09 17:00:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][260/332]  lr: 1.0000e-02  eta: 4:04:40  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 2.1753  loss: 1.0592  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7043  loss_aux: 0.3548\n",
            "02/09 17:00:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][280/332]  lr: 1.0000e-02  eta: 4:04:32  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 1.8717  loss: 1.0868  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7222  loss_aux: 0.3646\n",
            "02/09 17:00:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][300/332]  lr: 1.0000e-02  eta: 4:04:24  time: 0.3943  data_time: 0.0100  memory: 6616  grad_norm: 1.9822  loss: 1.1177  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7596  loss_aux: 0.3582\n",
            "02/09 17:00:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][320/332]  lr: 1.0000e-02  eta: 4:04:16  time: 0.3944  data_time: 0.0099  memory: 6616  grad_norm: 1.9599  loss: 1.0716  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7138  loss_aux: 0.3577\n",
            "02/09 17:00:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:00:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][332/332]  lr: 1.0000e-02  eta: 4:04:11  time: 0.3894  data_time: 0.0097  memory: 6616  grad_norm: 1.9624  loss: 1.0827  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7214  loss_aux: 0.3612\n",
            "02/09 17:00:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 39 epochs\n",
            "02/09 17:00:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][ 20/332]  lr: 1.0000e-02  eta: 4:04:05  time: 0.4466  data_time: 0.0613  memory: 6616  grad_norm: 1.7870  loss: 1.0618  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7149  loss_aux: 0.3468\n",
            "02/09 17:01:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][ 40/332]  lr: 1.0000e-02  eta: 4:03:57  time: 0.3958  data_time: 0.0108  memory: 6616  grad_norm: 1.9683  loss: 1.1038  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7405  loss_aux: 0.3633\n",
            "02/09 17:01:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:01:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][ 60/332]  lr: 1.0000e-02  eta: 4:03:49  time: 0.3957  data_time: 0.0111  memory: 6616  grad_norm: 1.8053  loss: 1.0736  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7298  loss_aux: 0.3438\n",
            "02/09 17:01:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][ 80/332]  lr: 1.0000e-02  eta: 4:03:41  time: 0.3938  data_time: 0.0100  memory: 6616  grad_norm: 1.7970  loss: 1.0903  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7251  loss_aux: 0.3653\n",
            "02/09 17:01:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][100/332]  lr: 1.0000e-02  eta: 4:03:33  time: 0.3959  data_time: 0.0107  memory: 6616  grad_norm: 1.8413  loss: 1.0952  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7466  loss_aux: 0.3487\n",
            "02/09 17:01:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][120/332]  lr: 1.0000e-02  eta: 4:03:25  time: 0.3950  data_time: 0.0108  memory: 6616  grad_norm: 2.1582  loss: 1.1444  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7713  loss_aux: 0.3731\n",
            "02/09 17:01:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][140/332]  lr: 1.0000e-02  eta: 4:03:17  time: 0.3943  data_time: 0.0096  memory: 6616  grad_norm: 2.1443  loss: 1.1012  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7440  loss_aux: 0.3572\n",
            "02/09 17:01:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][160/332]  lr: 1.0000e-02  eta: 4:03:09  time: 0.3948  data_time: 0.0105  memory: 6616  grad_norm: 1.7847  loss: 1.1088  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7448  loss_aux: 0.3640\n",
            "02/09 17:01:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][180/332]  lr: 1.0000e-02  eta: 4:03:01  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 1.6631  loss: 1.0738  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7086  loss_aux: 0.3652\n",
            "02/09 17:02:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][200/332]  lr: 1.0000e-02  eta: 4:02:53  time: 0.3946  data_time: 0.0097  memory: 6616  grad_norm: 1.9712  loss: 1.1079  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7517  loss_aux: 0.3562\n",
            "02/09 17:02:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][220/332]  lr: 1.0000e-02  eta: 4:02:44  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 1.8444  loss: 1.0308  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6908  loss_aux: 0.3401\n",
            "02/09 17:02:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][240/332]  lr: 1.0000e-02  eta: 4:02:36  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 1.8238  loss: 1.1222  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7579  loss_aux: 0.3643\n",
            "02/09 17:02:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][260/332]  lr: 1.0000e-02  eta: 4:02:28  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 1.8295  loss: 1.1087  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7624  loss_aux: 0.3463\n",
            "02/09 17:02:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][280/332]  lr: 1.0000e-02  eta: 4:02:20  time: 0.3953  data_time: 0.0103  memory: 6616  grad_norm: 1.8373  loss: 1.0542  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7047  loss_aux: 0.3495\n",
            "02/09 17:02:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][300/332]  lr: 1.0000e-02  eta: 4:02:12  time: 0.3940  data_time: 0.0096  memory: 6616  grad_norm: 1.8810  loss: 1.0540  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7046  loss_aux: 0.3494\n",
            "02/09 17:02:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][320/332]  lr: 1.0000e-02  eta: 4:02:04  time: 0.3944  data_time: 0.0097  memory: 6616  grad_norm: 1.7513  loss: 1.0522  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7133  loss_aux: 0.3389\n",
            "02/09 17:02:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:02:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][332/332]  lr: 1.0000e-02  eta: 4:01:59  time: 0.3891  data_time: 0.0091  memory: 6616  grad_norm: 2.2630  loss: 1.0763  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7293  loss_aux: 0.3470\n",
            "02/09 17:02:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 40 epochs\n",
            "02/09 17:03:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [40][20/42]    eta: 0:00:03  time: 0.1797  data_time: 0.0728  memory: 1447  \n",
            "02/09 17:03:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [40][40/42]    eta: 0:00:00  time: 0.1112  data_time: 0.0110  memory: 1447  \n",
            "02/09 17:03:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][42/42]    acc/top1: 0.5482  acc/top5: 1.0000  acc/mean1: 0.5225  data_time: 0.0394  time: 0.1404\n",
            "02/09 17:03:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb/best_acc_top1_epoch_10.pth is removed\n",
            "02/09 17:03:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.5482 acc/top1 at 40 epoch is saved to best_acc_top1_epoch_40.pth.\n",
            "02/09 17:03:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][ 20/332]  lr: 1.0000e-02  eta: 4:01:53  time: 0.4333  data_time: 0.0467  memory: 6616  grad_norm: 2.1035  loss: 1.0776  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7250  loss_aux: 0.3526\n",
            "02/09 17:03:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][ 40/332]  lr: 1.0000e-02  eta: 4:01:45  time: 0.3940  data_time: 0.0099  memory: 6616  grad_norm: 2.2100  loss: 1.1541  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8023  loss_aux: 0.3518\n",
            "02/09 17:03:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][ 60/332]  lr: 1.0000e-02  eta: 4:01:37  time: 0.3953  data_time: 0.0103  memory: 6616  grad_norm: 1.8550  loss: 1.0918  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7401  loss_aux: 0.3518\n",
            "02/09 17:03:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][ 80/332]  lr: 1.0000e-02  eta: 4:01:28  time: 0.3944  data_time: 0.0102  memory: 6616  grad_norm: 1.8035  loss: 1.0325  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6928  loss_aux: 0.3398\n",
            "02/09 17:03:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][100/332]  lr: 1.0000e-02  eta: 4:01:20  time: 0.3946  data_time: 0.0098  memory: 6616  grad_norm: 2.0590  loss: 1.0988  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7400  loss_aux: 0.3588\n",
            "02/09 17:03:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][120/332]  lr: 1.0000e-02  eta: 4:01:12  time: 0.3943  data_time: 0.0100  memory: 6616  grad_norm: 1.7981  loss: 1.0621  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7050  loss_aux: 0.3571\n",
            "02/09 17:04:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][140/332]  lr: 1.0000e-02  eta: 4:01:04  time: 0.3956  data_time: 0.0108  memory: 6616  grad_norm: 2.0383  loss: 1.1886  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8256  loss_aux: 0.3630\n",
            "02/09 17:04:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][160/332]  lr: 1.0000e-02  eta: 4:00:56  time: 0.3944  data_time: 0.0101  memory: 6616  grad_norm: 2.0072  loss: 1.0943  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7346  loss_aux: 0.3597\n",
            "02/09 17:04:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][180/332]  lr: 1.0000e-02  eta: 4:00:48  time: 0.3943  data_time: 0.0099  memory: 6616  grad_norm: 2.2267  loss: 1.0978  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7442  loss_aux: 0.3536\n",
            "02/09 17:04:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][200/332]  lr: 1.0000e-02  eta: 4:00:40  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 1.9183  loss: 1.1053  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7561  loss_aux: 0.3491\n",
            "02/09 17:04:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][220/332]  lr: 1.0000e-02  eta: 4:00:32  time: 0.3953  data_time: 0.0104  memory: 6616  grad_norm: 1.5610  loss: 1.0620  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6996  loss_aux: 0.3624\n",
            "02/09 17:04:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][240/332]  lr: 1.0000e-02  eta: 4:00:24  time: 0.3941  data_time: 0.0100  memory: 6616  grad_norm: 1.8928  loss: 1.0956  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7258  loss_aux: 0.3699\n",
            "02/09 17:04:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][260/332]  lr: 1.0000e-02  eta: 4:00:15  time: 0.3951  data_time: 0.0105  memory: 6616  grad_norm: 1.9519  loss: 1.0895  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7251  loss_aux: 0.3644\n",
            "02/09 17:05:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][280/332]  lr: 1.0000e-02  eta: 4:00:07  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 2.1116  loss: 1.0725  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7123  loss_aux: 0.3602\n",
            "02/09 17:05:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][300/332]  lr: 1.0000e-02  eta: 3:59:59  time: 0.3945  data_time: 0.0104  memory: 6616  grad_norm: 2.0340  loss: 1.0855  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7331  loss_aux: 0.3524\n",
            "02/09 17:05:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][320/332]  lr: 1.0000e-02  eta: 3:59:51  time: 0.3957  data_time: 0.0109  memory: 6616  grad_norm: 1.8370  loss: 1.0527  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6910  loss_aux: 0.3618\n",
            "02/09 17:05:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:05:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][332/332]  lr: 1.0000e-02  eta: 3:59:46  time: 0.3892  data_time: 0.0096  memory: 6616  grad_norm: 2.0160  loss: 1.1179  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7631  loss_aux: 0.3548\n",
            "02/09 17:05:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 41 epochs\n",
            "02/09 17:05:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][ 20/332]  lr: 1.0000e-02  eta: 3:59:41  time: 0.4471  data_time: 0.0602  memory: 6616  grad_norm: 2.3428  loss: 1.0722  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7225  loss_aux: 0.3497\n",
            "02/09 17:05:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][ 40/332]  lr: 1.0000e-02  eta: 3:59:33  time: 0.3952  data_time: 0.0102  memory: 6616  grad_norm: 2.7407  loss: 1.1469  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7903  loss_aux: 0.3566\n",
            "02/09 17:05:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][ 60/332]  lr: 1.0000e-02  eta: 3:59:25  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 2.3015  loss: 1.0679  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7228  loss_aux: 0.3451\n",
            "02/09 17:05:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][ 80/332]  lr: 1.0000e-02  eta: 3:59:16  time: 0.3947  data_time: 0.0100  memory: 6616  grad_norm: 2.1715  loss: 1.0924  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7422  loss_aux: 0.3502\n",
            "02/09 17:06:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][100/332]  lr: 1.0000e-02  eta: 3:59:08  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 1.9481  loss: 1.0853  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7216  loss_aux: 0.3638\n",
            "02/09 17:06:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][120/332]  lr: 1.0000e-02  eta: 3:59:00  time: 0.3946  data_time: 0.0098  memory: 6616  grad_norm: 1.7838  loss: 1.0591  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7064  loss_aux: 0.3527\n",
            "02/09 17:06:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][140/332]  lr: 1.0000e-02  eta: 3:58:52  time: 0.3945  data_time: 0.0100  memory: 6616  grad_norm: 2.1255  loss: 1.1064  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7484  loss_aux: 0.3579\n",
            "02/09 17:06:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][160/332]  lr: 1.0000e-02  eta: 3:58:44  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 2.0846  loss: 1.0918  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7287  loss_aux: 0.3630\n",
            "02/09 17:06:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][180/332]  lr: 1.0000e-02  eta: 3:58:36  time: 0.3942  data_time: 0.0096  memory: 6616  grad_norm: 2.2970  loss: 1.0931  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7361  loss_aux: 0.3570\n",
            "02/09 17:06:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][200/332]  lr: 1.0000e-02  eta: 3:58:28  time: 0.3949  data_time: 0.0107  memory: 6616  grad_norm: 1.8900  loss: 1.0448  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7022  loss_aux: 0.3426\n",
            "02/09 17:06:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][220/332]  lr: 1.0000e-02  eta: 3:58:20  time: 0.3954  data_time: 0.0107  memory: 6616  grad_norm: 2.2499  loss: 1.1677  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8085  loss_aux: 0.3592\n",
            "02/09 17:07:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][240/332]  lr: 1.0000e-02  eta: 3:58:12  time: 0.3940  data_time: 0.0097  memory: 6616  grad_norm: 2.3768  loss: 1.0878  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7357  loss_aux: 0.3521\n",
            "02/09 17:07:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][260/332]  lr: 1.0000e-02  eta: 3:58:04  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 1.9987  loss: 1.1165  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7501  loss_aux: 0.3664\n",
            "02/09 17:07:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][280/332]  lr: 1.0000e-02  eta: 3:57:56  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 1.7290  loss: 1.0281  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6725  loss_aux: 0.3556\n",
            "02/09 17:07:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][300/332]  lr: 1.0000e-02  eta: 3:57:47  time: 0.3945  data_time: 0.0099  memory: 6616  grad_norm: 2.0035  loss: 1.0989  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7352  loss_aux: 0.3637\n",
            "02/09 17:07:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][320/332]  lr: 1.0000e-02  eta: 3:57:39  time: 0.3945  data_time: 0.0097  memory: 6616  grad_norm: 2.4427  loss: 1.0439  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7092  loss_aux: 0.3347\n",
            "02/09 17:07:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:07:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][332/332]  lr: 1.0000e-02  eta: 3:57:34  time: 0.3890  data_time: 0.0094  memory: 6616  grad_norm: 2.3916  loss: 1.1165  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7467  loss_aux: 0.3699\n",
            "02/09 17:07:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 42 epochs\n",
            "02/09 17:07:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][ 20/332]  lr: 1.0000e-02  eta: 3:57:29  time: 0.4469  data_time: 0.0600  memory: 6616  grad_norm: 2.0054  loss: 1.0955  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7356  loss_aux: 0.3599\n",
            "02/09 17:07:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][ 40/332]  lr: 1.0000e-02  eta: 3:57:21  time: 0.3948  data_time: 0.0104  memory: 6616  grad_norm: 2.3118  loss: 1.1196  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7488  loss_aux: 0.3708\n",
            "02/09 17:08:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:08:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][ 60/332]  lr: 1.0000e-02  eta: 3:57:13  time: 0.3940  data_time: 0.0099  memory: 6616  grad_norm: 2.0016  loss: 1.0494  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7030  loss_aux: 0.3465\n",
            "02/09 17:08:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][ 80/332]  lr: 1.0000e-02  eta: 3:57:05  time: 0.3958  data_time: 0.0109  memory: 6616  grad_norm: 1.9887  loss: 1.1181  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7633  loss_aux: 0.3548\n",
            "02/09 17:08:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][100/332]  lr: 1.0000e-02  eta: 3:56:56  time: 0.3959  data_time: 0.0109  memory: 6616  grad_norm: 1.8888  loss: 1.0333  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6972  loss_aux: 0.3360\n",
            "02/09 17:08:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][120/332]  lr: 1.0000e-02  eta: 3:56:48  time: 0.3947  data_time: 0.0099  memory: 6616  grad_norm: 2.4185  loss: 1.0756  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7108  loss_aux: 0.3648\n",
            "02/09 17:08:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][140/332]  lr: 1.0000e-02  eta: 3:56:40  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 2.9813  loss: 1.1408  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7648  loss_aux: 0.3760\n",
            "02/09 17:08:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][160/332]  lr: 1.0000e-02  eta: 3:56:32  time: 0.3963  data_time: 0.0108  memory: 6616  grad_norm: 2.6854  loss: 1.1283  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7582  loss_aux: 0.3701\n",
            "02/09 17:08:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][180/332]  lr: 1.0000e-02  eta: 3:56:24  time: 0.3944  data_time: 0.0099  memory: 6616  grad_norm: 2.8728  loss: 1.1757  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7765  loss_aux: 0.3991\n",
            "02/09 17:08:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][200/332]  lr: 1.0000e-02  eta: 3:56:16  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 2.4558  loss: 1.0720  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7069  loss_aux: 0.3651\n",
            "02/09 17:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][220/332]  lr: 1.0000e-02  eta: 3:56:08  time: 0.3951  data_time: 0.0100  memory: 6616  grad_norm: 3.5183  loss: 1.0983  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7160  loss_aux: 0.3823\n",
            "02/09 17:09:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][240/332]  lr: 1.0000e-02  eta: 3:56:00  time: 0.3941  data_time: 0.0098  memory: 6616  grad_norm: 2.2192  loss: 1.0651  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7110  loss_aux: 0.3540\n",
            "02/09 17:09:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][260/332]  lr: 1.0000e-02  eta: 3:55:52  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 2.2318  loss: 1.0518  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7055  loss_aux: 0.3463\n",
            "02/09 17:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][280/332]  lr: 1.0000e-02  eta: 3:55:44  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 2.4562  loss: 1.1721  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7678  loss_aux: 0.4043\n",
            "02/09 17:09:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][300/332]  lr: 1.0000e-02  eta: 3:55:36  time: 0.3947  data_time: 0.0100  memory: 6616  grad_norm: 2.7714  loss: 1.1740  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7849  loss_aux: 0.3891\n",
            "02/09 17:09:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][320/332]  lr: 1.0000e-02  eta: 3:55:27  time: 0.3945  data_time: 0.0099  memory: 6616  grad_norm: 2.2422  loss: 1.1345  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7674  loss_aux: 0.3671\n",
            "02/09 17:09:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:09:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][332/332]  lr: 1.0000e-02  eta: 3:55:22  time: 0.3897  data_time: 0.0095  memory: 6616  grad_norm: 2.3207  loss: 1.1149  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7472  loss_aux: 0.3677\n",
            "02/09 17:09:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 43 epochs\n",
            "02/09 17:10:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][ 20/332]  lr: 1.0000e-02  eta: 3:55:17  time: 0.4473  data_time: 0.0608  memory: 6616  grad_norm: 2.0744  loss: 1.0720  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7268  loss_aux: 0.3452\n",
            "02/09 17:10:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][ 40/332]  lr: 1.0000e-02  eta: 3:55:09  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 2.6841  loss: 1.0474  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6863  loss_aux: 0.3610\n",
            "02/09 17:10:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][ 60/332]  lr: 1.0000e-02  eta: 3:55:01  time: 0.3946  data_time: 0.0100  memory: 6616  grad_norm: 2.3659  loss: 1.0751  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7008  loss_aux: 0.3744\n",
            "02/09 17:10:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][ 80/332]  lr: 1.0000e-02  eta: 3:54:53  time: 0.3952  data_time: 0.0106  memory: 6616  grad_norm: 2.2123  loss: 1.0805  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7194  loss_aux: 0.3611\n",
            "02/09 17:10:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][100/332]  lr: 1.0000e-02  eta: 3:54:45  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 2.0219  loss: 1.0410  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7028  loss_aux: 0.3382\n",
            "02/09 17:10:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][120/332]  lr: 1.0000e-02  eta: 3:54:36  time: 0.3943  data_time: 0.0098  memory: 6616  grad_norm: 2.7161  loss: 1.0873  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7164  loss_aux: 0.3709\n",
            "02/09 17:10:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][140/332]  lr: 1.0000e-02  eta: 3:54:28  time: 0.3952  data_time: 0.0107  memory: 6616  grad_norm: 2.5425  loss: 1.1003  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7331  loss_aux: 0.3672\n",
            "02/09 17:10:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][160/332]  lr: 1.0000e-02  eta: 3:54:20  time: 0.3944  data_time: 0.0096  memory: 6616  grad_norm: 2.0100  loss: 1.0656  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7034  loss_aux: 0.3623\n",
            "02/09 17:11:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][180/332]  lr: 1.0000e-02  eta: 3:54:12  time: 0.3941  data_time: 0.0097  memory: 6616  grad_norm: 3.6758  loss: 1.1328  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7792  loss_aux: 0.3535\n",
            "02/09 17:11:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][200/332]  lr: 1.0000e-02  eta: 3:54:04  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 2.3962  loss: 1.1327  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7712  loss_aux: 0.3615\n",
            "02/09 17:11:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][220/332]  lr: 1.0000e-02  eta: 3:53:56  time: 0.3949  data_time: 0.0103  memory: 6616  grad_norm: 2.1271  loss: 1.0586  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7073  loss_aux: 0.3513\n",
            "02/09 17:11:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][240/332]  lr: 1.0000e-02  eta: 3:53:48  time: 0.3950  data_time: 0.0101  memory: 6616  grad_norm: 2.1720  loss: 1.0942  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7411  loss_aux: 0.3531\n",
            "02/09 17:11:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][260/332]  lr: 1.0000e-02  eta: 3:53:40  time: 0.3962  data_time: 0.0108  memory: 6616  grad_norm: 2.3915  loss: 1.1066  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7413  loss_aux: 0.3653\n",
            "02/09 17:11:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][280/332]  lr: 1.0000e-02  eta: 3:53:32  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 2.2478  loss: 1.1262  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7631  loss_aux: 0.3631\n",
            "02/09 17:11:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][300/332]  lr: 1.0000e-02  eta: 3:53:24  time: 0.3968  data_time: 0.0113  memory: 6616  grad_norm: 1.8375  loss: 1.0072  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6567  loss_aux: 0.3505\n",
            "02/09 17:12:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][320/332]  lr: 1.0000e-02  eta: 3:53:16  time: 0.3950  data_time: 0.0106  memory: 6616  grad_norm: 2.9639  loss: 1.1032  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7353  loss_aux: 0.3680\n",
            "02/09 17:12:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:12:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][332/332]  lr: 1.0000e-02  eta: 3:53:11  time: 0.3898  data_time: 0.0095  memory: 6616  grad_norm: 1.9294  loss: 1.0799  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.7138  loss_aux: 0.3661\n",
            "02/09 17:12:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 44 epochs\n",
            "02/09 17:12:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][ 20/332]  lr: 1.0000e-02  eta: 3:53:05  time: 0.4468  data_time: 0.0567  memory: 6616  grad_norm: 2.3310  loss: 1.1060  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7352  loss_aux: 0.3708\n",
            "02/09 17:12:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][ 40/332]  lr: 1.0000e-02  eta: 3:52:57  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 1.9313  loss: 1.1593  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7908  loss_aux: 0.3685\n",
            "02/09 17:12:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][ 60/332]  lr: 1.0000e-02  eta: 3:52:49  time: 0.3947  data_time: 0.0099  memory: 6616  grad_norm: 1.8466  loss: 1.0920  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7406  loss_aux: 0.3514\n",
            "02/09 17:12:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][ 80/332]  lr: 1.0000e-02  eta: 3:52:41  time: 0.3965  data_time: 0.0111  memory: 6616  grad_norm: 1.8825  loss: 1.0308  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6923  loss_aux: 0.3385\n",
            "02/09 17:12:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][100/332]  lr: 1.0000e-02  eta: 3:52:33  time: 0.3953  data_time: 0.0103  memory: 6616  grad_norm: 2.0989  loss: 1.0114  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6709  loss_aux: 0.3405\n",
            "02/09 17:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][120/332]  lr: 1.0000e-02  eta: 3:52:25  time: 0.3949  data_time: 0.0103  memory: 6616  grad_norm: 2.3313  loss: 1.1278  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7576  loss_aux: 0.3702\n",
            "02/09 17:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][140/332]  lr: 1.0000e-02  eta: 3:52:17  time: 0.3965  data_time: 0.0112  memory: 6616  grad_norm: 1.8917  loss: 1.1145  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7622  loss_aux: 0.3523\n",
            "02/09 17:13:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][160/332]  lr: 1.0000e-02  eta: 3:52:09  time: 0.3945  data_time: 0.0098  memory: 6616  grad_norm: 2.5131  loss: 1.0855  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7308  loss_aux: 0.3547\n",
            "02/09 17:13:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][180/332]  lr: 1.0000e-02  eta: 3:52:01  time: 0.3957  data_time: 0.0106  memory: 6616  grad_norm: 2.0752  loss: 1.0681  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7258  loss_aux: 0.3422\n",
            "02/09 17:13:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][200/332]  lr: 1.0000e-02  eta: 3:51:53  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 2.5114  loss: 1.1391  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7898  loss_aux: 0.3492\n",
            "02/09 17:13:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][220/332]  lr: 1.0000e-02  eta: 3:51:45  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 3.1682  loss: 1.1344  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7843  loss_aux: 0.3501\n",
            "02/09 17:13:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][240/332]  lr: 1.0000e-02  eta: 3:51:36  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 2.4274  loss: 1.0946  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7457  loss_aux: 0.3489\n",
            "02/09 17:13:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][260/332]  lr: 1.0000e-02  eta: 3:51:28  time: 0.3954  data_time: 0.0106  memory: 6616  grad_norm: 3.1234  loss: 1.1753  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8164  loss_aux: 0.3589\n",
            "02/09 17:14:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][280/332]  lr: 1.0000e-02  eta: 3:51:20  time: 0.3957  data_time: 0.0107  memory: 6616  grad_norm: 2.0112  loss: 1.1162  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7746  loss_aux: 0.3416\n",
            "02/09 17:14:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][300/332]  lr: 1.0000e-02  eta: 3:51:12  time: 0.3962  data_time: 0.0113  memory: 6616  grad_norm: 1.9690  loss: 1.0766  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7375  loss_aux: 0.3391\n",
            "02/09 17:14:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][320/332]  lr: 1.0000e-02  eta: 3:51:04  time: 0.3950  data_time: 0.0103  memory: 6616  grad_norm: 1.9720  loss: 1.0683  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7284  loss_aux: 0.3399\n",
            "02/09 17:14:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:14:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][332/332]  lr: 1.0000e-02  eta: 3:50:59  time: 0.3896  data_time: 0.0096  memory: 6616  grad_norm: 2.4760  loss: 1.1172  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7690  loss_aux: 0.3481\n",
            "02/09 17:14:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 45 epochs\n",
            "02/09 17:14:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][ 20/332]  lr: 1.0000e-02  eta: 3:50:53  time: 0.4379  data_time: 0.0514  memory: 6616  grad_norm: 2.6954  loss: 1.1123  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7574  loss_aux: 0.3549\n",
            "02/09 17:14:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][ 40/332]  lr: 1.0000e-02  eta: 3:50:45  time: 0.3946  data_time: 0.0099  memory: 6616  grad_norm: 2.6553  loss: 1.0725  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7033  loss_aux: 0.3691\n",
            "02/09 17:14:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:14:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][ 60/332]  lr: 1.0000e-02  eta: 3:50:37  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 2.0378  loss: 1.0477  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6976  loss_aux: 0.3500\n",
            "02/09 17:14:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][ 80/332]  lr: 1.0000e-02  eta: 3:50:29  time: 0.3953  data_time: 0.0105  memory: 6616  grad_norm: 2.4360  loss: 1.0958  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7387  loss_aux: 0.3571\n",
            "02/09 17:15:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][100/332]  lr: 1.0000e-02  eta: 3:50:21  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 2.2954  loss: 1.0997  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7346  loss_aux: 0.3652\n",
            "02/09 17:15:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][120/332]  lr: 1.0000e-02  eta: 3:50:13  time: 0.3949  data_time: 0.0106  memory: 6616  grad_norm: 2.2201  loss: 1.0531  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7056  loss_aux: 0.3474\n",
            "02/09 17:15:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][140/332]  lr: 1.0000e-02  eta: 3:50:05  time: 0.3964  data_time: 0.0107  memory: 6616  grad_norm: 2.0807  loss: 1.1450  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7916  loss_aux: 0.3534\n",
            "02/09 17:15:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][160/332]  lr: 1.0000e-02  eta: 3:49:57  time: 0.3942  data_time: 0.0101  memory: 6616  grad_norm: 2.5795  loss: 1.1508  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7963  loss_aux: 0.3545\n",
            "02/09 17:15:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][180/332]  lr: 1.0000e-02  eta: 3:49:49  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 1.9270  loss: 1.0555  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7142  loss_aux: 0.3413\n",
            "02/09 17:15:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][200/332]  lr: 1.0000e-02  eta: 3:49:40  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 1.9952  loss: 1.0820  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7178  loss_aux: 0.3642\n",
            "02/09 17:15:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][220/332]  lr: 1.0000e-02  eta: 3:49:32  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 1.9313  loss: 1.0893  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7358  loss_aux: 0.3534\n",
            "02/09 17:16:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][240/332]  lr: 1.0000e-02  eta: 3:49:24  time: 0.3953  data_time: 0.0105  memory: 6616  grad_norm: 1.8398  loss: 1.0837  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7243  loss_aux: 0.3594\n",
            "02/09 17:16:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][260/332]  lr: 1.0000e-02  eta: 3:49:16  time: 0.3946  data_time: 0.0099  memory: 6616  grad_norm: 1.7389  loss: 1.0662  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7121  loss_aux: 0.3541\n",
            "02/09 17:16:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][280/332]  lr: 1.0000e-02  eta: 3:49:08  time: 0.3943  data_time: 0.0102  memory: 6616  grad_norm: 1.6665  loss: 1.0063  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6650  loss_aux: 0.3413\n",
            "02/09 17:16:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][300/332]  lr: 1.0000e-02  eta: 3:49:00  time: 0.3971  data_time: 0.0112  memory: 6616  grad_norm: 2.1331  loss: 1.0495  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6999  loss_aux: 0.3496\n",
            "02/09 17:16:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][320/332]  lr: 1.0000e-02  eta: 3:48:52  time: 0.3944  data_time: 0.0101  memory: 6616  grad_norm: 1.7617  loss: 1.0328  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6919  loss_aux: 0.3409\n",
            "02/09 17:16:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:16:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][332/332]  lr: 1.0000e-02  eta: 3:48:47  time: 0.3901  data_time: 0.0100  memory: 6616  grad_norm: 2.1223  loss: 1.1471  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7852  loss_aux: 0.3619\n",
            "02/09 17:16:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 46 epochs\n",
            "02/09 17:16:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][ 20/332]  lr: 1.0000e-02  eta: 3:48:41  time: 0.4384  data_time: 0.0492  memory: 6616  grad_norm: 1.9619  loss: 1.1165  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7454  loss_aux: 0.3711\n",
            "02/09 17:16:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][ 40/332]  lr: 1.0000e-02  eta: 3:48:33  time: 0.3947  data_time: 0.0103  memory: 6616  grad_norm: 2.0031  loss: 1.1281  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7733  loss_aux: 0.3548\n",
            "02/09 17:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][ 60/332]  lr: 1.0000e-02  eta: 3:48:25  time: 0.3955  data_time: 0.0103  memory: 6616  grad_norm: 1.9840  loss: 1.0948  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7436  loss_aux: 0.3513\n",
            "02/09 17:17:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][ 80/332]  lr: 1.0000e-02  eta: 3:48:17  time: 0.3964  data_time: 0.0113  memory: 6616  grad_norm: 2.1189  loss: 1.1266  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7787  loss_aux: 0.3480\n",
            "02/09 17:17:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][100/332]  lr: 1.0000e-02  eta: 3:48:09  time: 0.3951  data_time: 0.0104  memory: 6616  grad_norm: 2.4284  loss: 1.1481  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7919  loss_aux: 0.3562\n",
            "02/09 17:17:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][120/332]  lr: 1.0000e-02  eta: 3:48:01  time: 0.3952  data_time: 0.0104  memory: 6616  grad_norm: 1.9745  loss: 1.0929  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7437  loss_aux: 0.3492\n",
            "02/09 17:17:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][140/332]  lr: 1.0000e-02  eta: 3:47:53  time: 0.3961  data_time: 0.0114  memory: 6616  grad_norm: 2.0412  loss: 1.1233  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7701  loss_aux: 0.3531\n",
            "02/09 17:17:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][160/332]  lr: 1.0000e-02  eta: 3:47:45  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 1.5434  loss: 1.0430  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6892  loss_aux: 0.3538\n",
            "02/09 17:17:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][180/332]  lr: 1.0000e-02  eta: 3:47:37  time: 0.3966  data_time: 0.0112  memory: 6616  grad_norm: 1.7346  loss: 1.0409  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7091  loss_aux: 0.3318\n",
            "02/09 17:17:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][200/332]  lr: 1.0000e-02  eta: 3:47:28  time: 0.3957  data_time: 0.0106  memory: 6616  grad_norm: 1.9255  loss: 1.1467  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7746  loss_aux: 0.3721\n",
            "02/09 17:18:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][220/332]  lr: 1.0000e-02  eta: 3:47:20  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 1.8075  loss: 1.1077  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7533  loss_aux: 0.3544\n",
            "02/09 17:18:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][240/332]  lr: 1.0000e-02  eta: 3:47:12  time: 0.3955  data_time: 0.0109  memory: 6616  grad_norm: 2.0994  loss: 1.0870  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7320  loss_aux: 0.3550\n",
            "02/09 17:18:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][260/332]  lr: 1.0000e-02  eta: 3:47:04  time: 0.3951  data_time: 0.0100  memory: 6616  grad_norm: 1.9608  loss: 1.0792  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7204  loss_aux: 0.3588\n",
            "02/09 17:18:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][280/332]  lr: 1.0000e-02  eta: 3:46:56  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 1.8130  loss: 1.0582  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7208  loss_aux: 0.3374\n",
            "02/09 17:18:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][300/332]  lr: 1.0000e-02  eta: 3:46:48  time: 0.3950  data_time: 0.0100  memory: 6616  grad_norm: 1.8266  loss: 1.0815  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7320  loss_aux: 0.3495\n",
            "02/09 17:18:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][320/332]  lr: 1.0000e-02  eta: 3:46:40  time: 0.3956  data_time: 0.0108  memory: 6616  grad_norm: 1.8671  loss: 1.0790  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7222  loss_aux: 0.3568\n",
            "02/09 17:18:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:18:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][332/332]  lr: 1.0000e-02  eta: 3:46:35  time: 0.3902  data_time: 0.0100  memory: 6616  grad_norm: 1.8594  loss: 1.1084  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.7548  loss_aux: 0.3536\n",
            "02/09 17:18:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 47 epochs\n",
            "02/09 17:19:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][ 20/332]  lr: 1.0000e-02  eta: 3:46:30  time: 0.4580  data_time: 0.0702  memory: 6616  grad_norm: 1.9593  loss: 1.1734  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8066  loss_aux: 0.3668\n",
            "02/09 17:19:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][ 40/332]  lr: 1.0000e-02  eta: 3:46:22  time: 0.3946  data_time: 0.0097  memory: 6616  grad_norm: 1.8424  loss: 1.0439  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6984  loss_aux: 0.3455\n",
            "02/09 17:19:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][ 60/332]  lr: 1.0000e-02  eta: 3:46:14  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 1.8563  loss: 1.0657  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6986  loss_aux: 0.3672\n",
            "02/09 17:19:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][ 80/332]  lr: 1.0000e-02  eta: 3:46:06  time: 0.3957  data_time: 0.0109  memory: 6616  grad_norm: 2.0961  loss: 1.1083  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7688  loss_aux: 0.3395\n",
            "02/09 17:19:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][100/332]  lr: 1.0000e-02  eta: 3:45:58  time: 0.3949  data_time: 0.0100  memory: 6616  grad_norm: 1.8979  loss: 1.1134  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7542  loss_aux: 0.3592\n",
            "02/09 17:19:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][120/332]  lr: 1.0000e-02  eta: 3:45:50  time: 0.3959  data_time: 0.0107  memory: 6616  grad_norm: 1.7348  loss: 1.1011  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7336  loss_aux: 0.3675\n",
            "02/09 17:19:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][140/332]  lr: 1.0000e-02  eta: 3:45:41  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 3.0147  loss: 1.0944  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7469  loss_aux: 0.3475\n",
            "02/09 17:19:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][160/332]  lr: 1.0000e-02  eta: 3:45:33  time: 0.3941  data_time: 0.0097  memory: 6616  grad_norm: 1.8082  loss: 1.0555  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7084  loss_aux: 0.3471\n",
            "02/09 17:20:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][180/332]  lr: 1.0000e-02  eta: 3:45:25  time: 0.3959  data_time: 0.0111  memory: 6616  grad_norm: 1.5497  loss: 1.0423  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6938  loss_aux: 0.3485\n",
            "02/09 17:20:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][200/332]  lr: 1.0000e-02  eta: 3:45:17  time: 0.3950  data_time: 0.0105  memory: 6616  grad_norm: 2.0275  loss: 1.1122  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7609  loss_aux: 0.3513\n",
            "02/09 17:20:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][220/332]  lr: 1.0000e-02  eta: 3:45:09  time: 0.3949  data_time: 0.0103  memory: 6616  grad_norm: 1.9183  loss: 1.0740  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7161  loss_aux: 0.3579\n",
            "02/09 17:20:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][240/332]  lr: 1.0000e-02  eta: 3:45:01  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 1.7297  loss: 1.0822  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7204  loss_aux: 0.3618\n",
            "02/09 17:20:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][260/332]  lr: 1.0000e-02  eta: 3:44:53  time: 0.3954  data_time: 0.0107  memory: 6616  grad_norm: 1.5887  loss: 1.0769  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7175  loss_aux: 0.3594\n",
            "02/09 17:20:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][280/332]  lr: 1.0000e-02  eta: 3:44:45  time: 0.3959  data_time: 0.0106  memory: 6616  grad_norm: 1.8769  loss: 1.1000  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7521  loss_aux: 0.3479\n",
            "02/09 17:20:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][300/332]  lr: 1.0000e-02  eta: 3:44:37  time: 0.3952  data_time: 0.0108  memory: 6616  grad_norm: 2.3181  loss: 1.0028  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6699  loss_aux: 0.3329\n",
            "02/09 17:21:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][320/332]  lr: 1.0000e-02  eta: 3:44:29  time: 0.3945  data_time: 0.0100  memory: 6616  grad_norm: 1.7897  loss: 1.1227  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7578  loss_aux: 0.3649\n",
            "02/09 17:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][332/332]  lr: 1.0000e-02  eta: 3:44:24  time: 0.3899  data_time: 0.0099  memory: 6616  grad_norm: 1.8882  loss: 1.1095  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7556  loss_aux: 0.3539\n",
            "02/09 17:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 48 epochs\n",
            "02/09 17:21:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][ 20/332]  lr: 1.0000e-02  eta: 3:44:18  time: 0.4434  data_time: 0.0560  memory: 6616  grad_norm: 2.0744  loss: 1.0791  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7359  loss_aux: 0.3432\n",
            "02/09 17:21:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][ 40/332]  lr: 1.0000e-02  eta: 3:44:10  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 1.6699  loss: 1.0921  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7357  loss_aux: 0.3564\n",
            "02/09 17:21:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][ 60/332]  lr: 1.0000e-02  eta: 3:44:02  time: 0.3955  data_time: 0.0101  memory: 6616  grad_norm: 2.0785  loss: 1.1081  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7620  loss_aux: 0.3461\n",
            "02/09 17:21:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:21:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][ 80/332]  lr: 1.0000e-02  eta: 3:43:54  time: 0.3956  data_time: 0.0106  memory: 6616  grad_norm: 2.4529  loss: 1.0933  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7444  loss_aux: 0.3489\n",
            "02/09 17:21:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][100/332]  lr: 1.0000e-02  eta: 3:43:46  time: 0.3960  data_time: 0.0106  memory: 6616  grad_norm: 1.9044  loss: 1.1183  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7611  loss_aux: 0.3571\n",
            "02/09 17:21:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][120/332]  lr: 1.0000e-02  eta: 3:43:38  time: 0.3954  data_time: 0.0107  memory: 6616  grad_norm: 1.6483  loss: 1.0343  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6804  loss_aux: 0.3539\n",
            "02/09 17:22:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][140/332]  lr: 1.0000e-02  eta: 3:43:30  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 1.8709  loss: 1.0505  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7064  loss_aux: 0.3440\n",
            "02/09 17:22:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][160/332]  lr: 1.0000e-02  eta: 3:43:22  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 1.8415  loss: 1.0849  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7344  loss_aux: 0.3505\n",
            "02/09 17:22:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][180/332]  lr: 1.0000e-02  eta: 3:43:14  time: 0.3956  data_time: 0.0108  memory: 6616  grad_norm: 1.8058  loss: 1.0929  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7254  loss_aux: 0.3675\n",
            "02/09 17:22:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][200/332]  lr: 1.0000e-02  eta: 3:43:05  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 1.8330  loss: 1.1013  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7382  loss_aux: 0.3631\n",
            "02/09 17:22:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][220/332]  lr: 1.0000e-02  eta: 3:42:57  time: 0.3949  data_time: 0.0098  memory: 6616  grad_norm: 1.5057  loss: 1.0255  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6877  loss_aux: 0.3377\n",
            "02/09 17:22:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][240/332]  lr: 1.0000e-02  eta: 3:42:49  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 1.9342  loss: 1.0869  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7305  loss_aux: 0.3564\n",
            "02/09 17:22:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][260/332]  lr: 1.0000e-02  eta: 3:42:41  time: 0.3950  data_time: 0.0100  memory: 6616  grad_norm: 2.1495  loss: 1.1044  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7554  loss_aux: 0.3490\n",
            "02/09 17:23:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][280/332]  lr: 1.0000e-02  eta: 3:42:33  time: 0.3951  data_time: 0.0104  memory: 6616  grad_norm: 2.0687  loss: 1.1324  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7635  loss_aux: 0.3689\n",
            "02/09 17:23:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][300/332]  lr: 1.0000e-02  eta: 3:42:25  time: 0.3958  data_time: 0.0109  memory: 6616  grad_norm: 1.9413  loss: 1.1159  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7615  loss_aux: 0.3544\n",
            "02/09 17:23:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][320/332]  lr: 1.0000e-02  eta: 3:42:17  time: 0.3942  data_time: 0.0096  memory: 6616  grad_norm: 1.9801  loss: 1.1147  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7539  loss_aux: 0.3608\n",
            "02/09 17:23:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:23:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][332/332]  lr: 1.0000e-02  eta: 3:42:12  time: 0.3902  data_time: 0.0099  memory: 6616  grad_norm: 1.8574  loss: 1.0648  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.7187  loss_aux: 0.3462\n",
            "02/09 17:23:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 49 epochs\n",
            "02/09 17:23:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][ 20/332]  lr: 1.0000e-02  eta: 3:42:06  time: 0.4345  data_time: 0.0476  memory: 6616  grad_norm: 1.7543  loss: 1.1209  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7582  loss_aux: 0.3627\n",
            "02/09 17:23:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][ 40/332]  lr: 1.0000e-02  eta: 3:41:58  time: 0.3939  data_time: 0.0097  memory: 6616  grad_norm: 1.7402  loss: 1.1561  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7894  loss_aux: 0.3667\n",
            "02/09 17:23:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][ 60/332]  lr: 1.0000e-02  eta: 3:41:50  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 1.6615  loss: 1.0534  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7079  loss_aux: 0.3455\n",
            "02/09 17:23:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][ 80/332]  lr: 1.0000e-02  eta: 3:41:41  time: 0.3946  data_time: 0.0100  memory: 6616  grad_norm: 2.0348  loss: 1.1127  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7443  loss_aux: 0.3684\n",
            "02/09 17:24:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][100/332]  lr: 1.0000e-02  eta: 3:41:33  time: 0.3940  data_time: 0.0094  memory: 6616  grad_norm: 1.8607  loss: 1.1159  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7576  loss_aux: 0.3583\n",
            "02/09 17:24:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][120/332]  lr: 1.0000e-02  eta: 3:41:25  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 1.7900  loss: 1.0932  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7516  loss_aux: 0.3416\n",
            "02/09 17:24:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][140/332]  lr: 1.0000e-02  eta: 3:41:17  time: 0.3957  data_time: 0.0106  memory: 6616  grad_norm: 1.8483  loss: 1.0429  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6947  loss_aux: 0.3482\n",
            "02/09 17:24:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][160/332]  lr: 1.0000e-02  eta: 3:41:09  time: 0.3948  data_time: 0.0104  memory: 6616  grad_norm: 1.9000  loss: 1.0983  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7454  loss_aux: 0.3529\n",
            "02/09 17:24:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][180/332]  lr: 1.0000e-02  eta: 3:41:01  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 2.0861  loss: 1.0193  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6729  loss_aux: 0.3464\n",
            "02/09 17:24:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][200/332]  lr: 1.0000e-02  eta: 3:40:53  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 2.3214  loss: 1.1271  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7792  loss_aux: 0.3480\n",
            "02/09 17:24:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][220/332]  lr: 1.0000e-02  eta: 3:40:45  time: 0.3934  data_time: 0.0094  memory: 6616  grad_norm: 2.0139  loss: 1.1531  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8012  loss_aux: 0.3519\n",
            "02/09 17:24:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][240/332]  lr: 1.0000e-02  eta: 3:40:37  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 1.7544  loss: 1.0079  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6642  loss_aux: 0.3437\n",
            "02/09 17:25:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][260/332]  lr: 1.0000e-02  eta: 3:40:29  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 1.9762  loss: 1.0895  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7343  loss_aux: 0.3553\n",
            "02/09 17:25:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][280/332]  lr: 1.0000e-02  eta: 3:40:21  time: 0.3942  data_time: 0.0100  memory: 6616  grad_norm: 1.9483  loss: 0.9874  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6606  loss_aux: 0.3268\n",
            "02/09 17:25:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][300/332]  lr: 1.0000e-02  eta: 3:40:13  time: 0.3946  data_time: 0.0100  memory: 6616  grad_norm: 1.7187  loss: 1.0698  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7232  loss_aux: 0.3465\n",
            "02/09 17:25:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][320/332]  lr: 1.0000e-02  eta: 3:40:05  time: 0.3944  data_time: 0.0098  memory: 6616  grad_norm: 1.8737  loss: 1.1117  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7589  loss_aux: 0.3528\n",
            "02/09 17:25:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:25:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][332/332]  lr: 1.0000e-02  eta: 3:40:00  time: 0.3897  data_time: 0.0097  memory: 6616  grad_norm: 1.8686  loss: 1.0805  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7474  loss_aux: 0.3331\n",
            "02/09 17:25:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 50 epochs\n",
            "02/09 17:25:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [50][20/42]    eta: 0:00:03  time: 0.1766  data_time: 0.0703  memory: 1447  \n",
            "02/09 17:25:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [50][40/42]    eta: 0:00:00  time: 0.1167  data_time: 0.0126  memory: 1447  \n",
            "02/09 17:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][42/42]    acc/top1: 0.5120  acc/top5: 1.0000  acc/mean1: 0.4818  data_time: 0.0390  time: 0.1415\n",
            "02/09 17:25:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][ 20/332]  lr: 1.0000e-02  eta: 3:39:54  time: 0.4508  data_time: 0.0665  memory: 6616  grad_norm: 2.0563  loss: 1.0724  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7303  loss_aux: 0.3421\n",
            "02/09 17:26:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][ 40/332]  lr: 1.0000e-02  eta: 3:39:46  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 1.6284  loss: 1.0546  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7034  loss_aux: 0.3512\n",
            "02/09 17:26:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][ 60/332]  lr: 1.0000e-02  eta: 3:39:38  time: 0.3958  data_time: 0.0108  memory: 6616  grad_norm: 2.0945  loss: 1.1138  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7576  loss_aux: 0.3562\n",
            "02/09 17:26:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][ 80/332]  lr: 1.0000e-02  eta: 3:39:30  time: 0.3943  data_time: 0.0099  memory: 6616  grad_norm: 1.9522  loss: 1.0670  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7256  loss_aux: 0.3414\n",
            "02/09 17:26:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][100/332]  lr: 1.0000e-02  eta: 3:39:21  time: 0.3955  data_time: 0.0105  memory: 6616  grad_norm: 1.8385  loss: 1.0793  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7328  loss_aux: 0.3464\n",
            "02/09 17:26:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][120/332]  lr: 1.0000e-02  eta: 3:39:13  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 2.0746  loss: 1.0992  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7549  loss_aux: 0.3443\n",
            "02/09 17:26:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][140/332]  lr: 1.0000e-02  eta: 3:39:05  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 1.8437  loss: 1.0918  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7309  loss_aux: 0.3609\n",
            "02/09 17:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][160/332]  lr: 1.0000e-02  eta: 3:38:57  time: 0.3950  data_time: 0.0100  memory: 6616  grad_norm: 1.8599  loss: 1.0776  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7201  loss_aux: 0.3575\n",
            "02/09 17:26:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][180/332]  lr: 1.0000e-02  eta: 3:38:49  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 1.7362  loss: 1.0599  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7147  loss_aux: 0.3452\n",
            "02/09 17:27:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][200/332]  lr: 1.0000e-02  eta: 3:38:41  time: 0.3951  data_time: 0.0105  memory: 6616  grad_norm: 1.8615  loss: 1.1174  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7562  loss_aux: 0.3611\n",
            "02/09 17:27:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][220/332]  lr: 1.0000e-02  eta: 3:38:33  time: 0.3961  data_time: 0.0104  memory: 6616  grad_norm: 1.8322  loss: 1.1070  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7415  loss_aux: 0.3655\n",
            "02/09 17:27:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][240/332]  lr: 1.0000e-02  eta: 3:38:25  time: 0.3937  data_time: 0.0094  memory: 6616  grad_norm: 1.8317  loss: 1.1027  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7574  loss_aux: 0.3452\n",
            "02/09 17:27:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][260/332]  lr: 1.0000e-02  eta: 3:38:17  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 1.8381  loss: 1.0711  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7145  loss_aux: 0.3567\n",
            "02/09 17:27:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][280/332]  lr: 1.0000e-02  eta: 3:38:09  time: 0.3941  data_time: 0.0098  memory: 6616  grad_norm: 1.7427  loss: 1.1006  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7387  loss_aux: 0.3619\n",
            "02/09 17:27:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][300/332]  lr: 1.0000e-02  eta: 3:38:01  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 2.1611  loss: 1.1104  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7595  loss_aux: 0.3509\n",
            "02/09 17:27:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][320/332]  lr: 1.0000e-02  eta: 3:37:53  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 1.7342  loss: 1.0635  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7073  loss_aux: 0.3562\n",
            "02/09 17:27:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:27:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][332/332]  lr: 1.0000e-02  eta: 3:37:48  time: 0.3892  data_time: 0.0090  memory: 6616  grad_norm: 1.8219  loss: 1.1070  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7564  loss_aux: 0.3506\n",
            "02/09 17:27:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 51 epochs\n",
            "02/09 17:28:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][ 20/332]  lr: 1.0000e-02  eta: 3:37:41  time: 0.4401  data_time: 0.0530  memory: 6616  grad_norm: 1.6417  loss: 1.0855  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7303  loss_aux: 0.3552\n",
            "02/09 17:28:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][ 40/332]  lr: 1.0000e-02  eta: 3:37:33  time: 0.3960  data_time: 0.0107  memory: 6616  grad_norm: 1.7676  loss: 1.0659  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7174  loss_aux: 0.3485\n",
            "02/09 17:28:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][ 60/332]  lr: 1.0000e-02  eta: 3:37:25  time: 0.3949  data_time: 0.0105  memory: 6616  grad_norm: 1.6668  loss: 1.0493  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7047  loss_aux: 0.3446\n",
            "02/09 17:28:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][ 80/332]  lr: 1.0000e-02  eta: 3:37:17  time: 0.3946  data_time: 0.0098  memory: 6616  grad_norm: 1.6205  loss: 1.0662  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7261  loss_aux: 0.3401\n",
            "02/09 17:28:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][100/332]  lr: 1.0000e-02  eta: 3:37:09  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 1.7966  loss: 1.0271  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6798  loss_aux: 0.3472\n",
            "02/09 17:28:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][120/332]  lr: 1.0000e-02  eta: 3:37:01  time: 0.3951  data_time: 0.0104  memory: 6616  grad_norm: 1.8171  loss: 1.1013  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7349  loss_aux: 0.3664\n",
            "02/09 17:28:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][140/332]  lr: 1.0000e-02  eta: 3:36:53  time: 0.3940  data_time: 0.0095  memory: 6616  grad_norm: 2.1401  loss: 1.0751  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7155  loss_aux: 0.3597\n",
            "02/09 17:29:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][160/332]  lr: 1.0000e-02  eta: 3:36:45  time: 0.3945  data_time: 0.0098  memory: 6616  grad_norm: 1.8098  loss: 1.0980  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7344  loss_aux: 0.3637\n",
            "02/09 17:29:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][180/332]  lr: 1.0000e-02  eta: 3:36:37  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 1.6470  loss: 1.0735  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7162  loss_aux: 0.3573\n",
            "02/09 17:29:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][200/332]  lr: 1.0000e-02  eta: 3:36:29  time: 0.3946  data_time: 0.0102  memory: 6616  grad_norm: 1.7330  loss: 1.0450  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7016  loss_aux: 0.3434\n",
            "02/09 17:29:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][220/332]  lr: 1.0000e-02  eta: 3:36:21  time: 0.3964  data_time: 0.0114  memory: 6616  grad_norm: 1.6734  loss: 1.0805  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7365  loss_aux: 0.3440\n",
            "02/09 17:29:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][240/332]  lr: 1.0000e-02  eta: 3:36:13  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 1.5504  loss: 1.0184  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6874  loss_aux: 0.3310\n",
            "02/09 17:29:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][260/332]  lr: 1.0000e-02  eta: 3:36:05  time: 0.3960  data_time: 0.0107  memory: 6616  grad_norm: 2.1069  loss: 1.0981  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7439  loss_aux: 0.3542\n",
            "02/09 17:29:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][280/332]  lr: 1.0000e-02  eta: 3:35:57  time: 0.3960  data_time: 0.0109  memory: 6616  grad_norm: 1.5271  loss: 1.0826  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7177  loss_aux: 0.3649\n",
            "02/09 17:29:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][300/332]  lr: 1.0000e-02  eta: 3:35:49  time: 0.3945  data_time: 0.0102  memory: 6616  grad_norm: 1.5517  loss: 1.0044  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6560  loss_aux: 0.3484\n",
            "02/09 17:30:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][320/332]  lr: 1.0000e-02  eta: 3:35:41  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 1.7575  loss: 1.0868  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7330  loss_aux: 0.3538\n",
            "02/09 17:30:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:30:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][332/332]  lr: 1.0000e-02  eta: 3:35:36  time: 0.3892  data_time: 0.0092  memory: 6616  grad_norm: 1.6305  loss: 1.0198  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6794  loss_aux: 0.3404\n",
            "02/09 17:30:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 52 epochs\n",
            "02/09 17:30:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][ 20/332]  lr: 1.0000e-02  eta: 3:35:29  time: 0.4446  data_time: 0.0562  memory: 6616  grad_norm: 1.9075  loss: 1.0648  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7181  loss_aux: 0.3467\n",
            "02/09 17:30:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][ 40/332]  lr: 1.0000e-02  eta: 3:35:21  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 1.5150  loss: 1.0100  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6687  loss_aux: 0.3413\n",
            "02/09 17:30:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][ 60/332]  lr: 1.0000e-02  eta: 3:35:13  time: 0.3951  data_time: 0.0102  memory: 6616  grad_norm: 1.8805  loss: 1.0874  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7405  loss_aux: 0.3469\n",
            "02/09 17:30:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][ 80/332]  lr: 1.0000e-02  eta: 3:35:05  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 1.8251  loss: 1.0428  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6950  loss_aux: 0.3479\n",
            "02/09 17:30:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][100/332]  lr: 1.0000e-02  eta: 3:34:57  time: 0.3952  data_time: 0.0105  memory: 6616  grad_norm: 2.0140  loss: 1.1003  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7620  loss_aux: 0.3383\n",
            "02/09 17:31:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][120/332]  lr: 1.0000e-02  eta: 3:34:49  time: 0.3958  data_time: 0.0107  memory: 6616  grad_norm: 1.7400  loss: 1.0558  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7126  loss_aux: 0.3431\n",
            "02/09 17:31:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][140/332]  lr: 1.0000e-02  eta: 3:34:41  time: 0.3945  data_time: 0.0102  memory: 6616  grad_norm: 1.7708  loss: 1.1236  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7552  loss_aux: 0.3684\n",
            "02/09 17:31:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][160/332]  lr: 1.0000e-02  eta: 3:34:33  time: 0.3941  data_time: 0.0096  memory: 6616  grad_norm: 1.7676  loss: 1.1250  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.7690  loss_aux: 0.3560\n",
            "02/09 17:31:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][180/332]  lr: 1.0000e-02  eta: 3:34:25  time: 0.3949  data_time: 0.0100  memory: 6616  grad_norm: 1.6702  loss: 1.0811  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7226  loss_aux: 0.3586\n",
            "02/09 17:31:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][200/332]  lr: 1.0000e-02  eta: 3:34:17  time: 0.3944  data_time: 0.0097  memory: 6616  grad_norm: 1.7266  loss: 1.0869  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7435  loss_aux: 0.3433\n",
            "02/09 17:31:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][220/332]  lr: 1.0000e-02  eta: 3:34:09  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 1.5659  loss: 1.0604  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7026  loss_aux: 0.3578\n",
            "02/09 17:31:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][240/332]  lr: 1.0000e-02  eta: 3:34:01  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 1.6344  loss: 1.0933  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7400  loss_aux: 0.3533\n",
            "02/09 17:31:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][260/332]  lr: 1.0000e-02  eta: 3:33:53  time: 0.3940  data_time: 0.0095  memory: 6616  grad_norm: 1.5119  loss: 1.0777  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7241  loss_aux: 0.3535\n",
            "02/09 17:32:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][280/332]  lr: 1.0000e-02  eta: 3:33:45  time: 0.3952  data_time: 0.0104  memory: 6616  grad_norm: 1.4526  loss: 1.0109  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6815  loss_aux: 0.3294\n",
            "02/09 17:32:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][300/332]  lr: 1.0000e-02  eta: 3:33:37  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 2.1257  loss: 1.0884  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7390  loss_aux: 0.3494\n",
            "02/09 17:32:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][320/332]  lr: 1.0000e-02  eta: 3:33:29  time: 0.3955  data_time: 0.0105  memory: 6616  grad_norm: 1.5104  loss: 1.0653  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7079  loss_aux: 0.3574\n",
            "02/09 17:32:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:32:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][332/332]  lr: 1.0000e-02  eta: 3:33:24  time: 0.3893  data_time: 0.0091  memory: 6616  grad_norm: 1.6956  loss: 1.0974  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7386  loss_aux: 0.3587\n",
            "02/09 17:32:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 53 epochs\n",
            "02/09 17:32:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][ 20/332]  lr: 1.0000e-02  eta: 3:33:17  time: 0.4388  data_time: 0.0527  memory: 6616  grad_norm: 1.9070  loss: 1.0740  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7134  loss_aux: 0.3606\n",
            "02/09 17:32:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][ 40/332]  lr: 1.0000e-02  eta: 3:33:09  time: 0.3958  data_time: 0.0109  memory: 6616  grad_norm: 3.2914  loss: 1.1022  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7336  loss_aux: 0.3686\n",
            "02/09 17:32:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][ 60/332]  lr: 1.0000e-02  eta: 3:33:01  time: 0.3952  data_time: 0.0104  memory: 6616  grad_norm: 3.2867  loss: 1.1793  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.8097  loss_aux: 0.3696\n",
            "02/09 17:33:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][ 80/332]  lr: 1.0000e-02  eta: 3:32:53  time: 0.3934  data_time: 0.0093  memory: 6616  grad_norm: 2.2216  loss: 1.0934  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7133  loss_aux: 0.3801\n",
            "02/09 17:33:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][100/332]  lr: 1.0000e-02  eta: 3:32:45  time: 0.3952  data_time: 0.0104  memory: 6616  grad_norm: 1.9816  loss: 1.0433  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6976  loss_aux: 0.3458\n",
            "02/09 17:33:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][120/332]  lr: 1.0000e-02  eta: 3:32:37  time: 0.3958  data_time: 0.0107  memory: 6616  grad_norm: 1.8719  loss: 1.0609  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6998  loss_aux: 0.3612\n",
            "02/09 17:33:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][140/332]  lr: 1.0000e-02  eta: 3:32:29  time: 0.3939  data_time: 0.0095  memory: 6616  grad_norm: 2.6010  loss: 1.0890  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7311  loss_aux: 0.3579\n",
            "02/09 17:33:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][160/332]  lr: 1.0000e-02  eta: 3:32:21  time: 0.3958  data_time: 0.0107  memory: 6616  grad_norm: 2.2197  loss: 1.1527  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7904  loss_aux: 0.3623\n",
            "02/09 17:33:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][180/332]  lr: 1.0000e-02  eta: 3:32:13  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 2.0745  loss: 1.1226  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7438  loss_aux: 0.3788\n",
            "02/09 17:33:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][200/332]  lr: 1.0000e-02  eta: 3:32:05  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 2.0168  loss: 1.1351  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7610  loss_aux: 0.3741\n",
            "02/09 17:33:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][220/332]  lr: 1.0000e-02  eta: 3:31:57  time: 0.3947  data_time: 0.0098  memory: 6616  grad_norm: 2.1459  loss: 1.1027  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7463  loss_aux: 0.3564\n",
            "02/09 17:34:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][240/332]  lr: 1.0000e-02  eta: 3:31:49  time: 0.3948  data_time: 0.0099  memory: 6616  grad_norm: 1.8046  loss: 1.0362  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6782  loss_aux: 0.3580\n",
            "02/09 17:34:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][260/332]  lr: 1.0000e-02  eta: 3:31:41  time: 0.3935  data_time: 0.0094  memory: 6616  grad_norm: 2.1093  loss: 1.1168  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7599  loss_aux: 0.3569\n",
            "02/09 17:34:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][280/332]  lr: 1.0000e-02  eta: 3:31:32  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 1.7752  loss: 1.0196  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6884  loss_aux: 0.3312\n",
            "02/09 17:34:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][300/332]  lr: 1.0000e-02  eta: 3:31:24  time: 0.3944  data_time: 0.0099  memory: 6616  grad_norm: 2.1107  loss: 1.0877  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7102  loss_aux: 0.3775\n",
            "02/09 17:34:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][320/332]  lr: 1.0000e-02  eta: 3:31:16  time: 0.3944  data_time: 0.0101  memory: 6616  grad_norm: 2.0141  loss: 1.0087  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6732  loss_aux: 0.3355\n",
            "02/09 17:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][332/332]  lr: 1.0000e-02  eta: 3:31:11  time: 0.3894  data_time: 0.0098  memory: 6616  grad_norm: 1.9273  loss: 1.0022  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6556  loss_aux: 0.3465\n",
            "02/09 17:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 54 epochs\n",
            "02/09 17:34:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][ 20/332]  lr: 1.0000e-02  eta: 3:31:05  time: 0.4360  data_time: 0.0463  memory: 6616  grad_norm: 1.8384  loss: 1.1044  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7392  loss_aux: 0.3651\n",
            "02/09 17:34:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][ 40/332]  lr: 1.0000e-02  eta: 3:30:57  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 1.6755  loss: 1.0622  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7068  loss_aux: 0.3554\n",
            "02/09 17:35:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][ 60/332]  lr: 1.0000e-02  eta: 3:30:49  time: 0.3956  data_time: 0.0111  memory: 6616  grad_norm: 1.8317  loss: 1.0407  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7023  loss_aux: 0.3384\n",
            "02/09 17:35:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:35:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][ 80/332]  lr: 1.0000e-02  eta: 3:30:41  time: 0.3940  data_time: 0.0099  memory: 6616  grad_norm: 1.9805  loss: 1.1104  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7703  loss_aux: 0.3402\n",
            "02/09 17:35:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][100/332]  lr: 1.0000e-02  eta: 3:30:32  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 1.8607  loss: 1.0462  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7140  loss_aux: 0.3322\n",
            "02/09 17:35:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][120/332]  lr: 1.0000e-02  eta: 3:30:24  time: 0.3947  data_time: 0.0106  memory: 6616  grad_norm: 1.8033  loss: 1.0796  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.7281  loss_aux: 0.3515\n",
            "02/09 17:35:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][140/332]  lr: 1.0000e-02  eta: 3:30:16  time: 0.3933  data_time: 0.0097  memory: 6616  grad_norm: 1.7756  loss: 1.0787  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7284  loss_aux: 0.3503\n",
            "02/09 17:35:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][160/332]  lr: 1.0000e-02  eta: 3:30:08  time: 0.3950  data_time: 0.0107  memory: 6616  grad_norm: 1.7626  loss: 1.0496  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6997  loss_aux: 0.3499\n",
            "02/09 17:35:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][180/332]  lr: 1.0000e-02  eta: 3:30:00  time: 0.3952  data_time: 0.0105  memory: 6616  grad_norm: 1.7613  loss: 1.0488  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7014  loss_aux: 0.3474\n",
            "02/09 17:36:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][200/332]  lr: 1.0000e-02  eta: 3:29:52  time: 0.3942  data_time: 0.0098  memory: 6616  grad_norm: 1.7426  loss: 1.0511  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7018  loss_aux: 0.3493\n",
            "02/09 17:36:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][220/332]  lr: 1.0000e-02  eta: 3:29:44  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 2.0317  loss: 1.1063  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7537  loss_aux: 0.3527\n",
            "02/09 17:36:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][240/332]  lr: 1.0000e-02  eta: 3:29:36  time: 0.3944  data_time: 0.0099  memory: 6616  grad_norm: 2.0080  loss: 1.1076  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7552  loss_aux: 0.3523\n",
            "02/09 17:36:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][260/332]  lr: 1.0000e-02  eta: 3:29:28  time: 0.3943  data_time: 0.0099  memory: 6616  grad_norm: 1.9597  loss: 1.1023  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7335  loss_aux: 0.3688\n",
            "02/09 17:36:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][280/332]  lr: 1.0000e-02  eta: 3:29:20  time: 0.3947  data_time: 0.0104  memory: 6616  grad_norm: 2.3257  loss: 1.1426  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7816  loss_aux: 0.3610\n",
            "02/09 17:36:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][300/332]  lr: 1.0000e-02  eta: 3:29:12  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 1.5663  loss: 1.0686  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7138  loss_aux: 0.3547\n",
            "02/09 17:36:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][320/332]  lr: 1.0000e-02  eta: 3:29:04  time: 0.3941  data_time: 0.0101  memory: 6616  grad_norm: 1.7004  loss: 1.0957  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7414  loss_aux: 0.3543\n",
            "02/09 17:36:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:36:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][332/332]  lr: 1.0000e-02  eta: 3:28:59  time: 0.3886  data_time: 0.0091  memory: 6616  grad_norm: 1.5119  loss: 1.0392  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6957  loss_aux: 0.3435\n",
            "02/09 17:36:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 55 epochs\n",
            "02/09 17:37:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][ 20/332]  lr: 1.0000e-02  eta: 3:28:53  time: 0.4488  data_time: 0.0584  memory: 6616  grad_norm: 1.6188  loss: 1.0434  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6866  loss_aux: 0.3568\n",
            "02/09 17:37:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][ 40/332]  lr: 1.0000e-02  eta: 3:28:45  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 1.8488  loss: 1.1009  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7342  loss_aux: 0.3667\n",
            "02/09 17:37:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][ 60/332]  lr: 1.0000e-02  eta: 3:28:37  time: 0.3954  data_time: 0.0111  memory: 6616  grad_norm: 1.9828  loss: 1.0466  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7025  loss_aux: 0.3441\n",
            "02/09 17:37:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][ 80/332]  lr: 1.0000e-02  eta: 3:28:29  time: 0.3949  data_time: 0.0107  memory: 6616  grad_norm: 2.1145  loss: 1.1297  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7678  loss_aux: 0.3618\n",
            "02/09 17:37:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][100/332]  lr: 1.0000e-02  eta: 3:28:20  time: 0.3947  data_time: 0.0106  memory: 6616  grad_norm: 1.7716  loss: 1.0717  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7110  loss_aux: 0.3607\n",
            "02/09 17:37:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][120/332]  lr: 1.0000e-02  eta: 3:28:12  time: 0.3950  data_time: 0.0106  memory: 6616  grad_norm: 1.8475  loss: 1.0840  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7205  loss_aux: 0.3635\n",
            "02/09 17:37:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][140/332]  lr: 1.0000e-02  eta: 3:28:04  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 2.0532  loss: 1.0857  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7257  loss_aux: 0.3600\n",
            "02/09 17:38:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][160/332]  lr: 1.0000e-02  eta: 3:27:56  time: 0.3945  data_time: 0.0104  memory: 6616  grad_norm: 3.4031  loss: 1.0699  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7160  loss_aux: 0.3539\n",
            "02/09 17:38:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][180/332]  lr: 1.0000e-02  eta: 3:27:48  time: 0.3942  data_time: 0.0100  memory: 6616  grad_norm: 2.7911  loss: 1.1146  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7557  loss_aux: 0.3589\n",
            "02/09 17:38:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][200/332]  lr: 1.0000e-02  eta: 3:27:40  time: 0.3949  data_time: 0.0103  memory: 6616  grad_norm: 1.8062  loss: 1.0049  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6790  loss_aux: 0.3260\n",
            "02/09 17:38:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][220/332]  lr: 1.0000e-02  eta: 3:27:32  time: 0.3961  data_time: 0.0109  memory: 6616  grad_norm: 1.9727  loss: 1.0550  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7027  loss_aux: 0.3522\n",
            "02/09 17:38:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][240/332]  lr: 1.0000e-02  eta: 3:27:24  time: 0.3943  data_time: 0.0101  memory: 6616  grad_norm: 2.2713  loss: 1.0605  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7172  loss_aux: 0.3432\n",
            "02/09 17:38:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][260/332]  lr: 1.0000e-02  eta: 3:27:16  time: 0.3950  data_time: 0.0110  memory: 6616  grad_norm: 2.3331  loss: 1.1386  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7812  loss_aux: 0.3574\n",
            "02/09 17:38:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][280/332]  lr: 1.0000e-02  eta: 3:27:08  time: 0.3951  data_time: 0.0106  memory: 6616  grad_norm: 2.0430  loss: 1.0203  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6839  loss_aux: 0.3364\n",
            "02/09 17:38:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][300/332]  lr: 1.0000e-02  eta: 3:27:00  time: 0.3954  data_time: 0.0104  memory: 6616  grad_norm: 1.8899  loss: 1.0726  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7163  loss_aux: 0.3563\n",
            "02/09 17:39:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][320/332]  lr: 1.0000e-02  eta: 3:26:52  time: 0.3942  data_time: 0.0098  memory: 6616  grad_norm: 1.6771  loss: 1.0759  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7261  loss_aux: 0.3498\n",
            "02/09 17:39:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:39:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][332/332]  lr: 1.0000e-02  eta: 3:26:47  time: 0.3891  data_time: 0.0097  memory: 6616  grad_norm: 1.9233  loss: 1.1212  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.7715  loss_aux: 0.3497\n",
            "02/09 17:39:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 56 epochs\n",
            "02/09 17:39:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][ 20/332]  lr: 1.0000e-02  eta: 3:26:40  time: 0.4394  data_time: 0.0515  memory: 6616  grad_norm: 1.7545  loss: 1.0802  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7259  loss_aux: 0.3543\n",
            "02/09 17:39:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][ 40/332]  lr: 1.0000e-02  eta: 3:26:32  time: 0.3946  data_time: 0.0103  memory: 6616  grad_norm: 1.6341  loss: 1.0500  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7020  loss_aux: 0.3481\n",
            "02/09 17:39:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][ 60/332]  lr: 1.0000e-02  eta: 3:26:24  time: 0.3943  data_time: 0.0099  memory: 6616  grad_norm: 1.9626  loss: 1.0618  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7155  loss_aux: 0.3463\n",
            "02/09 17:39:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][ 80/332]  lr: 1.0000e-02  eta: 3:26:16  time: 0.3943  data_time: 0.0100  memory: 6616  grad_norm: 1.6886  loss: 1.0456  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7043  loss_aux: 0.3412\n",
            "02/09 17:39:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][100/332]  lr: 1.0000e-02  eta: 3:26:08  time: 0.3951  data_time: 0.0106  memory: 6616  grad_norm: 1.6312  loss: 1.0645  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7134  loss_aux: 0.3511\n",
            "02/09 17:39:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][120/332]  lr: 1.0000e-02  eta: 3:26:00  time: 0.3966  data_time: 0.0117  memory: 6616  grad_norm: 1.6225  loss: 1.0288  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6732  loss_aux: 0.3557\n",
            "02/09 17:40:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][140/332]  lr: 1.0000e-02  eta: 3:25:52  time: 0.3952  data_time: 0.0108  memory: 6616  grad_norm: 1.6961  loss: 1.0554  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7015  loss_aux: 0.3539\n",
            "02/09 17:40:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][160/332]  lr: 1.0000e-02  eta: 3:25:44  time: 0.3953  data_time: 0.0109  memory: 6616  grad_norm: 1.8563  loss: 1.0476  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7066  loss_aux: 0.3409\n",
            "02/09 17:40:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][180/332]  lr: 1.0000e-02  eta: 3:25:36  time: 0.3954  data_time: 0.0108  memory: 6616  grad_norm: 1.8938  loss: 1.1012  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7466  loss_aux: 0.3546\n",
            "02/09 17:40:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][200/332]  lr: 1.0000e-02  eta: 3:25:28  time: 0.3944  data_time: 0.0105  memory: 6616  grad_norm: 1.8003  loss: 1.0593  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7127  loss_aux: 0.3466\n",
            "02/09 17:40:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][220/332]  lr: 1.0000e-02  eta: 3:25:20  time: 0.3968  data_time: 0.0114  memory: 6616  grad_norm: 2.6057  loss: 1.1191  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7761  loss_aux: 0.3430\n",
            "02/09 17:40:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][240/332]  lr: 1.0000e-02  eta: 3:25:12  time: 0.3945  data_time: 0.0103  memory: 6616  grad_norm: 2.0143  loss: 1.0620  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7068  loss_aux: 0.3552\n",
            "02/09 17:40:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][260/332]  lr: 1.0000e-02  eta: 3:25:04  time: 0.3943  data_time: 0.0099  memory: 6616  grad_norm: 1.9792  loss: 1.1773  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.8045  loss_aux: 0.3728\n",
            "02/09 17:41:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][280/332]  lr: 1.0000e-02  eta: 3:24:56  time: 0.3959  data_time: 0.0110  memory: 6616  grad_norm: 2.7880  loss: 1.0919  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7342  loss_aux: 0.3577\n",
            "02/09 17:41:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][300/332]  lr: 1.0000e-02  eta: 3:24:48  time: 0.3949  data_time: 0.0103  memory: 6616  grad_norm: 1.8832  loss: 1.0937  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7356  loss_aux: 0.3581\n",
            "02/09 17:41:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][320/332]  lr: 1.0000e-02  eta: 3:24:40  time: 0.3937  data_time: 0.0099  memory: 6616  grad_norm: 1.6322  loss: 1.0759  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7140  loss_aux: 0.3618\n",
            "02/09 17:41:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:41:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][332/332]  lr: 1.0000e-02  eta: 3:24:35  time: 0.3893  data_time: 0.0097  memory: 6616  grad_norm: 2.0035  loss: 1.0422  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6982  loss_aux: 0.3440\n",
            "02/09 17:41:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 57 epochs\n",
            "02/09 17:41:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][ 20/332]  lr: 1.0000e-02  eta: 3:24:29  time: 0.4474  data_time: 0.0600  memory: 6616  grad_norm: 2.1633  loss: 1.0757  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7271  loss_aux: 0.3486\n",
            "02/09 17:41:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][ 40/332]  lr: 1.0000e-02  eta: 3:24:20  time: 0.3935  data_time: 0.0096  memory: 6616  grad_norm: 1.9150  loss: 1.0520  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6977  loss_aux: 0.3543\n",
            "02/09 17:41:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][ 60/332]  lr: 1.0000e-02  eta: 3:24:12  time: 0.3954  data_time: 0.0107  memory: 6616  grad_norm: 2.1333  loss: 0.9931  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6471  loss_aux: 0.3459\n",
            "02/09 17:41:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:41:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][ 80/332]  lr: 1.0000e-02  eta: 3:24:04  time: 0.3949  data_time: 0.0103  memory: 6616  grad_norm: 1.8635  loss: 1.0416  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7004  loss_aux: 0.3412\n",
            "02/09 17:42:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][100/332]  lr: 1.0000e-02  eta: 3:23:56  time: 0.3956  data_time: 0.0107  memory: 6616  grad_norm: 3.3722  loss: 1.2340  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.8219  loss_aux: 0.4121\n",
            "02/09 17:42:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][120/332]  lr: 1.0000e-02  eta: 3:23:48  time: 0.3948  data_time: 0.0105  memory: 6616  grad_norm: 2.0122  loss: 1.0819  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7154  loss_aux: 0.3666\n",
            "02/09 17:42:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][140/332]  lr: 1.0000e-02  eta: 3:23:40  time: 0.3950  data_time: 0.0105  memory: 6616  grad_norm: 2.3090  loss: 1.1228  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7635  loss_aux: 0.3593\n",
            "02/09 17:42:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][160/332]  lr: 1.0000e-02  eta: 3:23:32  time: 0.3955  data_time: 0.0108  memory: 6616  grad_norm: 1.8288  loss: 1.1056  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7584  loss_aux: 0.3472\n",
            "02/09 17:42:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][180/332]  lr: 1.0000e-02  eta: 3:23:24  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 2.2738  loss: 1.1867  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.8238  loss_aux: 0.3629\n",
            "02/09 17:42:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][200/332]  lr: 1.0000e-02  eta: 3:23:16  time: 0.3946  data_time: 0.0102  memory: 6616  grad_norm: 1.7377  loss: 1.0229  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6753  loss_aux: 0.3476\n",
            "02/09 17:42:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][220/332]  lr: 1.0000e-02  eta: 3:23:08  time: 0.3944  data_time: 0.0103  memory: 6616  grad_norm: 2.3728  loss: 1.0982  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7553  loss_aux: 0.3429\n",
            "02/09 17:43:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][240/332]  lr: 1.0000e-02  eta: 3:23:00  time: 0.3950  data_time: 0.0109  memory: 6616  grad_norm: 2.0404  loss: 1.0941  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7337  loss_aux: 0.3605\n",
            "02/09 17:43:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][260/332]  lr: 1.0000e-02  eta: 3:22:52  time: 0.3938  data_time: 0.0099  memory: 6616  grad_norm: 1.5313  loss: 1.0273  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6801  loss_aux: 0.3472\n",
            "02/09 17:43:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][280/332]  lr: 1.0000e-02  eta: 3:22:44  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 1.9568  loss: 1.1554  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7921  loss_aux: 0.3633\n",
            "02/09 17:43:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][300/332]  lr: 1.0000e-02  eta: 3:22:36  time: 0.3956  data_time: 0.0111  memory: 6616  grad_norm: 1.6828  loss: 1.0615  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7143  loss_aux: 0.3472\n",
            "02/09 17:43:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][320/332]  lr: 1.0000e-02  eta: 3:22:28  time: 0.3939  data_time: 0.0102  memory: 6616  grad_norm: 1.9175  loss: 1.0319  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6850  loss_aux: 0.3469\n",
            "02/09 17:43:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:43:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][332/332]  lr: 1.0000e-02  eta: 3:22:23  time: 0.3892  data_time: 0.0096  memory: 6616  grad_norm: 1.8156  loss: 1.0597  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6953  loss_aux: 0.3644\n",
            "02/09 17:43:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 58 epochs\n",
            "02/09 17:43:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][ 20/332]  lr: 1.0000e-02  eta: 3:22:16  time: 0.4430  data_time: 0.0568  memory: 6616  grad_norm: 1.7069  loss: 1.0422  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6940  loss_aux: 0.3483\n",
            "02/09 17:43:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][ 40/332]  lr: 1.0000e-02  eta: 3:22:08  time: 0.3938  data_time: 0.0096  memory: 6616  grad_norm: 1.8037  loss: 1.1085  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7574  loss_aux: 0.3511\n",
            "02/09 17:44:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][ 60/332]  lr: 1.0000e-02  eta: 3:22:00  time: 0.3947  data_time: 0.0103  memory: 6616  grad_norm: 1.9327  loss: 1.1214  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7554  loss_aux: 0.3660\n",
            "02/09 17:44:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][ 80/332]  lr: 1.0000e-02  eta: 3:21:52  time: 0.3949  data_time: 0.0104  memory: 6616  grad_norm: 1.7976  loss: 1.0680  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7138  loss_aux: 0.3542\n",
            "02/09 17:44:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][100/332]  lr: 1.0000e-02  eta: 3:21:44  time: 0.3939  data_time: 0.0097  memory: 6616  grad_norm: 1.8021  loss: 1.0883  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7292  loss_aux: 0.3591\n",
            "02/09 17:44:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][120/332]  lr: 1.0000e-02  eta: 3:21:36  time: 0.3942  data_time: 0.0103  memory: 6616  grad_norm: 2.1329  loss: 1.0558  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6979  loss_aux: 0.3579\n",
            "02/09 17:44:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][140/332]  lr: 1.0000e-02  eta: 3:21:28  time: 0.3945  data_time: 0.0104  memory: 6616  grad_norm: 1.8138  loss: 1.0552  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6890  loss_aux: 0.3661\n",
            "02/09 17:44:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][160/332]  lr: 1.0000e-02  eta: 3:21:20  time: 0.3951  data_time: 0.0106  memory: 6616  grad_norm: 1.9095  loss: 1.0759  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7295  loss_aux: 0.3463\n",
            "02/09 17:44:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][180/332]  lr: 1.0000e-02  eta: 3:21:12  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 1.7648  loss: 1.0430  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6967  loss_aux: 0.3462\n",
            "02/09 17:44:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][200/332]  lr: 1.0000e-02  eta: 3:21:04  time: 0.3941  data_time: 0.0098  memory: 6616  grad_norm: 1.8603  loss: 1.0188  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6616  loss_aux: 0.3572\n",
            "02/09 17:45:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][220/332]  lr: 1.0000e-02  eta: 3:20:56  time: 0.3951  data_time: 0.0107  memory: 6616  grad_norm: 1.7050  loss: 0.9762  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6511  loss_aux: 0.3252\n",
            "02/09 17:45:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][240/332]  lr: 1.0000e-02  eta: 3:20:48  time: 0.3951  data_time: 0.0105  memory: 6616  grad_norm: 2.2910  loss: 1.0924  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7383  loss_aux: 0.3541\n",
            "02/09 17:45:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][260/332]  lr: 1.0000e-02  eta: 3:20:40  time: 0.3941  data_time: 0.0097  memory: 6616  grad_norm: 2.3246  loss: 1.0857  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7286  loss_aux: 0.3571\n",
            "02/09 17:45:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][280/332]  lr: 1.0000e-02  eta: 3:20:32  time: 0.3942  data_time: 0.0100  memory: 6616  grad_norm: 1.7355  loss: 1.1350  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7925  loss_aux: 0.3425\n",
            "02/09 17:45:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][300/332]  lr: 1.0000e-02  eta: 3:20:24  time: 0.3944  data_time: 0.0099  memory: 6616  grad_norm: 2.0881  loss: 1.0491  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6883  loss_aux: 0.3608\n",
            "02/09 17:45:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][320/332]  lr: 1.0000e-02  eta: 3:20:16  time: 0.3940  data_time: 0.0099  memory: 6616  grad_norm: 1.6370  loss: 1.0639  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7107  loss_aux: 0.3532\n",
            "02/09 17:45:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:45:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][332/332]  lr: 1.0000e-02  eta: 3:20:11  time: 0.3893  data_time: 0.0096  memory: 6616  grad_norm: 1.6906  loss: 1.0946  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7438  loss_aux: 0.3508\n",
            "02/09 17:45:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 59 epochs\n",
            "02/09 17:46:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][ 20/332]  lr: 1.0000e-02  eta: 3:20:04  time: 0.4492  data_time: 0.0633  memory: 6616  grad_norm: 1.8945  loss: 1.0836  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7389  loss_aux: 0.3448\n",
            "02/09 17:46:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][ 40/332]  lr: 1.0000e-02  eta: 3:19:56  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 1.6729  loss: 1.0659  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7154  loss_aux: 0.3505\n",
            "02/09 17:46:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][ 60/332]  lr: 1.0000e-02  eta: 3:19:48  time: 0.3945  data_time: 0.0099  memory: 6616  grad_norm: 1.6708  loss: 1.0339  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6948  loss_aux: 0.3391\n",
            "02/09 17:46:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][ 80/332]  lr: 1.0000e-02  eta: 3:19:40  time: 0.3945  data_time: 0.0103  memory: 6616  grad_norm: 2.0950  loss: 1.0677  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7064  loss_aux: 0.3613\n",
            "02/09 17:46:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][100/332]  lr: 1.0000e-02  eta: 3:19:32  time: 0.3948  data_time: 0.0104  memory: 6616  grad_norm: 2.4315  loss: 1.0612  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7249  loss_aux: 0.3363\n",
            "02/09 17:46:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][120/332]  lr: 1.0000e-02  eta: 3:19:24  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 2.0560  loss: 1.0846  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7231  loss_aux: 0.3615\n",
            "02/09 17:46:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][140/332]  lr: 1.0000e-02  eta: 3:19:16  time: 0.3939  data_time: 0.0097  memory: 6616  grad_norm: 4.8257  loss: 1.0944  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7370  loss_aux: 0.3574\n",
            "02/09 17:46:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][160/332]  lr: 1.0000e-02  eta: 3:19:08  time: 0.3941  data_time: 0.0098  memory: 6616  grad_norm: 2.1919  loss: 1.0530  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6947  loss_aux: 0.3582\n",
            "02/09 17:47:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][180/332]  lr: 1.0000e-02  eta: 3:19:00  time: 0.3956  data_time: 0.0109  memory: 6616  grad_norm: 2.1501  loss: 1.0812  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7284  loss_aux: 0.3529\n",
            "02/09 17:47:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][200/332]  lr: 1.0000e-02  eta: 3:18:52  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 1.8416  loss: 1.0640  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7174  loss_aux: 0.3466\n",
            "02/09 17:47:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][220/332]  lr: 1.0000e-02  eta: 3:18:44  time: 0.3954  data_time: 0.0107  memory: 6616  grad_norm: 1.8026  loss: 1.0880  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7232  loss_aux: 0.3648\n",
            "02/09 17:47:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][240/332]  lr: 1.0000e-02  eta: 3:18:36  time: 0.3940  data_time: 0.0100  memory: 6616  grad_norm: 1.9417  loss: 1.0392  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7140  loss_aux: 0.3253\n",
            "02/09 17:47:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][260/332]  lr: 1.0000e-02  eta: 3:18:28  time: 0.3943  data_time: 0.0100  memory: 6616  grad_norm: 1.9585  loss: 1.1155  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7366  loss_aux: 0.3790\n",
            "02/09 17:47:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][280/332]  lr: 1.0000e-02  eta: 3:18:20  time: 0.3944  data_time: 0.0102  memory: 6616  grad_norm: 2.2799  loss: 1.1131  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7513  loss_aux: 0.3618\n",
            "02/09 17:47:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][300/332]  lr: 1.0000e-02  eta: 3:18:12  time: 0.3943  data_time: 0.0102  memory: 6616  grad_norm: 2.3122  loss: 1.0853  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7500  loss_aux: 0.3354\n",
            "02/09 17:48:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][320/332]  lr: 1.0000e-02  eta: 3:18:04  time: 0.3945  data_time: 0.0103  memory: 6616  grad_norm: 1.9234  loss: 1.0140  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6646  loss_aux: 0.3494\n",
            "02/09 17:48:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:48:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][332/332]  lr: 1.0000e-02  eta: 3:17:59  time: 0.3891  data_time: 0.0095  memory: 6616  grad_norm: 2.1537  loss: 1.1397  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.7739  loss_aux: 0.3659\n",
            "02/09 17:48:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 60 epochs\n",
            "02/09 17:48:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [60][20/42]    eta: 0:00:04  time: 0.1856  data_time: 0.0784  memory: 1447  \n",
            "02/09 17:48:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [60][40/42]    eta: 0:00:00  time: 0.1129  data_time: 0.0120  memory: 1447  \n",
            "02/09 17:48:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [60][42/42]    acc/top1: 0.5301  acc/top5: 1.0000  acc/mean1: 0.4980  data_time: 0.0425  time: 0.1439\n",
            "02/09 17:48:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][ 20/332]  lr: 1.0000e-02  eta: 3:17:52  time: 0.4415  data_time: 0.0567  memory: 6616  grad_norm: 2.1792  loss: 1.0727  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7027  loss_aux: 0.3700\n",
            "02/09 17:48:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][ 40/332]  lr: 1.0000e-02  eta: 3:17:44  time: 0.3944  data_time: 0.0104  memory: 6616  grad_norm: 1.8548  loss: 1.1049  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7361  loss_aux: 0.3688\n",
            "02/09 17:48:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][ 60/332]  lr: 1.0000e-02  eta: 3:17:36  time: 0.3943  data_time: 0.0102  memory: 6616  grad_norm: 1.7684  loss: 1.0612  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7069  loss_aux: 0.3543\n",
            "02/09 17:48:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:48:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][ 80/332]  lr: 1.0000e-02  eta: 3:17:28  time: 0.3934  data_time: 0.0099  memory: 6616  grad_norm: 1.6074  loss: 1.0399  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6942  loss_aux: 0.3457\n",
            "02/09 17:48:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][100/332]  lr: 1.0000e-02  eta: 3:17:20  time: 0.3945  data_time: 0.0102  memory: 6616  grad_norm: 1.9582  loss: 1.0562  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7053  loss_aux: 0.3508\n",
            "02/09 17:49:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][120/332]  lr: 1.0000e-02  eta: 3:17:12  time: 0.3938  data_time: 0.0098  memory: 6616  grad_norm: 1.6702  loss: 1.0507  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7030  loss_aux: 0.3477\n",
            "02/09 17:49:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][140/332]  lr: 1.0000e-02  eta: 3:17:04  time: 0.3944  data_time: 0.0104  memory: 6616  grad_norm: 1.7743  loss: 1.0836  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7240  loss_aux: 0.3596\n",
            "02/09 17:49:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][160/332]  lr: 1.0000e-02  eta: 3:16:56  time: 0.3946  data_time: 0.0102  memory: 6616  grad_norm: 1.9745  loss: 1.0608  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7147  loss_aux: 0.3461\n",
            "02/09 17:49:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][180/332]  lr: 1.0000e-02  eta: 3:16:48  time: 0.3939  data_time: 0.0100  memory: 6616  grad_norm: 1.9201  loss: 1.0261  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6810  loss_aux: 0.3451\n",
            "02/09 17:49:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][200/332]  lr: 1.0000e-02  eta: 3:16:40  time: 0.3942  data_time: 0.0101  memory: 6616  grad_norm: 1.8599  loss: 1.0227  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6658  loss_aux: 0.3569\n",
            "02/09 17:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][220/332]  lr: 1.0000e-02  eta: 3:16:32  time: 0.3946  data_time: 0.0104  memory: 6616  grad_norm: 1.9235  loss: 1.0542  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7004  loss_aux: 0.3538\n",
            "02/09 17:49:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][240/332]  lr: 1.0000e-02  eta: 3:16:23  time: 0.3943  data_time: 0.0100  memory: 6616  grad_norm: 1.7569  loss: 1.1176  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7528  loss_aux: 0.3647\n",
            "02/09 17:49:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][260/332]  lr: 1.0000e-02  eta: 3:16:15  time: 0.3953  data_time: 0.0106  memory: 6616  grad_norm: 1.9525  loss: 1.0896  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7265  loss_aux: 0.3632\n",
            "02/09 17:50:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][280/332]  lr: 1.0000e-02  eta: 3:16:07  time: 0.3943  data_time: 0.0097  memory: 6616  grad_norm: 1.8139  loss: 1.0474  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7086  loss_aux: 0.3388\n",
            "02/09 17:50:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][300/332]  lr: 1.0000e-02  eta: 3:15:59  time: 0.3950  data_time: 0.0103  memory: 6616  grad_norm: 1.8276  loss: 1.0683  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7234  loss_aux: 0.3449\n",
            "02/09 17:50:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][320/332]  lr: 1.0000e-02  eta: 3:15:51  time: 0.3945  data_time: 0.0105  memory: 6616  grad_norm: 1.9757  loss: 1.1175  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7501  loss_aux: 0.3674\n",
            "02/09 17:50:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:50:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][332/332]  lr: 1.0000e-02  eta: 3:15:46  time: 0.3898  data_time: 0.0101  memory: 6616  grad_norm: 1.6307  loss: 1.0433  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6998  loss_aux: 0.3435\n",
            "02/09 17:50:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 61 epochs\n",
            "02/09 17:50:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][ 20/332]  lr: 1.0000e-02  eta: 3:15:40  time: 0.4453  data_time: 0.0569  memory: 6616  grad_norm: 1.9761  loss: 1.0794  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7267  loss_aux: 0.3527\n",
            "02/09 17:50:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][ 40/332]  lr: 1.0000e-02  eta: 3:15:32  time: 0.3946  data_time: 0.0100  memory: 6616  grad_norm: 1.8206  loss: 1.1263  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7528  loss_aux: 0.3735\n",
            "02/09 17:50:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][ 60/332]  lr: 1.0000e-02  eta: 3:15:24  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 1.7229  loss: 1.1140  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7608  loss_aux: 0.3532\n",
            "02/09 17:51:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][ 80/332]  lr: 1.0000e-02  eta: 3:15:16  time: 0.3946  data_time: 0.0103  memory: 6616  grad_norm: 1.7913  loss: 1.0739  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7221  loss_aux: 0.3518\n",
            "02/09 17:51:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][100/332]  lr: 1.0000e-02  eta: 3:15:08  time: 0.3949  data_time: 0.0104  memory: 6616  grad_norm: 1.6545  loss: 1.0877  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7403  loss_aux: 0.3475\n",
            "02/09 17:51:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][120/332]  lr: 1.0000e-02  eta: 3:15:00  time: 0.3939  data_time: 0.0099  memory: 6616  grad_norm: 1.6868  loss: 1.0551  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6950  loss_aux: 0.3601\n",
            "02/09 17:51:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][140/332]  lr: 1.0000e-02  eta: 3:14:52  time: 0.3945  data_time: 0.0106  memory: 6616  grad_norm: 1.8609  loss: 1.0716  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7170  loss_aux: 0.3546\n",
            "02/09 17:51:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][160/332]  lr: 1.0000e-02  eta: 3:14:44  time: 0.3949  data_time: 0.0105  memory: 6616  grad_norm: 1.6226  loss: 1.0545  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7064  loss_aux: 0.3481\n",
            "02/09 17:51:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][180/332]  lr: 1.0000e-02  eta: 3:14:35  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 1.9017  loss: 1.0407  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6917  loss_aux: 0.3490\n",
            "02/09 17:51:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][200/332]  lr: 1.0000e-02  eta: 3:14:27  time: 0.3953  data_time: 0.0106  memory: 6616  grad_norm: 2.0128  loss: 1.0993  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7264  loss_aux: 0.3728\n",
            "02/09 17:51:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][220/332]  lr: 1.0000e-02  eta: 3:14:19  time: 0.3944  data_time: 0.0101  memory: 6616  grad_norm: 1.8149  loss: 1.1109  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7466  loss_aux: 0.3643\n",
            "02/09 17:52:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][240/332]  lr: 1.0000e-02  eta: 3:14:11  time: 0.3950  data_time: 0.0108  memory: 6616  grad_norm: 1.9379  loss: 1.0616  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7164  loss_aux: 0.3452\n",
            "02/09 17:52:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][260/332]  lr: 1.0000e-02  eta: 3:14:03  time: 0.3942  data_time: 0.0099  memory: 6616  grad_norm: 1.5856  loss: 0.9943  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6596  loss_aux: 0.3348\n",
            "02/09 17:52:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][280/332]  lr: 1.0000e-02  eta: 3:13:55  time: 0.3940  data_time: 0.0100  memory: 6616  grad_norm: 1.7779  loss: 1.0621  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7083  loss_aux: 0.3538\n",
            "02/09 17:52:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][300/332]  lr: 1.0000e-02  eta: 3:13:47  time: 0.3947  data_time: 0.0107  memory: 6616  grad_norm: 1.9165  loss: 1.0853  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7557  loss_aux: 0.3297\n",
            "02/09 17:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][320/332]  lr: 1.0000e-02  eta: 3:13:39  time: 0.3948  data_time: 0.0106  memory: 6616  grad_norm: 1.7967  loss: 1.0924  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7396  loss_aux: 0.3528\n",
            "02/09 17:52:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:52:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][332/332]  lr: 1.0000e-02  eta: 3:13:34  time: 0.3895  data_time: 0.0097  memory: 6616  grad_norm: 1.7732  loss: 1.0669  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7195  loss_aux: 0.3474\n",
            "02/09 17:52:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 62 epochs\n",
            "02/09 17:52:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][ 20/332]  lr: 1.0000e-02  eta: 3:13:28  time: 0.4402  data_time: 0.0523  memory: 6616  grad_norm: 1.6997  loss: 1.0673  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7131  loss_aux: 0.3541\n",
            "02/09 17:53:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][ 40/332]  lr: 1.0000e-02  eta: 3:13:19  time: 0.3940  data_time: 0.0098  memory: 6616  grad_norm: 1.8110  loss: 1.0639  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7122  loss_aux: 0.3517\n",
            "02/09 17:53:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][ 60/332]  lr: 1.0000e-02  eta: 3:13:11  time: 0.3939  data_time: 0.0098  memory: 6616  grad_norm: 1.7267  loss: 1.0560  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7023  loss_aux: 0.3537\n",
            "02/09 17:53:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][ 80/332]  lr: 1.0000e-02  eta: 3:13:03  time: 0.3948  data_time: 0.0101  memory: 6616  grad_norm: 2.0346  loss: 1.0533  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7111  loss_aux: 0.3421\n",
            "02/09 17:53:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][100/332]  lr: 1.0000e-02  eta: 3:12:55  time: 0.3953  data_time: 0.0105  memory: 6616  grad_norm: 1.7465  loss: 1.0397  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6968  loss_aux: 0.3428\n",
            "02/09 17:53:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][120/332]  lr: 1.0000e-02  eta: 3:12:47  time: 0.3943  data_time: 0.0098  memory: 6616  grad_norm: 2.5365  loss: 1.0567  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7121  loss_aux: 0.3445\n",
            "02/09 17:53:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][140/332]  lr: 1.0000e-02  eta: 3:12:39  time: 0.3945  data_time: 0.0098  memory: 6616  grad_norm: 2.1685  loss: 1.1064  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7525  loss_aux: 0.3539\n",
            "02/09 17:53:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][160/332]  lr: 1.0000e-02  eta: 3:12:31  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 2.3704  loss: 1.0835  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7230  loss_aux: 0.3605\n",
            "02/09 17:53:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][180/332]  lr: 1.0000e-02  eta: 3:12:23  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 1.8895  loss: 1.0265  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6851  loss_aux: 0.3414\n",
            "02/09 17:54:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][200/332]  lr: 1.0000e-02  eta: 3:12:15  time: 0.3951  data_time: 0.0105  memory: 6616  grad_norm: 2.8489  loss: 1.1212  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7484  loss_aux: 0.3729\n",
            "02/09 17:54:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][220/332]  lr: 1.0000e-02  eta: 3:12:07  time: 0.3948  data_time: 0.0104  memory: 6616  grad_norm: 1.8277  loss: 1.1021  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7406  loss_aux: 0.3615\n",
            "02/09 17:54:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][240/332]  lr: 1.0000e-02  eta: 3:11:59  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 1.6149  loss: 1.0577  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7215  loss_aux: 0.3362\n",
            "02/09 17:54:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][260/332]  lr: 1.0000e-02  eta: 3:11:51  time: 0.3948  data_time: 0.0104  memory: 6616  grad_norm: 2.1661  loss: 1.0660  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7154  loss_aux: 0.3507\n",
            "02/09 17:54:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][280/332]  lr: 1.0000e-02  eta: 3:11:43  time: 0.3948  data_time: 0.0101  memory: 6616  grad_norm: 3.8390  loss: 1.0864  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7364  loss_aux: 0.3500\n",
            "02/09 17:54:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][300/332]  lr: 1.0000e-02  eta: 3:11:35  time: 0.3955  data_time: 0.0109  memory: 6616  grad_norm: 2.8891  loss: 1.0555  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7056  loss_aux: 0.3499\n",
            "02/09 17:54:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][320/332]  lr: 1.0000e-02  eta: 3:11:27  time: 0.3947  data_time: 0.0103  memory: 6616  grad_norm: 3.7622  loss: 1.1012  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7284  loss_aux: 0.3728\n",
            "02/09 17:54:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:54:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][332/332]  lr: 1.0000e-02  eta: 3:11:22  time: 0.3895  data_time: 0.0101  memory: 6616  grad_norm: 2.0223  loss: 1.0022  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6515  loss_aux: 0.3506\n",
            "02/09 17:54:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 63 epochs\n",
            "02/09 17:55:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][ 20/332]  lr: 1.0000e-02  eta: 3:11:16  time: 0.4482  data_time: 0.0615  memory: 6616  grad_norm: 3.6599  loss: 1.0938  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7238  loss_aux: 0.3700\n",
            "02/09 17:55:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][ 40/332]  lr: 1.0000e-02  eta: 3:11:08  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 2.5836  loss: 1.0799  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7242  loss_aux: 0.3557\n",
            "02/09 17:55:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][ 60/332]  lr: 1.0000e-02  eta: 3:10:59  time: 0.3943  data_time: 0.0099  memory: 6616  grad_norm: 2.4036  loss: 1.0828  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7196  loss_aux: 0.3632\n",
            "02/09 17:55:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][ 80/332]  lr: 1.0000e-02  eta: 3:10:51  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 2.2263  loss: 1.1184  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7446  loss_aux: 0.3738\n",
            "02/09 17:55:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:55:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][100/332]  lr: 1.0000e-02  eta: 3:10:43  time: 0.3949  data_time: 0.0103  memory: 6616  grad_norm: 2.1434  loss: 1.0485  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6914  loss_aux: 0.3571\n",
            "02/09 17:55:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][120/332]  lr: 1.0000e-02  eta: 3:10:35  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 2.2542  loss: 1.0417  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6944  loss_aux: 0.3474\n",
            "02/09 17:55:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][140/332]  lr: 1.0000e-02  eta: 3:10:27  time: 0.3956  data_time: 0.0107  memory: 6616  grad_norm: 2.0767  loss: 1.0215  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6800  loss_aux: 0.3415\n",
            "02/09 17:56:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][160/332]  lr: 1.0000e-02  eta: 3:10:19  time: 0.3947  data_time: 0.0100  memory: 6616  grad_norm: 1.8577  loss: 1.0368  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7025  loss_aux: 0.3343\n",
            "02/09 17:56:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][180/332]  lr: 1.0000e-02  eta: 3:10:11  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 1.8761  loss: 0.9782  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6427  loss_aux: 0.3355\n",
            "02/09 17:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][200/332]  lr: 1.0000e-02  eta: 3:10:03  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 2.3231  loss: 1.1124  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7446  loss_aux: 0.3678\n",
            "02/09 17:56:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][220/332]  lr: 1.0000e-02  eta: 3:09:55  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 2.0655  loss: 1.0891  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7336  loss_aux: 0.3555\n",
            "02/09 17:56:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][240/332]  lr: 1.0000e-02  eta: 3:09:47  time: 0.3960  data_time: 0.0108  memory: 6616  grad_norm: 2.3025  loss: 1.0892  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7286  loss_aux: 0.3605\n",
            "02/09 17:56:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][260/332]  lr: 1.0000e-02  eta: 3:09:39  time: 0.3949  data_time: 0.0100  memory: 6616  grad_norm: 2.4870  loss: 1.1047  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7560  loss_aux: 0.3487\n",
            "02/09 17:56:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][280/332]  lr: 1.0000e-02  eta: 3:09:31  time: 0.3950  data_time: 0.0103  memory: 6616  grad_norm: 2.1425  loss: 1.0557  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7014  loss_aux: 0.3543\n",
            "02/09 17:56:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][300/332]  lr: 1.0000e-02  eta: 3:09:23  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 1.6859  loss: 1.0407  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6788  loss_aux: 0.3619\n",
            "02/09 17:57:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][320/332]  lr: 1.0000e-02  eta: 3:09:15  time: 0.3949  data_time: 0.0100  memory: 6616  grad_norm: 1.7796  loss: 1.0688  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7097  loss_aux: 0.3591\n",
            "02/09 17:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][332/332]  lr: 1.0000e-02  eta: 3:09:10  time: 0.3899  data_time: 0.0096  memory: 6616  grad_norm: 1.8591  loss: 1.0538  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.7079  loss_aux: 0.3459\n",
            "02/09 17:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 64 epochs\n",
            "02/09 17:57:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][ 20/332]  lr: 1.0000e-02  eta: 3:09:03  time: 0.4345  data_time: 0.0472  memory: 6616  grad_norm: 2.0433  loss: 1.1155  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7522  loss_aux: 0.3634\n",
            "02/09 17:57:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][ 40/332]  lr: 1.0000e-02  eta: 3:08:55  time: 0.3958  data_time: 0.0108  memory: 6616  grad_norm: 2.3683  loss: 1.1030  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7352  loss_aux: 0.3678\n",
            "02/09 17:57:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][ 60/332]  lr: 1.0000e-02  eta: 3:08:47  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 1.7900  loss: 1.1268  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7634  loss_aux: 0.3634\n",
            "02/09 17:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][ 80/332]  lr: 1.0000e-02  eta: 3:08:39  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 2.1953  loss: 1.0640  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7117  loss_aux: 0.3523\n",
            "02/09 17:57:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][100/332]  lr: 1.0000e-02  eta: 3:08:31  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 2.0965  loss: 1.0638  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7084  loss_aux: 0.3554\n",
            "02/09 17:58:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][120/332]  lr: 1.0000e-02  eta: 3:08:23  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 2.2447  loss: 1.0818  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7161  loss_aux: 0.3657\n",
            "02/09 17:58:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][140/332]  lr: 1.0000e-02  eta: 3:08:15  time: 0.3959  data_time: 0.0110  memory: 6616  grad_norm: 1.9029  loss: 1.0313  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6866  loss_aux: 0.3447\n",
            "02/09 17:58:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][160/332]  lr: 1.0000e-02  eta: 3:08:07  time: 0.3947  data_time: 0.0104  memory: 6616  grad_norm: 1.9592  loss: 1.0691  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7119  loss_aux: 0.3572\n",
            "02/09 17:58:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][180/332]  lr: 1.0000e-02  eta: 3:07:59  time: 0.3959  data_time: 0.0110  memory: 6616  grad_norm: 1.5473  loss: 1.0853  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7310  loss_aux: 0.3543\n",
            "02/09 17:58:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][200/332]  lr: 1.0000e-02  eta: 3:07:51  time: 0.3956  data_time: 0.0108  memory: 6616  grad_norm: 1.8340  loss: 1.0339  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6951  loss_aux: 0.3388\n",
            "02/09 17:58:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][220/332]  lr: 1.0000e-02  eta: 3:07:43  time: 0.3939  data_time: 0.0098  memory: 6616  grad_norm: 1.7937  loss: 1.0493  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7083  loss_aux: 0.3409\n",
            "02/09 17:58:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][240/332]  lr: 1.0000e-02  eta: 3:07:35  time: 0.3951  data_time: 0.0102  memory: 6616  grad_norm: 1.9558  loss: 1.0650  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7046  loss_aux: 0.3604\n",
            "02/09 17:58:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][260/332]  lr: 1.0000e-02  eta: 3:07:27  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 2.5522  loss: 1.1345  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7735  loss_aux: 0.3611\n",
            "02/09 17:59:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][280/332]  lr: 1.0000e-02  eta: 3:07:19  time: 0.3942  data_time: 0.0098  memory: 6616  grad_norm: 2.4414  loss: 1.0556  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7145  loss_aux: 0.3411\n",
            "02/09 17:59:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][300/332]  lr: 1.0000e-02  eta: 3:07:11  time: 0.3967  data_time: 0.0111  memory: 6616  grad_norm: 2.0711  loss: 1.0465  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6934  loss_aux: 0.3531\n",
            "02/09 17:59:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][320/332]  lr: 1.0000e-02  eta: 3:07:03  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 1.9664  loss: 1.1166  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7576  loss_aux: 0.3589\n",
            "02/09 17:59:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 17:59:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][332/332]  lr: 1.0000e-02  eta: 3:06:58  time: 0.3898  data_time: 0.0097  memory: 6616  grad_norm: 1.8199  loss: 1.0415  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6967  loss_aux: 0.3448\n",
            "02/09 17:59:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 65 epochs\n",
            "02/09 17:59:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][ 20/332]  lr: 1.0000e-02  eta: 3:06:51  time: 0.4326  data_time: 0.0457  memory: 6616  grad_norm: 1.8714  loss: 1.0542  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7087  loss_aux: 0.3455\n",
            "02/09 17:59:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][ 40/332]  lr: 1.0000e-02  eta: 3:06:43  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 1.8814  loss: 1.0357  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7065  loss_aux: 0.3292\n",
            "02/09 17:59:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][ 60/332]  lr: 1.0000e-02  eta: 3:06:35  time: 0.3942  data_time: 0.0100  memory: 6616  grad_norm: 1.7726  loss: 1.0728  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7222  loss_aux: 0.3506\n",
            "02/09 17:59:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][ 80/332]  lr: 1.0000e-02  eta: 3:06:27  time: 0.3947  data_time: 0.0106  memory: 6616  grad_norm: 1.8096  loss: 1.0629  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7081  loss_aux: 0.3549\n",
            "02/09 18:00:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][100/332]  lr: 1.0000e-02  eta: 3:06:19  time: 0.3942  data_time: 0.0100  memory: 6616  grad_norm: 2.0551  loss: 1.0848  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7304  loss_aux: 0.3544\n",
            "02/09 18:00:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][120/332]  lr: 1.0000e-02  eta: 3:06:11  time: 0.3942  data_time: 0.0102  memory: 6616  grad_norm: 2.5677  loss: 1.1059  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7552  loss_aux: 0.3507\n",
            "02/09 18:00:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][140/332]  lr: 1.0000e-02  eta: 3:06:03  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 1.9030  loss: 1.0592  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7105  loss_aux: 0.3487\n",
            "02/09 18:00:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][160/332]  lr: 1.0000e-02  eta: 3:05:55  time: 0.3942  data_time: 0.0098  memory: 6616  grad_norm: 1.7791  loss: 1.0489  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7053  loss_aux: 0.3436\n",
            "02/09 18:00:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][180/332]  lr: 1.0000e-02  eta: 3:05:47  time: 0.3952  data_time: 0.0107  memory: 6616  grad_norm: 1.8115  loss: 1.0301  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6828  loss_aux: 0.3473\n",
            "02/09 18:00:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][200/332]  lr: 1.0000e-02  eta: 3:05:39  time: 0.3958  data_time: 0.0110  memory: 6616  grad_norm: 1.7478  loss: 1.0502  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7009  loss_aux: 0.3492\n",
            "02/09 18:00:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][220/332]  lr: 1.0000e-02  eta: 3:05:31  time: 0.3945  data_time: 0.0099  memory: 6616  grad_norm: 1.8446  loss: 1.0468  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6908  loss_aux: 0.3560\n",
            "02/09 18:01:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][240/332]  lr: 1.0000e-02  eta: 3:05:23  time: 0.3959  data_time: 0.0111  memory: 6616  grad_norm: 1.6622  loss: 1.0478  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6993  loss_aux: 0.3486\n",
            "02/09 18:01:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][260/332]  lr: 1.0000e-02  eta: 3:05:15  time: 0.3955  data_time: 0.0111  memory: 6616  grad_norm: 2.3883  loss: 1.1195  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7554  loss_aux: 0.3641\n",
            "02/09 18:01:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][280/332]  lr: 1.0000e-02  eta: 3:05:07  time: 0.3944  data_time: 0.0099  memory: 6616  grad_norm: 1.7352  loss: 1.0796  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7182  loss_aux: 0.3613\n",
            "02/09 18:01:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][300/332]  lr: 1.0000e-02  eta: 3:04:59  time: 0.3946  data_time: 0.0100  memory: 6616  grad_norm: 1.7503  loss: 1.0771  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7124  loss_aux: 0.3648\n",
            "02/09 18:01:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][320/332]  lr: 1.0000e-02  eta: 3:04:51  time: 0.3946  data_time: 0.0105  memory: 6616  grad_norm: 1.6511  loss: 1.0388  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6824  loss_aux: 0.3564\n",
            "02/09 18:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][332/332]  lr: 1.0000e-02  eta: 3:04:46  time: 0.3900  data_time: 0.0099  memory: 6616  grad_norm: 1.5649  loss: 1.0341  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6889  loss_aux: 0.3453\n",
            "02/09 18:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 66 epochs\n",
            "02/09 18:01:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][ 20/332]  lr: 1.0000e-02  eta: 3:04:39  time: 0.4440  data_time: 0.0557  memory: 6616  grad_norm: 1.5331  loss: 1.0499  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7008  loss_aux: 0.3491\n",
            "02/09 18:01:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][ 40/332]  lr: 1.0000e-02  eta: 3:04:31  time: 0.3954  data_time: 0.0106  memory: 6616  grad_norm: 1.8731  loss: 1.0666  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7099  loss_aux: 0.3567\n",
            "02/09 18:02:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][ 60/332]  lr: 1.0000e-02  eta: 3:04:23  time: 0.3942  data_time: 0.0100  memory: 6616  grad_norm: 1.8059  loss: 1.0252  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6793  loss_aux: 0.3459\n",
            "02/09 18:02:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][ 80/332]  lr: 1.0000e-02  eta: 3:04:15  time: 0.3961  data_time: 0.0108  memory: 6616  grad_norm: 1.9893  loss: 1.0745  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7215  loss_aux: 0.3530\n",
            "02/09 18:02:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:02:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][100/332]  lr: 1.0000e-02  eta: 3:04:07  time: 0.3957  data_time: 0.0109  memory: 6616  grad_norm: 1.8091  loss: 1.0371  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6906  loss_aux: 0.3465\n",
            "02/09 18:02:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][120/332]  lr: 1.0000e-02  eta: 3:03:59  time: 0.3960  data_time: 0.0108  memory: 6616  grad_norm: 1.8121  loss: 1.0917  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7363  loss_aux: 0.3554\n",
            "02/09 18:02:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][140/332]  lr: 1.0000e-02  eta: 3:03:51  time: 0.3955  data_time: 0.0109  memory: 6616  grad_norm: 2.1268  loss: 1.0396  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7010  loss_aux: 0.3386\n",
            "02/09 18:02:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][160/332]  lr: 1.0000e-02  eta: 3:03:43  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 1.9505  loss: 1.0333  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6928  loss_aux: 0.3406\n",
            "02/09 18:02:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][180/332]  lr: 1.0000e-02  eta: 3:03:35  time: 0.3954  data_time: 0.0106  memory: 6616  grad_norm: 1.9280  loss: 1.1113  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7538  loss_aux: 0.3575\n",
            "02/09 18:03:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][200/332]  lr: 1.0000e-02  eta: 3:03:27  time: 0.3944  data_time: 0.0098  memory: 6616  grad_norm: 1.5916  loss: 1.0291  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6813  loss_aux: 0.3477\n",
            "02/09 18:03:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][220/332]  lr: 1.0000e-02  eta: 3:03:19  time: 0.3952  data_time: 0.0102  memory: 6616  grad_norm: 2.0325  loss: 1.0496  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7181  loss_aux: 0.3315\n",
            "02/09 18:03:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][240/332]  lr: 1.0000e-02  eta: 3:03:11  time: 0.3958  data_time: 0.0107  memory: 6616  grad_norm: 1.8729  loss: 1.1139  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7619  loss_aux: 0.3519\n",
            "02/09 18:03:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][260/332]  lr: 1.0000e-02  eta: 3:03:03  time: 0.3959  data_time: 0.0109  memory: 6616  grad_norm: 1.7183  loss: 1.0501  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6962  loss_aux: 0.3539\n",
            "02/09 18:03:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][280/332]  lr: 1.0000e-02  eta: 3:02:55  time: 0.3945  data_time: 0.0100  memory: 6616  grad_norm: 2.1823  loss: 1.0753  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7128  loss_aux: 0.3626\n",
            "02/09 18:03:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][300/332]  lr: 1.0000e-02  eta: 3:02:47  time: 0.3952  data_time: 0.0107  memory: 6616  grad_norm: 1.7718  loss: 1.0322  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6908  loss_aux: 0.3414\n",
            "02/09 18:03:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][320/332]  lr: 1.0000e-02  eta: 3:02:39  time: 0.3960  data_time: 0.0111  memory: 6616  grad_norm: 2.3069  loss: 1.0780  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7191  loss_aux: 0.3589\n",
            "02/09 18:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][332/332]  lr: 1.0000e-02  eta: 3:02:34  time: 0.3909  data_time: 0.0102  memory: 6616  grad_norm: 1.9533  loss: 1.0804  top1_acc: 0.0000  top5_acc: 1.0000  loss_cls: 0.7244  loss_aux: 0.3560\n",
            "02/09 18:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 67 epochs\n",
            "02/09 18:04:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][ 20/332]  lr: 1.0000e-02  eta: 3:02:27  time: 0.4388  data_time: 0.0516  memory: 6616  grad_norm: 2.2024  loss: 1.0273  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6780  loss_aux: 0.3493\n",
            "02/09 18:04:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][ 40/332]  lr: 1.0000e-02  eta: 3:02:19  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 1.8680  loss: 1.1076  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7619  loss_aux: 0.3457\n",
            "02/09 18:04:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][ 60/332]  lr: 1.0000e-02  eta: 3:02:11  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 2.4265  loss: 1.1094  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7358  loss_aux: 0.3736\n",
            "02/09 18:04:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][ 80/332]  lr: 1.0000e-02  eta: 3:02:03  time: 0.3952  data_time: 0.0107  memory: 6616  grad_norm: 2.0886  loss: 1.0488  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6987  loss_aux: 0.3502\n",
            "02/09 18:04:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][100/332]  lr: 1.0000e-02  eta: 3:01:55  time: 0.3950  data_time: 0.0100  memory: 6616  grad_norm: 2.0923  loss: 1.0900  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7307  loss_aux: 0.3593\n",
            "02/09 18:04:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][120/332]  lr: 1.0000e-02  eta: 3:01:47  time: 0.3946  data_time: 0.0103  memory: 6616  grad_norm: 1.7095  loss: 1.0892  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7203  loss_aux: 0.3689\n",
            "02/09 18:04:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][140/332]  lr: 1.0000e-02  eta: 3:01:39  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 1.9359  loss: 1.0615  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6999  loss_aux: 0.3616\n",
            "02/09 18:05:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][160/332]  lr: 1.0000e-02  eta: 3:01:31  time: 0.3946  data_time: 0.0103  memory: 6616  grad_norm: 2.0021  loss: 1.1063  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7441  loss_aux: 0.3622\n",
            "02/09 18:05:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][180/332]  lr: 1.0000e-02  eta: 3:01:23  time: 0.3949  data_time: 0.0106  memory: 6616  grad_norm: 2.2047  loss: 1.1215  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.7620  loss_aux: 0.3594\n",
            "02/09 18:05:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][200/332]  lr: 1.0000e-02  eta: 3:01:15  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 1.8483  loss: 1.0736  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7101  loss_aux: 0.3635\n",
            "02/09 18:05:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][220/332]  lr: 1.0000e-02  eta: 3:01:07  time: 0.3944  data_time: 0.0099  memory: 6616  grad_norm: 2.1204  loss: 1.0176  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6771  loss_aux: 0.3405\n",
            "02/09 18:05:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][240/332]  lr: 1.0000e-02  eta: 3:00:59  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 2.1416  loss: 1.0191  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6753  loss_aux: 0.3438\n",
            "02/09 18:05:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][260/332]  lr: 1.0000e-02  eta: 3:00:51  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 1.8251  loss: 1.0670  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7194  loss_aux: 0.3477\n",
            "02/09 18:05:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][280/332]  lr: 1.0000e-02  eta: 3:00:43  time: 0.3946  data_time: 0.0100  memory: 6616  grad_norm: 1.8034  loss: 1.0149  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6777  loss_aux: 0.3372\n",
            "02/09 18:05:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][300/332]  lr: 1.0000e-02  eta: 3:00:35  time: 0.3956  data_time: 0.0109  memory: 6616  grad_norm: 1.8550  loss: 1.0185  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6796  loss_aux: 0.3389\n",
            "02/09 18:06:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][320/332]  lr: 1.0000e-02  eta: 3:00:27  time: 0.3953  data_time: 0.0107  memory: 6616  grad_norm: 2.0186  loss: 1.0889  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7278  loss_aux: 0.3611\n",
            "02/09 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][332/332]  lr: 1.0000e-02  eta: 3:00:22  time: 0.3897  data_time: 0.0097  memory: 6616  grad_norm: 2.2003  loss: 1.1098  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7352  loss_aux: 0.3746\n",
            "02/09 18:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 68 epochs\n",
            "02/09 18:06:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][ 20/332]  lr: 1.0000e-02  eta: 3:00:15  time: 0.4493  data_time: 0.0617  memory: 6616  grad_norm: 1.8132  loss: 1.0539  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7014  loss_aux: 0.3525\n",
            "02/09 18:06:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][ 40/332]  lr: 1.0000e-02  eta: 3:00:07  time: 0.3957  data_time: 0.0106  memory: 6616  grad_norm: 1.8607  loss: 1.0592  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7111  loss_aux: 0.3481\n",
            "02/09 18:06:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][ 60/332]  lr: 1.0000e-02  eta: 2:59:59  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 2.2803  loss: 1.1517  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7683  loss_aux: 0.3834\n",
            "02/09 18:06:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][ 80/332]  lr: 1.0000e-02  eta: 2:59:51  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 1.9218  loss: 1.0811  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7282  loss_aux: 0.3529\n",
            "02/09 18:06:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][100/332]  lr: 1.0000e-02  eta: 2:59:43  time: 0.3951  data_time: 0.0104  memory: 6616  grad_norm: 1.8536  loss: 1.0891  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7372  loss_aux: 0.3519\n",
            "02/09 18:06:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][120/332]  lr: 1.0000e-02  eta: 2:59:35  time: 0.3947  data_time: 0.0104  memory: 6616  grad_norm: 1.6433  loss: 0.9643  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6312  loss_aux: 0.3331\n",
            "02/09 18:07:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][140/332]  lr: 1.0000e-02  eta: 2:59:27  time: 0.3952  data_time: 0.0106  memory: 6616  grad_norm: 1.7937  loss: 1.0278  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6794  loss_aux: 0.3484\n",
            "02/09 18:07:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][160/332]  lr: 1.0000e-02  eta: 2:59:19  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 1.5356  loss: 1.0492  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6944  loss_aux: 0.3548\n",
            "02/09 18:07:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][180/332]  lr: 1.0000e-02  eta: 2:59:11  time: 0.3956  data_time: 0.0107  memory: 6616  grad_norm: 1.8020  loss: 1.1173  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7481  loss_aux: 0.3692\n",
            "02/09 18:07:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][200/332]  lr: 1.0000e-02  eta: 2:59:03  time: 0.3951  data_time: 0.0108  memory: 6616  grad_norm: 1.7645  loss: 1.0564  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7000  loss_aux: 0.3564\n",
            "02/09 18:07:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][220/332]  lr: 1.0000e-02  eta: 2:58:55  time: 0.3953  data_time: 0.0105  memory: 6616  grad_norm: 1.8152  loss: 1.0509  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6972  loss_aux: 0.3537\n",
            "02/09 18:07:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][240/332]  lr: 1.0000e-02  eta: 2:58:47  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 2.0286  loss: 1.0685  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7231  loss_aux: 0.3454\n",
            "02/09 18:07:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][260/332]  lr: 1.0000e-02  eta: 2:58:39  time: 0.3953  data_time: 0.0104  memory: 6616  grad_norm: 2.7043  loss: 1.0890  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7323  loss_aux: 0.3567\n",
            "02/09 18:08:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][280/332]  lr: 1.0000e-02  eta: 2:58:31  time: 0.3948  data_time: 0.0105  memory: 6616  grad_norm: 1.8905  loss: 1.0344  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6936  loss_aux: 0.3408\n",
            "02/09 18:08:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][300/332]  lr: 1.0000e-02  eta: 2:58:23  time: 0.3955  data_time: 0.0107  memory: 6616  grad_norm: 1.5849  loss: 0.9637  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6452  loss_aux: 0.3185\n",
            "02/09 18:08:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][320/332]  lr: 1.0000e-02  eta: 2:58:15  time: 0.3944  data_time: 0.0102  memory: 6616  grad_norm: 1.8352  loss: 1.1207  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7554  loss_aux: 0.3653\n",
            "02/09 18:08:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:08:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][332/332]  lr: 1.0000e-02  eta: 2:58:10  time: 0.3888  data_time: 0.0094  memory: 6616  grad_norm: 1.6614  loss: 1.0691  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7294  loss_aux: 0.3398\n",
            "02/09 18:08:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 69 epochs\n",
            "02/09 18:08:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][ 20/332]  lr: 1.0000e-02  eta: 2:58:04  time: 0.4542  data_time: 0.0680  memory: 6616  grad_norm: 1.6242  loss: 1.0367  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6931  loss_aux: 0.3437\n",
            "02/09 18:08:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][ 40/332]  lr: 1.0000e-02  eta: 2:57:56  time: 0.3953  data_time: 0.0105  memory: 6616  grad_norm: 2.1949  loss: 1.0571  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7066  loss_aux: 0.3505\n",
            "02/09 18:08:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][ 60/332]  lr: 1.0000e-02  eta: 2:57:48  time: 0.3945  data_time: 0.0102  memory: 6616  grad_norm: 2.4392  loss: 1.0837  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7333  loss_aux: 0.3504\n",
            "02/09 18:08:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][ 80/332]  lr: 1.0000e-02  eta: 2:57:40  time: 0.3954  data_time: 0.0106  memory: 6616  grad_norm: 3.1625  loss: 1.0528  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7026  loss_aux: 0.3502\n",
            "02/09 18:09:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][100/332]  lr: 1.0000e-02  eta: 2:57:32  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 1.9863  loss: 1.0256  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6905  loss_aux: 0.3350\n",
            "02/09 18:09:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][120/332]  lr: 1.0000e-02  eta: 2:57:24  time: 0.3961  data_time: 0.0112  memory: 6616  grad_norm: 1.9728  loss: 1.0525  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6844  loss_aux: 0.3681\n",
            "02/09 18:09:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][140/332]  lr: 1.0000e-02  eta: 2:57:16  time: 0.3969  data_time: 0.0113  memory: 6616  grad_norm: 1.6625  loss: 1.0163  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6758  loss_aux: 0.3404\n",
            "02/09 18:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][160/332]  lr: 1.0000e-02  eta: 2:57:08  time: 0.3943  data_time: 0.0098  memory: 6616  grad_norm: 2.1230  loss: 1.0883  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7180  loss_aux: 0.3704\n",
            "02/09 18:09:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][180/332]  lr: 1.0000e-02  eta: 2:57:00  time: 0.3962  data_time: 0.0109  memory: 6616  grad_norm: 1.8885  loss: 1.1065  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7498  loss_aux: 0.3568\n",
            "02/09 18:09:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][200/332]  lr: 1.0000e-02  eta: 2:56:52  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 2.1354  loss: 1.0929  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7409  loss_aux: 0.3520\n",
            "02/09 18:09:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][220/332]  lr: 1.0000e-02  eta: 2:56:44  time: 0.3945  data_time: 0.0100  memory: 6616  grad_norm: 1.7047  loss: 1.0615  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7145  loss_aux: 0.3470\n",
            "02/09 18:10:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][240/332]  lr: 1.0000e-02  eta: 2:56:36  time: 0.3954  data_time: 0.0107  memory: 6616  grad_norm: 1.7158  loss: 1.0374  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6894  loss_aux: 0.3480\n",
            "02/09 18:10:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][260/332]  lr: 1.0000e-02  eta: 2:56:28  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 1.6476  loss: 1.0210  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6678  loss_aux: 0.3532\n",
            "02/09 18:10:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][280/332]  lr: 1.0000e-02  eta: 2:56:20  time: 0.3940  data_time: 0.0098  memory: 6616  grad_norm: 2.0724  loss: 1.1073  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7562  loss_aux: 0.3511\n",
            "02/09 18:10:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][300/332]  lr: 1.0000e-02  eta: 2:56:12  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 1.8557  loss: 1.0785  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7259  loss_aux: 0.3526\n",
            "02/09 18:10:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][320/332]  lr: 1.0000e-02  eta: 2:56:04  time: 0.3944  data_time: 0.0103  memory: 6616  grad_norm: 2.1247  loss: 1.0865  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7306  loss_aux: 0.3558\n",
            "02/09 18:10:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:10:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][332/332]  lr: 1.0000e-02  eta: 2:55:59  time: 0.3892  data_time: 0.0095  memory: 6616  grad_norm: 2.2599  loss: 1.0980  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7457  loss_aux: 0.3523\n",
            "02/09 18:10:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 70 epochs\n",
            "02/09 18:10:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [70][20/42]    eta: 0:00:03  time: 0.1799  data_time: 0.0709  memory: 1447  \n",
            "02/09 18:10:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [70][40/42]    eta: 0:00:00  time: 0.1255  data_time: 0.0231  memory: 1447  \n",
            "02/09 18:10:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [70][42/42]    acc/top1: 0.5392  acc/top5: 1.0000  acc/mean1: 0.5093  data_time: 0.0441  time: 0.1471\n",
            "02/09 18:10:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][ 20/332]  lr: 1.0000e-02  eta: 2:55:52  time: 0.4386  data_time: 0.0534  memory: 6616  grad_norm: 1.8501  loss: 1.0007  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6734  loss_aux: 0.3273\n",
            "02/09 18:11:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][ 40/332]  lr: 1.0000e-02  eta: 2:55:44  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 1.9080  loss: 1.0415  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6901  loss_aux: 0.3514\n",
            "02/09 18:11:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][ 60/332]  lr: 1.0000e-02  eta: 2:55:36  time: 0.3943  data_time: 0.0101  memory: 6616  grad_norm: 2.2213  loss: 1.0743  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7222  loss_aux: 0.3520\n",
            "02/09 18:11:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][ 80/332]  lr: 1.0000e-02  eta: 2:55:27  time: 0.3942  data_time: 0.0100  memory: 6616  grad_norm: 2.1563  loss: 1.0816  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7288  loss_aux: 0.3528\n",
            "02/09 18:11:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][100/332]  lr: 1.0000e-02  eta: 2:55:19  time: 0.3942  data_time: 0.0101  memory: 6616  grad_norm: 2.0832  loss: 1.0938  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7413  loss_aux: 0.3525\n",
            "02/09 18:11:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][120/332]  lr: 1.0000e-02  eta: 2:55:11  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 1.6824  loss: 1.0959  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.7394  loss_aux: 0.3565\n",
            "02/09 18:11:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][140/332]  lr: 1.0000e-02  eta: 2:55:03  time: 0.3941  data_time: 0.0098  memory: 6616  grad_norm: 2.3620  loss: 1.1032  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7432  loss_aux: 0.3600\n",
            "02/09 18:11:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][160/332]  lr: 1.0000e-02  eta: 2:54:55  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 1.6161  loss: 1.0681  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7132  loss_aux: 0.3549\n",
            "02/09 18:11:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][180/332]  lr: 1.0000e-02  eta: 2:54:47  time: 0.3947  data_time: 0.0103  memory: 6616  grad_norm: 1.6664  loss: 1.0858  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7333  loss_aux: 0.3526\n",
            "02/09 18:12:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][200/332]  lr: 1.0000e-02  eta: 2:54:39  time: 0.3956  data_time: 0.0106  memory: 6616  grad_norm: 1.5263  loss: 1.0813  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7289  loss_aux: 0.3524\n",
            "02/09 18:12:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][220/332]  lr: 1.0000e-02  eta: 2:54:31  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 1.5728  loss: 1.0816  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7290  loss_aux: 0.3526\n",
            "02/09 18:12:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][240/332]  lr: 1.0000e-02  eta: 2:54:23  time: 0.3939  data_time: 0.0099  memory: 6616  grad_norm: 1.6803  loss: 1.1017  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7424  loss_aux: 0.3593\n",
            "02/09 18:12:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][260/332]  lr: 1.0000e-02  eta: 2:54:15  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 1.5729  loss: 1.0819  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7234  loss_aux: 0.3585\n",
            "02/09 18:12:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][280/332]  lr: 1.0000e-02  eta: 2:54:07  time: 0.3950  data_time: 0.0105  memory: 6616  grad_norm: 1.4047  loss: 1.0792  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7238  loss_aux: 0.3553\n",
            "02/09 18:12:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][300/332]  lr: 1.0000e-02  eta: 2:53:59  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 1.6927  loss: 1.0794  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7356  loss_aux: 0.3438\n",
            "02/09 18:12:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][320/332]  lr: 1.0000e-02  eta: 2:53:51  time: 0.3947  data_time: 0.0099  memory: 6616  grad_norm: 1.5213  loss: 1.0693  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7141  loss_aux: 0.3552\n",
            "02/09 18:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][332/332]  lr: 1.0000e-02  eta: 2:53:46  time: 0.3889  data_time: 0.0092  memory: 6616  grad_norm: 2.2214  loss: 1.0570  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.7062  loss_aux: 0.3508\n",
            "02/09 18:12:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 71 epochs\n",
            "02/09 18:13:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][ 20/332]  lr: 1.0000e-02  eta: 2:53:39  time: 0.4330  data_time: 0.0454  memory: 6616  grad_norm: 1.6495  loss: 1.0845  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7182  loss_aux: 0.3663\n",
            "02/09 18:13:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][ 40/332]  lr: 1.0000e-02  eta: 2:53:31  time: 0.3952  data_time: 0.0106  memory: 6616  grad_norm: 1.5118  loss: 1.0552  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7116  loss_aux: 0.3436\n",
            "02/09 18:13:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][ 60/332]  lr: 1.0000e-02  eta: 2:53:23  time: 0.3963  data_time: 0.0108  memory: 6616  grad_norm: 1.5984  loss: 1.0745  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7236  loss_aux: 0.3509\n",
            "02/09 18:13:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][ 80/332]  lr: 1.0000e-02  eta: 2:53:15  time: 0.3938  data_time: 0.0097  memory: 6616  grad_norm: 1.6841  loss: 1.0990  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7444  loss_aux: 0.3546\n",
            "02/09 18:13:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][100/332]  lr: 1.0000e-02  eta: 2:53:07  time: 0.3940  data_time: 0.0098  memory: 6616  grad_norm: 1.4844  loss: 1.0787  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7331  loss_aux: 0.3456\n",
            "02/09 18:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][120/332]  lr: 1.0000e-02  eta: 2:52:59  time: 0.3958  data_time: 0.0111  memory: 6616  grad_norm: 1.3586  loss: 1.0559  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7043  loss_aux: 0.3516\n",
            "02/09 18:13:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][140/332]  lr: 1.0000e-02  eta: 2:52:51  time: 0.3940  data_time: 0.0097  memory: 6616  grad_norm: 1.3953  loss: 1.0646  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7124  loss_aux: 0.3523\n",
            "02/09 18:14:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][160/332]  lr: 1.0000e-02  eta: 2:52:43  time: 0.3952  data_time: 0.0104  memory: 6616  grad_norm: 1.5157  loss: 1.0614  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7029  loss_aux: 0.3585\n",
            "02/09 18:14:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][180/332]  lr: 1.0000e-02  eta: 2:52:35  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 1.4386  loss: 1.0743  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7164  loss_aux: 0.3579\n",
            "02/09 18:14:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][200/332]  lr: 1.0000e-02  eta: 2:52:27  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 1.6157  loss: 1.0805  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7421  loss_aux: 0.3385\n",
            "02/09 18:14:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][220/332]  lr: 1.0000e-02  eta: 2:52:19  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 1.7560  loss: 1.0635  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7173  loss_aux: 0.3462\n",
            "02/09 18:14:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][240/332]  lr: 1.0000e-02  eta: 2:52:11  time: 0.3941  data_time: 0.0098  memory: 6616  grad_norm: 1.7977  loss: 1.0851  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7245  loss_aux: 0.3606\n",
            "02/09 18:14:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][260/332]  lr: 1.0000e-02  eta: 2:52:03  time: 0.3943  data_time: 0.0101  memory: 6616  grad_norm: 1.7594  loss: 0.9844  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6557  loss_aux: 0.3286\n",
            "02/09 18:14:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][280/332]  lr: 1.0000e-02  eta: 2:51:55  time: 0.3956  data_time: 0.0108  memory: 6616  grad_norm: 1.5104  loss: 1.0683  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7004  loss_aux: 0.3680\n",
            "02/09 18:14:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][300/332]  lr: 1.0000e-02  eta: 2:51:47  time: 0.3939  data_time: 0.0099  memory: 6616  grad_norm: 1.4799  loss: 1.0398  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6910  loss_aux: 0.3488\n",
            "02/09 18:15:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][320/332]  lr: 1.0000e-02  eta: 2:51:39  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 1.6711  loss: 1.0184  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6871  loss_aux: 0.3313\n",
            "02/09 18:15:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:15:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][332/332]  lr: 1.0000e-02  eta: 2:51:34  time: 0.3887  data_time: 0.0092  memory: 6616  grad_norm: 1.4822  loss: 1.0301  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6816  loss_aux: 0.3484\n",
            "02/09 18:15:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 72 epochs\n",
            "02/09 18:15:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][ 20/332]  lr: 1.0000e-02  eta: 2:51:27  time: 0.4320  data_time: 0.0441  memory: 6616  grad_norm: 1.8069  loss: 1.0361  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6919  loss_aux: 0.3442\n",
            "02/09 18:15:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][ 40/332]  lr: 1.0000e-02  eta: 2:51:19  time: 0.3948  data_time: 0.0104  memory: 6616  grad_norm: 1.7367  loss: 1.0782  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7368  loss_aux: 0.3414\n",
            "02/09 18:15:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][ 60/332]  lr: 1.0000e-02  eta: 2:51:11  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 1.6001  loss: 1.0607  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7149  loss_aux: 0.3458\n",
            "02/09 18:15:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][ 80/332]  lr: 1.0000e-02  eta: 2:51:03  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 1.6968  loss: 1.1175  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7570  loss_aux: 0.3604\n",
            "02/09 18:15:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:15:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][100/332]  lr: 1.0000e-02  eta: 2:50:55  time: 0.3946  data_time: 0.0099  memory: 6616  grad_norm: 1.6108  loss: 1.0947  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7340  loss_aux: 0.3607\n",
            "02/09 18:16:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][120/332]  lr: 1.0000e-02  eta: 2:50:47  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 1.6447  loss: 1.0801  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7293  loss_aux: 0.3508\n",
            "02/09 18:16:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][140/332]  lr: 1.0000e-02  eta: 2:50:39  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 1.6545  loss: 1.0551  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7000  loss_aux: 0.3551\n",
            "02/09 18:16:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][160/332]  lr: 1.0000e-02  eta: 2:50:31  time: 0.3953  data_time: 0.0105  memory: 6616  grad_norm: 1.5834  loss: 1.0718  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7187  loss_aux: 0.3530\n",
            "02/09 18:16:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][180/332]  lr: 1.0000e-02  eta: 2:50:23  time: 0.3955  data_time: 0.0108  memory: 6616  grad_norm: 1.5700  loss: 1.0956  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7227  loss_aux: 0.3729\n",
            "02/09 18:16:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][200/332]  lr: 1.0000e-02  eta: 2:50:15  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 1.4603  loss: 1.0668  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7113  loss_aux: 0.3555\n",
            "02/09 18:16:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][220/332]  lr: 1.0000e-02  eta: 2:50:07  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 1.3730  loss: 1.0659  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7220  loss_aux: 0.3439\n",
            "02/09 18:16:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][240/332]  lr: 1.0000e-02  eta: 2:49:59  time: 0.3964  data_time: 0.0109  memory: 6616  grad_norm: 1.4846  loss: 1.0575  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7038  loss_aux: 0.3537\n",
            "02/09 18:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][260/332]  lr: 1.0000e-02  eta: 2:49:51  time: 0.3947  data_time: 0.0103  memory: 6616  grad_norm: 1.4557  loss: 0.9873  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6628  loss_aux: 0.3246\n",
            "02/09 18:17:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][280/332]  lr: 1.0000e-02  eta: 2:49:43  time: 0.3953  data_time: 0.0103  memory: 6616  grad_norm: 1.4911  loss: 1.0049  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6789  loss_aux: 0.3260\n",
            "02/09 18:17:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][300/332]  lr: 1.0000e-02  eta: 2:49:35  time: 0.3943  data_time: 0.0101  memory: 6616  grad_norm: 1.5270  loss: 1.0458  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6953  loss_aux: 0.3505\n",
            "02/09 18:17:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][320/332]  lr: 1.0000e-02  eta: 2:49:27  time: 0.3940  data_time: 0.0098  memory: 6616  grad_norm: 1.6592  loss: 1.0705  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7184  loss_aux: 0.3521\n",
            "02/09 18:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][332/332]  lr: 1.0000e-02  eta: 2:49:22  time: 0.3890  data_time: 0.0094  memory: 6616  grad_norm: 1.7623  loss: 1.1034  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7331  loss_aux: 0.3703\n",
            "02/09 18:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 73 epochs\n",
            "02/09 18:17:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][ 20/332]  lr: 1.0000e-02  eta: 2:49:15  time: 0.4361  data_time: 0.0490  memory: 6616  grad_norm: 1.5333  loss: 1.0033  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6626  loss_aux: 0.3408\n",
            "02/09 18:17:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][ 40/332]  lr: 1.0000e-02  eta: 2:49:07  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 1.7450  loss: 1.0651  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7054  loss_aux: 0.3596\n",
            "02/09 18:17:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][ 60/332]  lr: 1.0000e-02  eta: 2:48:59  time: 0.3949  data_time: 0.0104  memory: 6616  grad_norm: 1.7226  loss: 1.0593  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6988  loss_aux: 0.3605\n",
            "02/09 18:18:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][ 80/332]  lr: 1.0000e-02  eta: 2:48:51  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 1.5916  loss: 1.0634  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7071  loss_aux: 0.3563\n",
            "02/09 18:18:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][100/332]  lr: 1.0000e-02  eta: 2:48:43  time: 0.3948  data_time: 0.0104  memory: 6616  grad_norm: 1.6090  loss: 1.0196  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6798  loss_aux: 0.3398\n",
            "02/09 18:18:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][120/332]  lr: 1.0000e-02  eta: 2:48:35  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 1.7104  loss: 1.0939  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7402  loss_aux: 0.3537\n",
            "02/09 18:18:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][140/332]  lr: 1.0000e-02  eta: 2:48:27  time: 0.3944  data_time: 0.0099  memory: 6616  grad_norm: 1.5159  loss: 1.0602  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7076  loss_aux: 0.3526\n",
            "02/09 18:18:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][160/332]  lr: 1.0000e-02  eta: 2:48:19  time: 0.3948  data_time: 0.0101  memory: 6616  grad_norm: 1.3794  loss: 0.9926  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6546  loss_aux: 0.3381\n",
            "02/09 18:18:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][180/332]  lr: 1.0000e-02  eta: 2:48:11  time: 0.3938  data_time: 0.0099  memory: 6616  grad_norm: 1.4766  loss: 1.0681  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7103  loss_aux: 0.3578\n",
            "02/09 18:18:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][200/332]  lr: 1.0000e-02  eta: 2:48:03  time: 0.3942  data_time: 0.0098  memory: 6616  grad_norm: 1.4749  loss: 1.0415  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7031  loss_aux: 0.3385\n",
            "02/09 18:18:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][220/332]  lr: 1.0000e-02  eta: 2:47:55  time: 0.3951  data_time: 0.0105  memory: 6616  grad_norm: 1.5751  loss: 1.0130  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6701  loss_aux: 0.3429\n",
            "02/09 18:19:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][240/332]  lr: 1.0000e-02  eta: 2:47:47  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 1.5718  loss: 1.0252  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6914  loss_aux: 0.3338\n",
            "02/09 18:19:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][260/332]  lr: 1.0000e-02  eta: 2:47:39  time: 0.3940  data_time: 0.0098  memory: 6616  grad_norm: 1.8064  loss: 1.1328  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7749  loss_aux: 0.3579\n",
            "02/09 18:19:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][280/332]  lr: 1.0000e-02  eta: 2:47:31  time: 0.3963  data_time: 0.0110  memory: 6616  grad_norm: 1.4987  loss: 1.0676  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7164  loss_aux: 0.3512\n",
            "02/09 18:19:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][300/332]  lr: 1.0000e-02  eta: 2:47:23  time: 0.3949  data_time: 0.0099  memory: 6616  grad_norm: 1.5403  loss: 1.0704  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7229  loss_aux: 0.3475\n",
            "02/09 18:19:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][320/332]  lr: 1.0000e-02  eta: 2:47:15  time: 0.3946  data_time: 0.0100  memory: 6616  grad_norm: 1.5514  loss: 1.0547  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7154  loss_aux: 0.3393\n",
            "02/09 18:19:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:19:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][332/332]  lr: 1.0000e-02  eta: 2:47:10  time: 0.3892  data_time: 0.0093  memory: 6616  grad_norm: 1.6777  loss: 1.0610  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.7073  loss_aux: 0.3537\n",
            "02/09 18:19:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 74 epochs\n",
            "02/09 18:19:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][ 20/332]  lr: 1.0000e-02  eta: 2:47:03  time: 0.4547  data_time: 0.0677  memory: 6616  grad_norm: 1.6560  loss: 1.0654  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7080  loss_aux: 0.3574\n",
            "02/09 18:20:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][ 40/332]  lr: 1.0000e-02  eta: 2:46:55  time: 0.3935  data_time: 0.0092  memory: 6616  grad_norm: 1.4538  loss: 1.0287  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6810  loss_aux: 0.3477\n",
            "02/09 18:20:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][ 60/332]  lr: 1.0000e-02  eta: 2:46:47  time: 0.3957  data_time: 0.0107  memory: 6616  grad_norm: 1.5580  loss: 1.0463  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6975  loss_aux: 0.3488\n",
            "02/09 18:20:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][ 80/332]  lr: 1.0000e-02  eta: 2:46:39  time: 0.3959  data_time: 0.0108  memory: 6616  grad_norm: 1.4370  loss: 1.0290  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6829  loss_aux: 0.3460\n",
            "02/09 18:20:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][100/332]  lr: 1.0000e-02  eta: 2:46:31  time: 0.3945  data_time: 0.0104  memory: 6616  grad_norm: 1.3297  loss: 0.9508  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6398  loss_aux: 0.3110\n",
            "02/09 18:20:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][120/332]  lr: 1.0000e-02  eta: 2:46:23  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 1.5621  loss: 1.0328  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6872  loss_aux: 0.3457\n",
            "02/09 18:20:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][140/332]  lr: 1.0000e-02  eta: 2:46:15  time: 0.3958  data_time: 0.0108  memory: 6616  grad_norm: 1.6727  loss: 1.0982  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7351  loss_aux: 0.3631\n",
            "02/09 18:20:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][160/332]  lr: 1.0000e-02  eta: 2:46:07  time: 0.3952  data_time: 0.0105  memory: 6616  grad_norm: 1.3900  loss: 1.0051  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6735  loss_aux: 0.3316\n",
            "02/09 18:20:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][180/332]  lr: 1.0000e-02  eta: 2:45:59  time: 0.3953  data_time: 0.0103  memory: 6616  grad_norm: 1.6258  loss: 1.0892  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7349  loss_aux: 0.3542\n",
            "02/09 18:21:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][200/332]  lr: 1.0000e-02  eta: 2:45:51  time: 0.3946  data_time: 0.0102  memory: 6616  grad_norm: 1.5628  loss: 1.0309  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6795  loss_aux: 0.3515\n",
            "02/09 18:21:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][220/332]  lr: 1.0000e-02  eta: 2:45:43  time: 0.3951  data_time: 0.0105  memory: 6616  grad_norm: 1.5643  loss: 1.0549  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7032  loss_aux: 0.3516\n",
            "02/09 18:21:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][240/332]  lr: 1.0000e-02  eta: 2:45:35  time: 0.3957  data_time: 0.0108  memory: 6616  grad_norm: 1.4195  loss: 1.0128  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6723  loss_aux: 0.3404\n",
            "02/09 18:21:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][260/332]  lr: 1.0000e-02  eta: 2:45:27  time: 0.3943  data_time: 0.0103  memory: 6616  grad_norm: 1.7257  loss: 1.0427  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6997  loss_aux: 0.3431\n",
            "02/09 18:21:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][280/332]  lr: 1.0000e-02  eta: 2:45:19  time: 0.3958  data_time: 0.0107  memory: 6616  grad_norm: 1.6355  loss: 1.0373  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6845  loss_aux: 0.3528\n",
            "02/09 18:21:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][300/332]  lr: 1.0000e-02  eta: 2:45:11  time: 0.3941  data_time: 0.0096  memory: 6616  grad_norm: 1.5422  loss: 1.0068  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6570  loss_aux: 0.3498\n",
            "02/09 18:21:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][320/332]  lr: 1.0000e-02  eta: 2:45:03  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 1.7563  loss: 1.0853  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7350  loss_aux: 0.3503\n",
            "02/09 18:21:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:21:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][332/332]  lr: 1.0000e-02  eta: 2:44:58  time: 0.3893  data_time: 0.0094  memory: 6616  grad_norm: 1.7143  loss: 1.1032  top1_acc: 0.1667  top5_acc: 1.0000  loss_cls: 0.7513  loss_aux: 0.3518\n",
            "02/09 18:21:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 75 epochs\n",
            "02/09 18:22:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][ 20/332]  lr: 1.0000e-03  eta: 2:44:51  time: 0.4416  data_time: 0.0546  memory: 6616  grad_norm: 1.7498  loss: 1.0640  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7140  loss_aux: 0.3500\n",
            "02/09 18:22:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][ 40/332]  lr: 1.0000e-03  eta: 2:44:43  time: 0.3947  data_time: 0.0099  memory: 6616  grad_norm: 1.6022  loss: 1.0605  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7106  loss_aux: 0.3500\n",
            "02/09 18:22:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][ 60/332]  lr: 1.0000e-03  eta: 2:44:35  time: 0.3944  data_time: 0.0100  memory: 6616  grad_norm: 1.6537  loss: 1.0538  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7100  loss_aux: 0.3438\n",
            "02/09 18:22:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][ 80/332]  lr: 1.0000e-03  eta: 2:44:27  time: 0.3948  data_time: 0.0106  memory: 6616  grad_norm: 1.5193  loss: 1.0087  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6651  loss_aux: 0.3436\n",
            "02/09 18:22:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:22:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][100/332]  lr: 1.0000e-03  eta: 2:44:19  time: 0.3940  data_time: 0.0100  memory: 6616  grad_norm: 1.4955  loss: 1.0198  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6827  loss_aux: 0.3371\n",
            "02/09 18:22:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][120/332]  lr: 1.0000e-03  eta: 2:44:11  time: 0.3964  data_time: 0.0115  memory: 6616  grad_norm: 1.8740  loss: 1.0305  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6934  loss_aux: 0.3371\n",
            "02/09 18:22:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][140/332]  lr: 1.0000e-03  eta: 2:44:03  time: 0.3953  data_time: 0.0104  memory: 6616  grad_norm: 1.4245  loss: 1.0582  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7030  loss_aux: 0.3552\n",
            "02/09 18:23:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][160/332]  lr: 1.0000e-03  eta: 2:43:55  time: 0.3940  data_time: 0.0098  memory: 6616  grad_norm: 1.5180  loss: 1.0185  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6792  loss_aux: 0.3393\n",
            "02/09 18:23:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][180/332]  lr: 1.0000e-03  eta: 2:43:47  time: 0.3955  data_time: 0.0103  memory: 6616  grad_norm: 1.4662  loss: 1.0030  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6728  loss_aux: 0.3302\n",
            "02/09 18:23:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][200/332]  lr: 1.0000e-03  eta: 2:43:39  time: 0.3954  data_time: 0.0106  memory: 6616  grad_norm: 1.5797  loss: 1.0459  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6994  loss_aux: 0.3465\n",
            "02/09 18:23:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][220/332]  lr: 1.0000e-03  eta: 2:43:31  time: 0.3949  data_time: 0.0105  memory: 6616  grad_norm: 1.3331  loss: 0.9603  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6298  loss_aux: 0.3304\n",
            "02/09 18:23:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][240/332]  lr: 1.0000e-03  eta: 2:43:23  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 1.3501  loss: 1.0052  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6662  loss_aux: 0.3390\n",
            "02/09 18:23:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][260/332]  lr: 1.0000e-03  eta: 2:43:15  time: 0.3941  data_time: 0.0099  memory: 6616  grad_norm: 1.8962  loss: 1.0422  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6887  loss_aux: 0.3535\n",
            "02/09 18:23:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][280/332]  lr: 1.0000e-03  eta: 2:43:07  time: 0.3949  data_time: 0.0105  memory: 6616  grad_norm: 1.6803  loss: 1.0765  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7164  loss_aux: 0.3601\n",
            "02/09 18:23:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][300/332]  lr: 1.0000e-03  eta: 2:42:59  time: 0.3951  data_time: 0.0104  memory: 6616  grad_norm: 1.5690  loss: 1.0710  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7132  loss_aux: 0.3579\n",
            "02/09 18:24:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][320/332]  lr: 1.0000e-03  eta: 2:42:51  time: 0.3945  data_time: 0.0102  memory: 6616  grad_norm: 1.5939  loss: 1.0033  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6712  loss_aux: 0.3321\n",
            "02/09 18:24:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:24:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][332/332]  lr: 1.0000e-03  eta: 2:42:46  time: 0.3893  data_time: 0.0095  memory: 6616  grad_norm: 1.6213  loss: 1.0131  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6810  loss_aux: 0.3322\n",
            "02/09 18:24:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 76 epochs\n",
            "02/09 18:24:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][ 20/332]  lr: 1.0000e-03  eta: 2:42:39  time: 0.4363  data_time: 0.0493  memory: 6616  grad_norm: 1.5298  loss: 1.0653  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7074  loss_aux: 0.3579\n",
            "02/09 18:24:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][ 40/332]  lr: 1.0000e-03  eta: 2:42:31  time: 0.3940  data_time: 0.0096  memory: 6616  grad_norm: 1.4050  loss: 0.9940  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6647  loss_aux: 0.3292\n",
            "02/09 18:24:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][ 60/332]  lr: 1.0000e-03  eta: 2:42:23  time: 0.3946  data_time: 0.0104  memory: 6616  grad_norm: 1.6735  loss: 1.0339  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6892  loss_aux: 0.3447\n",
            "02/09 18:24:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][ 80/332]  lr: 1.0000e-03  eta: 2:42:15  time: 0.3959  data_time: 0.0110  memory: 6616  grad_norm: 1.3457  loss: 0.9851  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6480  loss_aux: 0.3371\n",
            "02/09 18:24:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][100/332]  lr: 1.0000e-03  eta: 2:42:07  time: 0.3945  data_time: 0.0100  memory: 6616  grad_norm: 1.6729  loss: 1.0149  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6803  loss_aux: 0.3346\n",
            "02/09 18:25:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][120/332]  lr: 1.0000e-03  eta: 2:41:59  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 1.6801  loss: 0.9426  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6272  loss_aux: 0.3155\n",
            "02/09 18:25:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][140/332]  lr: 1.0000e-03  eta: 2:41:51  time: 0.3953  data_time: 0.0106  memory: 6616  grad_norm: 1.4151  loss: 1.0406  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6843  loss_aux: 0.3563\n",
            "02/09 18:25:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][160/332]  lr: 1.0000e-03  eta: 2:41:43  time: 0.3942  data_time: 0.0098  memory: 6616  grad_norm: 1.5947  loss: 1.0372  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6931  loss_aux: 0.3441\n",
            "02/09 18:25:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][180/332]  lr: 1.0000e-03  eta: 2:41:35  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 1.5391  loss: 0.9940  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6644  loss_aux: 0.3296\n",
            "02/09 18:25:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][200/332]  lr: 1.0000e-03  eta: 2:41:27  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 1.5925  loss: 1.0597  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7142  loss_aux: 0.3455\n",
            "02/09 18:25:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][220/332]  lr: 1.0000e-03  eta: 2:41:19  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 1.5917  loss: 0.9986  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6606  loss_aux: 0.3380\n",
            "02/09 18:25:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][240/332]  lr: 1.0000e-03  eta: 2:41:11  time: 0.3950  data_time: 0.0105  memory: 6616  grad_norm: 1.5226  loss: 1.0499  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7012  loss_aux: 0.3488\n",
            "02/09 18:25:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][260/332]  lr: 1.0000e-03  eta: 2:41:03  time: 0.3956  data_time: 0.0106  memory: 6616  grad_norm: 1.5694  loss: 1.0544  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7166  loss_aux: 0.3378\n",
            "02/09 18:26:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][280/332]  lr: 1.0000e-03  eta: 2:40:55  time: 0.3941  data_time: 0.0097  memory: 6616  grad_norm: 1.5122  loss: 1.0504  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7078  loss_aux: 0.3427\n",
            "02/09 18:26:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][300/332]  lr: 1.0000e-03  eta: 2:40:47  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 1.6111  loss: 1.0333  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6862  loss_aux: 0.3471\n",
            "02/09 18:26:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][320/332]  lr: 1.0000e-03  eta: 2:40:39  time: 0.3937  data_time: 0.0094  memory: 6616  grad_norm: 1.5360  loss: 1.0181  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6680  loss_aux: 0.3501\n",
            "02/09 18:26:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:26:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][332/332]  lr: 1.0000e-03  eta: 2:40:34  time: 0.3891  data_time: 0.0091  memory: 6616  grad_norm: 1.5585  loss: 1.0741  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7113  loss_aux: 0.3629\n",
            "02/09 18:26:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 77 epochs\n",
            "02/09 18:26:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][ 20/332]  lr: 1.0000e-03  eta: 2:40:27  time: 0.4435  data_time: 0.0562  memory: 6616  grad_norm: 1.8188  loss: 0.9945  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6623  loss_aux: 0.3321\n",
            "02/09 18:26:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][ 40/332]  lr: 1.0000e-03  eta: 2:40:19  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 1.5332  loss: 1.0116  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6782  loss_aux: 0.3334\n",
            "02/09 18:26:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][ 60/332]  lr: 1.0000e-03  eta: 2:40:11  time: 0.3943  data_time: 0.0102  memory: 6616  grad_norm: 1.4794  loss: 1.0214  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6872  loss_aux: 0.3342\n",
            "02/09 18:26:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][ 80/332]  lr: 1.0000e-03  eta: 2:40:03  time: 0.3960  data_time: 0.0109  memory: 6616  grad_norm: 1.6945  loss: 1.0390  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6995  loss_aux: 0.3395\n",
            "02/09 18:27:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][100/332]  lr: 1.0000e-03  eta: 2:39:55  time: 0.3942  data_time: 0.0101  memory: 6616  grad_norm: 1.4212  loss: 0.9899  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6541  loss_aux: 0.3358\n",
            "02/09 18:27:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][120/332]  lr: 1.0000e-03  eta: 2:39:47  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 1.6152  loss: 1.0167  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6737  loss_aux: 0.3431\n",
            "02/09 18:27:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][140/332]  lr: 1.0000e-03  eta: 2:39:39  time: 0.3947  data_time: 0.0102  memory: 6616  grad_norm: 1.5751  loss: 1.0361  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6949  loss_aux: 0.3412\n",
            "02/09 18:27:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][160/332]  lr: 1.0000e-03  eta: 2:39:31  time: 0.3940  data_time: 0.0101  memory: 6616  grad_norm: 1.7530  loss: 1.0473  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6976  loss_aux: 0.3497\n",
            "02/09 18:27:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][180/332]  lr: 1.0000e-03  eta: 2:39:23  time: 0.3950  data_time: 0.0105  memory: 6616  grad_norm: 1.6392  loss: 1.0325  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6911  loss_aux: 0.3414\n",
            "02/09 18:27:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][200/332]  lr: 1.0000e-03  eta: 2:39:15  time: 0.3951  data_time: 0.0105  memory: 6616  grad_norm: 1.5720  loss: 1.0253  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6912  loss_aux: 0.3342\n",
            "02/09 18:27:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][220/332]  lr: 1.0000e-03  eta: 2:39:07  time: 0.3935  data_time: 0.0095  memory: 6616  grad_norm: 1.4777  loss: 1.0062  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6693  loss_aux: 0.3369\n",
            "02/09 18:28:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][240/332]  lr: 1.0000e-03  eta: 2:38:59  time: 0.3943  data_time: 0.0101  memory: 6616  grad_norm: 1.5853  loss: 1.0013  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6557  loss_aux: 0.3456\n",
            "02/09 18:28:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][260/332]  lr: 1.0000e-03  eta: 2:38:51  time: 0.3948  data_time: 0.0104  memory: 6616  grad_norm: 1.5765  loss: 1.0059  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6662  loss_aux: 0.3397\n",
            "02/09 18:28:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][280/332]  lr: 1.0000e-03  eta: 2:38:43  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 1.6664  loss: 1.0532  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7025  loss_aux: 0.3507\n",
            "02/09 18:28:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][300/332]  lr: 1.0000e-03  eta: 2:38:35  time: 0.3947  data_time: 0.0103  memory: 6616  grad_norm: 1.5318  loss: 1.0065  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6674  loss_aux: 0.3391\n",
            "02/09 18:28:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][320/332]  lr: 1.0000e-03  eta: 2:38:27  time: 0.3942  data_time: 0.0098  memory: 6616  grad_norm: 1.6862  loss: 1.0790  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7360  loss_aux: 0.3430\n",
            "02/09 18:28:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:28:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][332/332]  lr: 1.0000e-03  eta: 2:38:22  time: 0.3889  data_time: 0.0092  memory: 6616  grad_norm: 1.6124  loss: 1.0322  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7004  loss_aux: 0.3318\n",
            "02/09 18:28:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 78 epochs\n",
            "02/09 18:28:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][ 20/332]  lr: 1.0000e-03  eta: 2:38:14  time: 0.4351  data_time: 0.0484  memory: 6616  grad_norm: 1.7429  loss: 1.0418  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6999  loss_aux: 0.3419\n",
            "02/09 18:28:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][ 40/332]  lr: 1.0000e-03  eta: 2:38:06  time: 0.3952  data_time: 0.0107  memory: 6616  grad_norm: 1.5818  loss: 1.0407  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6917  loss_aux: 0.3490\n",
            "02/09 18:29:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][ 60/332]  lr: 1.0000e-03  eta: 2:37:58  time: 0.3948  data_time: 0.0103  memory: 6616  grad_norm: 1.5258  loss: 1.0260  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6945  loss_aux: 0.3315\n",
            "02/09 18:29:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][ 80/332]  lr: 1.0000e-03  eta: 2:37:50  time: 0.3949  data_time: 0.0105  memory: 6616  grad_norm: 1.4561  loss: 1.0138  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6733  loss_aux: 0.3405\n",
            "02/09 18:29:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][100/332]  lr: 1.0000e-03  eta: 2:37:42  time: 0.3952  data_time: 0.0104  memory: 6616  grad_norm: 1.5921  loss: 1.0792  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7283  loss_aux: 0.3508\n",
            "02/09 18:29:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:29:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][120/332]  lr: 1.0000e-03  eta: 2:37:34  time: 0.3946  data_time: 0.0105  memory: 6616  grad_norm: 1.7506  loss: 1.0367  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6945  loss_aux: 0.3422\n",
            "02/09 18:29:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][140/332]  lr: 1.0000e-03  eta: 2:37:26  time: 0.3959  data_time: 0.0109  memory: 6616  grad_norm: 1.5999  loss: 1.0452  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7030  loss_aux: 0.3421\n",
            "02/09 18:29:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][160/332]  lr: 1.0000e-03  eta: 2:37:18  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 1.5829  loss: 1.0463  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6999  loss_aux: 0.3464\n",
            "02/09 18:29:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][180/332]  lr: 1.0000e-03  eta: 2:37:10  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 1.8142  loss: 1.0463  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7091  loss_aux: 0.3372\n",
            "02/09 18:30:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][200/332]  lr: 1.0000e-03  eta: 2:37:02  time: 0.3945  data_time: 0.0099  memory: 6616  grad_norm: 1.5594  loss: 1.0069  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6709  loss_aux: 0.3360\n",
            "02/09 18:30:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][220/332]  lr: 1.0000e-03  eta: 2:36:54  time: 0.3939  data_time: 0.0095  memory: 6616  grad_norm: 1.7154  loss: 1.0300  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7009  loss_aux: 0.3291\n",
            "02/09 18:30:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][240/332]  lr: 1.0000e-03  eta: 2:36:46  time: 0.3960  data_time: 0.0108  memory: 6616  grad_norm: 1.5196  loss: 1.0173  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6840  loss_aux: 0.3333\n",
            "02/09 18:30:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][260/332]  lr: 1.0000e-03  eta: 2:36:38  time: 0.3953  data_time: 0.0103  memory: 6616  grad_norm: 1.6071  loss: 0.9782  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6475  loss_aux: 0.3307\n",
            "02/09 18:30:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][280/332]  lr: 1.0000e-03  eta: 2:36:30  time: 0.3946  data_time: 0.0103  memory: 6616  grad_norm: 1.7138  loss: 1.0534  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7033  loss_aux: 0.3501\n",
            "02/09 18:30:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][300/332]  lr: 1.0000e-03  eta: 2:36:22  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 1.6856  loss: 1.0252  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6816  loss_aux: 0.3436\n",
            "02/09 18:30:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][320/332]  lr: 1.0000e-03  eta: 2:36:14  time: 0.3945  data_time: 0.0102  memory: 6616  grad_norm: 1.7154  loss: 1.0085  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6787  loss_aux: 0.3298\n",
            "02/09 18:30:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:30:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][332/332]  lr: 1.0000e-03  eta: 2:36:10  time: 0.3902  data_time: 0.0102  memory: 6616  grad_norm: 1.6795  loss: 1.0333  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6931  loss_aux: 0.3402\n",
            "02/09 18:30:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 79 epochs\n",
            "02/09 18:31:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][ 20/332]  lr: 1.0000e-03  eta: 2:36:02  time: 0.4396  data_time: 0.0514  memory: 6616  grad_norm: 1.5492  loss: 0.9946  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6649  loss_aux: 0.3297\n",
            "02/09 18:31:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][ 40/332]  lr: 1.0000e-03  eta: 2:35:54  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 1.6540  loss: 1.0652  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7039  loss_aux: 0.3613\n",
            "02/09 18:31:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][ 60/332]  lr: 1.0000e-03  eta: 2:35:46  time: 0.3943  data_time: 0.0096  memory: 6616  grad_norm: 1.6791  loss: 1.0134  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6736  loss_aux: 0.3397\n",
            "02/09 18:31:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][ 80/332]  lr: 1.0000e-03  eta: 2:35:38  time: 0.3944  data_time: 0.0099  memory: 6616  grad_norm: 1.4991  loss: 1.0397  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6976  loss_aux: 0.3422\n",
            "02/09 18:31:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][100/332]  lr: 1.0000e-03  eta: 2:35:30  time: 0.3959  data_time: 0.0112  memory: 6616  grad_norm: 1.5517  loss: 1.0177  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6797  loss_aux: 0.3379\n",
            "02/09 18:31:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][120/332]  lr: 1.0000e-03  eta: 2:35:22  time: 0.3950  data_time: 0.0107  memory: 6616  grad_norm: 1.6092  loss: 1.0352  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6846  loss_aux: 0.3506\n",
            "02/09 18:31:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][140/332]  lr: 1.0000e-03  eta: 2:35:14  time: 0.3963  data_time: 0.0109  memory: 6616  grad_norm: 1.6939  loss: 1.0073  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6676  loss_aux: 0.3396\n",
            "02/09 18:31:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][160/332]  lr: 1.0000e-03  eta: 2:35:06  time: 0.3945  data_time: 0.0103  memory: 6616  grad_norm: 1.7345  loss: 0.9942  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6574  loss_aux: 0.3368\n",
            "02/09 18:32:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][180/332]  lr: 1.0000e-03  eta: 2:34:58  time: 0.3946  data_time: 0.0103  memory: 6616  grad_norm: 1.5842  loss: 1.0066  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6709  loss_aux: 0.3357\n",
            "02/09 18:32:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][200/332]  lr: 1.0000e-03  eta: 2:34:50  time: 0.3959  data_time: 0.0107  memory: 6616  grad_norm: 1.5886  loss: 1.0215  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6817  loss_aux: 0.3398\n",
            "02/09 18:32:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][220/332]  lr: 1.0000e-03  eta: 2:34:42  time: 0.3949  data_time: 0.0103  memory: 6616  grad_norm: 1.5640  loss: 0.9777  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6467  loss_aux: 0.3310\n",
            "02/09 18:32:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][240/332]  lr: 1.0000e-03  eta: 2:34:34  time: 0.3947  data_time: 0.0104  memory: 6616  grad_norm: 1.4998  loss: 0.9527  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6290  loss_aux: 0.3237\n",
            "02/09 18:32:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][260/332]  lr: 1.0000e-03  eta: 2:34:26  time: 0.3947  data_time: 0.0099  memory: 6616  grad_norm: 1.9176  loss: 1.0314  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6890  loss_aux: 0.3425\n",
            "02/09 18:32:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][280/332]  lr: 1.0000e-03  eta: 2:34:18  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 1.6856  loss: 0.9442  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6303  loss_aux: 0.3139\n",
            "02/09 18:32:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][300/332]  lr: 1.0000e-03  eta: 2:34:10  time: 0.3953  data_time: 0.0104  memory: 6616  grad_norm: 1.7534  loss: 1.0082  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6776  loss_aux: 0.3307\n",
            "02/09 18:33:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][320/332]  lr: 1.0000e-03  eta: 2:34:02  time: 0.3944  data_time: 0.0101  memory: 6616  grad_norm: 1.6824  loss: 1.0515  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7100  loss_aux: 0.3414\n",
            "02/09 18:33:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:33:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][332/332]  lr: 1.0000e-03  eta: 2:33:58  time: 0.3895  data_time: 0.0094  memory: 6616  grad_norm: 1.6231  loss: 1.0783  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.7153  loss_aux: 0.3630\n",
            "02/09 18:33:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 80 epochs\n",
            "02/09 18:33:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [80][20/42]    eta: 0:00:04  time: 0.1945  data_time: 0.0848  memory: 1447  \n",
            "02/09 18:33:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [80][40/42]    eta: 0:00:00  time: 0.1198  data_time: 0.0183  memory: 1447  \n",
            "02/09 18:33:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [80][42/42]    acc/top1: 0.6175  acc/top5: 1.0000  acc/mean1: 0.5995  data_time: 0.0484  time: 0.1512\n",
            "02/09 18:33:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb/best_acc_top1_epoch_40.pth is removed\n",
            "02/09 18:33:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6175 acc/top1 at 80 epoch is saved to best_acc_top1_epoch_80.pth.\n",
            "02/09 18:33:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][ 20/332]  lr: 1.0000e-03  eta: 2:33:50  time: 0.4327  data_time: 0.0462  memory: 6616  grad_norm: 1.6710  loss: 1.0377  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6820  loss_aux: 0.3557\n",
            "02/09 18:33:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][ 40/332]  lr: 1.0000e-03  eta: 2:33:42  time: 0.3936  data_time: 0.0093  memory: 6616  grad_norm: 1.6761  loss: 1.0102  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6650  loss_aux: 0.3452\n",
            "02/09 18:33:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][ 60/332]  lr: 1.0000e-03  eta: 2:33:34  time: 0.3962  data_time: 0.0112  memory: 6616  grad_norm: 1.5180  loss: 1.0258  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6827  loss_aux: 0.3431\n",
            "02/09 18:33:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][ 80/332]  lr: 1.0000e-03  eta: 2:33:26  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 1.6161  loss: 1.0039  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6709  loss_aux: 0.3330\n",
            "02/09 18:34:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][100/332]  lr: 1.0000e-03  eta: 2:33:18  time: 0.3950  data_time: 0.0105  memory: 6616  grad_norm: 1.7100  loss: 0.9978  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6632  loss_aux: 0.3346\n",
            "02/09 18:34:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][120/332]  lr: 1.0000e-03  eta: 2:33:10  time: 0.3953  data_time: 0.0104  memory: 6616  grad_norm: 1.7546  loss: 0.9451  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6364  loss_aux: 0.3087\n",
            "02/09 18:34:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][140/332]  lr: 1.0000e-03  eta: 2:33:02  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 1.9228  loss: 1.0781  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7192  loss_aux: 0.3589\n",
            "02/09 18:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][160/332]  lr: 1.0000e-03  eta: 2:32:54  time: 0.3943  data_time: 0.0100  memory: 6616  grad_norm: 1.5627  loss: 1.0237  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6796  loss_aux: 0.3441\n",
            "02/09 18:34:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][180/332]  lr: 1.0000e-03  eta: 2:32:46  time: 0.3950  data_time: 0.0106  memory: 6616  grad_norm: 1.5744  loss: 0.9825  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6516  loss_aux: 0.3310\n",
            "02/09 18:34:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][200/332]  lr: 1.0000e-03  eta: 2:32:38  time: 0.3953  data_time: 0.0105  memory: 6616  grad_norm: 1.5975  loss: 1.0528  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7121  loss_aux: 0.3407\n",
            "02/09 18:34:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][220/332]  lr: 1.0000e-03  eta: 2:32:30  time: 0.3954  data_time: 0.0106  memory: 6616  grad_norm: 1.5562  loss: 1.0080  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6705  loss_aux: 0.3375\n",
            "02/09 18:34:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][240/332]  lr: 1.0000e-03  eta: 2:32:22  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 1.4992  loss: 0.9948  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6635  loss_aux: 0.3314\n",
            "02/09 18:35:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][260/332]  lr: 1.0000e-03  eta: 2:32:14  time: 0.3950  data_time: 0.0101  memory: 6616  grad_norm: 1.7130  loss: 1.0054  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6604  loss_aux: 0.3450\n",
            "02/09 18:35:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][280/332]  lr: 1.0000e-03  eta: 2:32:06  time: 0.3954  data_time: 0.0104  memory: 6616  grad_norm: 1.7756  loss: 1.0447  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6947  loss_aux: 0.3501\n",
            "02/09 18:35:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][300/332]  lr: 1.0000e-03  eta: 2:31:58  time: 0.3950  data_time: 0.0101  memory: 6616  grad_norm: 1.6614  loss: 1.0134  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6740  loss_aux: 0.3394\n",
            "02/09 18:35:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][320/332]  lr: 1.0000e-03  eta: 2:31:50  time: 0.3945  data_time: 0.0100  memory: 6616  grad_norm: 1.7212  loss: 0.9958  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6525  loss_aux: 0.3434\n",
            "02/09 18:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][332/332]  lr: 1.0000e-03  eta: 2:31:45  time: 0.3903  data_time: 0.0100  memory: 6616  grad_norm: 1.5807  loss: 0.9937  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6554  loss_aux: 0.3383\n",
            "02/09 18:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 81 epochs\n",
            "02/09 18:35:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][ 20/332]  lr: 1.0000e-03  eta: 2:31:38  time: 0.4442  data_time: 0.0570  memory: 6616  grad_norm: 1.6437  loss: 1.0122  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6703  loss_aux: 0.3419\n",
            "02/09 18:35:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][ 40/332]  lr: 1.0000e-03  eta: 2:31:30  time: 0.3950  data_time: 0.0101  memory: 6616  grad_norm: 1.6412  loss: 1.0334  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6821  loss_aux: 0.3513\n",
            "02/09 18:35:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][ 60/332]  lr: 1.0000e-03  eta: 2:31:22  time: 0.3953  data_time: 0.0106  memory: 6616  grad_norm: 1.6316  loss: 0.9821  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6514  loss_aux: 0.3307\n",
            "02/09 18:36:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][ 80/332]  lr: 1.0000e-03  eta: 2:31:14  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 1.5479  loss: 1.0087  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6761  loss_aux: 0.3326\n",
            "02/09 18:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][100/332]  lr: 1.0000e-03  eta: 2:31:06  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 1.5853  loss: 0.9621  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6387  loss_aux: 0.3234\n",
            "02/09 18:36:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:36:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][120/332]  lr: 1.0000e-03  eta: 2:30:58  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 1.6554  loss: 1.0604  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7164  loss_aux: 0.3440\n",
            "02/09 18:36:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][140/332]  lr: 1.0000e-03  eta: 2:30:50  time: 0.3952  data_time: 0.0104  memory: 6616  grad_norm: 1.6614  loss: 1.0943  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7354  loss_aux: 0.3588\n",
            "02/09 18:36:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][160/332]  lr: 1.0000e-03  eta: 2:30:42  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 1.5639  loss: 1.0192  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6750  loss_aux: 0.3443\n",
            "02/09 18:36:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][180/332]  lr: 1.0000e-03  eta: 2:30:34  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 1.5763  loss: 1.0291  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6832  loss_aux: 0.3460\n",
            "02/09 18:36:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][200/332]  lr: 1.0000e-03  eta: 2:30:26  time: 0.3953  data_time: 0.0105  memory: 6616  grad_norm: 1.5764  loss: 1.0175  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6761  loss_aux: 0.3415\n",
            "02/09 18:37:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][220/332]  lr: 1.0000e-03  eta: 2:30:18  time: 0.3951  data_time: 0.0104  memory: 6616  grad_norm: 1.6341  loss: 1.0221  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6844  loss_aux: 0.3376\n",
            "02/09 18:37:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][240/332]  lr: 1.0000e-03  eta: 2:30:10  time: 0.3952  data_time: 0.0103  memory: 6616  grad_norm: 1.4438  loss: 1.0006  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6574  loss_aux: 0.3432\n",
            "02/09 18:37:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][260/332]  lr: 1.0000e-03  eta: 2:30:02  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 1.4947  loss: 0.9897  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6524  loss_aux: 0.3373\n",
            "02/09 18:37:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][280/332]  lr: 1.0000e-03  eta: 2:29:54  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 1.5407  loss: 1.0228  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6841  loss_aux: 0.3387\n",
            "02/09 18:37:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][300/332]  lr: 1.0000e-03  eta: 2:29:46  time: 0.3954  data_time: 0.0107  memory: 6616  grad_norm: 1.5597  loss: 0.9944  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6554  loss_aux: 0.3390\n",
            "02/09 18:37:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][320/332]  lr: 1.0000e-03  eta: 2:29:38  time: 0.3944  data_time: 0.0096  memory: 6616  grad_norm: 1.5455  loss: 1.0168  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6748  loss_aux: 0.3421\n",
            "02/09 18:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][332/332]  lr: 1.0000e-03  eta: 2:29:34  time: 0.3898  data_time: 0.0094  memory: 6616  grad_norm: 1.5032  loss: 0.9864  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6533  loss_aux: 0.3331\n",
            "02/09 18:37:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 82 epochs\n",
            "02/09 18:37:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][ 20/332]  lr: 1.0000e-03  eta: 2:29:26  time: 0.4463  data_time: 0.0587  memory: 6616  grad_norm: 1.4049  loss: 0.9757  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6453  loss_aux: 0.3304\n",
            "02/09 18:38:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][ 40/332]  lr: 1.0000e-03  eta: 2:29:18  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 1.5295  loss: 0.9493  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6264  loss_aux: 0.3230\n",
            "02/09 18:38:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][ 60/332]  lr: 1.0000e-03  eta: 2:29:10  time: 0.3946  data_time: 0.0099  memory: 6616  grad_norm: 1.7537  loss: 1.0592  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7068  loss_aux: 0.3524\n",
            "02/09 18:38:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][ 80/332]  lr: 1.0000e-03  eta: 2:29:02  time: 0.3956  data_time: 0.0106  memory: 6616  grad_norm: 1.8213  loss: 1.0044  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6678  loss_aux: 0.3365\n",
            "02/09 18:38:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][100/332]  lr: 1.0000e-03  eta: 2:28:54  time: 0.3950  data_time: 0.0101  memory: 6616  grad_norm: 1.6532  loss: 0.9872  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6526  loss_aux: 0.3346\n",
            "02/09 18:38:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][120/332]  lr: 1.0000e-03  eta: 2:28:46  time: 0.3958  data_time: 0.0107  memory: 6616  grad_norm: 1.8013  loss: 1.0696  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7234  loss_aux: 0.3462\n",
            "02/09 18:38:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][140/332]  lr: 1.0000e-03  eta: 2:28:39  time: 0.3957  data_time: 0.0106  memory: 6616  grad_norm: 2.0236  loss: 1.0684  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7204  loss_aux: 0.3479\n",
            "02/09 18:38:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][160/332]  lr: 1.0000e-03  eta: 2:28:31  time: 0.3946  data_time: 0.0102  memory: 6616  grad_norm: 1.7457  loss: 0.9579  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6213  loss_aux: 0.3367\n",
            "02/09 18:39:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][180/332]  lr: 1.0000e-03  eta: 2:28:23  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 1.6798  loss: 1.0550  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7032  loss_aux: 0.3518\n",
            "02/09 18:39:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][200/332]  lr: 1.0000e-03  eta: 2:28:15  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 1.5644  loss: 1.0177  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6834  loss_aux: 0.3344\n",
            "02/09 18:39:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][220/332]  lr: 1.0000e-03  eta: 2:28:07  time: 0.3950  data_time: 0.0100  memory: 6616  grad_norm: 1.6826  loss: 1.0125  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6744  loss_aux: 0.3382\n",
            "02/09 18:39:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][240/332]  lr: 1.0000e-03  eta: 2:27:59  time: 0.3948  data_time: 0.0099  memory: 6616  grad_norm: 1.5999  loss: 1.0034  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6634  loss_aux: 0.3401\n",
            "02/09 18:39:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][260/332]  lr: 1.0000e-03  eta: 2:27:51  time: 0.3962  data_time: 0.0108  memory: 6616  grad_norm: 1.6906  loss: 0.9754  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6468  loss_aux: 0.3287\n",
            "02/09 18:39:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][280/332]  lr: 1.0000e-03  eta: 2:27:43  time: 0.3953  data_time: 0.0104  memory: 6616  grad_norm: 1.5957  loss: 1.0065  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6670  loss_aux: 0.3395\n",
            "02/09 18:39:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][300/332]  lr: 1.0000e-03  eta: 2:27:35  time: 0.3950  data_time: 0.0097  memory: 6616  grad_norm: 1.7489  loss: 1.0855  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7324  loss_aux: 0.3531\n",
            "02/09 18:39:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][320/332]  lr: 1.0000e-03  eta: 2:27:27  time: 0.3957  data_time: 0.0106  memory: 6616  grad_norm: 1.6883  loss: 1.0357  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6943  loss_aux: 0.3413\n",
            "02/09 18:40:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:40:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][332/332]  lr: 1.0000e-03  eta: 2:27:22  time: 0.3903  data_time: 0.0097  memory: 6616  grad_norm: 1.5665  loss: 0.9832  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6564  loss_aux: 0.3268\n",
            "02/09 18:40:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 83 epochs\n",
            "02/09 18:40:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][ 20/332]  lr: 1.0000e-03  eta: 2:27:15  time: 0.4510  data_time: 0.0649  memory: 6616  grad_norm: 1.7695  loss: 1.0376  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6927  loss_aux: 0.3449\n",
            "02/09 18:40:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][ 40/332]  lr: 1.0000e-03  eta: 2:27:07  time: 0.3959  data_time: 0.0107  memory: 6616  grad_norm: 1.6403  loss: 1.0027  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6699  loss_aux: 0.3328\n",
            "02/09 18:40:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][ 60/332]  lr: 1.0000e-03  eta: 2:26:59  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 1.7819  loss: 1.0275  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6973  loss_aux: 0.3302\n",
            "02/09 18:40:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][ 80/332]  lr: 1.0000e-03  eta: 2:26:51  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 1.5821  loss: 1.0450  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6934  loss_aux: 0.3516\n",
            "02/09 18:40:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][100/332]  lr: 1.0000e-03  eta: 2:26:43  time: 0.3957  data_time: 0.0108  memory: 6616  grad_norm: 1.5782  loss: 1.0043  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6672  loss_aux: 0.3371\n",
            "02/09 18:40:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][120/332]  lr: 1.0000e-03  eta: 2:26:35  time: 0.3975  data_time: 0.0116  memory: 6616  grad_norm: 1.6325  loss: 0.9973  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6521  loss_aux: 0.3452\n",
            "02/09 18:41:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][140/332]  lr: 1.0000e-03  eta: 2:26:27  time: 0.3959  data_time: 0.0107  memory: 6616  grad_norm: 1.7567  loss: 1.0032  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6752  loss_aux: 0.3280\n",
            "02/09 18:41:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][160/332]  lr: 1.0000e-03  eta: 2:26:19  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 1.5546  loss: 1.0130  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6748  loss_aux: 0.3382\n",
            "02/09 18:41:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][180/332]  lr: 1.0000e-03  eta: 2:26:11  time: 0.3953  data_time: 0.0104  memory: 6616  grad_norm: 1.6096  loss: 1.0006  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6596  loss_aux: 0.3410\n",
            "02/09 18:41:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][200/332]  lr: 1.0000e-03  eta: 2:26:03  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 1.5621  loss: 0.9588  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6242  loss_aux: 0.3346\n",
            "02/09 18:41:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][220/332]  lr: 1.0000e-03  eta: 2:25:55  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 1.7922  loss: 1.0121  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6752  loss_aux: 0.3369\n",
            "02/09 18:41:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][240/332]  lr: 1.0000e-03  eta: 2:25:47  time: 0.3953  data_time: 0.0101  memory: 6616  grad_norm: 1.6449  loss: 0.9724  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6442  loss_aux: 0.3282\n",
            "02/09 18:41:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][260/332]  lr: 1.0000e-03  eta: 2:25:39  time: 0.3947  data_time: 0.0099  memory: 6616  grad_norm: 1.6904  loss: 0.9969  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6587  loss_aux: 0.3382\n",
            "02/09 18:41:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][280/332]  lr: 1.0000e-03  eta: 2:25:31  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 1.8762  loss: 1.0470  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7032  loss_aux: 0.3438\n",
            "02/09 18:42:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][300/332]  lr: 1.0000e-03  eta: 2:25:23  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 1.5558  loss: 1.0020  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6625  loss_aux: 0.3395\n",
            "02/09 18:42:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][320/332]  lr: 1.0000e-03  eta: 2:25:15  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 1.8369  loss: 1.0502  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7073  loss_aux: 0.3428\n",
            "02/09 18:42:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:42:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][332/332]  lr: 1.0000e-03  eta: 2:25:10  time: 0.3896  data_time: 0.0092  memory: 6616  grad_norm: 1.8134  loss: 1.0117  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6692  loss_aux: 0.3425\n",
            "02/09 18:42:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 84 epochs\n",
            "02/09 18:42:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][ 20/332]  lr: 1.0000e-03  eta: 2:25:03  time: 0.4386  data_time: 0.0491  memory: 6616  grad_norm: 1.6953  loss: 1.0205  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6867  loss_aux: 0.3338\n",
            "02/09 18:42:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][ 40/332]  lr: 1.0000e-03  eta: 2:24:55  time: 0.3948  data_time: 0.0102  memory: 6616  grad_norm: 1.7130  loss: 1.0160  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6749  loss_aux: 0.3411\n",
            "02/09 18:42:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][ 60/332]  lr: 1.0000e-03  eta: 2:24:47  time: 0.3946  data_time: 0.0102  memory: 6616  grad_norm: 1.6522  loss: 1.0194  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6775  loss_aux: 0.3419\n",
            "02/09 18:42:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][ 80/332]  lr: 1.0000e-03  eta: 2:24:39  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 1.6632  loss: 1.0159  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6802  loss_aux: 0.3357\n",
            "02/09 18:43:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][100/332]  lr: 1.0000e-03  eta: 2:24:31  time: 0.3952  data_time: 0.0102  memory: 6616  grad_norm: 1.6965  loss: 0.9940  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6626  loss_aux: 0.3314\n",
            "02/09 18:43:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:43:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][120/332]  lr: 1.0000e-03  eta: 2:24:23  time: 0.3941  data_time: 0.0098  memory: 6616  grad_norm: 1.6336  loss: 1.0032  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6613  loss_aux: 0.3419\n",
            "02/09 18:43:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][140/332]  lr: 1.0000e-03  eta: 2:24:15  time: 0.3951  data_time: 0.0104  memory: 6616  grad_norm: 1.6427  loss: 1.0118  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6676  loss_aux: 0.3442\n",
            "02/09 18:43:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][160/332]  lr: 1.0000e-03  eta: 2:24:07  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 1.6457  loss: 0.9988  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6551  loss_aux: 0.3437\n",
            "02/09 18:43:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][180/332]  lr: 1.0000e-03  eta: 2:23:59  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 1.8989  loss: 1.0252  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6867  loss_aux: 0.3385\n",
            "02/09 18:43:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][200/332]  lr: 1.0000e-03  eta: 2:23:51  time: 0.3960  data_time: 0.0106  memory: 6616  grad_norm: 1.7815  loss: 0.9910  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6521  loss_aux: 0.3389\n",
            "02/09 18:43:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][220/332]  lr: 1.0000e-03  eta: 2:23:43  time: 0.3951  data_time: 0.0100  memory: 6616  grad_norm: 1.7199  loss: 1.0108  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6717  loss_aux: 0.3391\n",
            "02/09 18:43:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][240/332]  lr: 1.0000e-03  eta: 2:23:35  time: 0.3946  data_time: 0.0098  memory: 6616  grad_norm: 1.7565  loss: 1.0481  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7075  loss_aux: 0.3407\n",
            "02/09 18:44:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][260/332]  lr: 1.0000e-03  eta: 2:23:27  time: 0.3950  data_time: 0.0100  memory: 6616  grad_norm: 1.6541  loss: 0.9959  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6755  loss_aux: 0.3204\n",
            "02/09 18:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][280/332]  lr: 1.0000e-03  eta: 2:23:19  time: 0.3956  data_time: 0.0105  memory: 6616  grad_norm: 1.8524  loss: 1.0011  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6661  loss_aux: 0.3349\n",
            "02/09 18:44:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][300/332]  lr: 1.0000e-03  eta: 2:23:11  time: 0.3955  data_time: 0.0101  memory: 6616  grad_norm: 1.8759  loss: 1.0412  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6961  loss_aux: 0.3452\n",
            "02/09 18:44:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][320/332]  lr: 1.0000e-03  eta: 2:23:03  time: 0.3955  data_time: 0.0103  memory: 6616  grad_norm: 1.8687  loss: 0.9872  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6519  loss_aux: 0.3353\n",
            "02/09 18:44:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:44:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][332/332]  lr: 1.0000e-03  eta: 2:22:58  time: 0.3896  data_time: 0.0094  memory: 6616  grad_norm: 1.8932  loss: 0.9592  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6375  loss_aux: 0.3217\n",
            "02/09 18:44:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 85 epochs\n",
            "02/09 18:44:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][ 20/332]  lr: 1.0000e-03  eta: 2:22:51  time: 0.4444  data_time: 0.0561  memory: 6616  grad_norm: 3.0910  loss: 1.0716  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7358  loss_aux: 0.3357\n",
            "02/09 18:44:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][ 40/332]  lr: 1.0000e-03  eta: 2:22:43  time: 0.3947  data_time: 0.0098  memory: 6616  grad_norm: 2.2405  loss: 1.0066  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6694  loss_aux: 0.3372\n",
            "02/09 18:44:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][ 60/332]  lr: 1.0000e-03  eta: 2:22:35  time: 0.3945  data_time: 0.0099  memory: 6616  grad_norm: 2.3905  loss: 0.9848  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6467  loss_aux: 0.3381\n",
            "02/09 18:45:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][ 80/332]  lr: 1.0000e-03  eta: 2:22:27  time: 0.3950  data_time: 0.0101  memory: 6616  grad_norm: 1.9208  loss: 1.0031  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6742  loss_aux: 0.3290\n",
            "02/09 18:45:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][100/332]  lr: 1.0000e-03  eta: 2:22:19  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 1.7969  loss: 1.0211  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6801  loss_aux: 0.3410\n",
            "02/09 18:45:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][120/332]  lr: 1.0000e-03  eta: 2:22:11  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 1.9323  loss: 1.0030  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6650  loss_aux: 0.3380\n",
            "02/09 18:45:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][140/332]  lr: 1.0000e-03  eta: 2:22:03  time: 0.3959  data_time: 0.0110  memory: 6616  grad_norm: 2.0534  loss: 1.0558  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7051  loss_aux: 0.3507\n",
            "02/09 18:45:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][160/332]  lr: 1.0000e-03  eta: 2:21:55  time: 0.3951  data_time: 0.0105  memory: 6616  grad_norm: 1.6648  loss: 0.9662  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6254  loss_aux: 0.3407\n",
            "02/09 18:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][180/332]  lr: 1.0000e-03  eta: 2:21:47  time: 0.3952  data_time: 0.0103  memory: 6616  grad_norm: 1.9115  loss: 1.0076  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6760  loss_aux: 0.3316\n",
            "02/09 18:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][200/332]  lr: 1.0000e-03  eta: 2:21:39  time: 0.3957  data_time: 0.0106  memory: 6616  grad_norm: 1.8464  loss: 1.0079  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6703  loss_aux: 0.3376\n",
            "02/09 18:46:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][220/332]  lr: 1.0000e-03  eta: 2:21:31  time: 0.3953  data_time: 0.0099  memory: 6616  grad_norm: 1.8672  loss: 1.0123  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6726  loss_aux: 0.3397\n",
            "02/09 18:46:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][240/332]  lr: 1.0000e-03  eta: 2:21:23  time: 0.3949  data_time: 0.0100  memory: 6616  grad_norm: 2.4088  loss: 0.9665  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6446  loss_aux: 0.3220\n",
            "02/09 18:46:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][260/332]  lr: 1.0000e-03  eta: 2:21:15  time: 0.3959  data_time: 0.0109  memory: 6616  grad_norm: 2.1270  loss: 1.0027  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6702  loss_aux: 0.3326\n",
            "02/09 18:46:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][280/332]  lr: 1.0000e-03  eta: 2:21:07  time: 0.3955  data_time: 0.0107  memory: 6616  grad_norm: 1.8018  loss: 1.0203  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6616  loss_aux: 0.3587\n",
            "02/09 18:46:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][300/332]  lr: 1.0000e-03  eta: 2:20:59  time: 0.3952  data_time: 0.0104  memory: 6616  grad_norm: 1.7542  loss: 0.9569  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6283  loss_aux: 0.3286\n",
            "02/09 18:46:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][320/332]  lr: 1.0000e-03  eta: 2:20:51  time: 0.3943  data_time: 0.0097  memory: 6616  grad_norm: 1.9322  loss: 1.0017  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6654  loss_aux: 0.3363\n",
            "02/09 18:46:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:46:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][332/332]  lr: 1.0000e-03  eta: 2:20:46  time: 0.3893  data_time: 0.0094  memory: 6616  grad_norm: 2.2797  loss: 1.0314  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6825  loss_aux: 0.3489\n",
            "02/09 18:46:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 86 epochs\n",
            "02/09 18:46:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][ 20/332]  lr: 1.0000e-03  eta: 2:20:39  time: 0.4373  data_time: 0.0482  memory: 6616  grad_norm: 1.8420  loss: 1.0035  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6855  loss_aux: 0.3180\n",
            "02/09 18:47:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][ 40/332]  lr: 1.0000e-03  eta: 2:20:31  time: 0.3959  data_time: 0.0106  memory: 6616  grad_norm: 2.0806  loss: 1.0591  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7080  loss_aux: 0.3512\n",
            "02/09 18:47:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][ 60/332]  lr: 1.0000e-03  eta: 2:20:23  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 1.7292  loss: 0.9439  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6288  loss_aux: 0.3150\n",
            "02/09 18:47:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][ 80/332]  lr: 1.0000e-03  eta: 2:20:15  time: 0.3981  data_time: 0.0120  memory: 6616  grad_norm: 1.8991  loss: 0.9756  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6484  loss_aux: 0.3272\n",
            "02/09 18:47:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][100/332]  lr: 1.0000e-03  eta: 2:20:07  time: 0.3964  data_time: 0.0108  memory: 6616  grad_norm: 2.0118  loss: 0.9676  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6417  loss_aux: 0.3259\n",
            "02/09 18:47:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][120/332]  lr: 1.0000e-03  eta: 2:19:59  time: 0.3947  data_time: 0.0099  memory: 6616  grad_norm: 2.0798  loss: 0.9872  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6512  loss_aux: 0.3360\n",
            "02/09 18:47:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][140/332]  lr: 1.0000e-03  eta: 2:19:51  time: 0.3954  data_time: 0.0101  memory: 6616  grad_norm: 2.1522  loss: 1.0591  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7060  loss_aux: 0.3531\n",
            "02/09 18:47:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][160/332]  lr: 1.0000e-03  eta: 2:19:43  time: 0.3950  data_time: 0.0104  memory: 6616  grad_norm: 2.1181  loss: 0.9775  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6496  loss_aux: 0.3279\n",
            "02/09 18:48:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][180/332]  lr: 1.0000e-03  eta: 2:19:35  time: 0.3945  data_time: 0.0098  memory: 6616  grad_norm: 2.2563  loss: 1.0340  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6874  loss_aux: 0.3465\n",
            "02/09 18:48:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][200/332]  lr: 1.0000e-03  eta: 2:19:27  time: 0.3949  data_time: 0.0098  memory: 6616  grad_norm: 2.2037  loss: 1.0467  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7021  loss_aux: 0.3446\n",
            "02/09 18:48:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][220/332]  lr: 1.0000e-03  eta: 2:19:19  time: 0.3965  data_time: 0.0115  memory: 6616  grad_norm: 2.0455  loss: 1.0007  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6647  loss_aux: 0.3360\n",
            "02/09 18:48:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][240/332]  lr: 1.0000e-03  eta: 2:19:11  time: 0.3951  data_time: 0.0105  memory: 6616  grad_norm: 1.8093  loss: 1.0619  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6997  loss_aux: 0.3622\n",
            "02/09 18:48:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][260/332]  lr: 1.0000e-03  eta: 2:19:03  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 2.1131  loss: 1.0472  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6972  loss_aux: 0.3499\n",
            "02/09 18:48:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][280/332]  lr: 1.0000e-03  eta: 2:18:55  time: 0.3959  data_time: 0.0107  memory: 6616  grad_norm: 1.8509  loss: 0.9842  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6467  loss_aux: 0.3375\n",
            "02/09 18:48:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][300/332]  lr: 1.0000e-03  eta: 2:18:47  time: 0.3949  data_time: 0.0099  memory: 6616  grad_norm: 1.7711  loss: 0.9974  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6659  loss_aux: 0.3315\n",
            "02/09 18:48:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][320/332]  lr: 1.0000e-03  eta: 2:18:39  time: 0.3953  data_time: 0.0101  memory: 6616  grad_norm: 1.7840  loss: 0.9987  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6603  loss_aux: 0.3384\n",
            "02/09 18:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][332/332]  lr: 1.0000e-03  eta: 2:18:34  time: 0.3900  data_time: 0.0095  memory: 6616  grad_norm: 1.7943  loss: 0.9789  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6541  loss_aux: 0.3248\n",
            "02/09 18:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 87 epochs\n",
            "02/09 18:49:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][ 20/332]  lr: 1.0000e-03  eta: 2:18:27  time: 0.4434  data_time: 0.0546  memory: 6616  grad_norm: 1.9537  loss: 0.9969  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6637  loss_aux: 0.3332\n",
            "02/09 18:49:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][ 40/332]  lr: 1.0000e-03  eta: 2:18:19  time: 0.3957  data_time: 0.0102  memory: 6616  grad_norm: 1.8927  loss: 0.9592  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6289  loss_aux: 0.3303\n",
            "02/09 18:49:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][ 60/332]  lr: 1.0000e-03  eta: 2:18:11  time: 0.3963  data_time: 0.0111  memory: 6616  grad_norm: 2.0750  loss: 1.0686  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7096  loss_aux: 0.3590\n",
            "02/09 18:49:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][ 80/332]  lr: 1.0000e-03  eta: 2:18:03  time: 0.3945  data_time: 0.0099  memory: 6616  grad_norm: 1.8517  loss: 0.9694  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6462  loss_aux: 0.3231\n",
            "02/09 18:49:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][100/332]  lr: 1.0000e-03  eta: 2:17:55  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 1.9263  loss: 1.0154  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6686  loss_aux: 0.3469\n",
            "02/09 18:49:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:49:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][120/332]  lr: 1.0000e-03  eta: 2:17:47  time: 0.3950  data_time: 0.0103  memory: 6616  grad_norm: 1.8683  loss: 1.0066  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6693  loss_aux: 0.3373\n",
            "02/09 18:49:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][140/332]  lr: 1.0000e-03  eta: 2:17:39  time: 0.3947  data_time: 0.0098  memory: 6616  grad_norm: 2.0319  loss: 1.0041  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6682  loss_aux: 0.3360\n",
            "02/09 18:50:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][160/332]  lr: 1.0000e-03  eta: 2:17:31  time: 0.3963  data_time: 0.0106  memory: 6616  grad_norm: 2.1401  loss: 1.0589  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7088  loss_aux: 0.3500\n",
            "02/09 18:50:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][180/332]  lr: 1.0000e-03  eta: 2:17:23  time: 0.3944  data_time: 0.0096  memory: 6616  grad_norm: 1.9164  loss: 0.9794  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6463  loss_aux: 0.3332\n",
            "02/09 18:50:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][200/332]  lr: 1.0000e-03  eta: 2:17:15  time: 0.3953  data_time: 0.0100  memory: 6616  grad_norm: 1.9649  loss: 1.0375  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6976  loss_aux: 0.3399\n",
            "02/09 18:50:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][220/332]  lr: 1.0000e-03  eta: 2:17:07  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 1.8978  loss: 0.9684  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6409  loss_aux: 0.3276\n",
            "02/09 18:50:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][240/332]  lr: 1.0000e-03  eta: 2:16:59  time: 0.3950  data_time: 0.0103  memory: 6616  grad_norm: 1.9180  loss: 0.9845  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6451  loss_aux: 0.3395\n",
            "02/09 18:50:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][260/332]  lr: 1.0000e-03  eta: 2:16:51  time: 0.3951  data_time: 0.0100  memory: 6616  grad_norm: 1.7159  loss: 0.9468  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6224  loss_aux: 0.3244\n",
            "02/09 18:50:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][280/332]  lr: 1.0000e-03  eta: 2:16:43  time: 0.3951  data_time: 0.0102  memory: 6616  grad_norm: 2.0968  loss: 1.0505  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7172  loss_aux: 0.3333\n",
            "02/09 18:51:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][300/332]  lr: 1.0000e-03  eta: 2:16:35  time: 0.3947  data_time: 0.0098  memory: 6616  grad_norm: 2.0790  loss: 1.0824  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7294  loss_aux: 0.3531\n",
            "02/09 18:51:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][320/332]  lr: 1.0000e-03  eta: 2:16:27  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 2.0743  loss: 0.9807  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6434  loss_aux: 0.3373\n",
            "02/09 18:51:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:51:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][332/332]  lr: 1.0000e-03  eta: 2:16:22  time: 0.3891  data_time: 0.0091  memory: 6616  grad_norm: 2.0308  loss: 0.9859  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6596  loss_aux: 0.3263\n",
            "02/09 18:51:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 88 epochs\n",
            "02/09 18:51:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][ 20/332]  lr: 1.0000e-03  eta: 2:16:15  time: 0.4431  data_time: 0.0569  memory: 6616  grad_norm: 1.8055  loss: 0.9932  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6592  loss_aux: 0.3339\n",
            "02/09 18:51:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][ 40/332]  lr: 1.0000e-03  eta: 2:16:07  time: 0.3952  data_time: 0.0103  memory: 6616  grad_norm: 2.0538  loss: 0.9485  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6200  loss_aux: 0.3284\n",
            "02/09 18:51:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][ 60/332]  lr: 1.0000e-03  eta: 2:15:59  time: 0.3961  data_time: 0.0111  memory: 6616  grad_norm: 2.0962  loss: 0.9990  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6657  loss_aux: 0.3332\n",
            "02/09 18:51:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][ 80/332]  lr: 1.0000e-03  eta: 2:15:51  time: 0.3939  data_time: 0.0098  memory: 6616  grad_norm: 2.1601  loss: 0.9977  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6668  loss_aux: 0.3308\n",
            "02/09 18:51:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][100/332]  lr: 1.0000e-03  eta: 2:15:43  time: 0.3956  data_time: 0.0105  memory: 6616  grad_norm: 2.0217  loss: 1.0136  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6761  loss_aux: 0.3375\n",
            "02/09 18:52:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][120/332]  lr: 1.0000e-03  eta: 2:15:35  time: 0.3956  data_time: 0.0107  memory: 6616  grad_norm: 2.2245  loss: 1.0621  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7132  loss_aux: 0.3488\n",
            "02/09 18:52:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][140/332]  lr: 1.0000e-03  eta: 2:15:27  time: 0.3937  data_time: 0.0097  memory: 6616  grad_norm: 1.9624  loss: 1.0135  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6689  loss_aux: 0.3446\n",
            "02/09 18:52:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][160/332]  lr: 1.0000e-03  eta: 2:15:19  time: 0.3953  data_time: 0.0105  memory: 6616  grad_norm: 1.9028  loss: 0.9668  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6375  loss_aux: 0.3293\n",
            "02/09 18:52:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][180/332]  lr: 1.0000e-03  eta: 2:15:11  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 1.9113  loss: 1.0709  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7074  loss_aux: 0.3635\n",
            "02/09 18:52:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][200/332]  lr: 1.0000e-03  eta: 2:15:03  time: 0.3946  data_time: 0.0100  memory: 6616  grad_norm: 1.8598  loss: 1.0301  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6943  loss_aux: 0.3358\n",
            "02/09 18:52:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][220/332]  lr: 1.0000e-03  eta: 2:14:55  time: 0.3953  data_time: 0.0106  memory: 6616  grad_norm: 2.1496  loss: 0.9630  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6412  loss_aux: 0.3218\n",
            "02/09 18:52:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][240/332]  lr: 1.0000e-03  eta: 2:14:47  time: 0.3941  data_time: 0.0097  memory: 6616  grad_norm: 1.6921  loss: 0.9801  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6527  loss_aux: 0.3274\n",
            "02/09 18:53:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][260/332]  lr: 1.0000e-03  eta: 2:14:39  time: 0.3945  data_time: 0.0099  memory: 6616  grad_norm: 1.8906  loss: 0.9993  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6673  loss_aux: 0.3320\n",
            "02/09 18:53:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][280/332]  lr: 1.0000e-03  eta: 2:14:31  time: 0.3961  data_time: 0.0108  memory: 6616  grad_norm: 1.9156  loss: 1.0345  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6894  loss_aux: 0.3451\n",
            "02/09 18:53:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][300/332]  lr: 1.0000e-03  eta: 2:14:23  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 2.0446  loss: 1.0403  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6919  loss_aux: 0.3484\n",
            "02/09 18:53:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][320/332]  lr: 1.0000e-03  eta: 2:14:15  time: 0.3944  data_time: 0.0098  memory: 6616  grad_norm: 1.7985  loss: 1.0383  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6965  loss_aux: 0.3419\n",
            "02/09 18:53:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:53:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][332/332]  lr: 1.0000e-03  eta: 2:14:10  time: 0.3895  data_time: 0.0093  memory: 6616  grad_norm: 1.9436  loss: 1.0475  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6954  loss_aux: 0.3521\n",
            "02/09 18:53:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 89 epochs\n",
            "02/09 18:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][ 20/332]  lr: 1.0000e-03  eta: 2:14:03  time: 0.4429  data_time: 0.0533  memory: 6616  grad_norm: 1.7917  loss: 0.9902  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6518  loss_aux: 0.3385\n",
            "02/09 18:53:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][ 40/332]  lr: 1.0000e-03  eta: 2:13:55  time: 0.3951  data_time: 0.0102  memory: 6616  grad_norm: 1.8366  loss: 1.0217  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6836  loss_aux: 0.3381\n",
            "02/09 18:53:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][ 60/332]  lr: 1.0000e-03  eta: 2:13:47  time: 0.3951  data_time: 0.0102  memory: 6616  grad_norm: 1.9284  loss: 0.9890  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6563  loss_aux: 0.3327\n",
            "02/09 18:54:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][ 80/332]  lr: 1.0000e-03  eta: 2:13:39  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 2.1609  loss: 1.0208  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6820  loss_aux: 0.3388\n",
            "02/09 18:54:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][100/332]  lr: 1.0000e-03  eta: 2:13:31  time: 0.3955  data_time: 0.0105  memory: 6616  grad_norm: 1.9376  loss: 0.9982  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6684  loss_aux: 0.3299\n",
            "02/09 18:54:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][120/332]  lr: 1.0000e-03  eta: 2:13:23  time: 0.3960  data_time: 0.0104  memory: 6616  grad_norm: 1.9320  loss: 1.0240  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6827  loss_aux: 0.3413\n",
            "02/09 18:54:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][140/332]  lr: 1.0000e-03  eta: 2:13:15  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 1.9456  loss: 1.0203  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6816  loss_aux: 0.3387\n",
            "02/09 18:54:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][160/332]  lr: 1.0000e-03  eta: 2:13:07  time: 0.3961  data_time: 0.0105  memory: 6616  grad_norm: 1.8708  loss: 0.9789  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6553  loss_aux: 0.3236\n",
            "02/09 18:54:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][180/332]  lr: 1.0000e-03  eta: 2:12:59  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 2.2509  loss: 1.0848  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7199  loss_aux: 0.3650\n",
            "02/09 18:54:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][200/332]  lr: 1.0000e-03  eta: 2:12:51  time: 0.3943  data_time: 0.0096  memory: 6616  grad_norm: 1.8693  loss: 0.9745  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6402  loss_aux: 0.3343\n",
            "02/09 18:55:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][220/332]  lr: 1.0000e-03  eta: 2:12:43  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 1.7386  loss: 1.0015  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6684  loss_aux: 0.3331\n",
            "02/09 18:55:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][240/332]  lr: 1.0000e-03  eta: 2:12:35  time: 0.3958  data_time: 0.0104  memory: 6616  grad_norm: 1.7181  loss: 0.9884  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6614  loss_aux: 0.3270\n",
            "02/09 18:55:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][260/332]  lr: 1.0000e-03  eta: 2:12:27  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 1.9063  loss: 1.0203  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6854  loss_aux: 0.3350\n",
            "02/09 18:55:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][280/332]  lr: 1.0000e-03  eta: 2:12:19  time: 0.3957  data_time: 0.0103  memory: 6616  grad_norm: 1.9717  loss: 1.0244  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6833  loss_aux: 0.3411\n",
            "02/09 18:55:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][300/332]  lr: 1.0000e-03  eta: 2:12:11  time: 0.3957  data_time: 0.0104  memory: 6616  grad_norm: 1.9816  loss: 1.0128  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6768  loss_aux: 0.3360\n",
            "02/09 18:55:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][320/332]  lr: 1.0000e-03  eta: 2:12:03  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 1.8894  loss: 0.9927  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6602  loss_aux: 0.3325\n",
            "02/09 18:55:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:55:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][332/332]  lr: 1.0000e-03  eta: 2:11:58  time: 0.3897  data_time: 0.0097  memory: 6616  grad_norm: 1.7396  loss: 0.9472  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6287  loss_aux: 0.3185\n",
            "02/09 18:55:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 90 epochs\n",
            "02/09 18:55:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [90][20/42]    eta: 0:00:03  time: 0.1816  data_time: 0.0734  memory: 1447  \n",
            "02/09 18:55:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [90][40/42]    eta: 0:00:00  time: 0.1129  data_time: 0.0131  memory: 1447  \n",
            "02/09 18:55:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [90][42/42]    acc/top1: 0.6114  acc/top5: 1.0000  acc/mean1: 0.5887  data_time: 0.0407  time: 0.1421\n",
            "02/09 18:56:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][ 20/332]  lr: 1.0000e-03  eta: 2:11:51  time: 0.4404  data_time: 0.0539  memory: 6616  grad_norm: 1.8542  loss: 0.9973  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6669  loss_aux: 0.3303\n",
            "02/09 18:56:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][ 40/332]  lr: 1.0000e-03  eta: 2:11:43  time: 0.3952  data_time: 0.0107  memory: 6616  grad_norm: 2.2096  loss: 1.0008  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6724  loss_aux: 0.3284\n",
            "02/09 18:56:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][ 60/332]  lr: 1.0000e-03  eta: 2:11:35  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 2.1400  loss: 0.9604  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6318  loss_aux: 0.3286\n",
            "02/09 18:56:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][ 80/332]  lr: 1.0000e-03  eta: 2:11:27  time: 0.3951  data_time: 0.0105  memory: 6616  grad_norm: 1.7903  loss: 0.9913  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6597  loss_aux: 0.3315\n",
            "02/09 18:56:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][100/332]  lr: 1.0000e-03  eta: 2:11:19  time: 0.3949  data_time: 0.0105  memory: 6616  grad_norm: 2.0075  loss: 0.9968  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6582  loss_aux: 0.3387\n",
            "02/09 18:56:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:56:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][120/332]  lr: 1.0000e-03  eta: 2:11:11  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 1.8475  loss: 1.0026  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6549  loss_aux: 0.3477\n",
            "02/09 18:56:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][140/332]  lr: 1.0000e-03  eta: 2:11:03  time: 0.3968  data_time: 0.0112  memory: 6616  grad_norm: 1.9780  loss: 1.0305  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6786  loss_aux: 0.3519\n",
            "02/09 18:56:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][160/332]  lr: 1.0000e-03  eta: 2:10:55  time: 0.3958  data_time: 0.0107  memory: 6616  grad_norm: 2.1122  loss: 1.0222  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6861  loss_aux: 0.3360\n",
            "02/09 18:57:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][180/332]  lr: 1.0000e-03  eta: 2:10:47  time: 0.3949  data_time: 0.0099  memory: 6616  grad_norm: 2.1516  loss: 1.0429  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6970  loss_aux: 0.3459\n",
            "02/09 18:57:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][200/332]  lr: 1.0000e-03  eta: 2:10:39  time: 0.3955  data_time: 0.0105  memory: 6616  grad_norm: 1.8957  loss: 0.9933  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6545  loss_aux: 0.3388\n",
            "02/09 18:57:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][220/332]  lr: 1.0000e-03  eta: 2:10:31  time: 0.3958  data_time: 0.0108  memory: 6616  grad_norm: 2.0004  loss: 0.9942  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6622  loss_aux: 0.3320\n",
            "02/09 18:57:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][240/332]  lr: 1.0000e-03  eta: 2:10:23  time: 0.3949  data_time: 0.0103  memory: 6616  grad_norm: 1.8073  loss: 0.9717  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6453  loss_aux: 0.3264\n",
            "02/09 18:57:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][260/332]  lr: 1.0000e-03  eta: 2:10:15  time: 0.3971  data_time: 0.0113  memory: 6616  grad_norm: 2.0820  loss: 0.9761  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6524  loss_aux: 0.3237\n",
            "02/09 18:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][280/332]  lr: 1.0000e-03  eta: 2:10:07  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 2.1021  loss: 1.0418  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6918  loss_aux: 0.3500\n",
            "02/09 18:57:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][300/332]  lr: 1.0000e-03  eta: 2:09:59  time: 0.3954  data_time: 0.0101  memory: 6616  grad_norm: 2.1204  loss: 1.0315  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6931  loss_aux: 0.3384\n",
            "02/09 18:58:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][320/332]  lr: 1.0000e-03  eta: 2:09:51  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 2.1217  loss: 1.0165  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6707  loss_aux: 0.3458\n",
            "02/09 18:58:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 18:58:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][332/332]  lr: 1.0000e-03  eta: 2:09:47  time: 0.3894  data_time: 0.0093  memory: 6616  grad_norm: 2.1830  loss: 1.0933  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.7354  loss_aux: 0.3579\n",
            "02/09 18:58:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 91 epochs\n",
            "02/09 18:58:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][ 20/332]  lr: 1.0000e-03  eta: 2:09:39  time: 0.4382  data_time: 0.0500  memory: 6616  grad_norm: 1.9713  loss: 0.9259  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6068  loss_aux: 0.3191\n",
            "02/09 18:58:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][ 40/332]  lr: 1.0000e-03  eta: 2:09:31  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 2.3221  loss: 1.0417  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6946  loss_aux: 0.3470\n",
            "02/09 18:58:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][ 60/332]  lr: 1.0000e-03  eta: 2:09:23  time: 0.3945  data_time: 0.0096  memory: 6616  grad_norm: 1.9437  loss: 0.9808  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6584  loss_aux: 0.3223\n",
            "02/09 18:58:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][ 80/332]  lr: 1.0000e-03  eta: 2:09:15  time: 0.3947  data_time: 0.0098  memory: 6616  grad_norm: 1.9963  loss: 1.0235  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6868  loss_aux: 0.3367\n",
            "02/09 18:58:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][100/332]  lr: 1.0000e-03  eta: 2:09:07  time: 0.3950  data_time: 0.0101  memory: 6616  grad_norm: 1.9086  loss: 0.9995  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6744  loss_aux: 0.3251\n",
            "02/09 18:58:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][120/332]  lr: 1.0000e-03  eta: 2:08:59  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 2.0907  loss: 1.0296  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6866  loss_aux: 0.3430\n",
            "02/09 18:59:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][140/332]  lr: 1.0000e-03  eta: 2:08:51  time: 0.3947  data_time: 0.0100  memory: 6616  grad_norm: 2.2611  loss: 1.0267  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6910  loss_aux: 0.3357\n",
            "02/09 18:59:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][160/332]  lr: 1.0000e-03  eta: 2:08:43  time: 0.3950  data_time: 0.0098  memory: 6616  grad_norm: 1.8408  loss: 1.0224  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6797  loss_aux: 0.3427\n",
            "02/09 18:59:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][180/332]  lr: 1.0000e-03  eta: 2:08:35  time: 0.3957  data_time: 0.0106  memory: 6616  grad_norm: 1.7675  loss: 0.9998  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6596  loss_aux: 0.3402\n",
            "02/09 18:59:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][200/332]  lr: 1.0000e-03  eta: 2:08:27  time: 0.3954  data_time: 0.0104  memory: 6616  grad_norm: 1.7238  loss: 1.0262  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6840  loss_aux: 0.3422\n",
            "02/09 18:59:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][220/332]  lr: 1.0000e-03  eta: 2:08:19  time: 0.3953  data_time: 0.0103  memory: 6616  grad_norm: 1.9792  loss: 1.0149  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6734  loss_aux: 0.3415\n",
            "02/09 18:59:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][240/332]  lr: 1.0000e-03  eta: 2:08:11  time: 0.3955  data_time: 0.0106  memory: 6616  grad_norm: 1.8011  loss: 1.0413  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6977  loss_aux: 0.3436\n",
            "02/09 18:59:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][260/332]  lr: 1.0000e-03  eta: 2:08:03  time: 0.3951  data_time: 0.0099  memory: 6616  grad_norm: 1.9013  loss: 0.9879  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6596  loss_aux: 0.3283\n",
            "02/09 18:59:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][280/332]  lr: 1.0000e-03  eta: 2:07:55  time: 0.3961  data_time: 0.0109  memory: 6616  grad_norm: 2.0139  loss: 0.9555  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6371  loss_aux: 0.3184\n",
            "02/09 19:00:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][300/332]  lr: 1.0000e-03  eta: 2:07:47  time: 0.3950  data_time: 0.0098  memory: 6616  grad_norm: 2.0214  loss: 1.0054  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6781  loss_aux: 0.3273\n",
            "02/09 19:00:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][320/332]  lr: 1.0000e-03  eta: 2:07:39  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 2.0238  loss: 0.9928  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6690  loss_aux: 0.3238\n",
            "02/09 19:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][332/332]  lr: 1.0000e-03  eta: 2:07:35  time: 0.3898  data_time: 0.0095  memory: 6616  grad_norm: 1.9633  loss: 1.0197  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6817  loss_aux: 0.3380\n",
            "02/09 19:00:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 92 epochs\n",
            "02/09 19:00:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][ 20/332]  lr: 1.0000e-03  eta: 2:07:27  time: 0.4421  data_time: 0.0538  memory: 6616  grad_norm: 2.3785  loss: 1.0359  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6891  loss_aux: 0.3468\n",
            "02/09 19:00:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][ 40/332]  lr: 1.0000e-03  eta: 2:07:19  time: 0.3956  data_time: 0.0105  memory: 6616  grad_norm: 2.1129  loss: 1.0111  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6629  loss_aux: 0.3482\n",
            "02/09 19:00:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][ 60/332]  lr: 1.0000e-03  eta: 2:07:11  time: 0.3962  data_time: 0.0110  memory: 6616  grad_norm: 1.8533  loss: 1.0023  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6691  loss_aux: 0.3332\n",
            "02/09 19:00:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][ 80/332]  lr: 1.0000e-03  eta: 2:07:03  time: 0.3942  data_time: 0.0095  memory: 6616  grad_norm: 1.9529  loss: 1.0053  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6735  loss_aux: 0.3318\n",
            "02/09 19:01:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][100/332]  lr: 1.0000e-03  eta: 2:06:55  time: 0.3945  data_time: 0.0098  memory: 6616  grad_norm: 2.0492  loss: 0.9363  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6225  loss_aux: 0.3137\n",
            "02/09 19:01:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][120/332]  lr: 1.0000e-03  eta: 2:06:47  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 1.9145  loss: 1.0273  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6794  loss_aux: 0.3480\n",
            "02/09 19:01:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][140/332]  lr: 1.0000e-03  eta: 2:06:39  time: 0.3947  data_time: 0.0099  memory: 6616  grad_norm: 1.9426  loss: 1.0149  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6783  loss_aux: 0.3366\n",
            "02/09 19:01:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][160/332]  lr: 1.0000e-03  eta: 2:06:31  time: 0.3960  data_time: 0.0109  memory: 6616  grad_norm: 1.8399  loss: 0.9961  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6664  loss_aux: 0.3297\n",
            "02/09 19:01:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][180/332]  lr: 1.0000e-03  eta: 2:06:23  time: 0.3963  data_time: 0.0107  memory: 6616  grad_norm: 1.8685  loss: 0.9943  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6564  loss_aux: 0.3379\n",
            "02/09 19:01:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][200/332]  lr: 1.0000e-03  eta: 2:06:15  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 1.6590  loss: 0.9447  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6219  loss_aux: 0.3228\n",
            "02/09 19:01:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][220/332]  lr: 1.0000e-03  eta: 2:06:07  time: 0.3950  data_time: 0.0099  memory: 6616  grad_norm: 2.0754  loss: 0.9390  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6147  loss_aux: 0.3243\n",
            "02/09 19:01:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][240/332]  lr: 1.0000e-03  eta: 2:05:59  time: 0.3961  data_time: 0.0105  memory: 6616  grad_norm: 2.0521  loss: 0.9988  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6617  loss_aux: 0.3371\n",
            "02/09 19:02:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][260/332]  lr: 1.0000e-03  eta: 2:05:51  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 2.1854  loss: 1.0308  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6823  loss_aux: 0.3484\n",
            "02/09 19:02:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][280/332]  lr: 1.0000e-03  eta: 2:05:43  time: 0.3956  data_time: 0.0100  memory: 6616  grad_norm: 1.9052  loss: 1.0081  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6858  loss_aux: 0.3223\n",
            "02/09 19:02:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][300/332]  lr: 1.0000e-03  eta: 2:05:35  time: 0.3954  data_time: 0.0101  memory: 6616  grad_norm: 2.2064  loss: 1.0351  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6991  loss_aux: 0.3360\n",
            "02/09 19:02:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][320/332]  lr: 1.0000e-03  eta: 2:05:27  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 2.0557  loss: 1.0425  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6999  loss_aux: 0.3426\n",
            "02/09 19:02:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:02:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][332/332]  lr: 1.0000e-03  eta: 2:05:23  time: 0.3905  data_time: 0.0095  memory: 6616  grad_norm: 1.8938  loss: 0.9710  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6415  loss_aux: 0.3295\n",
            "02/09 19:02:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 93 epochs\n",
            "02/09 19:02:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][ 20/332]  lr: 1.0000e-03  eta: 2:05:15  time: 0.4445  data_time: 0.0559  memory: 6616  grad_norm: 2.1792  loss: 1.0278  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6863  loss_aux: 0.3415\n",
            "02/09 19:02:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][ 40/332]  lr: 1.0000e-03  eta: 2:05:07  time: 0.3962  data_time: 0.0105  memory: 6616  grad_norm: 2.1737  loss: 0.9958  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6629  loss_aux: 0.3329\n",
            "02/09 19:03:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][ 60/332]  lr: 1.0000e-03  eta: 2:04:59  time: 0.3962  data_time: 0.0107  memory: 6616  grad_norm: 2.0306  loss: 0.9862  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6492  loss_aux: 0.3370\n",
            "02/09 19:03:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][ 80/332]  lr: 1.0000e-03  eta: 2:04:51  time: 0.3954  data_time: 0.0100  memory: 6616  grad_norm: 1.8081  loss: 1.0103  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6818  loss_aux: 0.3286\n",
            "02/09 19:03:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][100/332]  lr: 1.0000e-03  eta: 2:04:43  time: 0.3962  data_time: 0.0108  memory: 6616  grad_norm: 1.8733  loss: 0.9592  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6334  loss_aux: 0.3258\n",
            "02/09 19:03:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][120/332]  lr: 1.0000e-03  eta: 2:04:35  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 1.7648  loss: 0.9688  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6362  loss_aux: 0.3326\n",
            "02/09 19:03:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:03:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][140/332]  lr: 1.0000e-03  eta: 2:04:27  time: 0.3952  data_time: 0.0102  memory: 6616  grad_norm: 2.2308  loss: 1.0498  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7117  loss_aux: 0.3381\n",
            "02/09 19:03:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][160/332]  lr: 1.0000e-03  eta: 2:04:19  time: 0.3957  data_time: 0.0107  memory: 6616  grad_norm: 2.0334  loss: 1.0446  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6976  loss_aux: 0.3471\n",
            "02/09 19:03:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][180/332]  lr: 1.0000e-03  eta: 2:04:11  time: 0.3964  data_time: 0.0108  memory: 6616  grad_norm: 2.0149  loss: 0.9655  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6438  loss_aux: 0.3217\n",
            "02/09 19:03:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][200/332]  lr: 1.0000e-03  eta: 2:04:03  time: 0.3948  data_time: 0.0098  memory: 6616  grad_norm: 1.9498  loss: 1.0130  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6729  loss_aux: 0.3401\n",
            "02/09 19:04:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][220/332]  lr: 1.0000e-03  eta: 2:03:56  time: 0.3953  data_time: 0.0100  memory: 6616  grad_norm: 2.0945  loss: 1.0608  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7192  loss_aux: 0.3416\n",
            "02/09 19:04:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][240/332]  lr: 1.0000e-03  eta: 2:03:48  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 1.8911  loss: 0.9637  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6365  loss_aux: 0.3273\n",
            "02/09 19:04:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][260/332]  lr: 1.0000e-03  eta: 2:03:40  time: 0.3948  data_time: 0.0098  memory: 6616  grad_norm: 1.6997  loss: 0.9515  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6266  loss_aux: 0.3249\n",
            "02/09 19:04:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][280/332]  lr: 1.0000e-03  eta: 2:03:32  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 1.9783  loss: 0.9602  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6302  loss_aux: 0.3300\n",
            "02/09 19:04:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][300/332]  lr: 1.0000e-03  eta: 2:03:24  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 2.1210  loss: 1.0482  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7081  loss_aux: 0.3401\n",
            "02/09 19:04:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][320/332]  lr: 1.0000e-03  eta: 2:03:16  time: 0.3949  data_time: 0.0100  memory: 6616  grad_norm: 2.1056  loss: 1.0082  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6792  loss_aux: 0.3291\n",
            "02/09 19:04:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:04:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][332/332]  lr: 1.0000e-03  eta: 2:03:11  time: 0.3903  data_time: 0.0096  memory: 6616  grad_norm: 2.1337  loss: 0.9745  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6395  loss_aux: 0.3350\n",
            "02/09 19:04:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 94 epochs\n",
            "02/09 19:05:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][ 20/332]  lr: 1.0000e-03  eta: 2:03:03  time: 0.4478  data_time: 0.0592  memory: 6616  grad_norm: 1.9923  loss: 1.0459  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7065  loss_aux: 0.3394\n",
            "02/09 19:05:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][ 40/332]  lr: 1.0000e-03  eta: 2:02:55  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 2.0337  loss: 0.9802  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6459  loss_aux: 0.3344\n",
            "02/09 19:05:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][ 60/332]  lr: 1.0000e-03  eta: 2:02:47  time: 0.3959  data_time: 0.0105  memory: 6616  grad_norm: 1.9377  loss: 1.0160  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6803  loss_aux: 0.3357\n",
            "02/09 19:05:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][ 80/332]  lr: 1.0000e-03  eta: 2:02:40  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 1.7895  loss: 0.9841  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6521  loss_aux: 0.3320\n",
            "02/09 19:05:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][100/332]  lr: 1.0000e-03  eta: 2:02:32  time: 0.3945  data_time: 0.0097  memory: 6616  grad_norm: 1.8579  loss: 0.9831  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6503  loss_aux: 0.3328\n",
            "02/09 19:05:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][120/332]  lr: 1.0000e-03  eta: 2:02:24  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 2.0621  loss: 0.9930  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6638  loss_aux: 0.3292\n",
            "02/09 19:05:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][140/332]  lr: 1.0000e-03  eta: 2:02:16  time: 0.3955  data_time: 0.0101  memory: 6616  grad_norm: 2.2000  loss: 0.9748  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6486  loss_aux: 0.3262\n",
            "02/09 19:05:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][160/332]  lr: 1.0000e-03  eta: 2:02:08  time: 0.3945  data_time: 0.0098  memory: 6616  grad_norm: 2.1588  loss: 1.0050  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6647  loss_aux: 0.3403\n",
            "02/09 19:06:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][180/332]  lr: 1.0000e-03  eta: 2:02:00  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 1.9673  loss: 1.0006  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6784  loss_aux: 0.3222\n",
            "02/09 19:06:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][200/332]  lr: 1.0000e-03  eta: 2:01:52  time: 0.3963  data_time: 0.0107  memory: 6616  grad_norm: 1.9911  loss: 0.9792  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6474  loss_aux: 0.3318\n",
            "02/09 19:06:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][220/332]  lr: 1.0000e-03  eta: 2:01:44  time: 0.3955  data_time: 0.0101  memory: 6616  grad_norm: 2.3783  loss: 1.0196  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6885  loss_aux: 0.3311\n",
            "02/09 19:06:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][240/332]  lr: 1.0000e-03  eta: 2:01:36  time: 0.3970  data_time: 0.0113  memory: 6616  grad_norm: 1.9758  loss: 0.9620  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6346  loss_aux: 0.3273\n",
            "02/09 19:06:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][260/332]  lr: 1.0000e-03  eta: 2:01:28  time: 0.3953  data_time: 0.0101  memory: 6616  grad_norm: 2.0536  loss: 0.9791  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6455  loss_aux: 0.3335\n",
            "02/09 19:06:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][280/332]  lr: 1.0000e-03  eta: 2:01:20  time: 0.3955  data_time: 0.0105  memory: 6616  grad_norm: 1.9868  loss: 0.9689  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6488  loss_aux: 0.3201\n",
            "02/09 19:06:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][300/332]  lr: 1.0000e-03  eta: 2:01:12  time: 0.3966  data_time: 0.0111  memory: 6616  grad_norm: 2.1271  loss: 1.0006  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6621  loss_aux: 0.3385\n",
            "02/09 19:06:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][320/332]  lr: 1.0000e-03  eta: 2:01:04  time: 0.3959  data_time: 0.0106  memory: 6616  grad_norm: 2.0520  loss: 0.9608  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6377  loss_aux: 0.3231\n",
            "02/09 19:07:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:07:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][332/332]  lr: 1.0000e-03  eta: 2:00:59  time: 0.3899  data_time: 0.0093  memory: 6616  grad_norm: 2.0979  loss: 0.9982  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6678  loss_aux: 0.3304\n",
            "02/09 19:07:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 95 epochs\n",
            "02/09 19:07:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][ 20/332]  lr: 1.0000e-03  eta: 2:00:51  time: 0.4354  data_time: 0.0482  memory: 6616  grad_norm: 2.2528  loss: 1.0243  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6946  loss_aux: 0.3297\n",
            "02/09 19:07:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][ 40/332]  lr: 1.0000e-03  eta: 2:00:43  time: 0.3956  data_time: 0.0107  memory: 6616  grad_norm: 2.0888  loss: 1.0504  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7027  loss_aux: 0.3477\n",
            "02/09 19:07:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][ 60/332]  lr: 1.0000e-03  eta: 2:00:36  time: 0.3948  data_time: 0.0101  memory: 6616  grad_norm: 1.9208  loss: 0.9357  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6185  loss_aux: 0.3173\n",
            "02/09 19:07:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][ 80/332]  lr: 1.0000e-03  eta: 2:00:28  time: 0.3960  data_time: 0.0105  memory: 6616  grad_norm: 2.1188  loss: 0.9274  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6131  loss_aux: 0.3143\n",
            "02/09 19:07:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][100/332]  lr: 1.0000e-03  eta: 2:00:20  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 2.5066  loss: 0.9241  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6142  loss_aux: 0.3099\n",
            "02/09 19:07:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][120/332]  lr: 1.0000e-03  eta: 2:00:12  time: 0.3946  data_time: 0.0100  memory: 6616  grad_norm: 2.1028  loss: 0.9609  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6386  loss_aux: 0.3223\n",
            "02/09 19:08:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][140/332]  lr: 1.0000e-03  eta: 2:00:04  time: 0.3966  data_time: 0.0110  memory: 6616  grad_norm: 2.2279  loss: 1.0066  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6659  loss_aux: 0.3407\n",
            "02/09 19:08:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][160/332]  lr: 1.0000e-03  eta: 1:59:56  time: 0.3954  data_time: 0.0105  memory: 6616  grad_norm: 2.0086  loss: 1.0056  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6782  loss_aux: 0.3274\n",
            "02/09 19:08:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][180/332]  lr: 1.0000e-03  eta: 1:59:48  time: 0.3968  data_time: 0.0112  memory: 6616  grad_norm: 2.2166  loss: 0.9729  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6531  loss_aux: 0.3198\n",
            "02/09 19:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][200/332]  lr: 1.0000e-03  eta: 1:59:40  time: 0.3960  data_time: 0.0111  memory: 6616  grad_norm: 2.0763  loss: 1.0393  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6982  loss_aux: 0.3411\n",
            "02/09 19:08:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][220/332]  lr: 1.0000e-03  eta: 1:59:32  time: 0.3945  data_time: 0.0098  memory: 6616  grad_norm: 2.0596  loss: 1.0089  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6775  loss_aux: 0.3313\n",
            "02/09 19:08:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][240/332]  lr: 1.0000e-03  eta: 1:59:24  time: 0.3967  data_time: 0.0112  memory: 6616  grad_norm: 1.9679  loss: 0.9526  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6380  loss_aux: 0.3147\n",
            "02/09 19:08:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][260/332]  lr: 1.0000e-03  eta: 1:59:16  time: 0.3959  data_time: 0.0107  memory: 6616  grad_norm: 2.1577  loss: 1.0529  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7008  loss_aux: 0.3521\n",
            "02/09 19:08:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][280/332]  lr: 1.0000e-03  eta: 1:59:08  time: 0.3946  data_time: 0.0096  memory: 6616  grad_norm: 2.1809  loss: 1.0099  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6802  loss_aux: 0.3298\n",
            "02/09 19:09:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][300/332]  lr: 1.0000e-03  eta: 1:59:00  time: 0.3947  data_time: 0.0099  memory: 6616  grad_norm: 2.1276  loss: 1.0226  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6776  loss_aux: 0.3450\n",
            "02/09 19:09:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][320/332]  lr: 1.0000e-03  eta: 1:58:52  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 1.7795  loss: 1.0121  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6708  loss_aux: 0.3414\n",
            "02/09 19:09:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:09:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][332/332]  lr: 1.0000e-03  eta: 1:58:47  time: 0.3900  data_time: 0.0095  memory: 6616  grad_norm: 1.8722  loss: 0.9900  top1_acc: 0.1667  top5_acc: 1.0000  loss_cls: 0.6542  loss_aux: 0.3358\n",
            "02/09 19:09:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 96 epochs\n",
            "02/09 19:09:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][ 20/332]  lr: 1.0000e-03  eta: 1:58:39  time: 0.4334  data_time: 0.0424  memory: 6616  grad_norm: 1.9242  loss: 1.0272  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6800  loss_aux: 0.3472\n",
            "02/09 19:09:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][ 40/332]  lr: 1.0000e-03  eta: 1:58:31  time: 0.3959  data_time: 0.0108  memory: 6616  grad_norm: 2.0596  loss: 1.0208  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6837  loss_aux: 0.3371\n",
            "02/09 19:09:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][ 60/332]  lr: 1.0000e-03  eta: 1:58:23  time: 0.3952  data_time: 0.0102  memory: 6616  grad_norm: 1.9657  loss: 0.9797  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6496  loss_aux: 0.3301\n",
            "02/09 19:09:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][ 80/332]  lr: 1.0000e-03  eta: 1:58:16  time: 0.3965  data_time: 0.0112  memory: 6616  grad_norm: 1.9623  loss: 0.9490  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6399  loss_aux: 0.3091\n",
            "02/09 19:10:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][100/332]  lr: 1.0000e-03  eta: 1:58:08  time: 0.3949  data_time: 0.0100  memory: 6616  grad_norm: 2.0445  loss: 1.0075  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6823  loss_aux: 0.3252\n",
            "02/09 19:10:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][120/332]  lr: 1.0000e-03  eta: 1:58:00  time: 0.3946  data_time: 0.0101  memory: 6616  grad_norm: 1.9900  loss: 1.0181  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6696  loss_aux: 0.3485\n",
            "02/09 19:10:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:10:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][140/332]  lr: 1.0000e-03  eta: 1:57:52  time: 0.3956  data_time: 0.0101  memory: 6616  grad_norm: 1.9259  loss: 1.0067  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6680  loss_aux: 0.3387\n",
            "02/09 19:10:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][160/332]  lr: 1.0000e-03  eta: 1:57:44  time: 0.3955  data_time: 0.0101  memory: 6616  grad_norm: 1.9452  loss: 1.0286  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6828  loss_aux: 0.3459\n",
            "02/09 19:10:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][180/332]  lr: 1.0000e-03  eta: 1:57:36  time: 0.3975  data_time: 0.0116  memory: 6616  grad_norm: 1.7992  loss: 0.9547  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6306  loss_aux: 0.3242\n",
            "02/09 19:10:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][200/332]  lr: 1.0000e-03  eta: 1:57:28  time: 0.3962  data_time: 0.0109  memory: 6616  grad_norm: 1.9846  loss: 1.0151  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6767  loss_aux: 0.3383\n",
            "02/09 19:10:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][220/332]  lr: 1.0000e-03  eta: 1:57:20  time: 0.3955  data_time: 0.0100  memory: 6616  grad_norm: 1.9910  loss: 0.9453  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6235  loss_aux: 0.3218\n",
            "02/09 19:10:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][240/332]  lr: 1.0000e-03  eta: 1:57:12  time: 0.3964  data_time: 0.0110  memory: 6616  grad_norm: 2.3031  loss: 1.0149  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6728  loss_aux: 0.3421\n",
            "02/09 19:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][260/332]  lr: 1.0000e-03  eta: 1:57:04  time: 0.3967  data_time: 0.0110  memory: 6616  grad_norm: 2.0193  loss: 1.0628  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7131  loss_aux: 0.3497\n",
            "02/09 19:11:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][280/332]  lr: 1.0000e-03  eta: 1:56:56  time: 0.3956  data_time: 0.0107  memory: 6616  grad_norm: 1.8381  loss: 0.9928  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6666  loss_aux: 0.3262\n",
            "02/09 19:11:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][300/332]  lr: 1.0000e-03  eta: 1:56:48  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 1.8693  loss: 0.9566  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6258  loss_aux: 0.3307\n",
            "02/09 19:11:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][320/332]  lr: 1.0000e-03  eta: 1:56:40  time: 0.3953  data_time: 0.0101  memory: 6616  grad_norm: 2.0020  loss: 1.0262  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6971  loss_aux: 0.3291\n",
            "02/09 19:11:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:11:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][332/332]  lr: 1.0000e-03  eta: 1:56:35  time: 0.3898  data_time: 0.0096  memory: 6616  grad_norm: 1.9625  loss: 1.0345  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6988  loss_aux: 0.3357\n",
            "02/09 19:11:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 97 epochs\n",
            "02/09 19:11:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][ 20/332]  lr: 1.0000e-03  eta: 1:56:28  time: 0.4384  data_time: 0.0499  memory: 6616  grad_norm: 2.0269  loss: 1.0236  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6853  loss_aux: 0.3383\n",
            "02/09 19:11:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][ 40/332]  lr: 1.0000e-03  eta: 1:56:20  time: 0.3955  data_time: 0.0105  memory: 6616  grad_norm: 2.0055  loss: 1.0162  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6771  loss_aux: 0.3391\n",
            "02/09 19:12:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][ 60/332]  lr: 1.0000e-03  eta: 1:56:12  time: 0.3945  data_time: 0.0101  memory: 6616  grad_norm: 1.8697  loss: 1.0040  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6697  loss_aux: 0.3343\n",
            "02/09 19:12:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][ 80/332]  lr: 1.0000e-03  eta: 1:56:04  time: 0.3960  data_time: 0.0109  memory: 6616  grad_norm: 2.1569  loss: 1.0460  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7055  loss_aux: 0.3405\n",
            "02/09 19:12:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][100/332]  lr: 1.0000e-03  eta: 1:55:56  time: 0.3961  data_time: 0.0104  memory: 6616  grad_norm: 2.0523  loss: 1.0354  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6929  loss_aux: 0.3425\n",
            "02/09 19:12:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][120/332]  lr: 1.0000e-03  eta: 1:55:48  time: 0.3947  data_time: 0.0098  memory: 6616  grad_norm: 1.9661  loss: 1.0247  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6822  loss_aux: 0.3425\n",
            "02/09 19:12:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][140/332]  lr: 1.0000e-03  eta: 1:55:40  time: 0.3961  data_time: 0.0108  memory: 6616  grad_norm: 1.8045  loss: 0.9872  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6544  loss_aux: 0.3328\n",
            "02/09 19:12:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][160/332]  lr: 1.0000e-03  eta: 1:55:32  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 2.0493  loss: 1.0114  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6796  loss_aux: 0.3319\n",
            "02/09 19:12:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][180/332]  lr: 1.0000e-03  eta: 1:55:24  time: 0.3953  data_time: 0.0101  memory: 6616  grad_norm: 1.8541  loss: 0.9380  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6207  loss_aux: 0.3173\n",
            "02/09 19:12:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][200/332]  lr: 1.0000e-03  eta: 1:55:16  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 1.8605  loss: 0.9172  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6019  loss_aux: 0.3153\n",
            "02/09 19:13:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][220/332]  lr: 1.0000e-03  eta: 1:55:08  time: 0.3961  data_time: 0.0108  memory: 6616  grad_norm: 2.0906  loss: 1.0345  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6958  loss_aux: 0.3387\n",
            "02/09 19:13:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][240/332]  lr: 1.0000e-03  eta: 1:55:00  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 2.1802  loss: 1.0604  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7121  loss_aux: 0.3483\n",
            "02/09 19:13:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][260/332]  lr: 1.0000e-03  eta: 1:54:52  time: 0.3964  data_time: 0.0109  memory: 6616  grad_norm: 1.9907  loss: 1.0164  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6743  loss_aux: 0.3421\n",
            "02/09 19:13:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][280/332]  lr: 1.0000e-03  eta: 1:54:44  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 2.1708  loss: 1.0050  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6664  loss_aux: 0.3385\n",
            "02/09 19:13:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][300/332]  lr: 1.0000e-03  eta: 1:54:36  time: 0.3958  data_time: 0.0107  memory: 6616  grad_norm: 1.9405  loss: 1.0177  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6902  loss_aux: 0.3275\n",
            "02/09 19:13:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][320/332]  lr: 1.0000e-03  eta: 1:54:28  time: 0.3959  data_time: 0.0104  memory: 6616  grad_norm: 1.7665  loss: 0.9375  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6164  loss_aux: 0.3211\n",
            "02/09 19:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][332/332]  lr: 1.0000e-03  eta: 1:54:23  time: 0.3904  data_time: 0.0097  memory: 6616  grad_norm: 1.7623  loss: 1.0178  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6858  loss_aux: 0.3320\n",
            "02/09 19:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 98 epochs\n",
            "02/09 19:13:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][ 20/332]  lr: 1.0000e-03  eta: 1:54:16  time: 0.4483  data_time: 0.0607  memory: 6616  grad_norm: 1.9331  loss: 0.9816  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6494  loss_aux: 0.3322\n",
            "02/09 19:14:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][ 40/332]  lr: 1.0000e-03  eta: 1:54:08  time: 0.3961  data_time: 0.0107  memory: 6616  grad_norm: 1.7878  loss: 0.9533  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6270  loss_aux: 0.3263\n",
            "02/09 19:14:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][ 60/332]  lr: 1.0000e-03  eta: 1:54:00  time: 0.3958  data_time: 0.0104  memory: 6616  grad_norm: 2.0740  loss: 1.0177  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6846  loss_aux: 0.3331\n",
            "02/09 19:14:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][ 80/332]  lr: 1.0000e-03  eta: 1:53:52  time: 0.3963  data_time: 0.0108  memory: 6616  grad_norm: 2.0714  loss: 1.0140  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6836  loss_aux: 0.3304\n",
            "02/09 19:14:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][100/332]  lr: 1.0000e-03  eta: 1:53:44  time: 0.3951  data_time: 0.0100  memory: 6616  grad_norm: 1.9381  loss: 0.9967  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6675  loss_aux: 0.3292\n",
            "02/09 19:14:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][120/332]  lr: 1.0000e-03  eta: 1:53:36  time: 0.3954  data_time: 0.0100  memory: 6616  grad_norm: 1.8964  loss: 1.0297  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6809  loss_aux: 0.3487\n",
            "02/09 19:14:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][140/332]  lr: 1.0000e-03  eta: 1:53:28  time: 0.3963  data_time: 0.0107  memory: 6616  grad_norm: 1.9912  loss: 1.0566  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7094  loss_aux: 0.3472\n",
            "02/09 19:14:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][160/332]  lr: 1.0000e-03  eta: 1:53:20  time: 0.3959  data_time: 0.0106  memory: 6616  grad_norm: 1.6854  loss: 0.9397  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6244  loss_aux: 0.3153\n",
            "02/09 19:15:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][180/332]  lr: 1.0000e-03  eta: 1:53:12  time: 0.3948  data_time: 0.0101  memory: 6616  grad_norm: 1.8946  loss: 0.9792  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6490  loss_aux: 0.3301\n",
            "02/09 19:15:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][200/332]  lr: 1.0000e-03  eta: 1:53:04  time: 0.3963  data_time: 0.0106  memory: 6616  grad_norm: 1.8766  loss: 0.9536  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6363  loss_aux: 0.3173\n",
            "02/09 19:15:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][220/332]  lr: 1.0000e-03  eta: 1:52:56  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 1.8831  loss: 1.0472  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7031  loss_aux: 0.3441\n",
            "02/09 19:15:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][240/332]  lr: 1.0000e-03  eta: 1:52:48  time: 0.3957  data_time: 0.0104  memory: 6616  grad_norm: 1.8973  loss: 0.9518  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6342  loss_aux: 0.3176\n",
            "02/09 19:15:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][260/332]  lr: 1.0000e-03  eta: 1:52:40  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 1.9818  loss: 0.9915  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6553  loss_aux: 0.3362\n",
            "02/09 19:15:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][280/332]  lr: 1.0000e-03  eta: 1:52:32  time: 0.3955  data_time: 0.0103  memory: 6616  grad_norm: 2.0556  loss: 0.9305  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6200  loss_aux: 0.3104\n",
            "02/09 19:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][300/332]  lr: 1.0000e-03  eta: 1:52:24  time: 0.3953  data_time: 0.0100  memory: 6616  grad_norm: 2.1974  loss: 1.0274  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6798  loss_aux: 0.3475\n",
            "02/09 19:15:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][320/332]  lr: 1.0000e-03  eta: 1:52:16  time: 0.3968  data_time: 0.0107  memory: 6616  grad_norm: 2.0367  loss: 0.9898  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6572  loss_aux: 0.3326\n",
            "02/09 19:16:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:16:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][332/332]  lr: 1.0000e-03  eta: 1:52:11  time: 0.3901  data_time: 0.0094  memory: 6616  grad_norm: 2.0236  loss: 1.0033  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6675  loss_aux: 0.3358\n",
            "02/09 19:16:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 99 epochs\n",
            "02/09 19:16:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][ 20/332]  lr: 1.0000e-03  eta: 1:52:04  time: 0.4482  data_time: 0.0595  memory: 6616  grad_norm: 1.9167  loss: 0.9238  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6087  loss_aux: 0.3151\n",
            "02/09 19:16:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][ 40/332]  lr: 1.0000e-03  eta: 1:51:56  time: 0.3954  data_time: 0.0100  memory: 6616  grad_norm: 2.3695  loss: 1.0021  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6609  loss_aux: 0.3413\n",
            "02/09 19:16:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][ 60/332]  lr: 1.0000e-03  eta: 1:51:48  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 2.0130  loss: 0.9806  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6577  loss_aux: 0.3230\n",
            "02/09 19:16:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][ 80/332]  lr: 1.0000e-03  eta: 1:51:40  time: 0.3959  data_time: 0.0103  memory: 6616  grad_norm: 2.3906  loss: 0.9956  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6562  loss_aux: 0.3394\n",
            "02/09 19:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][100/332]  lr: 1.0000e-03  eta: 1:51:32  time: 0.3949  data_time: 0.0098  memory: 6616  grad_norm: 2.2883  loss: 1.0209  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6899  loss_aux: 0.3310\n",
            "02/09 19:16:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][120/332]  lr: 1.0000e-03  eta: 1:51:24  time: 0.3954  data_time: 0.0100  memory: 6616  grad_norm: 2.3581  loss: 1.0182  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6893  loss_aux: 0.3288\n",
            "02/09 19:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:17:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][140/332]  lr: 1.0000e-03  eta: 1:51:16  time: 0.3957  data_time: 0.0101  memory: 6616  grad_norm: 2.2596  loss: 1.0056  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6657  loss_aux: 0.3399\n",
            "02/09 19:17:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][160/332]  lr: 1.0000e-03  eta: 1:51:08  time: 0.3963  data_time: 0.0112  memory: 6616  grad_norm: 2.0869  loss: 0.9598  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6377  loss_aux: 0.3220\n",
            "02/09 19:17:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][180/332]  lr: 1.0000e-03  eta: 1:51:00  time: 0.3963  data_time: 0.0109  memory: 6616  grad_norm: 2.1487  loss: 0.9983  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6683  loss_aux: 0.3300\n",
            "02/09 19:17:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][200/332]  lr: 1.0000e-03  eta: 1:50:52  time: 0.3960  data_time: 0.0106  memory: 6616  grad_norm: 2.0566  loss: 0.9787  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6497  loss_aux: 0.3290\n",
            "02/09 19:17:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][220/332]  lr: 1.0000e-03  eta: 1:50:44  time: 0.3956  data_time: 0.0106  memory: 6616  grad_norm: 1.8938  loss: 0.9271  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6090  loss_aux: 0.3181\n",
            "02/09 19:17:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][240/332]  lr: 1.0000e-03  eta: 1:50:36  time: 0.3950  data_time: 0.0099  memory: 6616  grad_norm: 2.2409  loss: 0.9755  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6568  loss_aux: 0.3187\n",
            "02/09 19:17:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][260/332]  lr: 1.0000e-03  eta: 1:50:28  time: 0.3964  data_time: 0.0109  memory: 6616  grad_norm: 2.6129  loss: 1.0317  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6839  loss_aux: 0.3479\n",
            "02/09 19:17:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][280/332]  lr: 1.0000e-03  eta: 1:50:20  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 2.0744  loss: 0.9473  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6361  loss_aux: 0.3113\n",
            "02/09 19:18:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][300/332]  lr: 1.0000e-03  eta: 1:50:12  time: 0.3956  data_time: 0.0105  memory: 6616  grad_norm: 2.2964  loss: 0.9808  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6538  loss_aux: 0.3269\n",
            "02/09 19:18:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][320/332]  lr: 1.0000e-03  eta: 1:50:04  time: 0.3961  data_time: 0.0107  memory: 6616  grad_norm: 2.2307  loss: 1.0248  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6916  loss_aux: 0.3332\n",
            "02/09 19:18:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:18:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][332/332]  lr: 1.0000e-03  eta: 1:49:59  time: 0.3896  data_time: 0.0092  memory: 6616  grad_norm: 2.0822  loss: 1.0204  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6878  loss_aux: 0.3327\n",
            "02/09 19:18:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 100 epochs\n",
            "02/09 19:18:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [100][20/42]    eta: 0:00:04  time: 0.1864  data_time: 0.0779  memory: 1447  \n",
            "02/09 19:18:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [100][40/42]    eta: 0:00:00  time: 0.1144  data_time: 0.0134  memory: 1447  \n",
            "02/09 19:18:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [100][42/42]    acc/top1: 0.6114  acc/top5: 1.0000  acc/mean1: 0.5951  data_time: 0.0428  time: 0.1448\n",
            "02/09 19:18:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][ 20/332]  lr: 1.0000e-03  eta: 1:49:52  time: 0.4346  data_time: 0.0475  memory: 6616  grad_norm: 1.9951  loss: 0.9216  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6115  loss_aux: 0.3101\n",
            "02/09 19:18:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][ 40/332]  lr: 1.0000e-03  eta: 1:49:44  time: 0.3949  data_time: 0.0100  memory: 6616  grad_norm: 2.4288  loss: 1.0878  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7386  loss_aux: 0.3492\n",
            "02/09 19:18:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][ 60/332]  lr: 1.0000e-03  eta: 1:49:36  time: 0.3955  data_time: 0.0101  memory: 6616  grad_norm: 1.8952  loss: 0.9776  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6514  loss_aux: 0.3261\n",
            "02/09 19:18:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][ 80/332]  lr: 1.0000e-03  eta: 1:49:28  time: 0.3960  data_time: 0.0106  memory: 6616  grad_norm: 2.0767  loss: 0.9848  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6498  loss_aux: 0.3350\n",
            "02/09 19:19:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][100/332]  lr: 1.0000e-03  eta: 1:49:20  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 2.5386  loss: 1.0284  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6779  loss_aux: 0.3505\n",
            "02/09 19:19:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][120/332]  lr: 1.0000e-03  eta: 1:49:12  time: 0.3951  data_time: 0.0105  memory: 6616  grad_norm: 2.0318  loss: 0.9901  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6595  loss_aux: 0.3306\n",
            "02/09 19:19:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][140/332]  lr: 1.0000e-03  eta: 1:49:04  time: 0.3952  data_time: 0.0103  memory: 6616  grad_norm: 1.9990  loss: 0.9860  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6586  loss_aux: 0.3274\n",
            "02/09 19:19:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][160/332]  lr: 1.0000e-03  eta: 1:48:56  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 2.0188  loss: 0.9694  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6486  loss_aux: 0.3209\n",
            "02/09 19:19:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][180/332]  lr: 1.0000e-03  eta: 1:48:48  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 2.0766  loss: 0.9417  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6209  loss_aux: 0.3208\n",
            "02/09 19:19:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][200/332]  lr: 1.0000e-03  eta: 1:48:40  time: 0.3949  data_time: 0.0102  memory: 6616  grad_norm: 1.9167  loss: 0.9492  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6328  loss_aux: 0.3164\n",
            "02/09 19:19:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][220/332]  lr: 1.0000e-03  eta: 1:48:32  time: 0.3945  data_time: 0.0098  memory: 6616  grad_norm: 2.1475  loss: 0.9957  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6525  loss_aux: 0.3432\n",
            "02/09 19:20:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][240/332]  lr: 1.0000e-03  eta: 1:48:24  time: 0.3953  data_time: 0.0104  memory: 6616  grad_norm: 2.2446  loss: 1.0069  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6713  loss_aux: 0.3356\n",
            "02/09 19:20:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][260/332]  lr: 1.0000e-03  eta: 1:48:16  time: 0.3947  data_time: 0.0101  memory: 6616  grad_norm: 2.1388  loss: 1.0144  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6701  loss_aux: 0.3443\n",
            "02/09 19:20:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][280/332]  lr: 1.0000e-03  eta: 1:48:08  time: 0.3946  data_time: 0.0102  memory: 6616  grad_norm: 2.1704  loss: 1.0468  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6932  loss_aux: 0.3536\n",
            "02/09 19:20:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][300/332]  lr: 1.0000e-03  eta: 1:48:00  time: 0.3951  data_time: 0.0102  memory: 6616  grad_norm: 2.0737  loss: 1.0124  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6803  loss_aux: 0.3320\n",
            "02/09 19:20:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][320/332]  lr: 1.0000e-03  eta: 1:47:52  time: 0.3935  data_time: 0.0094  memory: 6616  grad_norm: 1.8892  loss: 1.0123  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6764  loss_aux: 0.3359\n",
            "02/09 19:20:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:20:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][332/332]  lr: 1.0000e-03  eta: 1:47:47  time: 0.3891  data_time: 0.0093  memory: 6616  grad_norm: 1.8849  loss: 0.9847  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6689  loss_aux: 0.3158\n",
            "02/09 19:20:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 101 epochs\n",
            "02/09 19:20:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][ 20/332]  lr: 1.0000e-03  eta: 1:47:40  time: 0.4501  data_time: 0.0624  memory: 6616  grad_norm: 1.9863  loss: 0.9524  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6339  loss_aux: 0.3185\n",
            "02/09 19:20:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][ 40/332]  lr: 1.0000e-03  eta: 1:47:32  time: 0.3945  data_time: 0.0094  memory: 6616  grad_norm: 2.0764  loss: 1.0072  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6699  loss_aux: 0.3373\n",
            "02/09 19:21:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][ 60/332]  lr: 1.0000e-03  eta: 1:47:24  time: 0.3953  data_time: 0.0107  memory: 6616  grad_norm: 1.7439  loss: 0.9151  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6044  loss_aux: 0.3108\n",
            "02/09 19:21:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][ 80/332]  lr: 1.0000e-03  eta: 1:47:16  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 1.9487  loss: 1.0004  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6653  loss_aux: 0.3351\n",
            "02/09 19:21:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][100/332]  lr: 1.0000e-03  eta: 1:47:08  time: 0.3950  data_time: 0.0101  memory: 6616  grad_norm: 2.0452  loss: 1.0300  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6972  loss_aux: 0.3328\n",
            "02/09 19:21:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][120/332]  lr: 1.0000e-03  eta: 1:47:00  time: 0.3955  data_time: 0.0100  memory: 6616  grad_norm: 1.9992  loss: 0.9802  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6478  loss_aux: 0.3324\n",
            "02/09 19:21:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][140/332]  lr: 1.0000e-03  eta: 1:46:52  time: 0.3950  data_time: 0.0099  memory: 6616  grad_norm: 2.0178  loss: 1.0536  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7043  loss_aux: 0.3493\n",
            "02/09 19:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][160/332]  lr: 1.0000e-03  eta: 1:46:44  time: 0.3945  data_time: 0.0099  memory: 6616  grad_norm: 1.9763  loss: 0.9443  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6254  loss_aux: 0.3189\n",
            "02/09 19:21:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][180/332]  lr: 1.0000e-03  eta: 1:46:36  time: 0.3956  data_time: 0.0101  memory: 6616  grad_norm: 1.9316  loss: 0.9660  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6422  loss_aux: 0.3237\n",
            "02/09 19:22:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][200/332]  lr: 1.0000e-03  eta: 1:46:28  time: 0.3952  data_time: 0.0102  memory: 6616  grad_norm: 2.1109  loss: 0.9711  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6490  loss_aux: 0.3221\n",
            "02/09 19:22:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][220/332]  lr: 1.0000e-03  eta: 1:46:20  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 1.9908  loss: 1.0479  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7032  loss_aux: 0.3447\n",
            "02/09 19:22:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][240/332]  lr: 1.0000e-03  eta: 1:46:12  time: 0.3961  data_time: 0.0107  memory: 6616  grad_norm: 2.0688  loss: 0.9413  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6334  loss_aux: 0.3079\n",
            "02/09 19:22:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][260/332]  lr: 1.0000e-03  eta: 1:46:04  time: 0.3959  data_time: 0.0103  memory: 6616  grad_norm: 2.4481  loss: 1.0205  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6797  loss_aux: 0.3408\n",
            "02/09 19:22:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][280/332]  lr: 1.0000e-03  eta: 1:45:56  time: 0.3955  data_time: 0.0101  memory: 6616  grad_norm: 1.9031  loss: 1.0139  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6861  loss_aux: 0.3278\n",
            "02/09 19:22:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][300/332]  lr: 1.0000e-03  eta: 1:45:48  time: 0.3964  data_time: 0.0104  memory: 6616  grad_norm: 1.8788  loss: 0.9726  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6422  loss_aux: 0.3304\n",
            "02/09 19:22:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][320/332]  lr: 1.0000e-03  eta: 1:45:40  time: 0.3961  data_time: 0.0104  memory: 6616  grad_norm: 1.8836  loss: 1.0180  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6742  loss_aux: 0.3437\n",
            "02/09 19:22:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:22:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][332/332]  lr: 1.0000e-03  eta: 1:45:35  time: 0.3916  data_time: 0.0104  memory: 6616  grad_norm: 1.9062  loss: 0.9802  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6525  loss_aux: 0.3278\n",
            "02/09 19:22:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 102 epochs\n",
            "02/09 19:23:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][ 20/332]  lr: 1.0000e-03  eta: 1:45:28  time: 0.4443  data_time: 0.0562  memory: 6616  grad_norm: 2.1477  loss: 0.9682  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6461  loss_aux: 0.3221\n",
            "02/09 19:23:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][ 40/332]  lr: 1.0000e-03  eta: 1:45:20  time: 0.3969  data_time: 0.0107  memory: 6616  grad_norm: 2.1904  loss: 0.9625  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6437  loss_aux: 0.3188\n",
            "02/09 19:23:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][ 60/332]  lr: 1.0000e-03  eta: 1:45:12  time: 0.3963  data_time: 0.0106  memory: 6616  grad_norm: 2.0877  loss: 0.9776  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6503  loss_aux: 0.3274\n",
            "02/09 19:23:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][ 80/332]  lr: 1.0000e-03  eta: 1:45:04  time: 0.3970  data_time: 0.0111  memory: 6616  grad_norm: 2.0215  loss: 1.0344  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6880  loss_aux: 0.3464\n",
            "02/09 19:23:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][100/332]  lr: 1.0000e-03  eta: 1:44:56  time: 0.3962  data_time: 0.0107  memory: 6616  grad_norm: 1.9693  loss: 0.9770  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6438  loss_aux: 0.3331\n",
            "02/09 19:23:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][120/332]  lr: 1.0000e-03  eta: 1:44:48  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 2.0080  loss: 1.0155  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6779  loss_aux: 0.3376\n",
            "02/09 19:23:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:23:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][140/332]  lr: 1.0000e-03  eta: 1:44:40  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 1.8787  loss: 0.9644  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6375  loss_aux: 0.3269\n",
            "02/09 19:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][160/332]  lr: 1.0000e-03  eta: 1:44:32  time: 0.3951  data_time: 0.0098  memory: 6616  grad_norm: 1.8310  loss: 0.9782  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6465  loss_aux: 0.3317\n",
            "02/09 19:24:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][180/332]  lr: 1.0000e-03  eta: 1:44:24  time: 0.3950  data_time: 0.0097  memory: 6616  grad_norm: 1.7956  loss: 0.9448  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6277  loss_aux: 0.3171\n",
            "02/09 19:24:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][200/332]  lr: 1.0000e-03  eta: 1:44:16  time: 0.3960  data_time: 0.0102  memory: 6616  grad_norm: 2.1022  loss: 0.9964  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6625  loss_aux: 0.3339\n",
            "02/09 19:24:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][220/332]  lr: 1.0000e-03  eta: 1:44:08  time: 0.3968  data_time: 0.0107  memory: 6616  grad_norm: 2.5330  loss: 1.0160  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6675  loss_aux: 0.3486\n",
            "02/09 19:24:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][240/332]  lr: 1.0000e-03  eta: 1:44:00  time: 0.3963  data_time: 0.0105  memory: 6616  grad_norm: 2.0660  loss: 0.9759  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6512  loss_aux: 0.3247\n",
            "02/09 19:24:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][260/332]  lr: 1.0000e-03  eta: 1:43:52  time: 0.3967  data_time: 0.0110  memory: 6616  grad_norm: 1.8848  loss: 0.9848  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6499  loss_aux: 0.3349\n",
            "02/09 19:24:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][280/332]  lr: 1.0000e-03  eta: 1:43:44  time: 0.3959  data_time: 0.0107  memory: 6616  grad_norm: 1.9375  loss: 1.0228  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6870  loss_aux: 0.3358\n",
            "02/09 19:24:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][300/332]  lr: 1.0000e-03  eta: 1:43:36  time: 0.3977  data_time: 0.0110  memory: 6616  grad_norm: 1.9810  loss: 0.9819  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6594  loss_aux: 0.3225\n",
            "02/09 19:25:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][320/332]  lr: 1.0000e-03  eta: 1:43:28  time: 0.3977  data_time: 0.0113  memory: 6616  grad_norm: 1.9398  loss: 1.0098  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6719  loss_aux: 0.3380\n",
            "02/09 19:25:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:25:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][332/332]  lr: 1.0000e-03  eta: 1:43:24  time: 0.3905  data_time: 0.0097  memory: 6616  grad_norm: 2.0708  loss: 1.0059  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6663  loss_aux: 0.3397\n",
            "02/09 19:25:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 103 epochs\n",
            "02/09 19:25:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][ 20/332]  lr: 1.0000e-03  eta: 1:43:16  time: 0.4472  data_time: 0.0579  memory: 6616  grad_norm: 1.8879  loss: 0.9601  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6268  loss_aux: 0.3333\n",
            "02/09 19:25:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][ 40/332]  lr: 1.0000e-03  eta: 1:43:08  time: 0.3969  data_time: 0.0112  memory: 6616  grad_norm: 2.1947  loss: 1.0135  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6811  loss_aux: 0.3324\n",
            "02/09 19:25:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][ 60/332]  lr: 1.0000e-03  eta: 1:43:00  time: 0.3964  data_time: 0.0106  memory: 6616  grad_norm: 2.0821  loss: 0.9745  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6430  loss_aux: 0.3315\n",
            "02/09 19:25:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][ 80/332]  lr: 1.0000e-03  eta: 1:42:52  time: 0.3964  data_time: 0.0106  memory: 6616  grad_norm: 2.1462  loss: 0.9951  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6598  loss_aux: 0.3353\n",
            "02/09 19:25:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][100/332]  lr: 1.0000e-03  eta: 1:42:44  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 2.3139  loss: 0.9668  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6453  loss_aux: 0.3214\n",
            "02/09 19:25:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][120/332]  lr: 1.0000e-03  eta: 1:42:36  time: 0.3967  data_time: 0.0109  memory: 6616  grad_norm: 2.1565  loss: 1.0291  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6946  loss_aux: 0.3344\n",
            "02/09 19:26:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][140/332]  lr: 1.0000e-03  eta: 1:42:28  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 2.0078  loss: 0.9515  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6333  loss_aux: 0.3182\n",
            "02/09 19:26:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][160/332]  lr: 1.0000e-03  eta: 1:42:20  time: 0.3959  data_time: 0.0109  memory: 6616  grad_norm: 2.2826  loss: 1.0401  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6975  loss_aux: 0.3427\n",
            "02/09 19:26:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][180/332]  lr: 1.0000e-03  eta: 1:42:12  time: 0.3957  data_time: 0.0104  memory: 6616  grad_norm: 1.8832  loss: 0.9731  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6581  loss_aux: 0.3150\n",
            "02/09 19:26:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][200/332]  lr: 1.0000e-03  eta: 1:42:04  time: 0.3969  data_time: 0.0111  memory: 6616  grad_norm: 2.1426  loss: 1.0665  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7224  loss_aux: 0.3441\n",
            "02/09 19:26:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][220/332]  lr: 1.0000e-03  eta: 1:41:57  time: 0.3970  data_time: 0.0109  memory: 6616  grad_norm: 1.9819  loss: 0.9486  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6311  loss_aux: 0.3176\n",
            "02/09 19:26:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][240/332]  lr: 1.0000e-03  eta: 1:41:49  time: 0.3967  data_time: 0.0111  memory: 6616  grad_norm: 1.9245  loss: 1.0049  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6683  loss_aux: 0.3366\n",
            "02/09 19:26:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][260/332]  lr: 1.0000e-03  eta: 1:41:41  time: 0.3959  data_time: 0.0106  memory: 6616  grad_norm: 2.0265  loss: 0.9933  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6690  loss_aux: 0.3243\n",
            "02/09 19:27:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][280/332]  lr: 1.0000e-03  eta: 1:41:33  time: 0.3958  data_time: 0.0102  memory: 6616  grad_norm: 1.9244  loss: 0.9801  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6491  loss_aux: 0.3310\n",
            "02/09 19:27:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][300/332]  lr: 1.0000e-03  eta: 1:41:25  time: 0.3957  data_time: 0.0101  memory: 6616  grad_norm: 1.9735  loss: 0.9508  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6202  loss_aux: 0.3306\n",
            "02/09 19:27:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][320/332]  lr: 1.0000e-03  eta: 1:41:17  time: 0.3964  data_time: 0.0105  memory: 6616  grad_norm: 2.2024  loss: 1.0272  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6763  loss_aux: 0.3509\n",
            "02/09 19:27:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:27:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][332/332]  lr: 1.0000e-03  eta: 1:41:12  time: 0.3902  data_time: 0.0094  memory: 6616  grad_norm: 2.3419  loss: 1.0045  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6627  loss_aux: 0.3418\n",
            "02/09 19:27:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 104 epochs\n",
            "02/09 19:27:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][ 20/332]  lr: 1.0000e-03  eta: 1:41:04  time: 0.4362  data_time: 0.0465  memory: 6616  grad_norm: 2.0431  loss: 1.0019  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6642  loss_aux: 0.3377\n",
            "02/09 19:27:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][ 40/332]  lr: 1.0000e-03  eta: 1:40:56  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 2.1668  loss: 1.0459  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7115  loss_aux: 0.3344\n",
            "02/09 19:27:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][ 60/332]  lr: 1.0000e-03  eta: 1:40:48  time: 0.3958  data_time: 0.0103  memory: 6616  grad_norm: 1.9109  loss: 0.9974  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6590  loss_aux: 0.3385\n",
            "02/09 19:27:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][ 80/332]  lr: 1.0000e-03  eta: 1:40:40  time: 0.3970  data_time: 0.0110  memory: 6616  grad_norm: 2.0209  loss: 0.9965  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6608  loss_aux: 0.3357\n",
            "02/09 19:28:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][100/332]  lr: 1.0000e-03  eta: 1:40:32  time: 0.3972  data_time: 0.0111  memory: 6616  grad_norm: 1.9995  loss: 0.9904  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6621  loss_aux: 0.3283\n",
            "02/09 19:28:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][120/332]  lr: 1.0000e-03  eta: 1:40:24  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 2.1098  loss: 0.9935  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6655  loss_aux: 0.3280\n",
            "02/09 19:28:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][140/332]  lr: 1.0000e-03  eta: 1:40:16  time: 0.3960  data_time: 0.0106  memory: 6616  grad_norm: 2.0914  loss: 0.9809  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6510  loss_aux: 0.3299\n",
            "02/09 19:28:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][160/332]  lr: 1.0000e-03  eta: 1:40:09  time: 0.3968  data_time: 0.0109  memory: 6616  grad_norm: 1.9280  loss: 0.9600  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6386  loss_aux: 0.3213\n",
            "02/09 19:28:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][180/332]  lr: 1.0000e-03  eta: 1:40:01  time: 0.3963  data_time: 0.0106  memory: 6616  grad_norm: 2.1918  loss: 1.0406  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6960  loss_aux: 0.3446\n",
            "02/09 19:28:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][200/332]  lr: 1.0000e-03  eta: 1:39:53  time: 0.3967  data_time: 0.0109  memory: 6616  grad_norm: 1.9173  loss: 0.9568  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6391  loss_aux: 0.3177\n",
            "02/09 19:28:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][220/332]  lr: 1.0000e-03  eta: 1:39:45  time: 0.3971  data_time: 0.0110  memory: 6616  grad_norm: 2.0026  loss: 1.0114  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6741  loss_aux: 0.3373\n",
            "02/09 19:29:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][240/332]  lr: 1.0000e-03  eta: 1:39:37  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 1.9499  loss: 0.9810  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6498  loss_aux: 0.3312\n",
            "02/09 19:29:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][260/332]  lr: 1.0000e-03  eta: 1:39:29  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 2.1312  loss: 0.9891  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6627  loss_aux: 0.3264\n",
            "02/09 19:29:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][280/332]  lr: 1.0000e-03  eta: 1:39:21  time: 0.3959  data_time: 0.0106  memory: 6616  grad_norm: 1.9662  loss: 1.0121  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6794  loss_aux: 0.3327\n",
            "02/09 19:29:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][300/332]  lr: 1.0000e-03  eta: 1:39:13  time: 0.3965  data_time: 0.0109  memory: 6616  grad_norm: 1.9361  loss: 0.9909  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6640  loss_aux: 0.3268\n",
            "02/09 19:29:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][320/332]  lr: 1.0000e-03  eta: 1:39:05  time: 0.3963  data_time: 0.0107  memory: 6616  grad_norm: 1.9701  loss: 1.0436  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7021  loss_aux: 0.3415\n",
            "02/09 19:29:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:29:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][332/332]  lr: 1.0000e-03  eta: 1:39:00  time: 0.3908  data_time: 0.0099  memory: 6616  grad_norm: 2.1706  loss: 1.0702  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7194  loss_aux: 0.3509\n",
            "02/09 19:29:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 105 epochs\n",
            "02/09 19:29:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][ 20/332]  lr: 1.0000e-03  eta: 1:38:52  time: 0.4473  data_time: 0.0584  memory: 6616  grad_norm: 2.2320  loss: 0.9445  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6284  loss_aux: 0.3161\n",
            "02/09 19:29:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][ 40/332]  lr: 1.0000e-03  eta: 1:38:44  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 2.0439  loss: 0.9932  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6642  loss_aux: 0.3291\n",
            "02/09 19:30:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][ 60/332]  lr: 1.0000e-03  eta: 1:38:36  time: 0.3957  data_time: 0.0102  memory: 6616  grad_norm: 2.1760  loss: 1.0113  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6790  loss_aux: 0.3323\n",
            "02/09 19:30:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][ 80/332]  lr: 1.0000e-03  eta: 1:38:29  time: 0.3968  data_time: 0.0110  memory: 6616  grad_norm: 2.0052  loss: 1.0011  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6698  loss_aux: 0.3313\n",
            "02/09 19:30:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][100/332]  lr: 1.0000e-03  eta: 1:38:21  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 1.8479  loss: 1.0267  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6836  loss_aux: 0.3431\n",
            "02/09 19:30:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][120/332]  lr: 1.0000e-03  eta: 1:38:13  time: 0.3953  data_time: 0.0100  memory: 6616  grad_norm: 1.9785  loss: 0.9521  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6343  loss_aux: 0.3178\n",
            "02/09 19:30:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:30:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][140/332]  lr: 1.0000e-03  eta: 1:38:05  time: 0.3967  data_time: 0.0108  memory: 6616  grad_norm: 2.0139  loss: 0.9167  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6073  loss_aux: 0.3094\n",
            "02/09 19:30:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][160/332]  lr: 1.0000e-03  eta: 1:37:57  time: 0.3964  data_time: 0.0106  memory: 6616  grad_norm: 2.0875  loss: 0.9899  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6526  loss_aux: 0.3372\n",
            "02/09 19:30:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][180/332]  lr: 1.0000e-03  eta: 1:37:49  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 1.9196  loss: 0.9989  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6690  loss_aux: 0.3300\n",
            "02/09 19:31:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][200/332]  lr: 1.0000e-03  eta: 1:37:41  time: 0.3966  data_time: 0.0107  memory: 6616  grad_norm: 1.9658  loss: 1.0054  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6799  loss_aux: 0.3255\n",
            "02/09 19:31:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][220/332]  lr: 1.0000e-03  eta: 1:37:33  time: 0.3960  data_time: 0.0103  memory: 6616  grad_norm: 2.0033  loss: 1.0443  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7057  loss_aux: 0.3387\n",
            "02/09 19:31:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][240/332]  lr: 1.0000e-03  eta: 1:37:25  time: 0.3955  data_time: 0.0099  memory: 6616  grad_norm: 1.9175  loss: 0.9952  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6614  loss_aux: 0.3337\n",
            "02/09 19:31:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][260/332]  lr: 1.0000e-03  eta: 1:37:17  time: 0.3963  data_time: 0.0105  memory: 6616  grad_norm: 1.9774  loss: 0.9670  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6457  loss_aux: 0.3213\n",
            "02/09 19:31:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][280/332]  lr: 1.0000e-03  eta: 1:37:09  time: 0.3966  data_time: 0.0107  memory: 6616  grad_norm: 2.0064  loss: 1.0136  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6753  loss_aux: 0.3383\n",
            "02/09 19:31:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][300/332]  lr: 1.0000e-03  eta: 1:37:01  time: 0.3957  data_time: 0.0104  memory: 6616  grad_norm: 2.0686  loss: 1.0036  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6701  loss_aux: 0.3335\n",
            "02/09 19:31:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][320/332]  lr: 1.0000e-03  eta: 1:36:53  time: 0.3966  data_time: 0.0108  memory: 6616  grad_norm: 2.3025  loss: 1.0398  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6810  loss_aux: 0.3588\n",
            "02/09 19:31:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:31:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][332/332]  lr: 1.0000e-03  eta: 1:36:48  time: 0.3905  data_time: 0.0098  memory: 6616  grad_norm: 2.1638  loss: 0.9799  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6406  loss_aux: 0.3392\n",
            "02/09 19:31:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 106 epochs\n",
            "02/09 19:32:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][ 20/332]  lr: 1.0000e-03  eta: 1:36:41  time: 0.4456  data_time: 0.0576  memory: 6616  grad_norm: 2.2913  loss: 1.0116  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6721  loss_aux: 0.3396\n",
            "02/09 19:32:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][ 40/332]  lr: 1.0000e-03  eta: 1:36:33  time: 0.3966  data_time: 0.0110  memory: 6616  grad_norm: 1.8160  loss: 0.9797  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6528  loss_aux: 0.3269\n",
            "02/09 19:32:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][ 60/332]  lr: 1.0000e-03  eta: 1:36:25  time: 0.3957  data_time: 0.0102  memory: 6616  grad_norm: 1.8000  loss: 0.9794  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6408  loss_aux: 0.3386\n",
            "02/09 19:32:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][ 80/332]  lr: 1.0000e-03  eta: 1:36:17  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 2.0987  loss: 1.0177  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6763  loss_aux: 0.3414\n",
            "02/09 19:32:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][100/332]  lr: 1.0000e-03  eta: 1:36:09  time: 0.3968  data_time: 0.0113  memory: 6616  grad_norm: 1.9706  loss: 0.9784  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6542  loss_aux: 0.3242\n",
            "02/09 19:32:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][120/332]  lr: 1.0000e-03  eta: 1:36:01  time: 0.3950  data_time: 0.0098  memory: 6616  grad_norm: 2.0262  loss: 0.9704  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6432  loss_aux: 0.3272\n",
            "02/09 19:32:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][140/332]  lr: 1.0000e-03  eta: 1:35:53  time: 0.3955  data_time: 0.0103  memory: 6616  grad_norm: 2.0513  loss: 1.0404  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6915  loss_aux: 0.3489\n",
            "02/09 19:33:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][160/332]  lr: 1.0000e-03  eta: 1:35:45  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 1.8503  loss: 0.9813  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6427  loss_aux: 0.3386\n",
            "02/09 19:33:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][180/332]  lr: 1.0000e-03  eta: 1:35:37  time: 0.3953  data_time: 0.0100  memory: 6616  grad_norm: 2.0020  loss: 0.9662  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6453  loss_aux: 0.3209\n",
            "02/09 19:33:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][200/332]  lr: 1.0000e-03  eta: 1:35:29  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 1.9277  loss: 1.0125  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6680  loss_aux: 0.3445\n",
            "02/09 19:33:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][220/332]  lr: 1.0000e-03  eta: 1:35:21  time: 0.3972  data_time: 0.0108  memory: 6616  grad_norm: 2.0884  loss: 1.0357  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6937  loss_aux: 0.3420\n",
            "02/09 19:33:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][240/332]  lr: 1.0000e-03  eta: 1:35:13  time: 0.3954  data_time: 0.0097  memory: 6616  grad_norm: 1.8574  loss: 0.9871  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6501  loss_aux: 0.3370\n",
            "02/09 19:33:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][260/332]  lr: 1.0000e-03  eta: 1:35:05  time: 0.3961  data_time: 0.0105  memory: 6616  grad_norm: 1.9929  loss: 1.0079  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6740  loss_aux: 0.3339\n",
            "02/09 19:33:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][280/332]  lr: 1.0000e-03  eta: 1:34:57  time: 0.3966  data_time: 0.0106  memory: 6616  grad_norm: 1.9070  loss: 0.9442  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6279  loss_aux: 0.3163\n",
            "02/09 19:33:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][300/332]  lr: 1.0000e-03  eta: 1:34:49  time: 0.3969  data_time: 0.0112  memory: 6616  grad_norm: 2.1389  loss: 0.9718  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6445  loss_aux: 0.3274\n",
            "02/09 19:34:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][320/332]  lr: 1.0000e-03  eta: 1:34:41  time: 0.3965  data_time: 0.0109  memory: 6616  grad_norm: 2.1521  loss: 0.9886  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6524  loss_aux: 0.3362\n",
            "02/09 19:34:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:34:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][332/332]  lr: 1.0000e-03  eta: 1:34:36  time: 0.3899  data_time: 0.0093  memory: 6616  grad_norm: 2.0278  loss: 0.9702  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6381  loss_aux: 0.3322\n",
            "02/09 19:34:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 107 epochs\n",
            "02/09 19:34:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][ 20/332]  lr: 1.0000e-03  eta: 1:34:29  time: 0.4415  data_time: 0.0511  memory: 6616  grad_norm: 1.8803  loss: 0.9704  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6402  loss_aux: 0.3302\n",
            "02/09 19:34:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][ 40/332]  lr: 1.0000e-03  eta: 1:34:21  time: 0.3965  data_time: 0.0104  memory: 6616  grad_norm: 2.0832  loss: 0.9286  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6183  loss_aux: 0.3103\n",
            "02/09 19:34:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][ 60/332]  lr: 1.0000e-03  eta: 1:34:13  time: 0.3953  data_time: 0.0099  memory: 6616  grad_norm: 2.1564  loss: 1.0562  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7098  loss_aux: 0.3464\n",
            "02/09 19:34:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][ 80/332]  lr: 1.0000e-03  eta: 1:34:05  time: 0.3973  data_time: 0.0112  memory: 6616  grad_norm: 1.9200  loss: 0.9633  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6356  loss_aux: 0.3277\n",
            "02/09 19:34:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][100/332]  lr: 1.0000e-03  eta: 1:33:57  time: 0.3977  data_time: 0.0117  memory: 6616  grad_norm: 2.1105  loss: 0.9765  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6414  loss_aux: 0.3351\n",
            "02/09 19:34:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][120/332]  lr: 1.0000e-03  eta: 1:33:49  time: 0.3963  data_time: 0.0105  memory: 6616  grad_norm: 2.1799  loss: 1.0068  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6722  loss_aux: 0.3346\n",
            "02/09 19:35:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][140/332]  lr: 1.0000e-03  eta: 1:33:41  time: 0.3974  data_time: 0.0110  memory: 6616  grad_norm: 1.9999  loss: 1.0149  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6770  loss_aux: 0.3379\n",
            "02/09 19:35:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][160/332]  lr: 1.0000e-03  eta: 1:33:33  time: 0.3976  data_time: 0.0115  memory: 6616  grad_norm: 2.0703  loss: 0.9355  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6203  loss_aux: 0.3153\n",
            "02/09 19:35:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][180/332]  lr: 1.0000e-03  eta: 1:33:25  time: 0.3960  data_time: 0.0103  memory: 6616  grad_norm: 2.1258  loss: 1.0026  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6693  loss_aux: 0.3333\n",
            "02/09 19:35:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][200/332]  lr: 1.0000e-03  eta: 1:33:17  time: 0.3962  data_time: 0.0102  memory: 6616  grad_norm: 2.2522  loss: 1.0070  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6797  loss_aux: 0.3273\n",
            "02/09 19:35:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][220/332]  lr: 1.0000e-03  eta: 1:33:09  time: 0.3959  data_time: 0.0100  memory: 6616  grad_norm: 2.2972  loss: 0.9611  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6536  loss_aux: 0.3075\n",
            "02/09 19:35:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][240/332]  lr: 1.0000e-03  eta: 1:33:01  time: 0.3950  data_time: 0.0100  memory: 6616  grad_norm: 2.2807  loss: 0.9778  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6459  loss_aux: 0.3319\n",
            "02/09 19:35:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][260/332]  lr: 1.0000e-03  eta: 1:32:53  time: 0.3967  data_time: 0.0109  memory: 6616  grad_norm: 2.0954  loss: 0.9912  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6588  loss_aux: 0.3324\n",
            "02/09 19:36:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][280/332]  lr: 1.0000e-03  eta: 1:32:45  time: 0.3953  data_time: 0.0101  memory: 6616  grad_norm: 2.1014  loss: 1.0441  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6945  loss_aux: 0.3496\n",
            "02/09 19:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][300/332]  lr: 1.0000e-03  eta: 1:32:37  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 2.0170  loss: 1.0061  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6620  loss_aux: 0.3441\n",
            "02/09 19:36:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][320/332]  lr: 1.0000e-03  eta: 1:32:29  time: 0.3966  data_time: 0.0110  memory: 6616  grad_norm: 2.3142  loss: 1.0514  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7018  loss_aux: 0.3496\n",
            "02/09 19:36:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:36:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][332/332]  lr: 1.0000e-03  eta: 1:32:24  time: 0.3905  data_time: 0.0096  memory: 6616  grad_norm: 2.4576  loss: 1.0351  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6979  loss_aux: 0.3372\n",
            "02/09 19:36:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 108 epochs\n",
            "02/09 19:36:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][ 20/332]  lr: 1.0000e-03  eta: 1:32:17  time: 0.4464  data_time: 0.0573  memory: 6616  grad_norm: 2.0814  loss: 1.0061  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6725  loss_aux: 0.3336\n",
            "02/09 19:36:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][ 40/332]  lr: 1.0000e-03  eta: 1:32:09  time: 0.3966  data_time: 0.0111  memory: 6616  grad_norm: 1.9533  loss: 0.9546  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6374  loss_aux: 0.3172\n",
            "02/09 19:36:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][ 60/332]  lr: 1.0000e-03  eta: 1:32:01  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 1.8085  loss: 0.9688  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6385  loss_aux: 0.3303\n",
            "02/09 19:36:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][ 80/332]  lr: 1.0000e-03  eta: 1:31:53  time: 0.3965  data_time: 0.0108  memory: 6616  grad_norm: 1.9420  loss: 0.9887  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6546  loss_aux: 0.3341\n",
            "02/09 19:37:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][100/332]  lr: 1.0000e-03  eta: 1:31:45  time: 0.3965  data_time: 0.0105  memory: 6616  grad_norm: 2.2281  loss: 1.0186  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6808  loss_aux: 0.3377\n",
            "02/09 19:37:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][120/332]  lr: 1.0000e-03  eta: 1:31:37  time: 0.3945  data_time: 0.0094  memory: 6616  grad_norm: 2.0975  loss: 1.0020  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6673  loss_aux: 0.3348\n",
            "02/09 19:37:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][140/332]  lr: 1.0000e-03  eta: 1:31:29  time: 0.3951  data_time: 0.0099  memory: 6616  grad_norm: 2.0106  loss: 1.0342  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6960  loss_aux: 0.3382\n",
            "02/09 19:37:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:37:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][160/332]  lr: 1.0000e-03  eta: 1:31:21  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 2.0380  loss: 0.9872  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6602  loss_aux: 0.3270\n",
            "02/09 19:37:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][180/332]  lr: 1.0000e-03  eta: 1:31:13  time: 0.3959  data_time: 0.0103  memory: 6616  grad_norm: 2.1568  loss: 1.0203  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6791  loss_aux: 0.3412\n",
            "02/09 19:37:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][200/332]  lr: 1.0000e-03  eta: 1:31:05  time: 0.3959  data_time: 0.0105  memory: 6616  grad_norm: 2.0585  loss: 1.0209  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6833  loss_aux: 0.3376\n",
            "02/09 19:37:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][220/332]  lr: 1.0000e-03  eta: 1:30:57  time: 0.3965  data_time: 0.0108  memory: 6616  grad_norm: 2.1106  loss: 0.9808  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6527  loss_aux: 0.3281\n",
            "02/09 19:38:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][240/332]  lr: 1.0000e-03  eta: 1:30:49  time: 0.3951  data_time: 0.0099  memory: 6616  grad_norm: 2.1546  loss: 0.9923  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6675  loss_aux: 0.3248\n",
            "02/09 19:38:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][260/332]  lr: 1.0000e-03  eta: 1:30:41  time: 0.3963  data_time: 0.0106  memory: 6616  grad_norm: 2.1619  loss: 1.0076  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6645  loss_aux: 0.3431\n",
            "02/09 19:38:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][280/332]  lr: 1.0000e-03  eta: 1:30:33  time: 0.3994  data_time: 0.0122  memory: 6616  grad_norm: 1.9073  loss: 1.0251  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6802  loss_aux: 0.3450\n",
            "02/09 19:38:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][300/332]  lr: 1.0000e-03  eta: 1:30:25  time: 0.3961  data_time: 0.0104  memory: 6616  grad_norm: 1.8907  loss: 0.9857  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6599  loss_aux: 0.3259\n",
            "02/09 19:38:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][320/332]  lr: 1.0000e-03  eta: 1:30:17  time: 0.3958  data_time: 0.0103  memory: 6616  grad_norm: 2.0228  loss: 0.9738  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6512  loss_aux: 0.3225\n",
            "02/09 19:38:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:38:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][332/332]  lr: 1.0000e-03  eta: 1:30:12  time: 0.3905  data_time: 0.0096  memory: 6616  grad_norm: 2.0156  loss: 0.9830  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6544  loss_aux: 0.3286\n",
            "02/09 19:38:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 109 epochs\n",
            "02/09 19:38:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][ 20/332]  lr: 1.0000e-03  eta: 1:30:05  time: 0.4503  data_time: 0.0636  memory: 6616  grad_norm: 1.8959  loss: 0.9437  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6280  loss_aux: 0.3156\n",
            "02/09 19:38:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][ 40/332]  lr: 1.0000e-03  eta: 1:29:57  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 2.0612  loss: 0.9649  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6409  loss_aux: 0.3240\n",
            "02/09 19:39:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][ 60/332]  lr: 1.0000e-03  eta: 1:29:49  time: 0.3963  data_time: 0.0106  memory: 6616  grad_norm: 2.0021  loss: 0.9998  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6628  loss_aux: 0.3370\n",
            "02/09 19:39:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][ 80/332]  lr: 1.0000e-03  eta: 1:29:41  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 2.0440  loss: 0.9870  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6528  loss_aux: 0.3342\n",
            "02/09 19:39:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][100/332]  lr: 1.0000e-03  eta: 1:29:33  time: 0.3965  data_time: 0.0109  memory: 6616  grad_norm: 2.0504  loss: 0.9397  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6176  loss_aux: 0.3221\n",
            "02/09 19:39:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][120/332]  lr: 1.0000e-03  eta: 1:29:25  time: 0.3966  data_time: 0.0108  memory: 6616  grad_norm: 2.1206  loss: 1.0179  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6731  loss_aux: 0.3449\n",
            "02/09 19:39:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][140/332]  lr: 1.0000e-03  eta: 1:29:17  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 1.9931  loss: 1.0188  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6874  loss_aux: 0.3313\n",
            "02/09 19:39:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][160/332]  lr: 1.0000e-03  eta: 1:29:09  time: 0.3967  data_time: 0.0107  memory: 6616  grad_norm: 1.9493  loss: 0.9965  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6567  loss_aux: 0.3398\n",
            "02/09 19:39:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][180/332]  lr: 1.0000e-03  eta: 1:29:01  time: 0.3972  data_time: 0.0107  memory: 6616  grad_norm: 1.9209  loss: 1.0068  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6764  loss_aux: 0.3303\n",
            "02/09 19:40:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][200/332]  lr: 1.0000e-03  eta: 1:28:53  time: 0.3958  data_time: 0.0099  memory: 6616  grad_norm: 1.8298  loss: 0.9758  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6446  loss_aux: 0.3312\n",
            "02/09 19:40:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][220/332]  lr: 1.0000e-03  eta: 1:28:45  time: 0.3966  data_time: 0.0108  memory: 6616  grad_norm: 2.2923  loss: 0.9731  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6485  loss_aux: 0.3246\n",
            "02/09 19:40:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][240/332]  lr: 1.0000e-03  eta: 1:28:37  time: 0.3958  data_time: 0.0102  memory: 6616  grad_norm: 2.0265  loss: 0.8656  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5716  loss_aux: 0.2940\n",
            "02/09 19:40:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][260/332]  lr: 1.0000e-03  eta: 1:28:29  time: 0.3957  data_time: 0.0102  memory: 6616  grad_norm: 2.5943  loss: 1.0664  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.7154  loss_aux: 0.3510\n",
            "02/09 19:40:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][280/332]  lr: 1.0000e-03  eta: 1:28:21  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 2.1327  loss: 1.0073  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6691  loss_aux: 0.3382\n",
            "02/09 19:40:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][300/332]  lr: 1.0000e-03  eta: 1:28:13  time: 0.3958  data_time: 0.0103  memory: 6616  grad_norm: 2.0277  loss: 0.9971  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6732  loss_aux: 0.3238\n",
            "02/09 19:40:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][320/332]  lr: 1.0000e-03  eta: 1:28:05  time: 0.3963  data_time: 0.0106  memory: 6616  grad_norm: 2.1156  loss: 0.9909  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6628  loss_aux: 0.3281\n",
            "02/09 19:40:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:40:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][332/332]  lr: 1.0000e-03  eta: 1:28:01  time: 0.3901  data_time: 0.0093  memory: 6616  grad_norm: 1.9960  loss: 0.9848  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6464  loss_aux: 0.3384\n",
            "02/09 19:40:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 110 epochs\n",
            "02/09 19:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [110][20/42]    eta: 0:00:04  time: 0.1821  data_time: 0.0765  memory: 1447  \n",
            "02/09 19:41:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [110][40/42]    eta: 0:00:00  time: 0.1140  data_time: 0.0128  memory: 1447  \n",
            "02/09 19:41:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [110][42/42]    acc/top1: 0.6114  acc/top5: 1.0000  acc/mean1: 0.5907  data_time: 0.0420  time: 0.1428\n",
            "02/09 19:41:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][ 20/332]  lr: 1.0000e-03  eta: 1:27:53  time: 0.4286  data_time: 0.0422  memory: 6616  grad_norm: 2.0264  loss: 0.9953  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6747  loss_aux: 0.3206\n",
            "02/09 19:41:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][ 40/332]  lr: 1.0000e-03  eta: 1:27:45  time: 0.3957  data_time: 0.0101  memory: 6616  grad_norm: 1.9281  loss: 1.0186  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6849  loss_aux: 0.3336\n",
            "02/09 19:41:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][ 60/332]  lr: 1.0000e-03  eta: 1:27:37  time: 0.3954  data_time: 0.0100  memory: 6616  grad_norm: 2.0178  loss: 0.9319  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6176  loss_aux: 0.3143\n",
            "02/09 19:41:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][ 80/332]  lr: 1.0000e-03  eta: 1:27:29  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 1.9189  loss: 1.0262  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6857  loss_aux: 0.3406\n",
            "02/09 19:41:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][100/332]  lr: 1.0000e-03  eta: 1:27:21  time: 0.3958  data_time: 0.0103  memory: 6616  grad_norm: 2.0860  loss: 0.9125  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6023  loss_aux: 0.3102\n",
            "02/09 19:41:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][120/332]  lr: 1.0000e-03  eta: 1:27:13  time: 0.3965  data_time: 0.0108  memory: 6616  grad_norm: 2.2029  loss: 0.9894  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6600  loss_aux: 0.3294\n",
            "02/09 19:41:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][140/332]  lr: 1.0000e-03  eta: 1:27:05  time: 0.3963  data_time: 0.0107  memory: 6616  grad_norm: 2.1593  loss: 0.9416  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6267  loss_aux: 0.3148\n",
            "02/09 19:42:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][160/332]  lr: 1.0000e-03  eta: 1:26:57  time: 0.3968  data_time: 0.0106  memory: 6616  grad_norm: 2.4066  loss: 0.9346  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6174  loss_aux: 0.3172\n",
            "02/09 19:42:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][180/332]  lr: 1.0000e-03  eta: 1:26:49  time: 0.3969  data_time: 0.0105  memory: 6616  grad_norm: 2.5690  loss: 1.0097  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6833  loss_aux: 0.3264\n",
            "02/09 19:42:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][200/332]  lr: 1.0000e-03  eta: 1:26:41  time: 0.3984  data_time: 0.0118  memory: 6616  grad_norm: 2.2374  loss: 0.9813  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6461  loss_aux: 0.3352\n",
            "02/09 19:42:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][220/332]  lr: 1.0000e-03  eta: 1:26:33  time: 0.3958  data_time: 0.0100  memory: 6616  grad_norm: 2.2344  loss: 0.9835  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6474  loss_aux: 0.3362\n",
            "02/09 19:42:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][240/332]  lr: 1.0000e-03  eta: 1:26:25  time: 0.3981  data_time: 0.0109  memory: 6616  grad_norm: 2.1022  loss: 0.9923  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6537  loss_aux: 0.3386\n",
            "02/09 19:42:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][260/332]  lr: 1.0000e-03  eta: 1:26:17  time: 0.3974  data_time: 0.0108  memory: 6616  grad_norm: 2.2499  loss: 1.0243  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6840  loss_aux: 0.3403\n",
            "02/09 19:42:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][280/332]  lr: 1.0000e-03  eta: 1:26:09  time: 0.3965  data_time: 0.0104  memory: 6616  grad_norm: 1.9206  loss: 0.9056  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5919  loss_aux: 0.3138\n",
            "02/09 19:43:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][300/332]  lr: 1.0000e-03  eta: 1:26:01  time: 0.3976  data_time: 0.0110  memory: 6616  grad_norm: 2.3401  loss: 0.9779  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6433  loss_aux: 0.3346\n",
            "02/09 19:43:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][320/332]  lr: 1.0000e-03  eta: 1:25:53  time: 0.3969  data_time: 0.0107  memory: 6616  grad_norm: 2.5377  loss: 0.9862  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6594  loss_aux: 0.3268\n",
            "02/09 19:43:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:43:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][332/332]  lr: 1.0000e-03  eta: 1:25:49  time: 0.3912  data_time: 0.0098  memory: 6616  grad_norm: 2.5424  loss: 0.9600  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6337  loss_aux: 0.3262\n",
            "02/09 19:43:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 111 epochs\n",
            "02/09 19:43:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][ 20/332]  lr: 1.0000e-03  eta: 1:25:41  time: 0.4458  data_time: 0.0568  memory: 6616  grad_norm: 2.5760  loss: 1.0145  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6786  loss_aux: 0.3359\n",
            "02/09 19:43:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][ 40/332]  lr: 1.0000e-03  eta: 1:25:33  time: 0.3967  data_time: 0.0105  memory: 6616  grad_norm: 2.1474  loss: 0.9496  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6281  loss_aux: 0.3215\n",
            "02/09 19:43:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][ 60/332]  lr: 1.0000e-03  eta: 1:25:25  time: 0.3959  data_time: 0.0101  memory: 6616  grad_norm: 2.2485  loss: 1.0461  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7004  loss_aux: 0.3456\n",
            "02/09 19:43:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][ 80/332]  lr: 1.0000e-03  eta: 1:25:17  time: 0.3968  data_time: 0.0104  memory: 6616  grad_norm: 1.9331  loss: 0.9541  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6329  loss_aux: 0.3211\n",
            "02/09 19:43:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][100/332]  lr: 1.0000e-03  eta: 1:25:09  time: 0.3963  data_time: 0.0100  memory: 6616  grad_norm: 2.1539  loss: 0.9716  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6502  loss_aux: 0.3214\n",
            "02/09 19:44:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][120/332]  lr: 1.0000e-03  eta: 1:25:01  time: 0.3959  data_time: 0.0102  memory: 6616  grad_norm: 2.0521  loss: 0.9529  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6355  loss_aux: 0.3175\n",
            "02/09 19:44:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][140/332]  lr: 1.0000e-03  eta: 1:24:53  time: 0.3971  data_time: 0.0108  memory: 6616  grad_norm: 2.2714  loss: 0.9837  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6501  loss_aux: 0.3336\n",
            "02/09 19:44:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:44:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][160/332]  lr: 1.0000e-03  eta: 1:24:45  time: 0.3972  data_time: 0.0111  memory: 6616  grad_norm: 2.4802  loss: 0.9644  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6464  loss_aux: 0.3180\n",
            "02/09 19:44:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][180/332]  lr: 1.0000e-03  eta: 1:24:37  time: 0.3963  data_time: 0.0102  memory: 6616  grad_norm: 2.2522  loss: 0.9422  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6266  loss_aux: 0.3156\n",
            "02/09 19:44:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][200/332]  lr: 1.0000e-03  eta: 1:24:29  time: 0.3974  data_time: 0.0113  memory: 6616  grad_norm: 2.1525  loss: 1.0028  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6658  loss_aux: 0.3370\n",
            "02/09 19:44:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][220/332]  lr: 1.0000e-03  eta: 1:24:21  time: 0.3959  data_time: 0.0101  memory: 6616  grad_norm: 2.2836  loss: 0.9835  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6582  loss_aux: 0.3253\n",
            "02/09 19:44:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][240/332]  lr: 1.0000e-03  eta: 1:24:13  time: 0.3957  data_time: 0.0103  memory: 6616  grad_norm: 2.2064  loss: 0.9551  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6315  loss_aux: 0.3236\n",
            "02/09 19:45:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][260/332]  lr: 1.0000e-03  eta: 1:24:05  time: 0.3960  data_time: 0.0105  memory: 6616  grad_norm: 2.2486  loss: 0.9872  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6554  loss_aux: 0.3318\n",
            "02/09 19:45:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][280/332]  lr: 1.0000e-03  eta: 1:23:58  time: 0.3956  data_time: 0.0100  memory: 6616  grad_norm: 2.4044  loss: 0.9788  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6591  loss_aux: 0.3197\n",
            "02/09 19:45:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][300/332]  lr: 1.0000e-03  eta: 1:23:50  time: 0.3962  data_time: 0.0105  memory: 6616  grad_norm: 2.3377  loss: 0.9591  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6411  loss_aux: 0.3180\n",
            "02/09 19:45:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][320/332]  lr: 1.0000e-03  eta: 1:23:42  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 2.2243  loss: 1.0108  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6727  loss_aux: 0.3381\n",
            "02/09 19:45:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:45:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][332/332]  lr: 1.0000e-03  eta: 1:23:37  time: 0.3907  data_time: 0.0098  memory: 6616  grad_norm: 2.3387  loss: 1.0204  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6747  loss_aux: 0.3457\n",
            "02/09 19:45:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 112 epochs\n",
            "02/09 19:45:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][ 20/332]  lr: 1.0000e-03  eta: 1:23:29  time: 0.4507  data_time: 0.0604  memory: 6616  grad_norm: 2.3776  loss: 1.0215  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6910  loss_aux: 0.3305\n",
            "02/09 19:45:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][ 40/332]  lr: 1.0000e-03  eta: 1:23:21  time: 0.3964  data_time: 0.0107  memory: 6616  grad_norm: 2.0503  loss: 0.9185  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6011  loss_aux: 0.3174\n",
            "02/09 19:45:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][ 60/332]  lr: 1.0000e-03  eta: 1:23:13  time: 0.3965  data_time: 0.0107  memory: 6616  grad_norm: 2.1010  loss: 1.0044  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6744  loss_aux: 0.3300\n",
            "02/09 19:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][ 80/332]  lr: 1.0000e-03  eta: 1:23:05  time: 0.3954  data_time: 0.0100  memory: 6616  grad_norm: 2.1343  loss: 1.0107  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6778  loss_aux: 0.3329\n",
            "02/09 19:46:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][100/332]  lr: 1.0000e-03  eta: 1:22:57  time: 0.3966  data_time: 0.0107  memory: 6616  grad_norm: 2.1002  loss: 0.9726  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6513  loss_aux: 0.3213\n",
            "02/09 19:46:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][120/332]  lr: 1.0000e-03  eta: 1:22:49  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 2.3177  loss: 0.9283  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6051  loss_aux: 0.3232\n",
            "02/09 19:46:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][140/332]  lr: 1.0000e-03  eta: 1:22:41  time: 0.3967  data_time: 0.0109  memory: 6616  grad_norm: 2.0384  loss: 0.9293  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6211  loss_aux: 0.3082\n",
            "02/09 19:46:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][160/332]  lr: 1.0000e-03  eta: 1:22:33  time: 0.3970  data_time: 0.0109  memory: 6616  grad_norm: 2.0248  loss: 0.9537  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6381  loss_aux: 0.3157\n",
            "02/09 19:46:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][180/332]  lr: 1.0000e-03  eta: 1:22:25  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 2.1938  loss: 0.9408  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6198  loss_aux: 0.3209\n",
            "02/09 19:46:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][200/332]  lr: 1.0000e-03  eta: 1:22:18  time: 0.3963  data_time: 0.0107  memory: 6616  grad_norm: 2.1703  loss: 0.9828  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6564  loss_aux: 0.3264\n",
            "02/09 19:47:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][220/332]  lr: 1.0000e-03  eta: 1:22:10  time: 0.3966  data_time: 0.0104  memory: 6616  grad_norm: 2.4093  loss: 1.0345  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6876  loss_aux: 0.3469\n",
            "02/09 19:47:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][240/332]  lr: 1.0000e-03  eta: 1:22:02  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 2.3819  loss: 1.0203  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6819  loss_aux: 0.3385\n",
            "02/09 19:47:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][260/332]  lr: 1.0000e-03  eta: 1:21:54  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 2.2979  loss: 1.0041  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6670  loss_aux: 0.3372\n",
            "02/09 19:47:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][280/332]  lr: 1.0000e-03  eta: 1:21:46  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 2.2945  loss: 0.9924  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6641  loss_aux: 0.3283\n",
            "02/09 19:47:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][300/332]  lr: 1.0000e-03  eta: 1:21:38  time: 0.3957  data_time: 0.0104  memory: 6616  grad_norm: 2.5759  loss: 0.9743  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6495  loss_aux: 0.3249\n",
            "02/09 19:47:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][320/332]  lr: 1.0000e-03  eta: 1:21:30  time: 0.3971  data_time: 0.0108  memory: 6616  grad_norm: 2.0542  loss: 0.9988  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6697  loss_aux: 0.3291\n",
            "02/09 19:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][332/332]  lr: 1.0000e-03  eta: 1:21:25  time: 0.3914  data_time: 0.0101  memory: 6616  grad_norm: 2.1438  loss: 0.9772  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6469  loss_aux: 0.3302\n",
            "02/09 19:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 113 epochs\n",
            "02/09 19:47:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][ 20/332]  lr: 1.0000e-03  eta: 1:21:17  time: 0.4604  data_time: 0.0722  memory: 6616  grad_norm: 2.0157  loss: 0.9709  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6401  loss_aux: 0.3308\n",
            "02/09 19:48:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][ 40/332]  lr: 1.0000e-03  eta: 1:21:09  time: 0.3967  data_time: 0.0108  memory: 6616  grad_norm: 2.0560  loss: 0.9584  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6446  loss_aux: 0.3138\n",
            "02/09 19:48:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][ 60/332]  lr: 1.0000e-03  eta: 1:21:01  time: 0.3947  data_time: 0.0095  memory: 6616  grad_norm: 2.3813  loss: 1.0210  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6864  loss_aux: 0.3345\n",
            "02/09 19:48:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][ 80/332]  lr: 1.0000e-03  eta: 1:20:53  time: 0.3961  data_time: 0.0103  memory: 6616  grad_norm: 2.2568  loss: 0.9797  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6514  loss_aux: 0.3282\n",
            "02/09 19:48:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][100/332]  lr: 1.0000e-03  eta: 1:20:46  time: 0.3964  data_time: 0.0103  memory: 6616  grad_norm: 2.1365  loss: 0.9689  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6424  loss_aux: 0.3265\n",
            "02/09 19:48:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][120/332]  lr: 1.0000e-03  eta: 1:20:38  time: 0.3960  data_time: 0.0104  memory: 6616  grad_norm: 1.7942  loss: 0.9610  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6430  loss_aux: 0.3179\n",
            "02/09 19:48:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][140/332]  lr: 1.0000e-03  eta: 1:20:30  time: 0.3962  data_time: 0.0105  memory: 6616  grad_norm: 2.0843  loss: 1.0203  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6792  loss_aux: 0.3411\n",
            "02/09 19:48:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][160/332]  lr: 1.0000e-03  eta: 1:20:22  time: 0.3970  data_time: 0.0111  memory: 6616  grad_norm: 2.1975  loss: 0.9634  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6405  loss_aux: 0.3229\n",
            "02/09 19:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][180/332]  lr: 1.0000e-03  eta: 1:20:14  time: 0.3954  data_time: 0.0101  memory: 6616  grad_norm: 2.0215  loss: 1.0032  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6680  loss_aux: 0.3352\n",
            "02/09 19:49:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][200/332]  lr: 1.0000e-03  eta: 1:20:06  time: 0.3957  data_time: 0.0100  memory: 6616  grad_norm: 1.9880  loss: 0.9606  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6413  loss_aux: 0.3193\n",
            "02/09 19:49:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][220/332]  lr: 1.0000e-03  eta: 1:19:58  time: 0.3959  data_time: 0.0102  memory: 6616  grad_norm: 2.1619  loss: 1.0125  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6786  loss_aux: 0.3339\n",
            "02/09 19:49:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][240/332]  lr: 1.0000e-03  eta: 1:19:50  time: 0.3958  data_time: 0.0102  memory: 6616  grad_norm: 2.2166  loss: 0.9989  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6665  loss_aux: 0.3324\n",
            "02/09 19:49:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][260/332]  lr: 1.0000e-03  eta: 1:19:42  time: 0.3973  data_time: 0.0110  memory: 6616  grad_norm: 2.2281  loss: 1.0112  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6771  loss_aux: 0.3341\n",
            "02/09 19:49:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][280/332]  lr: 1.0000e-03  eta: 1:19:34  time: 0.3963  data_time: 0.0104  memory: 6616  grad_norm: 2.1354  loss: 0.9556  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6350  loss_aux: 0.3206\n",
            "02/09 19:49:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][300/332]  lr: 1.0000e-03  eta: 1:19:26  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 2.3542  loss: 1.0431  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6894  loss_aux: 0.3537\n",
            "02/09 19:49:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][320/332]  lr: 1.0000e-03  eta: 1:19:18  time: 0.3959  data_time: 0.0103  memory: 6616  grad_norm: 2.0033  loss: 0.9924  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6473  loss_aux: 0.3451\n",
            "02/09 19:50:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:50:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][332/332]  lr: 1.0000e-03  eta: 1:19:13  time: 0.3902  data_time: 0.0093  memory: 6616  grad_norm: 2.1045  loss: 0.9984  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6581  loss_aux: 0.3404\n",
            "02/09 19:50:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 114 epochs\n",
            "02/09 19:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][ 20/332]  lr: 1.0000e-03  eta: 1:19:05  time: 0.4397  data_time: 0.0509  memory: 6616  grad_norm: 1.9789  loss: 0.9824  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6546  loss_aux: 0.3278\n",
            "02/09 19:50:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][ 40/332]  lr: 1.0000e-03  eta: 1:18:57  time: 0.3966  data_time: 0.0107  memory: 6616  grad_norm: 2.1558  loss: 0.9919  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6674  loss_aux: 0.3245\n",
            "02/09 19:50:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][ 60/332]  lr: 1.0000e-03  eta: 1:18:49  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 2.0756  loss: 1.0016  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6718  loss_aux: 0.3298\n",
            "02/09 19:50:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][ 80/332]  lr: 1.0000e-03  eta: 1:18:41  time: 0.3960  data_time: 0.0104  memory: 6616  grad_norm: 2.0141  loss: 0.9565  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6338  loss_aux: 0.3227\n",
            "02/09 19:50:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][100/332]  lr: 1.0000e-03  eta: 1:18:34  time: 0.3959  data_time: 0.0102  memory: 6616  grad_norm: 2.0795  loss: 0.9297  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6069  loss_aux: 0.3228\n",
            "02/09 19:50:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][120/332]  lr: 1.0000e-03  eta: 1:18:26  time: 0.3959  data_time: 0.0103  memory: 6616  grad_norm: 2.2445  loss: 0.9893  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6584  loss_aux: 0.3309\n",
            "02/09 19:50:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][140/332]  lr: 1.0000e-03  eta: 1:18:18  time: 0.3962  data_time: 0.0104  memory: 6616  grad_norm: 2.1218  loss: 1.0040  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6648  loss_aux: 0.3392\n",
            "02/09 19:51:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:51:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][160/332]  lr: 1.0000e-03  eta: 1:18:10  time: 0.3959  data_time: 0.0104  memory: 6616  grad_norm: 2.1961  loss: 1.0262  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6892  loss_aux: 0.3370\n",
            "02/09 19:51:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][180/332]  lr: 1.0000e-03  eta: 1:18:02  time: 0.3951  data_time: 0.0096  memory: 6616  grad_norm: 1.9023  loss: 0.9429  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6234  loss_aux: 0.3195\n",
            "02/09 19:51:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][200/332]  lr: 1.0000e-03  eta: 1:17:54  time: 0.3970  data_time: 0.0111  memory: 6616  grad_norm: 1.9344  loss: 0.9578  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6397  loss_aux: 0.3181\n",
            "02/09 19:51:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][220/332]  lr: 1.0000e-03  eta: 1:17:46  time: 0.3966  data_time: 0.0108  memory: 6616  grad_norm: 2.0324  loss: 0.9698  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6479  loss_aux: 0.3220\n",
            "02/09 19:51:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][240/332]  lr: 1.0000e-03  eta: 1:17:38  time: 0.3966  data_time: 0.0105  memory: 6616  grad_norm: 2.3141  loss: 0.9590  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6400  loss_aux: 0.3190\n",
            "02/09 19:51:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][260/332]  lr: 1.0000e-03  eta: 1:17:30  time: 0.3966  data_time: 0.0106  memory: 6616  grad_norm: 2.5081  loss: 1.0289  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6849  loss_aux: 0.3440\n",
            "02/09 19:51:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][280/332]  lr: 1.0000e-03  eta: 1:17:22  time: 0.3972  data_time: 0.0113  memory: 6616  grad_norm: 2.2641  loss: 0.9664  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6422  loss_aux: 0.3242\n",
            "02/09 19:52:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][300/332]  lr: 1.0000e-03  eta: 1:17:14  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 2.3646  loss: 1.0128  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6739  loss_aux: 0.3390\n",
            "02/09 19:52:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][320/332]  lr: 1.0000e-03  eta: 1:17:06  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 2.2507  loss: 0.9507  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6329  loss_aux: 0.3179\n",
            "02/09 19:52:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:52:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][332/332]  lr: 1.0000e-03  eta: 1:17:01  time: 0.3901  data_time: 0.0094  memory: 6616  grad_norm: 2.1983  loss: 0.9323  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6158  loss_aux: 0.3165\n",
            "02/09 19:52:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 115 epochs\n",
            "02/09 19:52:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][ 20/332]  lr: 1.0000e-03  eta: 1:16:53  time: 0.4462  data_time: 0.0584  memory: 6616  grad_norm: 2.4113  loss: 1.0022  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6561  loss_aux: 0.3460\n",
            "02/09 19:52:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][ 40/332]  lr: 1.0000e-03  eta: 1:16:45  time: 0.3952  data_time: 0.0099  memory: 6616  grad_norm: 2.4865  loss: 1.0086  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6705  loss_aux: 0.3380\n",
            "02/09 19:52:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][ 60/332]  lr: 1.0000e-03  eta: 1:16:38  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 1.9444  loss: 0.9575  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6352  loss_aux: 0.3223\n",
            "02/09 19:52:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][ 80/332]  lr: 1.0000e-03  eta: 1:16:30  time: 0.3962  data_time: 0.0105  memory: 6616  grad_norm: 2.2485  loss: 1.0300  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6942  loss_aux: 0.3358\n",
            "02/09 19:52:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][100/332]  lr: 1.0000e-03  eta: 1:16:22  time: 0.3964  data_time: 0.0107  memory: 6616  grad_norm: 2.4180  loss: 0.9758  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6519  loss_aux: 0.3239\n",
            "02/09 19:53:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][120/332]  lr: 1.0000e-03  eta: 1:16:14  time: 0.3962  data_time: 0.0102  memory: 6616  grad_norm: 2.0640  loss: 1.0424  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6965  loss_aux: 0.3459\n",
            "02/09 19:53:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][140/332]  lr: 1.0000e-03  eta: 1:16:06  time: 0.3966  data_time: 0.0110  memory: 6616  grad_norm: 2.1599  loss: 0.9469  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6367  loss_aux: 0.3101\n",
            "02/09 19:53:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][160/332]  lr: 1.0000e-03  eta: 1:15:58  time: 0.3960  data_time: 0.0106  memory: 6616  grad_norm: 2.2714  loss: 1.0400  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6996  loss_aux: 0.3404\n",
            "02/09 19:53:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][180/332]  lr: 1.0000e-03  eta: 1:15:50  time: 0.3956  data_time: 0.0100  memory: 6616  grad_norm: 2.0268  loss: 0.9825  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6556  loss_aux: 0.3269\n",
            "02/09 19:53:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][200/332]  lr: 1.0000e-03  eta: 1:15:42  time: 0.3963  data_time: 0.0109  memory: 6616  grad_norm: 2.1060  loss: 0.9607  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6365  loss_aux: 0.3243\n",
            "02/09 19:53:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][220/332]  lr: 1.0000e-03  eta: 1:15:34  time: 0.3963  data_time: 0.0106  memory: 6616  grad_norm: 2.2192  loss: 1.0168  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6773  loss_aux: 0.3395\n",
            "02/09 19:53:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][240/332]  lr: 1.0000e-03  eta: 1:15:26  time: 0.3958  data_time: 0.0104  memory: 6616  grad_norm: 2.1344  loss: 0.9788  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6522  loss_aux: 0.3266\n",
            "02/09 19:54:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][260/332]  lr: 1.0000e-03  eta: 1:15:18  time: 0.3967  data_time: 0.0106  memory: 6616  grad_norm: 1.9293  loss: 0.9367  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6135  loss_aux: 0.3232\n",
            "02/09 19:54:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][280/332]  lr: 1.0000e-03  eta: 1:15:10  time: 0.3968  data_time: 0.0111  memory: 6616  grad_norm: 1.8793  loss: 0.9422  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6223  loss_aux: 0.3200\n",
            "02/09 19:54:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][300/332]  lr: 1.0000e-03  eta: 1:15:02  time: 0.3956  data_time: 0.0100  memory: 6616  grad_norm: 2.5404  loss: 1.0274  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6687  loss_aux: 0.3587\n",
            "02/09 19:54:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][320/332]  lr: 1.0000e-03  eta: 1:14:54  time: 0.3958  data_time: 0.0101  memory: 6616  grad_norm: 2.0804  loss: 0.9757  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6357  loss_aux: 0.3399\n",
            "02/09 19:54:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:54:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][332/332]  lr: 1.0000e-03  eta: 1:14:49  time: 0.3907  data_time: 0.0093  memory: 6616  grad_norm: 2.2395  loss: 0.9993  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6645  loss_aux: 0.3348\n",
            "02/09 19:54:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 116 epochs\n",
            "02/09 19:54:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][ 20/332]  lr: 1.0000e-03  eta: 1:14:42  time: 0.4483  data_time: 0.0605  memory: 6616  grad_norm: 2.4333  loss: 0.9697  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6478  loss_aux: 0.3219\n",
            "02/09 19:54:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][ 40/332]  lr: 1.0000e-03  eta: 1:14:34  time: 0.3957  data_time: 0.0102  memory: 6616  grad_norm: 2.2696  loss: 0.9687  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6488  loss_aux: 0.3199\n",
            "02/09 19:54:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][ 60/332]  lr: 1.0000e-03  eta: 1:14:26  time: 0.3961  data_time: 0.0105  memory: 6616  grad_norm: 2.1146  loss: 0.9662  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6403  loss_aux: 0.3259\n",
            "02/09 19:55:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][ 80/332]  lr: 1.0000e-03  eta: 1:14:18  time: 0.3960  data_time: 0.0103  memory: 6616  grad_norm: 2.2222  loss: 0.9862  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6550  loss_aux: 0.3312\n",
            "02/09 19:55:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][100/332]  lr: 1.0000e-03  eta: 1:14:10  time: 0.3961  data_time: 0.0105  memory: 6616  grad_norm: 2.1441  loss: 0.9893  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6513  loss_aux: 0.3380\n",
            "02/09 19:55:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][120/332]  lr: 1.0000e-03  eta: 1:14:02  time: 0.3973  data_time: 0.0107  memory: 6616  grad_norm: 2.2225  loss: 0.9970  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6676  loss_aux: 0.3294\n",
            "02/09 19:55:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][140/332]  lr: 1.0000e-03  eta: 1:13:54  time: 0.3956  data_time: 0.0101  memory: 6616  grad_norm: 2.4222  loss: 0.9872  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6552  loss_aux: 0.3320\n",
            "02/09 19:55:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][160/332]  lr: 1.0000e-03  eta: 1:13:46  time: 0.3973  data_time: 0.0111  memory: 6616  grad_norm: 2.2934  loss: 0.9727  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6439  loss_aux: 0.3288\n",
            "02/09 19:55:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][180/332]  lr: 1.0000e-03  eta: 1:13:38  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 2.0725  loss: 0.9638  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6301  loss_aux: 0.3337\n",
            "02/09 19:55:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][200/332]  lr: 1.0000e-03  eta: 1:13:30  time: 0.3955  data_time: 0.0101  memory: 6616  grad_norm: 2.2115  loss: 0.9387  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6243  loss_aux: 0.3145\n",
            "02/09 19:56:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][220/332]  lr: 1.0000e-03  eta: 1:13:22  time: 0.3960  data_time: 0.0103  memory: 6616  grad_norm: 2.2774  loss: 1.0012  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6563  loss_aux: 0.3449\n",
            "02/09 19:56:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][240/332]  lr: 1.0000e-03  eta: 1:13:14  time: 0.3968  data_time: 0.0108  memory: 6616  grad_norm: 2.1676  loss: 1.0249  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6780  loss_aux: 0.3469\n",
            "02/09 19:56:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][260/332]  lr: 1.0000e-03  eta: 1:13:06  time: 0.3964  data_time: 0.0104  memory: 6616  grad_norm: 2.0236  loss: 1.0060  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6781  loss_aux: 0.3280\n",
            "02/09 19:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][280/332]  lr: 1.0000e-03  eta: 1:12:58  time: 0.3970  data_time: 0.0112  memory: 6616  grad_norm: 2.1032  loss: 0.9860  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6646  loss_aux: 0.3214\n",
            "02/09 19:56:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][300/332]  lr: 1.0000e-03  eta: 1:12:50  time: 0.3964  data_time: 0.0104  memory: 6616  grad_norm: 2.1048  loss: 0.9567  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6409  loss_aux: 0.3158\n",
            "02/09 19:56:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][320/332]  lr: 1.0000e-03  eta: 1:12:42  time: 0.3962  data_time: 0.0101  memory: 6616  grad_norm: 2.0708  loss: 0.9938  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6594  loss_aux: 0.3345\n",
            "02/09 19:56:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:56:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][332/332]  lr: 1.0000e-03  eta: 1:12:37  time: 0.3906  data_time: 0.0096  memory: 6616  grad_norm: 2.1891  loss: 0.9561  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6397  loss_aux: 0.3165\n",
            "02/09 19:56:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 117 epochs\n",
            "02/09 19:56:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][ 20/332]  lr: 1.0000e-03  eta: 1:12:30  time: 0.4460  data_time: 0.0576  memory: 6616  grad_norm: 2.1059  loss: 0.9346  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6205  loss_aux: 0.3141\n",
            "02/09 19:57:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][ 40/332]  lr: 1.0000e-03  eta: 1:12:22  time: 0.3951  data_time: 0.0097  memory: 6616  grad_norm: 2.1143  loss: 0.9750  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6473  loss_aux: 0.3277\n",
            "02/09 19:57:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][ 60/332]  lr: 1.0000e-03  eta: 1:12:14  time: 0.3957  data_time: 0.0100  memory: 6616  grad_norm: 2.4191  loss: 0.9782  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6507  loss_aux: 0.3275\n",
            "02/09 19:57:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][ 80/332]  lr: 1.0000e-03  eta: 1:12:06  time: 0.3967  data_time: 0.0108  memory: 6616  grad_norm: 2.2529  loss: 1.0112  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6875  loss_aux: 0.3236\n",
            "02/09 19:57:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][100/332]  lr: 1.0000e-03  eta: 1:11:58  time: 0.3953  data_time: 0.0097  memory: 6616  grad_norm: 2.3158  loss: 0.9477  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6356  loss_aux: 0.3121\n",
            "02/09 19:57:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][120/332]  lr: 1.0000e-03  eta: 1:11:50  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 2.4757  loss: 1.0437  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6943  loss_aux: 0.3494\n",
            "02/09 19:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][140/332]  lr: 1.0000e-03  eta: 1:11:42  time: 0.3962  data_time: 0.0107  memory: 6616  grad_norm: 2.1342  loss: 0.9723  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6555  loss_aux: 0.3168\n",
            "02/09 19:57:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:57:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][160/332]  lr: 1.0000e-03  eta: 1:11:34  time: 0.3954  data_time: 0.0101  memory: 6616  grad_norm: 2.3771  loss: 0.9555  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6296  loss_aux: 0.3260\n",
            "02/09 19:58:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][180/332]  lr: 1.0000e-03  eta: 1:11:26  time: 0.3966  data_time: 0.0108  memory: 6616  grad_norm: 2.5410  loss: 1.0030  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6745  loss_aux: 0.3285\n",
            "02/09 19:58:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][200/332]  lr: 1.0000e-03  eta: 1:11:18  time: 0.3949  data_time: 0.0100  memory: 6616  grad_norm: 2.2639  loss: 0.9965  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6698  loss_aux: 0.3267\n",
            "02/09 19:58:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][220/332]  lr: 1.0000e-03  eta: 1:11:10  time: 0.3964  data_time: 0.0105  memory: 6616  grad_norm: 2.0873  loss: 0.9530  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6355  loss_aux: 0.3175\n",
            "02/09 19:58:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][240/332]  lr: 1.0000e-03  eta: 1:11:02  time: 0.3968  data_time: 0.0106  memory: 6616  grad_norm: 2.0346  loss: 0.9051  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5991  loss_aux: 0.3060\n",
            "02/09 19:58:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][260/332]  lr: 1.0000e-03  eta: 1:10:54  time: 0.3959  data_time: 0.0102  memory: 6616  grad_norm: 2.4889  loss: 0.9532  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6245  loss_aux: 0.3287\n",
            "02/09 19:58:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][280/332]  lr: 1.0000e-03  eta: 1:10:46  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 2.5800  loss: 1.0571  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7070  loss_aux: 0.3501\n",
            "02/09 19:58:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][300/332]  lr: 1.0000e-03  eta: 1:10:38  time: 0.3966  data_time: 0.0106  memory: 6616  grad_norm: 2.3945  loss: 0.9766  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6570  loss_aux: 0.3196\n",
            "02/09 19:58:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][320/332]  lr: 1.0000e-03  eta: 1:10:30  time: 0.3951  data_time: 0.0098  memory: 6616  grad_norm: 2.3997  loss: 0.9693  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6481  loss_aux: 0.3213\n",
            "02/09 19:59:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 19:59:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][332/332]  lr: 1.0000e-03  eta: 1:10:25  time: 0.3907  data_time: 0.0096  memory: 6616  grad_norm: 2.4105  loss: 0.9781  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6465  loss_aux: 0.3316\n",
            "02/09 19:59:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 118 epochs\n",
            "02/09 19:59:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][ 20/332]  lr: 1.0000e-03  eta: 1:10:18  time: 0.4381  data_time: 0.0511  memory: 6616  grad_norm: 2.5828  loss: 1.0507  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7037  loss_aux: 0.3470\n",
            "02/09 19:59:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][ 40/332]  lr: 1.0000e-03  eta: 1:10:10  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 1.9813  loss: 0.9574  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6385  loss_aux: 0.3188\n",
            "02/09 19:59:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][ 60/332]  lr: 1.0000e-03  eta: 1:10:02  time: 0.3960  data_time: 0.0104  memory: 6616  grad_norm: 2.1649  loss: 0.9589  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6377  loss_aux: 0.3212\n",
            "02/09 19:59:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][ 80/332]  lr: 1.0000e-03  eta: 1:09:54  time: 0.3961  data_time: 0.0103  memory: 6616  grad_norm: 2.3850  loss: 0.9740  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6489  loss_aux: 0.3251\n",
            "02/09 19:59:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][100/332]  lr: 1.0000e-03  eta: 1:09:46  time: 0.3958  data_time: 0.0102  memory: 6616  grad_norm: 2.1500  loss: 1.0536  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6956  loss_aux: 0.3580\n",
            "02/09 19:59:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][120/332]  lr: 1.0000e-03  eta: 1:09:38  time: 0.3966  data_time: 0.0108  memory: 6616  grad_norm: 2.1960  loss: 1.0144  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6697  loss_aux: 0.3447\n",
            "02/09 19:59:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][140/332]  lr: 1.0000e-03  eta: 1:09:30  time: 0.3961  data_time: 0.0101  memory: 6616  grad_norm: 2.1321  loss: 0.9277  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6146  loss_aux: 0.3131\n",
            "02/09 20:00:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][160/332]  lr: 1.0000e-03  eta: 1:09:22  time: 0.3952  data_time: 0.0098  memory: 6616  grad_norm: 2.0760  loss: 0.9707  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6456  loss_aux: 0.3251\n",
            "02/09 20:00:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][180/332]  lr: 1.0000e-03  eta: 1:09:14  time: 0.3965  data_time: 0.0107  memory: 6616  grad_norm: 2.1027  loss: 0.9482  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6336  loss_aux: 0.3146\n",
            "02/09 20:00:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][200/332]  lr: 1.0000e-03  eta: 1:09:06  time: 0.3964  data_time: 0.0106  memory: 6616  grad_norm: 2.1741  loss: 0.9771  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6576  loss_aux: 0.3195\n",
            "02/09 20:00:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][220/332]  lr: 1.0000e-03  eta: 1:08:58  time: 0.3963  data_time: 0.0104  memory: 6616  grad_norm: 2.3456  loss: 0.9851  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6498  loss_aux: 0.3354\n",
            "02/09 20:00:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][240/332]  lr: 1.0000e-03  eta: 1:08:50  time: 0.3972  data_time: 0.0110  memory: 6616  grad_norm: 2.7009  loss: 1.0454  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7046  loss_aux: 0.3408\n",
            "02/09 20:00:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][260/332]  lr: 1.0000e-03  eta: 1:08:42  time: 0.3966  data_time: 0.0106  memory: 6616  grad_norm: 2.3822  loss: 0.9880  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6469  loss_aux: 0.3411\n",
            "02/09 20:00:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][280/332]  lr: 1.0000e-03  eta: 1:08:34  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 2.0690  loss: 0.9623  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6427  loss_aux: 0.3196\n",
            "02/09 20:01:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][300/332]  lr: 1.0000e-03  eta: 1:08:26  time: 0.3961  data_time: 0.0105  memory: 6616  grad_norm: 2.5159  loss: 1.0312  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6954  loss_aux: 0.3358\n",
            "02/09 20:01:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][320/332]  lr: 1.0000e-03  eta: 1:08:18  time: 0.3954  data_time: 0.0097  memory: 6616  grad_norm: 2.2717  loss: 0.9854  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6551  loss_aux: 0.3303\n",
            "02/09 20:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][332/332]  lr: 1.0000e-03  eta: 1:08:13  time: 0.3907  data_time: 0.0096  memory: 6616  grad_norm: 2.0977  loss: 0.9539  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6379  loss_aux: 0.3160\n",
            "02/09 20:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 119 epochs\n",
            "02/09 20:01:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][ 20/332]  lr: 1.0000e-03  eta: 1:08:06  time: 0.4385  data_time: 0.0494  memory: 6616  grad_norm: 2.0776  loss: 0.9764  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6449  loss_aux: 0.3315\n",
            "02/09 20:01:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][ 40/332]  lr: 1.0000e-03  eta: 1:07:58  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 2.3442  loss: 1.0491  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6990  loss_aux: 0.3501\n",
            "02/09 20:01:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][ 60/332]  lr: 1.0000e-03  eta: 1:07:50  time: 0.3955  data_time: 0.0103  memory: 6616  grad_norm: 2.1023  loss: 0.9556  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6360  loss_aux: 0.3195\n",
            "02/09 20:01:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][ 80/332]  lr: 1.0000e-03  eta: 1:07:42  time: 0.3963  data_time: 0.0105  memory: 6616  grad_norm: 2.1736  loss: 0.9709  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6483  loss_aux: 0.3226\n",
            "02/09 20:01:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][100/332]  lr: 1.0000e-03  eta: 1:07:34  time: 0.3955  data_time: 0.0100  memory: 6616  grad_norm: 1.9601  loss: 0.9298  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6143  loss_aux: 0.3155\n",
            "02/09 20:02:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][120/332]  lr: 1.0000e-03  eta: 1:07:26  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 2.1837  loss: 0.9818  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6553  loss_aux: 0.3266\n",
            "02/09 20:02:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][140/332]  lr: 1.0000e-03  eta: 1:07:18  time: 0.3964  data_time: 0.0106  memory: 6616  grad_norm: 2.4711  loss: 1.0434  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6912  loss_aux: 0.3522\n",
            "02/09 20:02:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][160/332]  lr: 1.0000e-03  eta: 1:07:10  time: 0.3947  data_time: 0.0097  memory: 6616  grad_norm: 2.3316  loss: 1.0455  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6999  loss_aux: 0.3455\n",
            "02/09 20:02:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][180/332]  lr: 1.0000e-03  eta: 1:07:02  time: 0.3949  data_time: 0.0097  memory: 6616  grad_norm: 2.0824  loss: 0.9987  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6677  loss_aux: 0.3310\n",
            "02/09 20:02:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][200/332]  lr: 1.0000e-03  eta: 1:06:54  time: 0.3968  data_time: 0.0105  memory: 6616  grad_norm: 2.1788  loss: 0.9935  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6613  loss_aux: 0.3322\n",
            "02/09 20:02:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][220/332]  lr: 1.0000e-03  eta: 1:06:46  time: 0.3951  data_time: 0.0099  memory: 6616  grad_norm: 2.1472  loss: 0.9312  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6164  loss_aux: 0.3147\n",
            "02/09 20:02:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][240/332]  lr: 1.0000e-03  eta: 1:06:38  time: 0.3965  data_time: 0.0107  memory: 6616  grad_norm: 2.3001  loss: 0.9965  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6663  loss_aux: 0.3301\n",
            "02/09 20:03:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][260/332]  lr: 1.0000e-03  eta: 1:06:30  time: 0.3954  data_time: 0.0100  memory: 6616  grad_norm: 2.2898  loss: 0.9300  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6088  loss_aux: 0.3213\n",
            "02/09 20:03:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][280/332]  lr: 1.0000e-03  eta: 1:06:22  time: 0.3940  data_time: 0.0094  memory: 6616  grad_norm: 2.5099  loss: 0.9732  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6476  loss_aux: 0.3256\n",
            "02/09 20:03:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][300/332]  lr: 1.0000e-03  eta: 1:06:14  time: 0.3964  data_time: 0.0105  memory: 6616  grad_norm: 2.2001  loss: 0.9811  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6553  loss_aux: 0.3258\n",
            "02/09 20:03:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][320/332]  lr: 1.0000e-03  eta: 1:06:06  time: 0.3965  data_time: 0.0106  memory: 6616  grad_norm: 2.2773  loss: 0.9303  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6199  loss_aux: 0.3104\n",
            "02/09 20:03:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:03:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][332/332]  lr: 1.0000e-03  eta: 1:06:01  time: 0.3908  data_time: 0.0097  memory: 6616  grad_norm: 2.2803  loss: 0.9704  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6398  loss_aux: 0.3306\n",
            "02/09 20:03:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 120 epochs\n",
            "02/09 20:03:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [120][20/42]    eta: 0:00:04  time: 0.2117  data_time: 0.1002  memory: 1447  \n",
            "02/09 20:03:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [120][40/42]    eta: 0:00:00  time: 0.1207  data_time: 0.0190  memory: 1447  \n",
            "02/09 20:03:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [120][42/42]    acc/top1: 0.6145  acc/top5: 1.0000  acc/mean1: 0.5951  data_time: 0.0559  time: 0.1597\n",
            "02/09 20:03:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][ 20/332]  lr: 1.0000e-03  eta: 1:05:53  time: 0.4378  data_time: 0.0504  memory: 6616  grad_norm: 2.3203  loss: 0.9727  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6393  loss_aux: 0.3334\n",
            "02/09 20:03:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][ 40/332]  lr: 1.0000e-03  eta: 1:05:46  time: 0.3960  data_time: 0.0107  memory: 6616  grad_norm: 2.5610  loss: 1.0143  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6793  loss_aux: 0.3350\n",
            "02/09 20:04:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][ 60/332]  lr: 1.0000e-03  eta: 1:05:38  time: 0.3963  data_time: 0.0109  memory: 6616  grad_norm: 2.3326  loss: 0.9679  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6394  loss_aux: 0.3285\n",
            "02/09 20:04:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][ 80/332]  lr: 1.0000e-03  eta: 1:05:30  time: 0.3961  data_time: 0.0101  memory: 6616  grad_norm: 2.4429  loss: 0.9862  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6536  loss_aux: 0.3326\n",
            "02/09 20:04:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][100/332]  lr: 1.0000e-03  eta: 1:05:22  time: 0.3970  data_time: 0.0109  memory: 6616  grad_norm: 2.7329  loss: 0.9883  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6577  loss_aux: 0.3306\n",
            "02/09 20:04:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][120/332]  lr: 1.0000e-03  eta: 1:05:14  time: 0.3966  data_time: 0.0104  memory: 6616  grad_norm: 2.4451  loss: 0.9467  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6259  loss_aux: 0.3208\n",
            "02/09 20:04:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][140/332]  lr: 1.0000e-03  eta: 1:05:06  time: 0.3952  data_time: 0.0097  memory: 6616  grad_norm: 2.1757  loss: 0.9791  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6460  loss_aux: 0.3331\n",
            "02/09 20:04:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:04:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][160/332]  lr: 1.0000e-03  eta: 1:04:58  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 2.5219  loss: 0.9344  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6244  loss_aux: 0.3100\n",
            "02/09 20:04:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][180/332]  lr: 1.0000e-03  eta: 1:04:50  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 2.2230  loss: 0.9711  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6373  loss_aux: 0.3338\n",
            "02/09 20:04:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][200/332]  lr: 1.0000e-03  eta: 1:04:42  time: 0.3953  data_time: 0.0100  memory: 6616  grad_norm: 2.2826  loss: 1.0277  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6859  loss_aux: 0.3418\n",
            "02/09 20:05:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][220/332]  lr: 1.0000e-03  eta: 1:04:34  time: 0.3965  data_time: 0.0106  memory: 6616  grad_norm: 2.0465  loss: 1.0351  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6972  loss_aux: 0.3379\n",
            "02/09 20:05:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][240/332]  lr: 1.0000e-03  eta: 1:04:26  time: 0.3962  data_time: 0.0103  memory: 6616  grad_norm: 2.0682  loss: 0.9758  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6596  loss_aux: 0.3162\n",
            "02/09 20:05:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][260/332]  lr: 1.0000e-03  eta: 1:04:18  time: 0.3952  data_time: 0.0098  memory: 6616  grad_norm: 2.2184  loss: 0.9930  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6649  loss_aux: 0.3281\n",
            "02/09 20:05:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][280/332]  lr: 1.0000e-03  eta: 1:04:10  time: 0.3953  data_time: 0.0101  memory: 6616  grad_norm: 2.0573  loss: 1.0092  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6721  loss_aux: 0.3371\n",
            "02/09 20:05:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][300/332]  lr: 1.0000e-03  eta: 1:04:02  time: 0.3966  data_time: 0.0107  memory: 6616  grad_norm: 2.0560  loss: 0.9765  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6515  loss_aux: 0.3250\n",
            "02/09 20:05:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][320/332]  lr: 1.0000e-03  eta: 1:03:54  time: 0.3947  data_time: 0.0096  memory: 6616  grad_norm: 2.0975  loss: 0.9683  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6466  loss_aux: 0.3218\n",
            "02/09 20:05:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:05:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][332/332]  lr: 1.0000e-03  eta: 1:03:49  time: 0.3900  data_time: 0.0094  memory: 6616  grad_norm: 1.9800  loss: 0.8930  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6001  loss_aux: 0.2930\n",
            "02/09 20:05:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 121 epochs\n",
            "02/09 20:06:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][ 20/332]  lr: 1.0000e-03  eta: 1:03:41  time: 0.4428  data_time: 0.0542  memory: 6616  grad_norm: 2.3591  loss: 1.0359  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6943  loss_aux: 0.3417\n",
            "02/09 20:06:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][ 40/332]  lr: 1.0000e-03  eta: 1:03:33  time: 0.3947  data_time: 0.0099  memory: 6616  grad_norm: 2.4540  loss: 1.0077  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6748  loss_aux: 0.3329\n",
            "02/09 20:06:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][ 60/332]  lr: 1.0000e-03  eta: 1:03:26  time: 0.3967  data_time: 0.0110  memory: 6616  grad_norm: 2.2331  loss: 0.9820  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6552  loss_aux: 0.3268\n",
            "02/09 20:06:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][ 80/332]  lr: 1.0000e-03  eta: 1:03:18  time: 0.3948  data_time: 0.0098  memory: 6616  grad_norm: 2.1250  loss: 0.9978  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6602  loss_aux: 0.3376\n",
            "02/09 20:06:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][100/332]  lr: 1.0000e-03  eta: 1:03:10  time: 0.3978  data_time: 0.0114  memory: 6616  grad_norm: 2.0883  loss: 0.9698  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6351  loss_aux: 0.3347\n",
            "02/09 20:06:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][120/332]  lr: 1.0000e-03  eta: 1:03:02  time: 0.3963  data_time: 0.0107  memory: 6616  grad_norm: 2.3220  loss: 0.9473  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6277  loss_aux: 0.3197\n",
            "02/09 20:06:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][140/332]  lr: 1.0000e-03  eta: 1:02:54  time: 0.3958  data_time: 0.0104  memory: 6616  grad_norm: 2.2357  loss: 0.9508  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6301  loss_aux: 0.3207\n",
            "02/09 20:06:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][160/332]  lr: 1.0000e-03  eta: 1:02:46  time: 0.3953  data_time: 0.0099  memory: 6616  grad_norm: 2.3026  loss: 0.9727  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6452  loss_aux: 0.3275\n",
            "02/09 20:07:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][180/332]  lr: 1.0000e-03  eta: 1:02:38  time: 0.3971  data_time: 0.0109  memory: 6616  grad_norm: 2.5715  loss: 0.9981  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6623  loss_aux: 0.3358\n",
            "02/09 20:07:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][200/332]  lr: 1.0000e-03  eta: 1:02:30  time: 0.3970  data_time: 0.0109  memory: 6616  grad_norm: 2.4619  loss: 0.9901  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6489  loss_aux: 0.3412\n",
            "02/09 20:07:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][220/332]  lr: 1.0000e-03  eta: 1:02:22  time: 0.3950  data_time: 0.0097  memory: 6616  grad_norm: 2.3619  loss: 0.9709  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6458  loss_aux: 0.3251\n",
            "02/09 20:07:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][240/332]  lr: 1.0000e-03  eta: 1:02:14  time: 0.3957  data_time: 0.0101  memory: 6616  grad_norm: 2.4264  loss: 1.0191  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6906  loss_aux: 0.3285\n",
            "02/09 20:07:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][260/332]  lr: 1.0000e-03  eta: 1:02:06  time: 0.3963  data_time: 0.0105  memory: 6616  grad_norm: 2.6629  loss: 1.0123  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6721  loss_aux: 0.3402\n",
            "02/09 20:07:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][280/332]  lr: 1.0000e-03  eta: 1:01:58  time: 0.3964  data_time: 0.0106  memory: 6616  grad_norm: 2.3910  loss: 0.9325  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6141  loss_aux: 0.3184\n",
            "02/09 20:07:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][300/332]  lr: 1.0000e-03  eta: 1:01:50  time: 0.3969  data_time: 0.0108  memory: 6616  grad_norm: 2.3844  loss: 0.9616  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6384  loss_aux: 0.3232\n",
            "02/09 20:08:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][320/332]  lr: 1.0000e-03  eta: 1:01:42  time: 0.3951  data_time: 0.0098  memory: 6616  grad_norm: 2.1632  loss: 0.9430  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6180  loss_aux: 0.3250\n",
            "02/09 20:08:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:08:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][332/332]  lr: 1.0000e-03  eta: 1:01:37  time: 0.3901  data_time: 0.0091  memory: 6616  grad_norm: 2.2395  loss: 0.9883  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6461  loss_aux: 0.3422\n",
            "02/09 20:08:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 122 epochs\n",
            "02/09 20:08:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][ 20/332]  lr: 1.0000e-03  eta: 1:01:29  time: 0.4394  data_time: 0.0503  memory: 6616  grad_norm: 2.1747  loss: 0.9395  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6283  loss_aux: 0.3112\n",
            "02/09 20:08:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][ 40/332]  lr: 1.0000e-03  eta: 1:01:21  time: 0.3960  data_time: 0.0106  memory: 6616  grad_norm: 2.3889  loss: 0.9657  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6456  loss_aux: 0.3201\n",
            "02/09 20:08:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][ 60/332]  lr: 1.0000e-03  eta: 1:01:14  time: 0.3953  data_time: 0.0098  memory: 6616  grad_norm: 2.1519  loss: 0.9716  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6431  loss_aux: 0.3285\n",
            "02/09 20:08:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][ 80/332]  lr: 1.0000e-03  eta: 1:01:06  time: 0.3964  data_time: 0.0106  memory: 6616  grad_norm: 2.4135  loss: 0.9721  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6514  loss_aux: 0.3206\n",
            "02/09 20:08:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][100/332]  lr: 1.0000e-03  eta: 1:00:58  time: 0.3968  data_time: 0.0107  memory: 6616  grad_norm: 2.4140  loss: 1.0615  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6984  loss_aux: 0.3631\n",
            "02/09 20:08:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][120/332]  lr: 1.0000e-03  eta: 1:00:50  time: 0.3954  data_time: 0.0099  memory: 6616  grad_norm: 2.1723  loss: 0.9917  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6586  loss_aux: 0.3331\n",
            "02/09 20:09:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][140/332]  lr: 1.0000e-03  eta: 1:00:42  time: 0.3961  data_time: 0.0105  memory: 6616  grad_norm: 2.1999  loss: 0.9969  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6705  loss_aux: 0.3264\n",
            "02/09 20:09:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][160/332]  lr: 1.0000e-03  eta: 1:00:34  time: 0.3959  data_time: 0.0106  memory: 6616  grad_norm: 2.8171  loss: 1.0448  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7023  loss_aux: 0.3425\n",
            "02/09 20:09:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][180/332]  lr: 1.0000e-03  eta: 1:00:26  time: 0.3951  data_time: 0.0097  memory: 6616  grad_norm: 2.3557  loss: 1.0068  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6680  loss_aux: 0.3388\n",
            "02/09 20:09:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][200/332]  lr: 1.0000e-03  eta: 1:00:18  time: 0.3960  data_time: 0.0101  memory: 6616  grad_norm: 2.1189  loss: 0.9443  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6271  loss_aux: 0.3172\n",
            "02/09 20:09:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][220/332]  lr: 1.0000e-03  eta: 1:00:10  time: 0.3954  data_time: 0.0098  memory: 6616  grad_norm: 2.3754  loss: 1.0055  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6670  loss_aux: 0.3385\n",
            "02/09 20:09:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][240/332]  lr: 1.0000e-03  eta: 1:00:02  time: 0.3951  data_time: 0.0098  memory: 6616  grad_norm: 2.2949  loss: 0.9674  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6444  loss_aux: 0.3231\n",
            "02/09 20:09:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][260/332]  lr: 1.0000e-03  eta: 0:59:54  time: 0.3964  data_time: 0.0106  memory: 6616  grad_norm: 2.3211  loss: 0.9846  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6600  loss_aux: 0.3246\n",
            "02/09 20:10:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][280/332]  lr: 1.0000e-03  eta: 0:59:46  time: 0.3956  data_time: 0.0106  memory: 6616  grad_norm: 2.3015  loss: 0.9113  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6058  loss_aux: 0.3055\n",
            "02/09 20:10:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][300/332]  lr: 1.0000e-03  eta: 0:59:38  time: 0.3963  data_time: 0.0107  memory: 6616  grad_norm: 2.3974  loss: 0.9067  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6017  loss_aux: 0.3050\n",
            "02/09 20:10:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][320/332]  lr: 1.0000e-03  eta: 0:59:30  time: 0.3959  data_time: 0.0103  memory: 6616  grad_norm: 2.4247  loss: 1.0337  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6850  loss_aux: 0.3487\n",
            "02/09 20:10:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:10:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][332/332]  lr: 1.0000e-03  eta: 0:59:25  time: 0.3900  data_time: 0.0093  memory: 6616  grad_norm: 2.4925  loss: 1.0200  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6732  loss_aux: 0.3468\n",
            "02/09 20:10:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 123 epochs\n",
            "02/09 20:10:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][ 20/332]  lr: 1.0000e-03  eta: 0:59:17  time: 0.4640  data_time: 0.0759  memory: 6616  grad_norm: 2.7385  loss: 1.0242  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6755  loss_aux: 0.3487\n",
            "02/09 20:10:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][ 40/332]  lr: 1.0000e-03  eta: 0:59:10  time: 0.3954  data_time: 0.0099  memory: 6616  grad_norm: 2.2521  loss: 1.0111  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6677  loss_aux: 0.3434\n",
            "02/09 20:10:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][ 60/332]  lr: 1.0000e-03  eta: 0:59:02  time: 0.3943  data_time: 0.0095  memory: 6616  grad_norm: 2.4371  loss: 0.9227  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6059  loss_aux: 0.3168\n",
            "02/09 20:10:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][ 80/332]  lr: 1.0000e-03  eta: 0:58:54  time: 0.3955  data_time: 0.0099  memory: 6616  grad_norm: 2.2558  loss: 0.9704  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6493  loss_aux: 0.3211\n",
            "02/09 20:11:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][100/332]  lr: 1.0000e-03  eta: 0:58:46  time: 0.3958  data_time: 0.0102  memory: 6616  grad_norm: 2.1614  loss: 0.9592  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6361  loss_aux: 0.3231\n",
            "02/09 20:11:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][120/332]  lr: 1.0000e-03  eta: 0:58:38  time: 0.3945  data_time: 0.0097  memory: 6616  grad_norm: 2.2087  loss: 1.0423  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6960  loss_aux: 0.3463\n",
            "02/09 20:11:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][140/332]  lr: 1.0000e-03  eta: 0:58:30  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 1.9994  loss: 0.9710  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6418  loss_aux: 0.3292\n",
            "02/09 20:11:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][160/332]  lr: 1.0000e-03  eta: 0:58:22  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 2.1439  loss: 0.9854  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6539  loss_aux: 0.3315\n",
            "02/09 20:11:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:11:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][180/332]  lr: 1.0000e-03  eta: 0:58:14  time: 0.3949  data_time: 0.0099  memory: 6616  grad_norm: 2.2008  loss: 1.0141  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6768  loss_aux: 0.3373\n",
            "02/09 20:11:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][200/332]  lr: 1.0000e-03  eta: 0:58:06  time: 0.3959  data_time: 0.0103  memory: 6616  grad_norm: 2.1349  loss: 1.0303  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6893  loss_aux: 0.3410\n",
            "02/09 20:11:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][220/332]  lr: 1.0000e-03  eta: 0:57:58  time: 0.3961  data_time: 0.0104  memory: 6616  grad_norm: 2.1265  loss: 0.9640  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6320  loss_aux: 0.3319\n",
            "02/09 20:12:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][240/332]  lr: 1.0000e-03  eta: 0:57:50  time: 0.3953  data_time: 0.0098  memory: 6616  grad_norm: 2.1938  loss: 1.0099  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6738  loss_aux: 0.3360\n",
            "02/09 20:12:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][260/332]  lr: 1.0000e-03  eta: 0:57:42  time: 0.3956  data_time: 0.0098  memory: 6616  grad_norm: 2.4215  loss: 1.0227  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6799  loss_aux: 0.3428\n",
            "02/09 20:12:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][280/332]  lr: 1.0000e-03  eta: 0:57:34  time: 0.3950  data_time: 0.0097  memory: 6616  grad_norm: 1.9971  loss: 1.0036  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6769  loss_aux: 0.3267\n",
            "02/09 20:12:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][300/332]  lr: 1.0000e-03  eta: 0:57:26  time: 0.3947  data_time: 0.0095  memory: 6616  grad_norm: 1.8495  loss: 0.9654  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6336  loss_aux: 0.3319\n",
            "02/09 20:12:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][320/332]  lr: 1.0000e-03  eta: 0:57:18  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 2.2190  loss: 1.0111  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6743  loss_aux: 0.3368\n",
            "02/09 20:12:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:12:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][332/332]  lr: 1.0000e-03  eta: 0:57:13  time: 0.3897  data_time: 0.0091  memory: 6616  grad_norm: 2.2518  loss: 0.9615  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6410  loss_aux: 0.3205\n",
            "02/09 20:12:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 124 epochs\n",
            "02/09 20:12:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][ 20/332]  lr: 1.0000e-03  eta: 0:57:05  time: 0.4486  data_time: 0.0592  memory: 6616  grad_norm: 2.3273  loss: 0.9878  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6602  loss_aux: 0.3276\n",
            "02/09 20:12:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][ 40/332]  lr: 1.0000e-03  eta: 0:56:57  time: 0.3960  data_time: 0.0107  memory: 6616  grad_norm: 2.3768  loss: 0.9592  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6341  loss_aux: 0.3252\n",
            "02/09 20:13:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][ 60/332]  lr: 1.0000e-03  eta: 0:56:50  time: 0.3967  data_time: 0.0108  memory: 6616  grad_norm: 2.3628  loss: 0.9712  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6461  loss_aux: 0.3251\n",
            "02/09 20:13:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][ 80/332]  lr: 1.0000e-03  eta: 0:56:42  time: 0.3962  data_time: 0.0107  memory: 6616  grad_norm: 2.3746  loss: 0.9528  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6274  loss_aux: 0.3254\n",
            "02/09 20:13:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][100/332]  lr: 1.0000e-03  eta: 0:56:34  time: 0.3960  data_time: 0.0105  memory: 6616  grad_norm: 2.5168  loss: 1.0231  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6779  loss_aux: 0.3452\n",
            "02/09 20:13:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][120/332]  lr: 1.0000e-03  eta: 0:56:26  time: 0.3957  data_time: 0.0101  memory: 6616  grad_norm: 2.6387  loss: 1.0337  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7020  loss_aux: 0.3317\n",
            "02/09 20:13:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][140/332]  lr: 1.0000e-03  eta: 0:56:18  time: 0.3952  data_time: 0.0099  memory: 6616  grad_norm: 2.2309  loss: 0.9545  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6284  loss_aux: 0.3260\n",
            "02/09 20:13:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][160/332]  lr: 1.0000e-03  eta: 0:56:10  time: 0.3960  data_time: 0.0104  memory: 6616  grad_norm: 2.3930  loss: 0.9500  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6254  loss_aux: 0.3245\n",
            "02/09 20:13:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][180/332]  lr: 1.0000e-03  eta: 0:56:02  time: 0.3969  data_time: 0.0106  memory: 6616  grad_norm: 2.4179  loss: 1.0088  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6812  loss_aux: 0.3276\n",
            "02/09 20:13:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][200/332]  lr: 1.0000e-03  eta: 0:55:54  time: 0.3958  data_time: 0.0100  memory: 6616  grad_norm: 2.3317  loss: 0.9463  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6297  loss_aux: 0.3165\n",
            "02/09 20:14:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][220/332]  lr: 1.0000e-03  eta: 0:55:46  time: 0.3962  data_time: 0.0104  memory: 6616  grad_norm: 2.6314  loss: 1.0392  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6948  loss_aux: 0.3444\n",
            "02/09 20:14:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][240/332]  lr: 1.0000e-03  eta: 0:55:38  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 2.2878  loss: 1.0104  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6701  loss_aux: 0.3403\n",
            "02/09 20:14:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][260/332]  lr: 1.0000e-03  eta: 0:55:30  time: 0.3976  data_time: 0.0109  memory: 6616  grad_norm: 2.0166  loss: 0.8965  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5945  loss_aux: 0.3020\n",
            "02/09 20:14:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][280/332]  lr: 1.0000e-03  eta: 0:55:22  time: 0.3953  data_time: 0.0100  memory: 6616  grad_norm: 2.1774  loss: 0.9304  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6215  loss_aux: 0.3089\n",
            "02/09 20:14:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][300/332]  lr: 1.0000e-03  eta: 0:55:14  time: 0.3960  data_time: 0.0105  memory: 6616  grad_norm: 2.4290  loss: 1.0946  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7371  loss_aux: 0.3575\n",
            "02/09 20:14:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][320/332]  lr: 1.0000e-03  eta: 0:55:06  time: 0.3959  data_time: 0.0103  memory: 6616  grad_norm: 2.5702  loss: 0.9813  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6541  loss_aux: 0.3272\n",
            "02/09 20:14:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:14:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][332/332]  lr: 1.0000e-03  eta: 0:55:01  time: 0.3898  data_time: 0.0094  memory: 6616  grad_norm: 2.2717  loss: 0.9892  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6588  loss_aux: 0.3304\n",
            "02/09 20:14:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 125 epochs\n",
            "02/09 20:15:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][ 20/332]  lr: 1.0000e-04  eta: 0:54:53  time: 0.4456  data_time: 0.0577  memory: 6616  grad_norm: 2.1263  loss: 0.9364  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6258  loss_aux: 0.3106\n",
            "02/09 20:15:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][ 40/332]  lr: 1.0000e-04  eta: 0:54:45  time: 0.3950  data_time: 0.0099  memory: 6616  grad_norm: 2.1952  loss: 0.9762  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6434  loss_aux: 0.3328\n",
            "02/09 20:15:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][ 60/332]  lr: 1.0000e-04  eta: 0:54:38  time: 0.3948  data_time: 0.0098  memory: 6616  grad_norm: 2.2246  loss: 0.9060  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6002  loss_aux: 0.3058\n",
            "02/09 20:15:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][ 80/332]  lr: 1.0000e-04  eta: 0:54:30  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 2.1574  loss: 0.9369  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6210  loss_aux: 0.3159\n",
            "02/09 20:15:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][100/332]  lr: 1.0000e-04  eta: 0:54:22  time: 0.3958  data_time: 0.0102  memory: 6616  grad_norm: 2.0921  loss: 0.9588  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6393  loss_aux: 0.3195\n",
            "02/09 20:15:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][120/332]  lr: 1.0000e-04  eta: 0:54:14  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 2.2471  loss: 0.9707  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6419  loss_aux: 0.3288\n",
            "02/09 20:15:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][140/332]  lr: 1.0000e-04  eta: 0:54:06  time: 0.3953  data_time: 0.0098  memory: 6616  grad_norm: 2.2090  loss: 0.9990  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6723  loss_aux: 0.3267\n",
            "02/09 20:15:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][160/332]  lr: 1.0000e-04  eta: 0:53:58  time: 0.3955  data_time: 0.0100  memory: 6616  grad_norm: 1.9741  loss: 0.9800  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6525  loss_aux: 0.3275\n",
            "02/09 20:16:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][180/332]  lr: 1.0000e-04  eta: 0:53:50  time: 0.3960  data_time: 0.0101  memory: 6616  grad_norm: 2.1132  loss: 1.0099  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6742  loss_aux: 0.3357\n",
            "02/09 20:16:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][200/332]  lr: 1.0000e-04  eta: 0:53:42  time: 0.3958  data_time: 0.0104  memory: 6616  grad_norm: 2.2600  loss: 1.0365  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6880  loss_aux: 0.3485\n",
            "02/09 20:16:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][220/332]  lr: 1.0000e-04  eta: 0:53:34  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 2.3421  loss: 0.9869  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6644  loss_aux: 0.3225\n",
            "02/09 20:16:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][240/332]  lr: 1.0000e-04  eta: 0:53:26  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 2.2221  loss: 1.0048  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6637  loss_aux: 0.3412\n",
            "02/09 20:16:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][260/332]  lr: 1.0000e-04  eta: 0:53:18  time: 0.3957  data_time: 0.0099  memory: 6616  grad_norm: 2.3520  loss: 0.9788  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6443  loss_aux: 0.3345\n",
            "02/09 20:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][280/332]  lr: 1.0000e-04  eta: 0:53:10  time: 0.3959  data_time: 0.0102  memory: 6616  grad_norm: 1.9969  loss: 0.9544  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6292  loss_aux: 0.3252\n",
            "02/09 20:16:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][300/332]  lr: 1.0000e-04  eta: 0:53:02  time: 0.3957  data_time: 0.0101  memory: 6616  grad_norm: 2.2094  loss: 1.0292  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6901  loss_aux: 0.3390\n",
            "02/09 20:17:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][320/332]  lr: 1.0000e-04  eta: 0:52:54  time: 0.3949  data_time: 0.0097  memory: 6616  grad_norm: 2.0387  loss: 0.9512  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6280  loss_aux: 0.3232\n",
            "02/09 20:17:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:17:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][332/332]  lr: 1.0000e-04  eta: 0:52:49  time: 0.3906  data_time: 0.0096  memory: 6616  grad_norm: 2.1185  loss: 0.9773  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6503  loss_aux: 0.3271\n",
            "02/09 20:17:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 126 epochs\n",
            "02/09 20:17:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][ 20/332]  lr: 1.0000e-04  eta: 0:52:41  time: 0.4423  data_time: 0.0535  memory: 6616  grad_norm: 2.1793  loss: 0.9753  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6459  loss_aux: 0.3293\n",
            "02/09 20:17:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][ 40/332]  lr: 1.0000e-04  eta: 0:52:33  time: 0.3956  data_time: 0.0101  memory: 6616  grad_norm: 2.0711  loss: 0.9815  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6477  loss_aux: 0.3337\n",
            "02/09 20:17:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][ 60/332]  lr: 1.0000e-04  eta: 0:52:25  time: 0.3957  data_time: 0.0104  memory: 6616  grad_norm: 2.2516  loss: 1.0251  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6773  loss_aux: 0.3478\n",
            "02/09 20:17:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][ 80/332]  lr: 1.0000e-04  eta: 0:52:17  time: 0.3961  data_time: 0.0105  memory: 6616  grad_norm: 2.0062  loss: 0.9394  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6197  loss_aux: 0.3197\n",
            "02/09 20:17:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][100/332]  lr: 1.0000e-04  eta: 0:52:10  time: 0.3954  data_time: 0.0098  memory: 6616  grad_norm: 2.1859  loss: 0.9894  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6625  loss_aux: 0.3269\n",
            "02/09 20:17:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][120/332]  lr: 1.0000e-04  eta: 0:52:02  time: 0.3956  data_time: 0.0100  memory: 6616  grad_norm: 2.1893  loss: 0.9937  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6593  loss_aux: 0.3343\n",
            "02/09 20:18:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][140/332]  lr: 1.0000e-04  eta: 0:51:54  time: 0.3964  data_time: 0.0104  memory: 6616  grad_norm: 2.1209  loss: 0.9460  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6205  loss_aux: 0.3256\n",
            "02/09 20:18:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][160/332]  lr: 1.0000e-04  eta: 0:51:46  time: 0.3953  data_time: 0.0098  memory: 6616  grad_norm: 2.1199  loss: 0.9589  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6317  loss_aux: 0.3272\n",
            "02/09 20:18:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:18:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][180/332]  lr: 1.0000e-04  eta: 0:51:38  time: 0.3962  data_time: 0.0105  memory: 6616  grad_norm: 2.1520  loss: 0.9517  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6311  loss_aux: 0.3207\n",
            "02/09 20:18:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][200/332]  lr: 1.0000e-04  eta: 0:51:30  time: 0.3961  data_time: 0.0105  memory: 6616  grad_norm: 2.3085  loss: 1.0242  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6847  loss_aux: 0.3395\n",
            "02/09 20:18:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][220/332]  lr: 1.0000e-04  eta: 0:51:22  time: 0.3958  data_time: 0.0101  memory: 6616  grad_norm: 2.0960  loss: 0.9150  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6062  loss_aux: 0.3088\n",
            "02/09 20:18:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][240/332]  lr: 1.0000e-04  eta: 0:51:14  time: 0.3965  data_time: 0.0107  memory: 6616  grad_norm: 2.2566  loss: 0.9348  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6195  loss_aux: 0.3153\n",
            "02/09 20:18:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][260/332]  lr: 1.0000e-04  eta: 0:51:06  time: 0.3961  data_time: 0.0104  memory: 6616  grad_norm: 2.2491  loss: 0.9812  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6521  loss_aux: 0.3291\n",
            "02/09 20:19:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][280/332]  lr: 1.0000e-04  eta: 0:50:58  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 2.3039  loss: 0.9958  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6508  loss_aux: 0.3450\n",
            "02/09 20:19:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][300/332]  lr: 1.0000e-04  eta: 0:50:50  time: 0.3967  data_time: 0.0104  memory: 6616  grad_norm: 2.1453  loss: 0.9321  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6146  loss_aux: 0.3175\n",
            "02/09 20:19:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][320/332]  lr: 1.0000e-04  eta: 0:50:42  time: 0.3956  data_time: 0.0098  memory: 6616  grad_norm: 2.1684  loss: 0.9811  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6500  loss_aux: 0.3311\n",
            "02/09 20:19:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:19:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][332/332]  lr: 1.0000e-04  eta: 0:50:37  time: 0.3906  data_time: 0.0095  memory: 6616  grad_norm: 2.2956  loss: 1.0144  top1_acc: 0.1667  top5_acc: 1.0000  loss_cls: 0.6740  loss_aux: 0.3404\n",
            "02/09 20:19:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 127 epochs\n",
            "02/09 20:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][ 20/332]  lr: 1.0000e-04  eta: 0:50:29  time: 0.4429  data_time: 0.0544  memory: 6616  grad_norm: 2.2275  loss: 0.9674  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6436  loss_aux: 0.3238\n",
            "02/09 20:19:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][ 40/332]  lr: 1.0000e-04  eta: 0:50:21  time: 0.3954  data_time: 0.0101  memory: 6616  grad_norm: 2.3396  loss: 0.9551  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6347  loss_aux: 0.3204\n",
            "02/09 20:19:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][ 60/332]  lr: 1.0000e-04  eta: 0:50:13  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 2.2970  loss: 0.9206  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6167  loss_aux: 0.3039\n",
            "02/09 20:19:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][ 80/332]  lr: 1.0000e-04  eta: 0:50:05  time: 0.3963  data_time: 0.0106  memory: 6616  grad_norm: 2.0904  loss: 0.9421  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6252  loss_aux: 0.3169\n",
            "02/09 20:20:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][100/332]  lr: 1.0000e-04  eta: 0:49:57  time: 0.3966  data_time: 0.0107  memory: 6616  grad_norm: 2.5172  loss: 1.0214  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6908  loss_aux: 0.3306\n",
            "02/09 20:20:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][120/332]  lr: 1.0000e-04  eta: 0:49:50  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 2.4017  loss: 1.0652  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7102  loss_aux: 0.3551\n",
            "02/09 20:20:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][140/332]  lr: 1.0000e-04  eta: 0:49:42  time: 0.3967  data_time: 0.0108  memory: 6616  grad_norm: 2.2545  loss: 0.9839  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6431  loss_aux: 0.3408\n",
            "02/09 20:20:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][160/332]  lr: 1.0000e-04  eta: 0:49:34  time: 0.3968  data_time: 0.0109  memory: 6616  grad_norm: 2.3158  loss: 0.9839  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6504  loss_aux: 0.3335\n",
            "02/09 20:20:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][180/332]  lr: 1.0000e-04  eta: 0:49:26  time: 0.3963  data_time: 0.0105  memory: 6616  grad_norm: 2.3664  loss: 0.9350  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6177  loss_aux: 0.3173\n",
            "02/09 20:20:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][200/332]  lr: 1.0000e-04  eta: 0:49:18  time: 0.3964  data_time: 0.0107  memory: 6616  grad_norm: 2.3017  loss: 0.9923  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6566  loss_aux: 0.3357\n",
            "02/09 20:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][220/332]  lr: 1.0000e-04  eta: 0:49:10  time: 0.3952  data_time: 0.0099  memory: 6616  grad_norm: 2.2848  loss: 0.9850  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6561  loss_aux: 0.3289\n",
            "02/09 20:21:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][240/332]  lr: 1.0000e-04  eta: 0:49:02  time: 0.3952  data_time: 0.0098  memory: 6616  grad_norm: 2.2292  loss: 0.9421  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6206  loss_aux: 0.3215\n",
            "02/09 20:21:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][260/332]  lr: 1.0000e-04  eta: 0:48:54  time: 0.3959  data_time: 0.0104  memory: 6616  grad_norm: 2.3472  loss: 1.0094  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6713  loss_aux: 0.3381\n",
            "02/09 20:21:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][280/332]  lr: 1.0000e-04  eta: 0:48:46  time: 0.3950  data_time: 0.0098  memory: 6616  grad_norm: 2.2080  loss: 0.9882  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6579  loss_aux: 0.3303\n",
            "02/09 20:21:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][300/332]  lr: 1.0000e-04  eta: 0:48:38  time: 0.3954  data_time: 0.0099  memory: 6616  grad_norm: 2.4976  loss: 1.0143  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6818  loss_aux: 0.3325\n",
            "02/09 20:21:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][320/332]  lr: 1.0000e-04  eta: 0:48:30  time: 0.3955  data_time: 0.0098  memory: 6616  grad_norm: 2.1702  loss: 0.9484  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6316  loss_aux: 0.3168\n",
            "02/09 20:21:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:21:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][332/332]  lr: 1.0000e-04  eta: 0:48:25  time: 0.3903  data_time: 0.0095  memory: 6616  grad_norm: 2.2655  loss: 0.9953  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6676  loss_aux: 0.3278\n",
            "02/09 20:21:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 128 epochs\n",
            "02/09 20:21:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][ 20/332]  lr: 1.0000e-04  eta: 0:48:17  time: 0.4561  data_time: 0.0679  memory: 6616  grad_norm: 2.1030  loss: 0.9840  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6613  loss_aux: 0.3227\n",
            "02/09 20:21:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][ 40/332]  lr: 1.0000e-04  eta: 0:48:09  time: 0.3949  data_time: 0.0097  memory: 6616  grad_norm: 2.1890  loss: 0.9630  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6375  loss_aux: 0.3256\n",
            "02/09 20:22:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][ 60/332]  lr: 1.0000e-04  eta: 0:48:01  time: 0.3948  data_time: 0.0099  memory: 6616  grad_norm: 2.1946  loss: 0.9146  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6027  loss_aux: 0.3120\n",
            "02/09 20:22:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][ 80/332]  lr: 1.0000e-04  eta: 0:47:53  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 2.3488  loss: 1.0218  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6729  loss_aux: 0.3489\n",
            "02/09 20:22:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][100/332]  lr: 1.0000e-04  eta: 0:47:45  time: 0.3959  data_time: 0.0104  memory: 6616  grad_norm: 2.3029  loss: 0.9803  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6493  loss_aux: 0.3309\n",
            "02/09 20:22:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][120/332]  lr: 1.0000e-04  eta: 0:47:38  time: 0.3956  data_time: 0.0101  memory: 6616  grad_norm: 2.1364  loss: 0.9575  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6388  loss_aux: 0.3188\n",
            "02/09 20:22:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][140/332]  lr: 1.0000e-04  eta: 0:47:30  time: 0.3966  data_time: 0.0107  memory: 6616  grad_norm: 2.4973  loss: 1.0147  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6797  loss_aux: 0.3350\n",
            "02/09 20:22:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][160/332]  lr: 1.0000e-04  eta: 0:47:22  time: 0.3966  data_time: 0.0107  memory: 6616  grad_norm: 2.2480  loss: 0.9779  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6470  loss_aux: 0.3309\n",
            "02/09 20:22:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][180/332]  lr: 1.0000e-04  eta: 0:47:14  time: 0.3949  data_time: 0.0099  memory: 6616  grad_norm: 2.3750  loss: 0.9083  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5967  loss_aux: 0.3116\n",
            "02/09 20:22:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][200/332]  lr: 1.0000e-04  eta: 0:47:06  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 2.2547  loss: 0.9768  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6429  loss_aux: 0.3339\n",
            "02/09 20:23:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][220/332]  lr: 1.0000e-04  eta: 0:46:58  time: 0.3964  data_time: 0.0111  memory: 6616  grad_norm: 2.3717  loss: 0.9334  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6162  loss_aux: 0.3173\n",
            "02/09 20:23:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][240/332]  lr: 1.0000e-04  eta: 0:46:50  time: 0.3956  data_time: 0.0101  memory: 6616  grad_norm: 2.4169  loss: 1.0063  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6674  loss_aux: 0.3389\n",
            "02/09 20:23:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][260/332]  lr: 1.0000e-04  eta: 0:46:42  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 2.3315  loss: 0.9861  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6487  loss_aux: 0.3375\n",
            "02/09 20:23:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][280/332]  lr: 1.0000e-04  eta: 0:46:34  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 2.3130  loss: 0.9943  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6654  loss_aux: 0.3289\n",
            "02/09 20:23:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][300/332]  lr: 1.0000e-04  eta: 0:46:26  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 2.3243  loss: 0.9377  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6164  loss_aux: 0.3213\n",
            "02/09 20:23:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][320/332]  lr: 1.0000e-04  eta: 0:46:18  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 2.1466  loss: 0.9218  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6162  loss_aux: 0.3056\n",
            "02/09 20:23:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:23:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][332/332]  lr: 1.0000e-04  eta: 0:46:13  time: 0.3893  data_time: 0.0087  memory: 6616  grad_norm: 2.5872  loss: 0.9766  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6513  loss_aux: 0.3253\n",
            "02/09 20:23:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 129 epochs\n",
            "02/09 20:24:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][ 20/332]  lr: 1.0000e-04  eta: 0:46:05  time: 0.4428  data_time: 0.0552  memory: 6616  grad_norm: 2.3145  loss: 0.9501  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6351  loss_aux: 0.3150\n",
            "02/09 20:24:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][ 40/332]  lr: 1.0000e-04  eta: 0:45:57  time: 0.3947  data_time: 0.0095  memory: 6616  grad_norm: 2.0787  loss: 0.9432  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6257  loss_aux: 0.3175\n",
            "02/09 20:24:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][ 60/332]  lr: 1.0000e-04  eta: 0:45:49  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 2.4418  loss: 1.0002  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6640  loss_aux: 0.3363\n",
            "02/09 20:24:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][ 80/332]  lr: 1.0000e-04  eta: 0:45:41  time: 0.3941  data_time: 0.0096  memory: 6616  grad_norm: 2.3630  loss: 0.9437  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6310  loss_aux: 0.3127\n",
            "02/09 20:24:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][100/332]  lr: 1.0000e-04  eta: 0:45:33  time: 0.3957  data_time: 0.0099  memory: 6616  grad_norm: 2.4356  loss: 0.9838  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6479  loss_aux: 0.3359\n",
            "02/09 20:24:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][120/332]  lr: 1.0000e-04  eta: 0:45:25  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 2.4079  loss: 0.9628  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6337  loss_aux: 0.3291\n",
            "02/09 20:24:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][140/332]  lr: 1.0000e-04  eta: 0:45:17  time: 0.3955  data_time: 0.0108  memory: 6616  grad_norm: 2.2158  loss: 0.9947  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6655  loss_aux: 0.3293\n",
            "02/09 20:24:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][160/332]  lr: 1.0000e-04  eta: 0:45:10  time: 0.3957  data_time: 0.0103  memory: 6616  grad_norm: 2.4545  loss: 0.9980  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6587  loss_aux: 0.3394\n",
            "02/09 20:25:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:25:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][180/332]  lr: 1.0000e-04  eta: 0:45:02  time: 0.3958  data_time: 0.0103  memory: 6616  grad_norm: 2.3133  loss: 0.9817  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6537  loss_aux: 0.3280\n",
            "02/09 20:25:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][200/332]  lr: 1.0000e-04  eta: 0:44:54  time: 0.3963  data_time: 0.0108  memory: 6616  grad_norm: 2.3234  loss: 0.9212  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6136  loss_aux: 0.3076\n",
            "02/09 20:25:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][220/332]  lr: 1.0000e-04  eta: 0:44:46  time: 0.3964  data_time: 0.0106  memory: 6616  grad_norm: 2.5000  loss: 1.0123  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6613  loss_aux: 0.3509\n",
            "02/09 20:25:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][240/332]  lr: 1.0000e-04  eta: 0:44:38  time: 0.3966  data_time: 0.0111  memory: 6616  grad_norm: 2.5672  loss: 0.9491  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6329  loss_aux: 0.3163\n",
            "02/09 20:25:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][260/332]  lr: 1.0000e-04  eta: 0:44:30  time: 0.3955  data_time: 0.0101  memory: 6616  grad_norm: 2.5095  loss: 0.9793  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6497  loss_aux: 0.3297\n",
            "02/09 20:25:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][280/332]  lr: 1.0000e-04  eta: 0:44:22  time: 0.3963  data_time: 0.0105  memory: 6616  grad_norm: 2.3646  loss: 0.9749  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6432  loss_aux: 0.3317\n",
            "02/09 20:25:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][300/332]  lr: 1.0000e-04  eta: 0:44:14  time: 0.3959  data_time: 0.0105  memory: 6616  grad_norm: 2.2364  loss: 1.0078  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6677  loss_aux: 0.3401\n",
            "02/09 20:26:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][320/332]  lr: 1.0000e-04  eta: 0:44:06  time: 0.3946  data_time: 0.0097  memory: 6616  grad_norm: 2.4079  loss: 0.9853  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6585  loss_aux: 0.3268\n",
            "02/09 20:26:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:26:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][332/332]  lr: 1.0000e-04  eta: 0:44:01  time: 0.3899  data_time: 0.0092  memory: 6616  grad_norm: 2.4583  loss: 0.9494  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6400  loss_aux: 0.3094\n",
            "02/09 20:26:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 130 epochs\n",
            "02/09 20:26:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [130][20/42]    eta: 0:00:04  time: 0.1828  data_time: 0.0744  memory: 1447  \n",
            "02/09 20:26:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [130][40/42]    eta: 0:00:00  time: 0.1118  data_time: 0.0114  memory: 1447  \n",
            "02/09 20:26:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [130][42/42]    acc/top1: 0.6416  acc/top5: 1.0000  acc/mean1: 0.6229  data_time: 0.0403  time: 0.1421\n",
            "02/09 20:26:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb/best_acc_top1_epoch_80.pth is removed\n",
            "02/09 20:26:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6416 acc/top1 at 130 epoch is saved to best_acc_top1_epoch_130.pth.\n",
            "02/09 20:26:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][ 20/332]  lr: 1.0000e-04  eta: 0:43:53  time: 0.4418  data_time: 0.0559  memory: 6616  grad_norm: 2.3011  loss: 0.9778  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6448  loss_aux: 0.3329\n",
            "02/09 20:26:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][ 40/332]  lr: 1.0000e-04  eta: 0:43:45  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 2.2824  loss: 0.9817  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6494  loss_aux: 0.3322\n",
            "02/09 20:26:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][ 60/332]  lr: 1.0000e-04  eta: 0:43:37  time: 0.3949  data_time: 0.0098  memory: 6616  grad_norm: 2.3815  loss: 0.9985  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6597  loss_aux: 0.3387\n",
            "02/09 20:26:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][ 80/332]  lr: 1.0000e-04  eta: 0:43:29  time: 0.3948  data_time: 0.0097  memory: 6616  grad_norm: 2.1356  loss: 0.9268  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6093  loss_aux: 0.3175\n",
            "02/09 20:26:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][100/332]  lr: 1.0000e-04  eta: 0:43:21  time: 0.3957  data_time: 0.0106  memory: 6616  grad_norm: 2.2160  loss: 0.8943  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5905  loss_aux: 0.3039\n",
            "02/09 20:27:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][120/332]  lr: 1.0000e-04  eta: 0:43:13  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 2.3793  loss: 1.0039  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6798  loss_aux: 0.3240\n",
            "02/09 20:27:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][140/332]  lr: 1.0000e-04  eta: 0:43:05  time: 0.3945  data_time: 0.0097  memory: 6616  grad_norm: 2.4711  loss: 0.9751  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6488  loss_aux: 0.3262\n",
            "02/09 20:27:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][160/332]  lr: 1.0000e-04  eta: 0:42:57  time: 0.3956  data_time: 0.0101  memory: 6616  grad_norm: 2.2563  loss: 0.9302  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6194  loss_aux: 0.3108\n",
            "02/09 20:27:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][180/332]  lr: 1.0000e-04  eta: 0:42:49  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 2.3998  loss: 1.0512  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.7001  loss_aux: 0.3511\n",
            "02/09 20:27:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][200/332]  lr: 1.0000e-04  eta: 0:42:42  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 2.7037  loss: 0.9996  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6572  loss_aux: 0.3424\n",
            "02/09 20:27:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][220/332]  lr: 1.0000e-04  eta: 0:42:34  time: 0.3971  data_time: 0.0111  memory: 6616  grad_norm: 2.3347  loss: 0.9617  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6381  loss_aux: 0.3236\n",
            "02/09 20:27:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][240/332]  lr: 1.0000e-04  eta: 0:42:26  time: 0.3960  data_time: 0.0106  memory: 6616  grad_norm: 2.4271  loss: 0.8928  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5901  loss_aux: 0.3027\n",
            "02/09 20:28:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][260/332]  lr: 1.0000e-04  eta: 0:42:18  time: 0.3961  data_time: 0.0103  memory: 6616  grad_norm: 2.2014  loss: 0.9288  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6132  loss_aux: 0.3157\n",
            "02/09 20:28:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][280/332]  lr: 1.0000e-04  eta: 0:42:10  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 2.2397  loss: 0.9410  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6223  loss_aux: 0.3187\n",
            "02/09 20:28:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][300/332]  lr: 1.0000e-04  eta: 0:42:02  time: 0.3965  data_time: 0.0108  memory: 6616  grad_norm: 2.3699  loss: 0.9805  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6534  loss_aux: 0.3270\n",
            "02/09 20:28:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][320/332]  lr: 1.0000e-04  eta: 0:41:54  time: 0.3943  data_time: 0.0093  memory: 6616  grad_norm: 2.5438  loss: 1.0042  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6761  loss_aux: 0.3281\n",
            "02/09 20:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][332/332]  lr: 1.0000e-04  eta: 0:41:49  time: 0.3896  data_time: 0.0092  memory: 6616  grad_norm: 2.4764  loss: 0.9534  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6329  loss_aux: 0.3205\n",
            "02/09 20:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 131 epochs\n",
            "02/09 20:28:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][ 20/332]  lr: 1.0000e-04  eta: 0:41:41  time: 0.4420  data_time: 0.0535  memory: 6616  grad_norm: 2.4606  loss: 1.0216  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6819  loss_aux: 0.3398\n",
            "02/09 20:28:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][ 40/332]  lr: 1.0000e-04  eta: 0:41:33  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 2.4098  loss: 0.9689  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6480  loss_aux: 0.3208\n",
            "02/09 20:28:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][ 60/332]  lr: 1.0000e-04  eta: 0:41:25  time: 0.3948  data_time: 0.0099  memory: 6616  grad_norm: 2.4181  loss: 0.8752  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5744  loss_aux: 0.3007\n",
            "02/09 20:29:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][ 80/332]  lr: 1.0000e-04  eta: 0:41:17  time: 0.3962  data_time: 0.0104  memory: 6616  grad_norm: 2.3812  loss: 0.9802  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6487  loss_aux: 0.3315\n",
            "02/09 20:29:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][100/332]  lr: 1.0000e-04  eta: 0:41:09  time: 0.3950  data_time: 0.0099  memory: 6616  grad_norm: 2.6309  loss: 1.0355  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6832  loss_aux: 0.3522\n",
            "02/09 20:29:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][120/332]  lr: 1.0000e-04  eta: 0:41:01  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 2.3031  loss: 0.9455  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6266  loss_aux: 0.3189\n",
            "02/09 20:29:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][140/332]  lr: 1.0000e-04  eta: 0:40:53  time: 0.3962  data_time: 0.0107  memory: 6616  grad_norm: 2.4123  loss: 0.9608  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6458  loss_aux: 0.3150\n",
            "02/09 20:29:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][160/332]  lr: 1.0000e-04  eta: 0:40:45  time: 0.3953  data_time: 0.0100  memory: 6616  grad_norm: 2.3769  loss: 0.9148  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6077  loss_aux: 0.3071\n",
            "02/09 20:29:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][180/332]  lr: 1.0000e-04  eta: 0:40:37  time: 0.3950  data_time: 0.0100  memory: 6616  grad_norm: 2.5065  loss: 0.9893  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6529  loss_aux: 0.3365\n",
            "02/09 20:29:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][200/332]  lr: 1.0000e-04  eta: 0:40:29  time: 0.3950  data_time: 0.0099  memory: 6616  grad_norm: 2.5588  loss: 1.0054  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6794  loss_aux: 0.3259\n",
            "02/09 20:30:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][220/332]  lr: 1.0000e-04  eta: 0:40:21  time: 0.3955  data_time: 0.0103  memory: 6616  grad_norm: 2.6273  loss: 0.9972  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6593  loss_aux: 0.3379\n",
            "02/09 20:30:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][240/332]  lr: 1.0000e-04  eta: 0:40:14  time: 0.3953  data_time: 0.0100  memory: 6616  grad_norm: 2.5088  loss: 0.9461  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6193  loss_aux: 0.3268\n",
            "02/09 20:30:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][260/332]  lr: 1.0000e-04  eta: 0:40:06  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 2.3221  loss: 0.9188  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6073  loss_aux: 0.3115\n",
            "02/09 20:30:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][280/332]  lr: 1.0000e-04  eta: 0:39:58  time: 0.3951  data_time: 0.0099  memory: 6616  grad_norm: 2.4030  loss: 1.0150  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6751  loss_aux: 0.3399\n",
            "02/09 20:30:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][300/332]  lr: 1.0000e-04  eta: 0:39:50  time: 0.3954  data_time: 0.0100  memory: 6616  grad_norm: 2.4539  loss: 0.9868  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6556  loss_aux: 0.3312\n",
            "02/09 20:30:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][320/332]  lr: 1.0000e-04  eta: 0:39:42  time: 0.3953  data_time: 0.0099  memory: 6616  grad_norm: 2.5768  loss: 0.9740  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6481  loss_aux: 0.3259\n",
            "02/09 20:30:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:30:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][332/332]  lr: 1.0000e-04  eta: 0:39:37  time: 0.3902  data_time: 0.0096  memory: 6616  grad_norm: 2.7585  loss: 0.9701  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6430  loss_aux: 0.3271\n",
            "02/09 20:30:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 132 epochs\n",
            "02/09 20:30:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][ 20/332]  lr: 1.0000e-04  eta: 0:39:29  time: 0.4505  data_time: 0.0620  memory: 6616  grad_norm: 2.6637  loss: 1.0107  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6678  loss_aux: 0.3429\n",
            "02/09 20:31:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][ 40/332]  lr: 1.0000e-04  eta: 0:39:21  time: 0.3959  data_time: 0.0109  memory: 6616  grad_norm: 2.7870  loss: 1.0079  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6712  loss_aux: 0.3367\n",
            "02/09 20:31:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][ 60/332]  lr: 1.0000e-04  eta: 0:39:13  time: 0.3947  data_time: 0.0098  memory: 6616  grad_norm: 2.5060  loss: 0.9506  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6234  loss_aux: 0.3272\n",
            "02/09 20:31:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][ 80/332]  lr: 1.0000e-04  eta: 0:39:05  time: 0.3957  data_time: 0.0103  memory: 6616  grad_norm: 3.4052  loss: 0.9760  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6473  loss_aux: 0.3286\n",
            "02/09 20:31:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][100/332]  lr: 1.0000e-04  eta: 0:38:57  time: 0.3945  data_time: 0.0097  memory: 6616  grad_norm: 2.6182  loss: 1.0148  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6801  loss_aux: 0.3347\n",
            "02/09 20:31:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][120/332]  lr: 1.0000e-04  eta: 0:38:49  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 2.6722  loss: 0.9751  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6574  loss_aux: 0.3177\n",
            "02/09 20:31:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][140/332]  lr: 1.0000e-04  eta: 0:38:41  time: 0.3952  data_time: 0.0098  memory: 6616  grad_norm: 2.5759  loss: 1.0006  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6642  loss_aux: 0.3363\n",
            "02/09 20:31:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][160/332]  lr: 1.0000e-04  eta: 0:38:33  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 2.4040  loss: 1.0405  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6944  loss_aux: 0.3461\n",
            "02/09 20:31:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:32:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][180/332]  lr: 1.0000e-04  eta: 0:38:25  time: 0.3950  data_time: 0.0098  memory: 6616  grad_norm: 2.3649  loss: 0.9787  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6468  loss_aux: 0.3319\n",
            "02/09 20:32:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][200/332]  lr: 1.0000e-04  eta: 0:38:17  time: 0.3963  data_time: 0.0108  memory: 6616  grad_norm: 2.3235  loss: 0.9325  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6268  loss_aux: 0.3057\n",
            "02/09 20:32:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][220/332]  lr: 1.0000e-04  eta: 0:38:09  time: 0.3960  data_time: 0.0109  memory: 6616  grad_norm: 2.5296  loss: 0.9804  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6581  loss_aux: 0.3223\n",
            "02/09 20:32:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][240/332]  lr: 1.0000e-04  eta: 0:38:01  time: 0.3956  data_time: 0.0099  memory: 6616  grad_norm: 2.2911  loss: 0.8937  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5918  loss_aux: 0.3019\n",
            "02/09 20:32:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][260/332]  lr: 1.0000e-04  eta: 0:37:54  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 2.3443  loss: 0.9257  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6078  loss_aux: 0.3179\n",
            "02/09 20:32:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][280/332]  lr: 1.0000e-04  eta: 0:37:46  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 2.3989  loss: 0.9652  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6388  loss_aux: 0.3263\n",
            "02/09 20:32:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][300/332]  lr: 1.0000e-04  eta: 0:37:38  time: 0.3948  data_time: 0.0099  memory: 6616  grad_norm: 2.3294  loss: 1.0242  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6866  loss_aux: 0.3376\n",
            "02/09 20:32:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][320/332]  lr: 1.0000e-04  eta: 0:37:30  time: 0.3947  data_time: 0.0099  memory: 6616  grad_norm: 2.4431  loss: 1.0380  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6925  loss_aux: 0.3455\n",
            "02/09 20:33:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:33:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][332/332]  lr: 1.0000e-04  eta: 0:37:25  time: 0.3896  data_time: 0.0092  memory: 6616  grad_norm: 2.3293  loss: 0.9898  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6572  loss_aux: 0.3326\n",
            "02/09 20:33:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 133 epochs\n",
            "02/09 20:33:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][ 20/332]  lr: 1.0000e-04  eta: 0:37:17  time: 0.4538  data_time: 0.0667  memory: 6616  grad_norm: 2.1731  loss: 0.9850  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6457  loss_aux: 0.3392\n",
            "02/09 20:33:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][ 40/332]  lr: 1.0000e-04  eta: 0:37:09  time: 0.3943  data_time: 0.0096  memory: 6616  grad_norm: 2.3547  loss: 0.9549  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6337  loss_aux: 0.3212\n",
            "02/09 20:33:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][ 60/332]  lr: 1.0000e-04  eta: 0:37:01  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 2.3897  loss: 0.9601  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6364  loss_aux: 0.3237\n",
            "02/09 20:33:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][ 80/332]  lr: 1.0000e-04  eta: 0:36:53  time: 0.3952  data_time: 0.0103  memory: 6616  grad_norm: 2.3300  loss: 0.9587  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6344  loss_aux: 0.3243\n",
            "02/09 20:33:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][100/332]  lr: 1.0000e-04  eta: 0:36:45  time: 0.3962  data_time: 0.0108  memory: 6616  grad_norm: 2.4469  loss: 1.0023  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6650  loss_aux: 0.3373\n",
            "02/09 20:33:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][120/332]  lr: 1.0000e-04  eta: 0:36:37  time: 0.3945  data_time: 0.0095  memory: 6616  grad_norm: 2.5081  loss: 0.9840  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6478  loss_aux: 0.3362\n",
            "02/09 20:34:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][140/332]  lr: 1.0000e-04  eta: 0:36:29  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 2.7476  loss: 0.9568  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6311  loss_aux: 0.3257\n",
            "02/09 20:34:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][160/332]  lr: 1.0000e-04  eta: 0:36:21  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 2.5032  loss: 0.9789  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6536  loss_aux: 0.3253\n",
            "02/09 20:34:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][180/332]  lr: 1.0000e-04  eta: 0:36:13  time: 0.3951  data_time: 0.0099  memory: 6616  grad_norm: 2.9588  loss: 1.0470  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6955  loss_aux: 0.3515\n",
            "02/09 20:34:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][200/332]  lr: 1.0000e-04  eta: 0:36:05  time: 0.3959  data_time: 0.0106  memory: 6616  grad_norm: 2.6286  loss: 0.9515  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6325  loss_aux: 0.3190\n",
            "02/09 20:34:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][220/332]  lr: 1.0000e-04  eta: 0:35:57  time: 0.3963  data_time: 0.0104  memory: 6616  grad_norm: 2.4478  loss: 0.8890  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5813  loss_aux: 0.3078\n",
            "02/09 20:34:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][240/332]  lr: 1.0000e-04  eta: 0:35:49  time: 0.3949  data_time: 0.0099  memory: 6616  grad_norm: 2.3935  loss: 0.9561  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6279  loss_aux: 0.3283\n",
            "02/09 20:34:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][260/332]  lr: 1.0000e-04  eta: 0:35:41  time: 0.3972  data_time: 0.0112  memory: 6616  grad_norm: 2.5687  loss: 0.9682  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6435  loss_aux: 0.3247\n",
            "02/09 20:34:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][280/332]  lr: 1.0000e-04  eta: 0:35:34  time: 0.3963  data_time: 0.0108  memory: 6616  grad_norm: 2.3990  loss: 0.9413  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6278  loss_aux: 0.3134\n",
            "02/09 20:35:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][300/332]  lr: 1.0000e-04  eta: 0:35:26  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 2.4079  loss: 0.9802  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6526  loss_aux: 0.3276\n",
            "02/09 20:35:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][320/332]  lr: 1.0000e-04  eta: 0:35:18  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 2.4701  loss: 1.0083  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6697  loss_aux: 0.3386\n",
            "02/09 20:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][332/332]  lr: 1.0000e-04  eta: 0:35:13  time: 0.3899  data_time: 0.0094  memory: 6616  grad_norm: 2.4213  loss: 0.9414  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6130  loss_aux: 0.3284\n",
            "02/09 20:35:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 134 epochs\n",
            "02/09 20:35:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][ 20/332]  lr: 1.0000e-04  eta: 0:35:05  time: 0.4401  data_time: 0.0522  memory: 6616  grad_norm: 2.9518  loss: 0.9739  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6487  loss_aux: 0.3252\n",
            "02/09 20:35:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][ 40/332]  lr: 1.0000e-04  eta: 0:34:57  time: 0.3951  data_time: 0.0097  memory: 6616  grad_norm: 2.6964  loss: 0.9258  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6047  loss_aux: 0.3211\n",
            "02/09 20:35:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][ 60/332]  lr: 1.0000e-04  eta: 0:34:49  time: 0.3947  data_time: 0.0097  memory: 6616  grad_norm: 2.5005  loss: 0.9343  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6099  loss_aux: 0.3244\n",
            "02/09 20:35:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][ 80/332]  lr: 1.0000e-04  eta: 0:34:41  time: 0.3943  data_time: 0.0096  memory: 6616  grad_norm: 2.3750  loss: 0.9334  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6034  loss_aux: 0.3300\n",
            "02/09 20:35:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][100/332]  lr: 1.0000e-04  eta: 0:34:33  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 2.6682  loss: 1.0411  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6929  loss_aux: 0.3481\n",
            "02/09 20:36:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][120/332]  lr: 1.0000e-04  eta: 0:34:25  time: 0.3963  data_time: 0.0111  memory: 6616  grad_norm: 2.4857  loss: 0.9499  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6314  loss_aux: 0.3185\n",
            "02/09 20:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][140/332]  lr: 1.0000e-04  eta: 0:34:17  time: 0.3948  data_time: 0.0097  memory: 6616  grad_norm: 2.5397  loss: 0.9254  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6162  loss_aux: 0.3092\n",
            "02/09 20:36:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][160/332]  lr: 1.0000e-04  eta: 0:34:09  time: 0.3959  data_time: 0.0107  memory: 6616  grad_norm: 2.4641  loss: 0.9773  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6424  loss_aux: 0.3349\n",
            "02/09 20:36:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][180/332]  lr: 1.0000e-04  eta: 0:34:01  time: 0.3952  data_time: 0.0099  memory: 6616  grad_norm: 2.3910  loss: 0.9892  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6572  loss_aux: 0.3320\n",
            "02/09 20:36:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][200/332]  lr: 1.0000e-04  eta: 0:33:53  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 2.2057  loss: 0.9125  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6064  loss_aux: 0.3060\n",
            "02/09 20:36:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][220/332]  lr: 1.0000e-04  eta: 0:33:45  time: 0.3949  data_time: 0.0100  memory: 6616  grad_norm: 2.3097  loss: 0.9501  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6249  loss_aux: 0.3253\n",
            "02/09 20:36:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][240/332]  lr: 1.0000e-04  eta: 0:33:37  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 2.4808  loss: 0.9592  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6372  loss_aux: 0.3221\n",
            "02/09 20:37:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][260/332]  lr: 1.0000e-04  eta: 0:33:29  time: 0.3955  data_time: 0.0099  memory: 6616  grad_norm: 2.5654  loss: 0.9682  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6428  loss_aux: 0.3254\n",
            "02/09 20:37:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][280/332]  lr: 1.0000e-04  eta: 0:33:21  time: 0.3954  data_time: 0.0104  memory: 6616  grad_norm: 2.6833  loss: 0.9994  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6648  loss_aux: 0.3346\n",
            "02/09 20:37:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][300/332]  lr: 1.0000e-04  eta: 0:33:13  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 2.8238  loss: 0.9018  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6008  loss_aux: 0.3010\n",
            "02/09 20:37:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][320/332]  lr: 1.0000e-04  eta: 0:33:05  time: 0.3944  data_time: 0.0096  memory: 6616  grad_norm: 2.6594  loss: 0.9872  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6577  loss_aux: 0.3295\n",
            "02/09 20:37:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:37:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][332/332]  lr: 1.0000e-04  eta: 0:33:01  time: 0.3902  data_time: 0.0097  memory: 6616  grad_norm: 2.2613  loss: 0.9663  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6451  loss_aux: 0.3213\n",
            "02/09 20:37:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 135 epochs\n",
            "02/09 20:37:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][ 20/332]  lr: 1.0000e-04  eta: 0:32:53  time: 0.4487  data_time: 0.0617  memory: 6616  grad_norm: 2.4338  loss: 0.9356  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6197  loss_aux: 0.3159\n",
            "02/09 20:37:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][ 40/332]  lr: 1.0000e-04  eta: 0:32:45  time: 0.3949  data_time: 0.0099  memory: 6616  grad_norm: 2.5746  loss: 0.9631  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6410  loss_aux: 0.3221\n",
            "02/09 20:37:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][ 60/332]  lr: 1.0000e-04  eta: 0:32:37  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 2.3831  loss: 0.9193  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6007  loss_aux: 0.3186\n",
            "02/09 20:38:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][ 80/332]  lr: 1.0000e-04  eta: 0:32:29  time: 0.3960  data_time: 0.0103  memory: 6616  grad_norm: 2.6258  loss: 0.9850  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6568  loss_aux: 0.3282\n",
            "02/09 20:38:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][100/332]  lr: 1.0000e-04  eta: 0:32:21  time: 0.3960  data_time: 0.0103  memory: 6616  grad_norm: 2.5993  loss: 1.0114  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6676  loss_aux: 0.3439\n",
            "02/09 20:38:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][120/332]  lr: 1.0000e-04  eta: 0:32:13  time: 0.3955  data_time: 0.0103  memory: 6616  grad_norm: 2.5711  loss: 1.0097  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6787  loss_aux: 0.3310\n",
            "02/09 20:38:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][140/332]  lr: 1.0000e-04  eta: 0:32:05  time: 0.3963  data_time: 0.0106  memory: 6616  grad_norm: 2.6617  loss: 0.9847  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6683  loss_aux: 0.3164\n",
            "02/09 20:38:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][160/332]  lr: 1.0000e-04  eta: 0:31:57  time: 0.3945  data_time: 0.0098  memory: 6616  grad_norm: 2.3893  loss: 0.9714  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6471  loss_aux: 0.3243\n",
            "02/09 20:38:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:38:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][180/332]  lr: 1.0000e-04  eta: 0:31:49  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 2.5117  loss: 0.9600  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6367  loss_aux: 0.3233\n",
            "02/09 20:38:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][200/332]  lr: 1.0000e-04  eta: 0:31:41  time: 0.3957  data_time: 0.0104  memory: 6616  grad_norm: 2.4101  loss: 0.9657  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6369  loss_aux: 0.3288\n",
            "02/09 20:39:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][220/332]  lr: 1.0000e-04  eta: 0:31:33  time: 0.3955  data_time: 0.0103  memory: 6616  grad_norm: 2.6814  loss: 0.9317  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6174  loss_aux: 0.3143\n",
            "02/09 20:39:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][240/332]  lr: 1.0000e-04  eta: 0:31:25  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 2.3507  loss: 0.9473  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6188  loss_aux: 0.3286\n",
            "02/09 20:39:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][260/332]  lr: 1.0000e-04  eta: 0:31:17  time: 0.3954  data_time: 0.0099  memory: 6616  grad_norm: 2.8729  loss: 1.0213  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6797  loss_aux: 0.3416\n",
            "02/09 20:39:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][280/332]  lr: 1.0000e-04  eta: 0:31:09  time: 0.3957  data_time: 0.0101  memory: 6616  grad_norm: 2.3734  loss: 0.9655  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6407  loss_aux: 0.3248\n",
            "02/09 20:39:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][300/332]  lr: 1.0000e-04  eta: 0:31:01  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 2.6454  loss: 0.9839  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6531  loss_aux: 0.3308\n",
            "02/09 20:39:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][320/332]  lr: 1.0000e-04  eta: 0:30:53  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 2.4266  loss: 0.9442  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6294  loss_aux: 0.3148\n",
            "02/09 20:39:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:39:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][332/332]  lr: 1.0000e-04  eta: 0:30:49  time: 0.3914  data_time: 0.0103  memory: 6616  grad_norm: 2.2221  loss: 0.9434  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6339  loss_aux: 0.3096\n",
            "02/09 20:39:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 136 epochs\n",
            "02/09 20:39:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][ 20/332]  lr: 1.0000e-04  eta: 0:30:41  time: 0.4338  data_time: 0.0457  memory: 6616  grad_norm: 2.4337  loss: 0.9413  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6214  loss_aux: 0.3199\n",
            "02/09 20:40:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][ 40/332]  lr: 1.0000e-04  eta: 0:30:33  time: 0.3957  data_time: 0.0102  memory: 6616  grad_norm: 3.3044  loss: 0.9697  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6425  loss_aux: 0.3272\n",
            "02/09 20:40:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][ 60/332]  lr: 1.0000e-04  eta: 0:30:25  time: 0.3956  data_time: 0.0105  memory: 6616  grad_norm: 2.5144  loss: 0.9779  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6445  loss_aux: 0.3333\n",
            "02/09 20:40:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][ 80/332]  lr: 1.0000e-04  eta: 0:30:17  time: 0.3965  data_time: 0.0111  memory: 6616  grad_norm: 2.4777  loss: 0.9580  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6307  loss_aux: 0.3272\n",
            "02/09 20:40:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][100/332]  lr: 1.0000e-04  eta: 0:30:09  time: 0.3960  data_time: 0.0108  memory: 6616  grad_norm: 2.3176  loss: 0.9617  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6367  loss_aux: 0.3251\n",
            "02/09 20:40:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][120/332]  lr: 1.0000e-04  eta: 0:30:01  time: 0.3948  data_time: 0.0100  memory: 6616  grad_norm: 2.5299  loss: 1.0145  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6850  loss_aux: 0.3295\n",
            "02/09 20:40:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][140/332]  lr: 1.0000e-04  eta: 0:29:53  time: 0.3952  data_time: 0.0098  memory: 6616  grad_norm: 2.4661  loss: 0.9694  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6497  loss_aux: 0.3197\n",
            "02/09 20:40:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][160/332]  lr: 1.0000e-04  eta: 0:29:45  time: 0.3953  data_time: 0.0099  memory: 6616  grad_norm: 2.5007  loss: 1.0043  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6713  loss_aux: 0.3330\n",
            "02/09 20:41:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][180/332]  lr: 1.0000e-04  eta: 0:29:37  time: 0.3947  data_time: 0.0096  memory: 6616  grad_norm: 2.2950  loss: 0.9427  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6196  loss_aux: 0.3231\n",
            "02/09 20:41:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][200/332]  lr: 1.0000e-04  eta: 0:29:29  time: 0.3965  data_time: 0.0108  memory: 6616  grad_norm: 2.2253  loss: 0.9508  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6328  loss_aux: 0.3181\n",
            "02/09 20:41:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][220/332]  lr: 1.0000e-04  eta: 0:29:21  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 2.4826  loss: 0.9750  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6547  loss_aux: 0.3203\n",
            "02/09 20:41:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][240/332]  lr: 1.0000e-04  eta: 0:29:13  time: 0.3958  data_time: 0.0104  memory: 6616  grad_norm: 3.0424  loss: 0.9265  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6178  loss_aux: 0.3087\n",
            "02/09 20:41:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][260/332]  lr: 1.0000e-04  eta: 0:29:05  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 2.7439  loss: 0.9359  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6183  loss_aux: 0.3176\n",
            "02/09 20:41:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][280/332]  lr: 1.0000e-04  eta: 0:28:57  time: 0.3951  data_time: 0.0098  memory: 6616  grad_norm: 2.6073  loss: 0.9677  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6436  loss_aux: 0.3241\n",
            "02/09 20:41:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][300/332]  lr: 1.0000e-04  eta: 0:28:49  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 2.6189  loss: 0.9205  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6089  loss_aux: 0.3116\n",
            "02/09 20:41:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][320/332]  lr: 1.0000e-04  eta: 0:28:41  time: 0.3950  data_time: 0.0096  memory: 6616  grad_norm: 2.4765  loss: 0.9946  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6591  loss_aux: 0.3354\n",
            "02/09 20:42:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:42:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][332/332]  lr: 1.0000e-04  eta: 0:28:37  time: 0.3898  data_time: 0.0091  memory: 6616  grad_norm: 2.8278  loss: 1.0109  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6670  loss_aux: 0.3439\n",
            "02/09 20:42:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 137 epochs\n",
            "02/09 20:42:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][ 20/332]  lr: 1.0000e-04  eta: 0:28:29  time: 0.4474  data_time: 0.0581  memory: 6616  grad_norm: 2.5746  loss: 0.9912  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6602  loss_aux: 0.3310\n",
            "02/09 20:42:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][ 40/332]  lr: 1.0000e-04  eta: 0:28:21  time: 0.3948  data_time: 0.0098  memory: 6616  grad_norm: 2.4616  loss: 0.9650  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6507  loss_aux: 0.3143\n",
            "02/09 20:42:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][ 60/332]  lr: 1.0000e-04  eta: 0:28:13  time: 0.3942  data_time: 0.0095  memory: 6616  grad_norm: 2.6659  loss: 0.9921  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6577  loss_aux: 0.3344\n",
            "02/09 20:42:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][ 80/332]  lr: 1.0000e-04  eta: 0:28:05  time: 0.3954  data_time: 0.0101  memory: 6616  grad_norm: 2.6982  loss: 1.0031  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6672  loss_aux: 0.3358\n",
            "02/09 20:42:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][100/332]  lr: 1.0000e-04  eta: 0:27:57  time: 0.3950  data_time: 0.0101  memory: 6616  grad_norm: 2.4262  loss: 0.9103  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6018  loss_aux: 0.3085\n",
            "02/09 20:42:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][120/332]  lr: 1.0000e-04  eta: 0:27:49  time: 0.3944  data_time: 0.0096  memory: 6616  grad_norm: 2.5907  loss: 0.9614  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6425  loss_aux: 0.3188\n",
            "02/09 20:42:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][140/332]  lr: 1.0000e-04  eta: 0:27:41  time: 0.3955  data_time: 0.0100  memory: 6616  grad_norm: 2.3704  loss: 0.9377  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6225  loss_aux: 0.3152\n",
            "02/09 20:43:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][160/332]  lr: 1.0000e-04  eta: 0:27:33  time: 0.3957  data_time: 0.0103  memory: 6616  grad_norm: 2.6161  loss: 0.9835  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6608  loss_aux: 0.3227\n",
            "02/09 20:43:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][180/332]  lr: 1.0000e-04  eta: 0:27:25  time: 0.3948  data_time: 0.0098  memory: 6616  grad_norm: 2.4865  loss: 0.9235  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6009  loss_aux: 0.3226\n",
            "02/09 20:43:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][200/332]  lr: 1.0000e-04  eta: 0:27:17  time: 0.3950  data_time: 0.0099  memory: 6616  grad_norm: 2.6760  loss: 0.9986  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6593  loss_aux: 0.3393\n",
            "02/09 20:43:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][220/332]  lr: 1.0000e-04  eta: 0:27:09  time: 0.3958  data_time: 0.0104  memory: 6616  grad_norm: 2.7682  loss: 0.9932  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6585  loss_aux: 0.3346\n",
            "02/09 20:43:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][240/332]  lr: 1.0000e-04  eta: 0:27:01  time: 0.3963  data_time: 0.0108  memory: 6616  grad_norm: 2.3863  loss: 0.9725  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6458  loss_aux: 0.3266\n",
            "02/09 20:43:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][260/332]  lr: 1.0000e-04  eta: 0:26:53  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 2.5747  loss: 1.0098  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6742  loss_aux: 0.3356\n",
            "02/09 20:43:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][280/332]  lr: 1.0000e-04  eta: 0:26:45  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 2.6652  loss: 0.9913  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6594  loss_aux: 0.3318\n",
            "02/09 20:44:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][300/332]  lr: 1.0000e-04  eta: 0:26:37  time: 0.3946  data_time: 0.0096  memory: 6616  grad_norm: 2.4731  loss: 0.9946  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6648  loss_aux: 0.3298\n",
            "02/09 20:44:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][320/332]  lr: 1.0000e-04  eta: 0:26:29  time: 0.3998  data_time: 0.0124  memory: 6616  grad_norm: 2.4378  loss: 0.9168  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6038  loss_aux: 0.3129\n",
            "02/09 20:44:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:44:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][332/332]  lr: 1.0000e-04  eta: 0:26:24  time: 0.3910  data_time: 0.0104  memory: 6616  grad_norm: 2.4716  loss: 1.0004  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6653  loss_aux: 0.3351\n",
            "02/09 20:44:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 138 epochs\n",
            "02/09 20:44:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][ 20/332]  lr: 1.0000e-04  eta: 0:26:17  time: 0.4512  data_time: 0.0636  memory: 6616  grad_norm: 2.3316  loss: 0.9176  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6075  loss_aux: 0.3101\n",
            "02/09 20:44:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][ 40/332]  lr: 1.0000e-04  eta: 0:26:09  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 2.7908  loss: 1.0206  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6786  loss_aux: 0.3420\n",
            "02/09 20:44:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][ 60/332]  lr: 1.0000e-04  eta: 0:26:01  time: 0.3962  data_time: 0.0107  memory: 6616  grad_norm: 2.7167  loss: 1.0274  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6916  loss_aux: 0.3358\n",
            "02/09 20:44:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][ 80/332]  lr: 1.0000e-04  eta: 0:25:53  time: 0.3961  data_time: 0.0108  memory: 6616  grad_norm: 2.4705  loss: 0.9503  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6253  loss_aux: 0.3250\n",
            "02/09 20:44:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][100/332]  lr: 1.0000e-04  eta: 0:25:45  time: 0.3959  data_time: 0.0106  memory: 6616  grad_norm: 2.4550  loss: 0.9907  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6549  loss_aux: 0.3358\n",
            "02/09 20:45:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][120/332]  lr: 1.0000e-04  eta: 0:25:37  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 2.3439  loss: 0.8963  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5909  loss_aux: 0.3054\n",
            "02/09 20:45:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][140/332]  lr: 1.0000e-04  eta: 0:25:29  time: 0.3950  data_time: 0.0098  memory: 6616  grad_norm: 2.5836  loss: 0.9758  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6528  loss_aux: 0.3230\n",
            "02/09 20:45:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][160/332]  lr: 1.0000e-04  eta: 0:25:21  time: 0.3961  data_time: 0.0107  memory: 6616  grad_norm: 2.3567  loss: 0.9772  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6435  loss_aux: 0.3337\n",
            "02/09 20:45:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][180/332]  lr: 1.0000e-04  eta: 0:25:13  time: 0.3953  data_time: 0.0101  memory: 6616  grad_norm: 2.5561  loss: 0.9885  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6495  loss_aux: 0.3390\n",
            "02/09 20:45:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:45:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][200/332]  lr: 1.0000e-04  eta: 0:25:05  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 2.6601  loss: 0.9762  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6483  loss_aux: 0.3279\n",
            "02/09 20:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][220/332]  lr: 1.0000e-04  eta: 0:24:57  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 2.5478  loss: 0.9922  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6603  loss_aux: 0.3318\n",
            "02/09 20:45:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][240/332]  lr: 1.0000e-04  eta: 0:24:49  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 2.6478  loss: 0.9685  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6447  loss_aux: 0.3238\n",
            "02/09 20:46:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][260/332]  lr: 1.0000e-04  eta: 0:24:41  time: 0.3951  data_time: 0.0102  memory: 6616  grad_norm: 2.3912  loss: 0.9756  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6508  loss_aux: 0.3248\n",
            "02/09 20:46:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][280/332]  lr: 1.0000e-04  eta: 0:24:33  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 2.7676  loss: 0.9385  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6196  loss_aux: 0.3189\n",
            "02/09 20:46:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][300/332]  lr: 1.0000e-04  eta: 0:24:25  time: 0.3962  data_time: 0.0107  memory: 6616  grad_norm: 2.5564  loss: 0.9192  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6074  loss_aux: 0.3118\n",
            "02/09 20:46:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][320/332]  lr: 1.0000e-04  eta: 0:24:17  time: 0.3949  data_time: 0.0099  memory: 6616  grad_norm: 2.7339  loss: 0.9714  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6443  loss_aux: 0.3271\n",
            "02/09 20:46:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:46:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][332/332]  lr: 1.0000e-04  eta: 0:24:12  time: 0.3899  data_time: 0.0097  memory: 6616  grad_norm: 2.9235  loss: 1.0204  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6805  loss_aux: 0.3399\n",
            "02/09 20:46:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 139 epochs\n",
            "02/09 20:46:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][ 20/332]  lr: 1.0000e-04  eta: 0:24:05  time: 0.4382  data_time: 0.0499  memory: 6616  grad_norm: 2.7720  loss: 0.9232  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6106  loss_aux: 0.3126\n",
            "02/09 20:46:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][ 40/332]  lr: 1.0000e-04  eta: 0:23:57  time: 0.3943  data_time: 0.0096  memory: 6616  grad_norm: 3.3508  loss: 1.0325  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6914  loss_aux: 0.3412\n",
            "02/09 20:46:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][ 60/332]  lr: 1.0000e-04  eta: 0:23:49  time: 0.3958  data_time: 0.0105  memory: 6616  grad_norm: 2.4503  loss: 0.9731  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6485  loss_aux: 0.3247\n",
            "02/09 20:47:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][ 80/332]  lr: 1.0000e-04  eta: 0:23:41  time: 0.3958  data_time: 0.0103  memory: 6616  grad_norm: 2.4227  loss: 0.8718  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5712  loss_aux: 0.3006\n",
            "02/09 20:47:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][100/332]  lr: 1.0000e-04  eta: 0:23:33  time: 0.3951  data_time: 0.0098  memory: 6616  grad_norm: 2.5781  loss: 0.9323  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6161  loss_aux: 0.3162\n",
            "02/09 20:47:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][120/332]  lr: 1.0000e-04  eta: 0:23:25  time: 0.3951  data_time: 0.0099  memory: 6616  grad_norm: 2.3720  loss: 0.9508  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6333  loss_aux: 0.3175\n",
            "02/09 20:47:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][140/332]  lr: 1.0000e-04  eta: 0:23:17  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 2.6777  loss: 1.0070  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6681  loss_aux: 0.3389\n",
            "02/09 20:47:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][160/332]  lr: 1.0000e-04  eta: 0:23:09  time: 0.3957  data_time: 0.0103  memory: 6616  grad_norm: 2.7295  loss: 0.9456  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6215  loss_aux: 0.3241\n",
            "02/09 20:47:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][180/332]  lr: 1.0000e-04  eta: 0:23:01  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 2.3426  loss: 0.8910  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5907  loss_aux: 0.3003\n",
            "02/09 20:47:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][200/332]  lr: 1.0000e-04  eta: 0:22:53  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 2.7071  loss: 0.9794  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6486  loss_aux: 0.3308\n",
            "02/09 20:48:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][220/332]  lr: 1.0000e-04  eta: 0:22:45  time: 0.3953  data_time: 0.0101  memory: 6616  grad_norm: 3.0504  loss: 1.0137  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6743  loss_aux: 0.3394\n",
            "02/09 20:48:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][240/332]  lr: 1.0000e-04  eta: 0:22:37  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 2.8223  loss: 0.9961  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6615  loss_aux: 0.3346\n",
            "02/09 20:48:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][260/332]  lr: 1.0000e-04  eta: 0:22:29  time: 0.3951  data_time: 0.0097  memory: 6616  grad_norm: 2.6029  loss: 0.9972  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6683  loss_aux: 0.3289\n",
            "02/09 20:48:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][280/332]  lr: 1.0000e-04  eta: 0:22:21  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 2.7784  loss: 1.0117  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6747  loss_aux: 0.3370\n",
            "02/09 20:48:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][300/332]  lr: 1.0000e-04  eta: 0:22:13  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 2.5011  loss: 1.0168  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6647  loss_aux: 0.3521\n",
            "02/09 20:48:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][320/332]  lr: 1.0000e-04  eta: 0:22:05  time: 0.3953  data_time: 0.0099  memory: 6616  grad_norm: 2.5674  loss: 0.9816  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6506  loss_aux: 0.3309\n",
            "02/09 20:48:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:48:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][332/332]  lr: 1.0000e-04  eta: 0:22:00  time: 0.3905  data_time: 0.0096  memory: 6616  grad_norm: 2.6029  loss: 0.9846  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6584  loss_aux: 0.3262\n",
            "02/09 20:48:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 140 epochs\n",
            "02/09 20:48:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [140][20/42]    eta: 0:00:03  time: 0.1791  data_time: 0.0689  memory: 1447  \n",
            "02/09 20:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [140][40/42]    eta: 0:00:00  time: 0.1153  data_time: 0.0144  memory: 1447  \n",
            "02/09 20:48:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [140][42/42]    acc/top1: 0.6205  acc/top5: 1.0000  acc/mean1: 0.5996  data_time: 0.0391  time: 0.1419\n",
            "02/09 20:49:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][ 20/332]  lr: 1.0000e-04  eta: 0:21:52  time: 0.4568  data_time: 0.0708  memory: 6616  grad_norm: 2.7666  loss: 0.9515  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6296  loss_aux: 0.3219\n",
            "02/09 20:49:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][ 40/332]  lr: 1.0000e-04  eta: 0:21:45  time: 0.3955  data_time: 0.0104  memory: 6616  grad_norm: 2.4400  loss: 0.9542  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6328  loss_aux: 0.3214\n",
            "02/09 20:49:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][ 60/332]  lr: 1.0000e-04  eta: 0:21:37  time: 0.3961  data_time: 0.0108  memory: 6616  grad_norm: 2.7714  loss: 0.9075  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6010  loss_aux: 0.3064\n",
            "02/09 20:49:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][ 80/332]  lr: 1.0000e-04  eta: 0:21:29  time: 0.3966  data_time: 0.0105  memory: 6616  grad_norm: 2.5517  loss: 1.0526  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.7102  loss_aux: 0.3424\n",
            "02/09 20:49:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][100/332]  lr: 1.0000e-04  eta: 0:21:21  time: 0.3950  data_time: 0.0100  memory: 6616  grad_norm: 2.4885  loss: 1.0320  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6859  loss_aux: 0.3460\n",
            "02/09 20:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][120/332]  lr: 1.0000e-04  eta: 0:21:13  time: 0.3965  data_time: 0.0113  memory: 6616  grad_norm: 2.3934  loss: 0.9777  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6510  loss_aux: 0.3267\n",
            "02/09 20:49:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][140/332]  lr: 1.0000e-04  eta: 0:21:05  time: 0.3951  data_time: 0.0103  memory: 6616  grad_norm: 2.4082  loss: 0.9996  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6688  loss_aux: 0.3308\n",
            "02/09 20:49:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][160/332]  lr: 1.0000e-04  eta: 0:20:57  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 2.7072  loss: 0.9695  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6450  loss_aux: 0.3246\n",
            "02/09 20:50:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][180/332]  lr: 1.0000e-04  eta: 0:20:49  time: 0.3958  data_time: 0.0107  memory: 6616  grad_norm: 2.5311  loss: 0.9747  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6473  loss_aux: 0.3274\n",
            "02/09 20:50:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][200/332]  lr: 1.0000e-04  eta: 0:20:41  time: 0.3950  data_time: 0.0101  memory: 6616  grad_norm: 3.0211  loss: 0.9575  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6288  loss_aux: 0.3288\n",
            "02/09 20:50:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][220/332]  lr: 1.0000e-04  eta: 0:20:33  time: 0.3964  data_time: 0.0107  memory: 6616  grad_norm: 2.9021  loss: 0.9365  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6078  loss_aux: 0.3287\n",
            "02/09 20:50:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][240/332]  lr: 1.0000e-04  eta: 0:20:25  time: 0.3957  data_time: 0.0102  memory: 6616  grad_norm: 2.7091  loss: 0.9409  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6211  loss_aux: 0.3199\n",
            "02/09 20:50:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][260/332]  lr: 1.0000e-04  eta: 0:20:17  time: 0.3957  data_time: 0.0102  memory: 6616  grad_norm: 2.6903  loss: 0.9425  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6270  loss_aux: 0.3155\n",
            "02/09 20:50:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][280/332]  lr: 1.0000e-04  eta: 0:20:09  time: 0.3967  data_time: 0.0105  memory: 6616  grad_norm: 2.5809  loss: 0.9388  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6175  loss_aux: 0.3214\n",
            "02/09 20:50:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][300/332]  lr: 1.0000e-04  eta: 0:20:01  time: 0.3947  data_time: 0.0098  memory: 6616  grad_norm: 2.5258  loss: 0.9472  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6306  loss_aux: 0.3167\n",
            "02/09 20:51:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][320/332]  lr: 1.0000e-04  eta: 0:19:53  time: 0.3966  data_time: 0.0106  memory: 6616  grad_norm: 2.5416  loss: 0.9782  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6504  loss_aux: 0.3277\n",
            "02/09 20:51:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:51:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][332/332]  lr: 1.0000e-04  eta: 0:19:48  time: 0.3899  data_time: 0.0091  memory: 6616  grad_norm: 2.5874  loss: 0.9685  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6339  loss_aux: 0.3346\n",
            "02/09 20:51:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 141 epochs\n",
            "02/09 20:51:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][ 20/332]  lr: 1.0000e-04  eta: 0:19:40  time: 0.4416  data_time: 0.0515  memory: 6616  grad_norm: 2.9083  loss: 0.9915  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6662  loss_aux: 0.3254\n",
            "02/09 20:51:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][ 40/332]  lr: 1.0000e-04  eta: 0:19:32  time: 0.3951  data_time: 0.0100  memory: 6616  grad_norm: 2.7098  loss: 0.9725  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6476  loss_aux: 0.3249\n",
            "02/09 20:51:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][ 60/332]  lr: 1.0000e-04  eta: 0:19:24  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 2.4171  loss: 0.9674  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6430  loss_aux: 0.3244\n",
            "02/09 20:51:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][ 80/332]  lr: 1.0000e-04  eta: 0:19:16  time: 0.3953  data_time: 0.0099  memory: 6616  grad_norm: 2.4326  loss: 0.9201  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6085  loss_aux: 0.3116\n",
            "02/09 20:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][100/332]  lr: 1.0000e-04  eta: 0:19:09  time: 0.3954  data_time: 0.0100  memory: 6616  grad_norm: 2.7879  loss: 0.9978  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6672  loss_aux: 0.3307\n",
            "02/09 20:51:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][120/332]  lr: 1.0000e-04  eta: 0:19:01  time: 0.3968  data_time: 0.0110  memory: 6616  grad_norm: 2.7432  loss: 0.9961  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6654  loss_aux: 0.3307\n",
            "02/09 20:52:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][140/332]  lr: 1.0000e-04  eta: 0:18:53  time: 0.3952  data_time: 0.0102  memory: 6616  grad_norm: 2.6329  loss: 0.9771  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6597  loss_aux: 0.3174\n",
            "02/09 20:52:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][160/332]  lr: 1.0000e-04  eta: 0:18:45  time: 0.3950  data_time: 0.0099  memory: 6616  grad_norm: 2.8850  loss: 0.9930  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6731  loss_aux: 0.3200\n",
            "02/09 20:52:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][180/332]  lr: 1.0000e-04  eta: 0:18:37  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 2.4428  loss: 0.9204  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6136  loss_aux: 0.3068\n",
            "02/09 20:52:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:52:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][200/332]  lr: 1.0000e-04  eta: 0:18:29  time: 0.3954  data_time: 0.0101  memory: 6616  grad_norm: 2.3134  loss: 0.9440  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6151  loss_aux: 0.3290\n",
            "02/09 20:52:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][220/332]  lr: 1.0000e-04  eta: 0:18:21  time: 0.3954  data_time: 0.0100  memory: 6616  grad_norm: 2.8229  loss: 1.0540  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.7113  loss_aux: 0.3427\n",
            "02/09 20:52:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][240/332]  lr: 1.0000e-04  eta: 0:18:13  time: 0.3949  data_time: 0.0097  memory: 6616  grad_norm: 3.0623  loss: 1.0079  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6831  loss_aux: 0.3248\n",
            "02/09 20:52:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][260/332]  lr: 1.0000e-04  eta: 0:18:05  time: 0.3948  data_time: 0.0096  memory: 6616  grad_norm: 2.5239  loss: 0.9592  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6340  loss_aux: 0.3251\n",
            "02/09 20:53:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][280/332]  lr: 1.0000e-04  eta: 0:17:57  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 2.7609  loss: 0.9829  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6541  loss_aux: 0.3287\n",
            "02/09 20:53:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][300/332]  lr: 1.0000e-04  eta: 0:17:49  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 2.8146  loss: 0.9681  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6411  loss_aux: 0.3270\n",
            "02/09 20:53:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][320/332]  lr: 1.0000e-04  eta: 0:17:41  time: 0.3941  data_time: 0.0094  memory: 6616  grad_norm: 2.8818  loss: 0.9480  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6299  loss_aux: 0.3181\n",
            "02/09 20:53:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:53:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][332/332]  lr: 1.0000e-04  eta: 0:17:36  time: 0.3895  data_time: 0.0093  memory: 6616  grad_norm: 2.8999  loss: 0.9765  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6555  loss_aux: 0.3210\n",
            "02/09 20:53:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 142 epochs\n",
            "02/09 20:53:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][ 20/332]  lr: 1.0000e-04  eta: 0:17:28  time: 0.4531  data_time: 0.0665  memory: 6616  grad_norm: 2.5318  loss: 0.9481  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6293  loss_aux: 0.3188\n",
            "02/09 20:53:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][ 40/332]  lr: 1.0000e-04  eta: 0:17:20  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 2.6510  loss: 0.9988  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6647  loss_aux: 0.3341\n",
            "02/09 20:53:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][ 60/332]  lr: 1.0000e-04  eta: 0:17:12  time: 0.3963  data_time: 0.0107  memory: 6616  grad_norm: 2.8026  loss: 0.9757  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6483  loss_aux: 0.3274\n",
            "02/09 20:53:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][ 80/332]  lr: 1.0000e-04  eta: 0:17:04  time: 0.3962  data_time: 0.0106  memory: 6616  grad_norm: 2.5359  loss: 0.9502  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6224  loss_aux: 0.3278\n",
            "02/09 20:54:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][100/332]  lr: 1.0000e-04  eta: 0:16:56  time: 0.3951  data_time: 0.0100  memory: 6616  grad_norm: 2.7484  loss: 1.0015  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6702  loss_aux: 0.3313\n",
            "02/09 20:54:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][120/332]  lr: 1.0000e-04  eta: 0:16:48  time: 0.3958  data_time: 0.0103  memory: 6616  grad_norm: 2.6118  loss: 0.9793  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6524  loss_aux: 0.3268\n",
            "02/09 20:54:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][140/332]  lr: 1.0000e-04  eta: 0:16:41  time: 0.3948  data_time: 0.0098  memory: 6616  grad_norm: 2.9525  loss: 0.9558  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6363  loss_aux: 0.3195\n",
            "02/09 20:54:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][160/332]  lr: 1.0000e-04  eta: 0:16:33  time: 0.3945  data_time: 0.0097  memory: 6616  grad_norm: 2.9083  loss: 0.9488  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6292  loss_aux: 0.3196\n",
            "02/09 20:54:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][180/332]  lr: 1.0000e-04  eta: 0:16:25  time: 0.3947  data_time: 0.0098  memory: 6616  grad_norm: 2.8627  loss: 0.9631  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6365  loss_aux: 0.3266\n",
            "02/09 20:54:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][200/332]  lr: 1.0000e-04  eta: 0:16:17  time: 0.3950  data_time: 0.0100  memory: 6616  grad_norm: 2.9429  loss: 0.9348  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6158  loss_aux: 0.3189\n",
            "02/09 20:54:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][220/332]  lr: 1.0000e-04  eta: 0:16:09  time: 0.3953  data_time: 0.0101  memory: 6616  grad_norm: 3.1291  loss: 0.9373  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6149  loss_aux: 0.3225\n",
            "02/09 20:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][240/332]  lr: 1.0000e-04  eta: 0:16:01  time: 0.3959  data_time: 0.0103  memory: 6616  grad_norm: 3.0443  loss: 0.9872  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6560  loss_aux: 0.3311\n",
            "02/09 20:55:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][260/332]  lr: 1.0000e-04  eta: 0:15:53  time: 0.3954  data_time: 0.0101  memory: 6616  grad_norm: 3.6399  loss: 1.0697  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7207  loss_aux: 0.3490\n",
            "02/09 20:55:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][280/332]  lr: 1.0000e-04  eta: 0:15:45  time: 0.3949  data_time: 0.0101  memory: 6616  grad_norm: 2.9547  loss: 0.9520  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6282  loss_aux: 0.3238\n",
            "02/09 20:55:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][300/332]  lr: 1.0000e-04  eta: 0:15:37  time: 0.3953  data_time: 0.0103  memory: 6616  grad_norm: 2.6472  loss: 0.9647  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6354  loss_aux: 0.3294\n",
            "02/09 20:55:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][320/332]  lr: 1.0000e-04  eta: 0:15:29  time: 0.3959  data_time: 0.0104  memory: 6616  grad_norm: 2.6236  loss: 0.9805  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6517  loss_aux: 0.3288\n",
            "02/09 20:55:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:55:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][332/332]  lr: 1.0000e-04  eta: 0:15:24  time: 0.3903  data_time: 0.0096  memory: 6616  grad_norm: 2.5753  loss: 0.9807  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6499  loss_aux: 0.3308\n",
            "02/09 20:55:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 143 epochs\n",
            "02/09 20:55:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][ 20/332]  lr: 1.0000e-04  eta: 0:15:16  time: 0.4546  data_time: 0.0666  memory: 6616  grad_norm: 2.6400  loss: 0.9848  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6512  loss_aux: 0.3336\n",
            "02/09 20:55:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][ 40/332]  lr: 1.0000e-04  eta: 0:15:08  time: 0.3959  data_time: 0.0102  memory: 6616  grad_norm: 2.5904  loss: 0.9363  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6181  loss_aux: 0.3183\n",
            "02/09 20:56:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][ 60/332]  lr: 1.0000e-04  eta: 0:15:00  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 3.0757  loss: 0.9903  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6640  loss_aux: 0.3262\n",
            "02/09 20:56:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][ 80/332]  lr: 1.0000e-04  eta: 0:14:52  time: 0.3958  data_time: 0.0104  memory: 6616  grad_norm: 2.4787  loss: 0.9475  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6277  loss_aux: 0.3198\n",
            "02/09 20:56:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][100/332]  lr: 1.0000e-04  eta: 0:14:44  time: 0.3958  data_time: 0.0101  memory: 6616  grad_norm: 2.9298  loss: 0.9583  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6434  loss_aux: 0.3149\n",
            "02/09 20:56:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][120/332]  lr: 1.0000e-04  eta: 0:14:36  time: 0.3951  data_time: 0.0101  memory: 6616  grad_norm: 2.9908  loss: 1.0131  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6690  loss_aux: 0.3441\n",
            "02/09 20:56:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][140/332]  lr: 1.0000e-04  eta: 0:14:28  time: 0.3963  data_time: 0.0104  memory: 6616  grad_norm: 2.5536  loss: 0.9477  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6363  loss_aux: 0.3115\n",
            "02/09 20:56:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][160/332]  lr: 1.0000e-04  eta: 0:14:20  time: 0.3966  data_time: 0.0111  memory: 6616  grad_norm: 2.6787  loss: 0.9352  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6203  loss_aux: 0.3150\n",
            "02/09 20:56:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][180/332]  lr: 1.0000e-04  eta: 0:14:13  time: 0.3945  data_time: 0.0096  memory: 6616  grad_norm: 2.8388  loss: 0.9687  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6411  loss_aux: 0.3275\n",
            "02/09 20:56:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][200/332]  lr: 1.0000e-04  eta: 0:14:05  time: 0.3969  data_time: 0.0109  memory: 6616  grad_norm: 3.0893  loss: 0.9994  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6696  loss_aux: 0.3299\n",
            "02/09 20:57:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][220/332]  lr: 1.0000e-04  eta: 0:13:57  time: 0.3962  data_time: 0.0105  memory: 6616  grad_norm: 2.8188  loss: 0.9843  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6567  loss_aux: 0.3276\n",
            "02/09 20:57:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][240/332]  lr: 1.0000e-04  eta: 0:13:49  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 2.5266  loss: 0.9481  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6219  loss_aux: 0.3262\n",
            "02/09 20:57:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][260/332]  lr: 1.0000e-04  eta: 0:13:41  time: 0.3962  data_time: 0.0105  memory: 6616  grad_norm: 2.5656  loss: 0.9423  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6268  loss_aux: 0.3155\n",
            "02/09 20:57:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][280/332]  lr: 1.0000e-04  eta: 0:13:33  time: 0.3962  data_time: 0.0105  memory: 6616  grad_norm: 2.6064  loss: 0.9301  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6188  loss_aux: 0.3112\n",
            "02/09 20:57:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][300/332]  lr: 1.0000e-04  eta: 0:13:25  time: 0.3960  data_time: 0.0105  memory: 6616  grad_norm: 2.6336  loss: 1.0047  top1_acc: 0.1250  top5_acc: 1.0000  loss_cls: 0.6771  loss_aux: 0.3276\n",
            "02/09 20:57:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][320/332]  lr: 1.0000e-04  eta: 0:13:17  time: 0.3958  data_time: 0.0103  memory: 6616  grad_norm: 2.8752  loss: 0.9925  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6595  loss_aux: 0.3330\n",
            "02/09 20:57:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:57:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][332/332]  lr: 1.0000e-04  eta: 0:13:12  time: 0.3904  data_time: 0.0100  memory: 6616  grad_norm: 2.6121  loss: 0.9246  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6036  loss_aux: 0.3210\n",
            "02/09 20:57:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 144 epochs\n",
            "02/09 20:58:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][ 20/332]  lr: 1.0000e-04  eta: 0:13:04  time: 0.4457  data_time: 0.0564  memory: 6616  grad_norm: 2.5868  loss: 0.9395  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6107  loss_aux: 0.3288\n",
            "02/09 20:58:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][ 40/332]  lr: 1.0000e-04  eta: 0:12:56  time: 0.3958  data_time: 0.0103  memory: 6616  grad_norm: 3.0090  loss: 0.9931  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6565  loss_aux: 0.3367\n",
            "02/09 20:58:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][ 60/332]  lr: 1.0000e-04  eta: 0:12:48  time: 0.3954  data_time: 0.0101  memory: 6616  grad_norm: 2.7537  loss: 0.9754  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6533  loss_aux: 0.3221\n",
            "02/09 20:58:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][ 80/332]  lr: 1.0000e-04  eta: 0:12:40  time: 0.3954  data_time: 0.0100  memory: 6616  grad_norm: 2.9725  loss: 0.9739  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6372  loss_aux: 0.3367\n",
            "02/09 20:58:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][100/332]  lr: 1.0000e-04  eta: 0:12:32  time: 0.3966  data_time: 0.0110  memory: 6616  grad_norm: 3.3106  loss: 0.9569  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6390  loss_aux: 0.3179\n",
            "02/09 20:58:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][120/332]  lr: 1.0000e-04  eta: 0:12:24  time: 0.3957  data_time: 0.0103  memory: 6616  grad_norm: 3.4730  loss: 1.0449  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6831  loss_aux: 0.3618\n",
            "02/09 20:58:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][140/332]  lr: 1.0000e-04  eta: 0:12:16  time: 0.3968  data_time: 0.0108  memory: 6616  grad_norm: 2.7107  loss: 0.8849  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5796  loss_aux: 0.3053\n",
            "02/09 20:58:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][160/332]  lr: 1.0000e-04  eta: 0:12:08  time: 0.3964  data_time: 0.0109  memory: 6616  grad_norm: 2.9491  loss: 0.9616  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6386  loss_aux: 0.3230\n",
            "02/09 20:59:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][180/332]  lr: 1.0000e-04  eta: 0:12:00  time: 0.3967  data_time: 0.0110  memory: 6616  grad_norm: 3.2597  loss: 0.9053  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5925  loss_aux: 0.3128\n",
            "02/09 20:59:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 20:59:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][200/332]  lr: 1.0000e-04  eta: 0:11:52  time: 0.3959  data_time: 0.0105  memory: 6616  grad_norm: 2.7347  loss: 0.9905  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6669  loss_aux: 0.3236\n",
            "02/09 20:59:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][220/332]  lr: 1.0000e-04  eta: 0:11:45  time: 0.3973  data_time: 0.0111  memory: 6616  grad_norm: 2.8861  loss: 1.0200  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6829  loss_aux: 0.3371\n",
            "02/09 20:59:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][240/332]  lr: 1.0000e-04  eta: 0:11:37  time: 0.3954  data_time: 0.0102  memory: 6616  grad_norm: 2.5787  loss: 0.9341  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6167  loss_aux: 0.3174\n",
            "02/09 20:59:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][260/332]  lr: 1.0000e-04  eta: 0:11:29  time: 0.3970  data_time: 0.0112  memory: 6616  grad_norm: 2.5664  loss: 0.9600  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6263  loss_aux: 0.3338\n",
            "02/09 20:59:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][280/332]  lr: 1.0000e-04  eta: 0:11:21  time: 0.3966  data_time: 0.0108  memory: 6616  grad_norm: 2.6115  loss: 0.9321  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6204  loss_aux: 0.3117\n",
            "02/09 20:59:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][300/332]  lr: 1.0000e-04  eta: 0:11:13  time: 0.3953  data_time: 0.0099  memory: 6616  grad_norm: 2.6250  loss: 0.9559  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6335  loss_aux: 0.3224\n",
            "02/09 21:00:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][320/332]  lr: 1.0000e-04  eta: 0:11:05  time: 0.3949  data_time: 0.0100  memory: 6616  grad_norm: 2.6622  loss: 0.9657  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6445  loss_aux: 0.3213\n",
            "02/09 21:00:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 21:00:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][332/332]  lr: 1.0000e-04  eta: 0:11:00  time: 0.3893  data_time: 0.0092  memory: 6616  grad_norm: 2.8060  loss: 1.0071  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6750  loss_aux: 0.3320\n",
            "02/09 21:00:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 145 epochs\n",
            "02/09 21:00:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][ 20/332]  lr: 1.0000e-04  eta: 0:10:52  time: 0.4333  data_time: 0.0465  memory: 6616  grad_norm: 2.8586  loss: 0.9551  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6389  loss_aux: 0.3162\n",
            "02/09 21:00:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][ 40/332]  lr: 1.0000e-04  eta: 0:10:44  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 2.7379  loss: 0.9450  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6206  loss_aux: 0.3244\n",
            "02/09 21:00:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][ 60/332]  lr: 1.0000e-04  eta: 0:10:36  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 2.8641  loss: 1.0349  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6926  loss_aux: 0.3423\n",
            "02/09 21:00:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][ 80/332]  lr: 1.0000e-04  eta: 0:10:28  time: 0.3957  data_time: 0.0104  memory: 6616  grad_norm: 3.1718  loss: 0.9090  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5954  loss_aux: 0.3137\n",
            "02/09 21:00:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][100/332]  lr: 1.0000e-04  eta: 0:10:20  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 3.9717  loss: 0.9740  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6557  loss_aux: 0.3184\n",
            "02/09 21:00:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][120/332]  lr: 1.0000e-04  eta: 0:10:12  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 2.6395  loss: 0.9003  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5949  loss_aux: 0.3055\n",
            "02/09 21:01:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][140/332]  lr: 1.0000e-04  eta: 0:10:04  time: 0.3952  data_time: 0.0098  memory: 6616  grad_norm: 2.6695  loss: 0.9882  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6690  loss_aux: 0.3191\n",
            "02/09 21:01:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][160/332]  lr: 1.0000e-04  eta: 0:09:56  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 3.0464  loss: 1.0245  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6828  loss_aux: 0.3417\n",
            "02/09 21:01:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][180/332]  lr: 1.0000e-04  eta: 0:09:48  time: 0.3958  data_time: 0.0102  memory: 6616  grad_norm: 2.5173  loss: 0.9349  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6169  loss_aux: 0.3180\n",
            "02/09 21:01:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][200/332]  lr: 1.0000e-04  eta: 0:09:40  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 2.9185  loss: 0.9227  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6139  loss_aux: 0.3088\n",
            "02/09 21:01:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][220/332]  lr: 1.0000e-04  eta: 0:09:32  time: 0.3958  data_time: 0.0103  memory: 6616  grad_norm: 2.6303  loss: 0.9164  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5970  loss_aux: 0.3194\n",
            "02/09 21:01:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][240/332]  lr: 1.0000e-04  eta: 0:09:24  time: 0.3958  data_time: 0.0106  memory: 6616  grad_norm: 2.4588  loss: 0.9375  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6341  loss_aux: 0.3033\n",
            "02/09 21:01:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][260/332]  lr: 1.0000e-04  eta: 0:09:17  time: 0.3959  data_time: 0.0106  memory: 6616  grad_norm: 2.8686  loss: 0.9864  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6664  loss_aux: 0.3200\n",
            "02/09 21:02:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][280/332]  lr: 1.0000e-04  eta: 0:09:09  time: 0.3965  data_time: 0.0109  memory: 6616  grad_norm: 2.5629  loss: 0.9127  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5966  loss_aux: 0.3161\n",
            "02/09 21:02:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][300/332]  lr: 1.0000e-04  eta: 0:09:01  time: 0.3973  data_time: 0.0110  memory: 6616  grad_norm: 2.6027  loss: 0.9138  top1_acc: 0.2500  top5_acc: 1.0000  loss_cls: 0.6067  loss_aux: 0.3070\n",
            "02/09 21:02:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][320/332]  lr: 1.0000e-04  eta: 0:08:53  time: 0.3957  data_time: 0.0102  memory: 6616  grad_norm: 2.9744  loss: 1.0020  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6655  loss_aux: 0.3365\n",
            "02/09 21:02:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 21:02:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][332/332]  lr: 1.0000e-04  eta: 0:08:48  time: 0.3904  data_time: 0.0095  memory: 6616  grad_norm: 2.9643  loss: 0.9928  top1_acc: 0.6667  top5_acc: 1.0000  loss_cls: 0.6561  loss_aux: 0.3366\n",
            "02/09 21:02:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 146 epochs\n",
            "02/09 21:02:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][ 20/332]  lr: 1.0000e-04  eta: 0:08:40  time: 0.4411  data_time: 0.0520  memory: 6616  grad_norm: 2.6142  loss: 0.9215  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6010  loss_aux: 0.3204\n",
            "02/09 21:02:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][ 40/332]  lr: 1.0000e-04  eta: 0:08:32  time: 0.3948  data_time: 0.0097  memory: 6616  grad_norm: 2.7712  loss: 0.9426  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6277  loss_aux: 0.3149\n",
            "02/09 21:02:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][ 60/332]  lr: 1.0000e-04  eta: 0:08:24  time: 0.3955  data_time: 0.0101  memory: 6616  grad_norm: 2.9223  loss: 1.0441  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6973  loss_aux: 0.3467\n",
            "02/09 21:02:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][ 80/332]  lr: 1.0000e-04  eta: 0:08:16  time: 0.3955  data_time: 0.0103  memory: 6616  grad_norm: 2.5546  loss: 0.8855  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5753  loss_aux: 0.3102\n",
            "02/09 21:03:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][100/332]  lr: 1.0000e-04  eta: 0:08:08  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 2.6113  loss: 0.9911  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6584  loss_aux: 0.3327\n",
            "02/09 21:03:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][120/332]  lr: 1.0000e-04  eta: 0:08:00  time: 0.3954  data_time: 0.0101  memory: 6616  grad_norm: 3.0057  loss: 0.9628  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6447  loss_aux: 0.3181\n",
            "02/09 21:03:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][140/332]  lr: 1.0000e-04  eta: 0:07:52  time: 0.3953  data_time: 0.0100  memory: 6616  grad_norm: 2.7981  loss: 0.9724  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6505  loss_aux: 0.3219\n",
            "02/09 21:03:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][160/332]  lr: 1.0000e-04  eta: 0:07:44  time: 0.3963  data_time: 0.0108  memory: 6616  grad_norm: 2.6203  loss: 0.9981  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6642  loss_aux: 0.3339\n",
            "02/09 21:03:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][180/332]  lr: 1.0000e-04  eta: 0:07:36  time: 0.3973  data_time: 0.0113  memory: 6616  grad_norm: 2.5486  loss: 0.9185  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6092  loss_aux: 0.3093\n",
            "02/09 21:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][200/332]  lr: 1.0000e-04  eta: 0:07:28  time: 0.3964  data_time: 0.0103  memory: 6616  grad_norm: 2.5381  loss: 0.9467  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6303  loss_aux: 0.3164\n",
            "02/09 21:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][220/332]  lr: 1.0000e-04  eta: 0:07:20  time: 0.3970  data_time: 0.0108  memory: 6616  grad_norm: 2.6940  loss: 0.9541  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6348  loss_aux: 0.3194\n",
            "02/09 21:04:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][240/332]  lr: 1.0000e-04  eta: 0:07:12  time: 0.3965  data_time: 0.0108  memory: 6616  grad_norm: 2.6689  loss: 1.0078  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6661  loss_aux: 0.3417\n",
            "02/09 21:04:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][260/332]  lr: 1.0000e-04  eta: 0:07:04  time: 0.3953  data_time: 0.0099  memory: 6616  grad_norm: 2.8837  loss: 0.9338  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6177  loss_aux: 0.3161\n",
            "02/09 21:04:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][280/332]  lr: 1.0000e-04  eta: 0:06:56  time: 0.3963  data_time: 0.0106  memory: 6616  grad_norm: 2.8360  loss: 1.0385  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6839  loss_aux: 0.3546\n",
            "02/09 21:04:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][300/332]  lr: 1.0000e-04  eta: 0:06:49  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 2.5055  loss: 0.9812  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6514  loss_aux: 0.3299\n",
            "02/09 21:04:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][320/332]  lr: 1.0000e-04  eta: 0:06:41  time: 0.3946  data_time: 0.0097  memory: 6616  grad_norm: 2.4931  loss: 0.9708  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6442  loss_aux: 0.3267\n",
            "02/09 21:04:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 21:04:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][332/332]  lr: 1.0000e-04  eta: 0:06:36  time: 0.3898  data_time: 0.0092  memory: 6616  grad_norm: 2.5904  loss: 0.9881  top1_acc: 0.3333  top5_acc: 1.0000  loss_cls: 0.6576  loss_aux: 0.3305\n",
            "02/09 21:04:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 147 epochs\n",
            "02/09 21:04:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][ 20/332]  lr: 1.0000e-04  eta: 0:06:28  time: 0.4354  data_time: 0.0466  memory: 6616  grad_norm: 2.9223  loss: 1.0029  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6659  loss_aux: 0.3370\n",
            "02/09 21:04:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][ 40/332]  lr: 1.0000e-04  eta: 0:06:20  time: 0.3958  data_time: 0.0104  memory: 6616  grad_norm: 2.6217  loss: 0.9518  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6370  loss_aux: 0.3147\n",
            "02/09 21:05:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][ 60/332]  lr: 1.0000e-04  eta: 0:06:12  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 2.7968  loss: 0.9403  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6291  loss_aux: 0.3112\n",
            "02/09 21:05:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][ 80/332]  lr: 1.0000e-04  eta: 0:06:04  time: 0.3959  data_time: 0.0104  memory: 6616  grad_norm: 2.9456  loss: 0.9162  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6082  loss_aux: 0.3080\n",
            "02/09 21:05:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][100/332]  lr: 1.0000e-04  eta: 0:05:56  time: 0.3960  data_time: 0.0105  memory: 6616  grad_norm: 2.9274  loss: 0.9802  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6526  loss_aux: 0.3276\n",
            "02/09 21:05:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][120/332]  lr: 1.0000e-04  eta: 0:05:48  time: 0.3954  data_time: 0.0103  memory: 6616  grad_norm: 2.9625  loss: 0.9507  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6316  loss_aux: 0.3191\n",
            "02/09 21:05:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][140/332]  lr: 1.0000e-04  eta: 0:05:40  time: 0.3956  data_time: 0.0102  memory: 6616  grad_norm: 2.9711  loss: 0.9447  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6206  loss_aux: 0.3241\n",
            "02/09 21:05:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][160/332]  lr: 1.0000e-04  eta: 0:05:32  time: 0.3953  data_time: 0.0100  memory: 6616  grad_norm: 2.7565  loss: 0.9705  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6407  loss_aux: 0.3298\n",
            "02/09 21:05:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][180/332]  lr: 1.0000e-04  eta: 0:05:24  time: 0.3962  data_time: 0.0104  memory: 6616  grad_norm: 3.3593  loss: 0.9022  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5923  loss_aux: 0.3100\n",
            "02/09 21:05:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 21:05:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][200/332]  lr: 1.0000e-04  eta: 0:05:16  time: 0.3953  data_time: 0.0099  memory: 6616  grad_norm: 2.7357  loss: 0.9003  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5984  loss_aux: 0.3019\n",
            "02/09 21:06:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][220/332]  lr: 1.0000e-04  eta: 0:05:08  time: 0.3950  data_time: 0.0102  memory: 6616  grad_norm: 3.1864  loss: 0.9960  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6612  loss_aux: 0.3347\n",
            "02/09 21:06:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][240/332]  lr: 1.0000e-04  eta: 0:05:00  time: 0.3960  data_time: 0.0104  memory: 6616  grad_norm: 2.8732  loss: 0.9870  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6521  loss_aux: 0.3349\n",
            "02/09 21:06:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][260/332]  lr: 1.0000e-04  eta: 0:04:52  time: 0.3961  data_time: 0.0104  memory: 6616  grad_norm: 3.0214  loss: 0.9487  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6246  loss_aux: 0.3241\n",
            "02/09 21:06:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][280/332]  lr: 1.0000e-04  eta: 0:04:44  time: 0.3950  data_time: 0.0099  memory: 6616  grad_norm: 2.8830  loss: 0.9388  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6237  loss_aux: 0.3151\n",
            "02/09 21:06:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][300/332]  lr: 1.0000e-04  eta: 0:04:36  time: 0.3961  data_time: 0.0106  memory: 6616  grad_norm: 2.8746  loss: 0.9966  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6709  loss_aux: 0.3257\n",
            "02/09 21:06:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][320/332]  lr: 1.0000e-04  eta: 0:04:28  time: 0.3949  data_time: 0.0099  memory: 6616  grad_norm: 2.8130  loss: 0.9237  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6048  loss_aux: 0.3189\n",
            "02/09 21:06:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 21:06:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][332/332]  lr: 1.0000e-04  eta: 0:04:24  time: 0.3906  data_time: 0.0098  memory: 6616  grad_norm: 2.8316  loss: 0.9555  top1_acc: 0.8333  top5_acc: 1.0000  loss_cls: 0.6316  loss_aux: 0.3239\n",
            "02/09 21:06:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 148 epochs\n",
            "02/09 21:07:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][ 20/332]  lr: 1.0000e-04  eta: 0:04:16  time: 0.4562  data_time: 0.0682  memory: 6616  grad_norm: 2.6884  loss: 1.0117  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6730  loss_aux: 0.3387\n",
            "02/09 21:07:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][ 40/332]  lr: 1.0000e-04  eta: 0:04:08  time: 0.3950  data_time: 0.0099  memory: 6616  grad_norm: 2.7559  loss: 0.9788  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6506  loss_aux: 0.3282\n",
            "02/09 21:07:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][ 60/332]  lr: 1.0000e-04  eta: 0:04:00  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 2.8397  loss: 0.9945  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6614  loss_aux: 0.3332\n",
            "02/09 21:07:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][ 80/332]  lr: 1.0000e-04  eta: 0:03:52  time: 0.3962  data_time: 0.0108  memory: 6616  grad_norm: 2.7543  loss: 0.8740  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5703  loss_aux: 0.3037\n",
            "02/09 21:07:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][100/332]  lr: 1.0000e-04  eta: 0:03:44  time: 0.3963  data_time: 0.0105  memory: 6616  grad_norm: 2.7017  loss: 0.9006  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5943  loss_aux: 0.3062\n",
            "02/09 21:07:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][120/332]  lr: 1.0000e-04  eta: 0:03:36  time: 0.3956  data_time: 0.0103  memory: 6616  grad_norm: 3.0487  loss: 0.9842  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6579  loss_aux: 0.3263\n",
            "02/09 21:07:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][140/332]  lr: 1.0000e-04  eta: 0:03:28  time: 0.3964  data_time: 0.0107  memory: 6616  grad_norm: 2.7075  loss: 0.9600  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6357  loss_aux: 0.3244\n",
            "02/09 21:07:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][160/332]  lr: 1.0000e-04  eta: 0:03:20  time: 0.3957  data_time: 0.0099  memory: 6616  grad_norm: 2.8567  loss: 0.9961  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6619  loss_aux: 0.3342\n",
            "02/09 21:08:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][180/332]  lr: 1.0000e-04  eta: 0:03:12  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 3.5751  loss: 1.0117  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6797  loss_aux: 0.3320\n",
            "02/09 21:08:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][200/332]  lr: 1.0000e-04  eta: 0:03:04  time: 0.3978  data_time: 0.0113  memory: 6616  grad_norm: 2.8493  loss: 0.9780  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6422  loss_aux: 0.3358\n",
            "02/09 21:08:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][220/332]  lr: 1.0000e-04  eta: 0:02:56  time: 0.3953  data_time: 0.0102  memory: 6616  grad_norm: 2.7842  loss: 0.9278  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6035  loss_aux: 0.3242\n",
            "02/09 21:08:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][240/332]  lr: 1.0000e-04  eta: 0:02:48  time: 0.3961  data_time: 0.0104  memory: 6616  grad_norm: 2.8669  loss: 1.0048  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6669  loss_aux: 0.3378\n",
            "02/09 21:08:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][260/332]  lr: 1.0000e-04  eta: 0:02:40  time: 0.3955  data_time: 0.0102  memory: 6616  grad_norm: 2.8014  loss: 0.9450  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6296  loss_aux: 0.3154\n",
            "02/09 21:08:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][280/332]  lr: 1.0000e-04  eta: 0:02:32  time: 0.3948  data_time: 0.0101  memory: 6616  grad_norm: 2.6566  loss: 0.9500  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6216  loss_aux: 0.3284\n",
            "02/09 21:08:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][300/332]  lr: 1.0000e-04  eta: 0:02:24  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 2.7411  loss: 0.9078  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5945  loss_aux: 0.3133\n",
            "02/09 21:09:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][320/332]  lr: 1.0000e-04  eta: 0:02:16  time: 0.3954  data_time: 0.0101  memory: 6616  grad_norm: 2.9175  loss: 0.9664  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6437  loss_aux: 0.3227\n",
            "02/09 21:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 21:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][332/332]  lr: 1.0000e-04  eta: 0:02:12  time: 0.3907  data_time: 0.0099  memory: 6616  grad_norm: 3.0862  loss: 0.9720  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6516  loss_aux: 0.3204\n",
            "02/09 21:09:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 149 epochs\n",
            "02/09 21:09:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][ 20/332]  lr: 1.0000e-04  eta: 0:02:04  time: 0.4429  data_time: 0.0543  memory: 6616  grad_norm: 2.8667  loss: 1.0141  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6736  loss_aux: 0.3405\n",
            "02/09 21:09:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][ 40/332]  lr: 1.0000e-04  eta: 0:01:56  time: 0.3977  data_time: 0.0118  memory: 6616  grad_norm: 2.9071  loss: 0.9552  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6373  loss_aux: 0.3179\n",
            "02/09 21:09:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][ 60/332]  lr: 1.0000e-04  eta: 0:01:48  time: 0.3951  data_time: 0.0100  memory: 6616  grad_norm: 2.8710  loss: 1.0309  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6886  loss_aux: 0.3423\n",
            "02/09 21:09:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][ 80/332]  lr: 1.0000e-04  eta: 0:01:40  time: 0.3957  data_time: 0.0105  memory: 6616  grad_norm: 2.8231  loss: 1.0213  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.6802  loss_aux: 0.3411\n",
            "02/09 21:09:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][100/332]  lr: 1.0000e-04  eta: 0:01:32  time: 0.3973  data_time: 0.0115  memory: 6616  grad_norm: 2.7299  loss: 0.9322  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6113  loss_aux: 0.3209\n",
            "02/09 21:09:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][120/332]  lr: 1.0000e-04  eta: 0:01:24  time: 0.3958  data_time: 0.0104  memory: 6616  grad_norm: 2.8119  loss: 0.9629  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6366  loss_aux: 0.3263\n",
            "02/09 21:10:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][140/332]  lr: 1.0000e-04  eta: 0:01:16  time: 0.3960  data_time: 0.0105  memory: 6616  grad_norm: 2.7417  loss: 0.9692  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6465  loss_aux: 0.3227\n",
            "02/09 21:10:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][160/332]  lr: 1.0000e-04  eta: 0:01:08  time: 0.3952  data_time: 0.0100  memory: 6616  grad_norm: 2.7599  loss: 0.9960  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6666  loss_aux: 0.3294\n",
            "02/09 21:10:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][180/332]  lr: 1.0000e-04  eta: 0:01:00  time: 0.3957  data_time: 0.0100  memory: 6616  grad_norm: 2.9998  loss: 0.9336  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6147  loss_aux: 0.3189\n",
            "02/09 21:10:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][200/332]  lr: 1.0000e-04  eta: 0:00:52  time: 0.3954  data_time: 0.0104  memory: 6616  grad_norm: 3.0087  loss: 0.9596  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6404  loss_aux: 0.3192\n",
            "02/09 21:10:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][220/332]  lr: 1.0000e-04  eta: 0:00:44  time: 0.3956  data_time: 0.0104  memory: 6616  grad_norm: 2.8131  loss: 0.9220  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6066  loss_aux: 0.3154\n",
            "02/09 21:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][240/332]  lr: 1.0000e-04  eta: 0:00:36  time: 0.3952  data_time: 0.0101  memory: 6616  grad_norm: 2.9210  loss: 0.9679  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6369  loss_aux: 0.3310\n",
            "02/09 21:10:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][260/332]  lr: 1.0000e-04  eta: 0:00:28  time: 0.3963  data_time: 0.0107  memory: 6616  grad_norm: 3.2658  loss: 0.9474  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6299  loss_aux: 0.3175\n",
            "02/09 21:11:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][280/332]  lr: 1.0000e-04  eta: 0:00:20  time: 0.3963  data_time: 0.0110  memory: 6616  grad_norm: 2.9064  loss: 0.9919  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6553  loss_aux: 0.3367\n",
            "02/09 21:11:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][300/332]  lr: 1.0000e-04  eta: 0:00:12  time: 0.3955  data_time: 0.0101  memory: 6616  grad_norm: 2.8906  loss: 0.9943  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6592  loss_aux: 0.3351\n",
            "02/09 21:11:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][320/332]  lr: 1.0000e-04  eta: 0:00:04  time: 0.3961  data_time: 0.0104  memory: 6616  grad_norm: 3.3050  loss: 1.0153  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6753  loss_aux: 0.3400\n",
            "02/09 21:11:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb_20240209_153244\n",
            "02/09 21:11:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][332/332]  lr: 1.0000e-04  eta: 0:00:00  time: 0.3906  data_time: 0.0097  memory: 6616  grad_norm: 2.9860  loss: 0.9514  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.6328  loss_aux: 0.3186\n",
            "02/09 21:11:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 150 epochs\n",
            "02/09 21:11:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [150][20/42]    eta: 0:00:04  time: 0.1979  data_time: 0.0874  memory: 1447  \n",
            "02/09 21:11:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [150][40/42]    eta: 0:00:00  time: 0.1147  data_time: 0.0151  memory: 1447  \n",
            "02/09 21:11:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [150][42/42]    acc/top1: 0.6386  acc/top5: 1.0000  acc/mean1: 0.6173  data_time: 0.0481  time: 0.1505\n"
          ]
        }
      ],
      "source": [
        "!python ./tools/train.py ./cuny/configs/tpn/no_pretrain_tpn-slowonly_imagenet-pretrained-r50_8xb8-8x8x1-150e_kinetics400-rgb.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TsVCPys7dO1d"
      },
      "outputs": [],
      "source": [
        "!cp -r work_dirs /content/drive/MyDrive/cuny_dataset/"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ykj0I2v7v5ao"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}