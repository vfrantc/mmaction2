{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vfrantc/mmaction2/blob/main/cuny/experiments/no_pretrain_slowonly.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jIT8tO-DStuc",
        "outputId": "d41cee8c-1bcd-4d82-f698-be54a4ebd14c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.7/132.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.9/32.9 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pytorchvideo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.7/52.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m34.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.5/259.5 kB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.4/239.4 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.1/953.1 kB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.7/89.7 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.0/94.0 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.0/443.0 kB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for oss2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for aliyun-python-sdk-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for crcmod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "lida 0.0.10 requires fastapi, which is not installed.\n",
            "lida 0.0.10 requires kaleido, which is not installed.\n",
            "lida 0.0.10 requires python-multipart, which is not installed.\n",
            "lida 0.0.10 requires uvicorn, which is not installed.\n",
            "cvxpy 1.3.3 requires setuptools>65.5.1, but you have setuptools 60.2.0 which is incompatible.\n",
            "google-colab 1.0.0 requires requests==2.31.0, but you have requests 2.28.2 which is incompatible.\n",
            "yfinance 0.2.36 requires requests>=2.31, but you have requests 2.28.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m451.7/451.7 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.7/254.7 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.1/94.1 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.6/50.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.0/436.0 kB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for chumpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "/content\n",
            "rm: cannot remove '/content/mmaction2/': No such file or directory\n",
            "Cloning into 'mmaction2'...\n",
            "remote: Enumerating objects: 22455, done.\u001b[K\n",
            "remote: Counting objects: 100% (369/369), done.\u001b[K\n",
            "remote: Compressing objects: 100% (178/178), done.\u001b[K\n",
            "remote: Total 22455 (delta 210), reused 334 (delta 185), pack-reused 22086\u001b[K\n",
            "Receiving objects: 100% (22455/22455), 65.47 MiB | 34.45 MiB/s, done.\n",
            "Resolving deltas: 100% (15768/15768), done.\n",
            "/content/mmaction2\n",
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Obtaining file:///content/mmaction2\n",
            "  Running command python setup.py egg_info\n",
            "  running egg_info\n",
            "  creating /tmp/pip-pip-egg-info-fs_uac9_/mmaction2.egg-info\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-fs_uac9_/mmaction2.egg-info/SOURCES.txt'\n",
            "  warning: no files found matching 'mmaction/.mim/model-index.yml'\n",
            "  warning: no files found matching 'mmaction/.mim/dataset-index.yml'\n",
            "  warning: no files found matching '*.py' under directory 'mmaction/.mim/configs'\n",
            "  warning: no files found matching '*.yml' under directory 'mmaction/.mim/configs'\n",
            "  warning: no files found matching '*.sh' under directory 'mmaction/.mim/tools'\n",
            "  warning: no files found matching '*.py' under directory 'mmaction/.mim/tools'\n",
            "  writing manifest file '/tmp/pip-pip-egg-info-fs_uac9_/mmaction2.egg-info/SOURCES.txt'\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting decord>=0.4.1 (from mmaction2==1.2.0)\n",
            "  Downloading decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.6/13.6 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from mmaction2==1.2.0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.23.5)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (4.8.0.76)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from mmaction2==1.2.0) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->mmaction2==1.2.0) (2.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (4.48.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (1.4.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (23.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->mmaction2==1.2.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->mmaction2==1.2.0) (1.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->mmaction2==1.2.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->mmaction2==1.2.0) (1.3.0)\n",
            "Installing collected packages: einops, decord, mmaction2\n",
            "  Running setup.py develop for mmaction2\n",
            "    Running command python setup.py develop\n",
            "    running develop\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/easy_install.py:156: EasyInstallDeprecationWarning: easy_install command is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    /usr/local/lib/python3.10/dist-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
            "      warnings.warn(\n",
            "    running egg_info\n",
            "    creating mmaction2.egg-info\n",
            "    writing manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    writing manifest file 'mmaction2.egg-info/SOURCES.txt'\n",
            "    running build_ext\n",
            "Successfully installed decord-0.6.0 einops-0.7.0 mmaction2-1.2.0\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# INSTALL REQUIREMENTS AND MMACTION\n",
        "!pip install pytorchvideo --quiet\n",
        "!pip install timm --quiet\n",
        "!pip install -U openmim --quiet\n",
        "!mim install mmengine --quiet\n",
        "!mim install mmcv --quiet\n",
        "!mim install mmdet --quiet\n",
        "!mim install mmpose --quiet\n",
        "\n",
        "# INSTALL MMACTION, OUR CONFIGS ARE THERE AS WELL\n",
        "%cd /content/\n",
        "!rm -r /content/mmaction2/\n",
        "!git clone https://github.com/vfrantc/mmaction2.git\n",
        "%cd mmaction2\n",
        "!pip install -v -e .\n",
        "\n",
        "# COPY DATASET\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "!cp /content/drive/MyDrive/cuny_dataset/cuny_dataset.zip .\n",
        "!unzip -qq cuny_dataset.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv content/mmaction2/data ."
      ],
      "metadata": {
        "id": "p-HNQ4rOzZf1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yYI5XnUtioeV"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07a89_KO_34J",
        "outputId": "1e6fd908-33c7-482f-b0a3-051baee40c89"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "E-8hE5fOhTMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6146f9d0-a71a-44fc-e786-d8fae481101d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "02/09 10:29:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - \n",
            "------------------------------------------------------------\n",
            "System environment:\n",
            "    sys.platform: linux\n",
            "    Python: 3.10.12 (main, Nov 20 2023, 15:14:05) [GCC 11.4.0]\n",
            "    CUDA available: True\n",
            "    MUSA available: False\n",
            "    numpy_random_seed: 474524625\n",
            "    GPU 0: Tesla V100-SXM2-16GB\n",
            "    CUDA_HOME: /usr/local/cuda\n",
            "    NVCC: Cuda compilation tools, release 12.2, V12.2.140\n",
            "    GCC: x86_64-linux-gnu-gcc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n",
            "    PyTorch: 2.1.0+cu121\n",
            "    PyTorch compiling details: PyTorch built with:\n",
            "  - GCC 9.3\n",
            "  - C++ Version: 201703\n",
            "  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications\n",
            "  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)\n",
            "  - OpenMP 201511 (a.k.a. OpenMP 4.5)\n",
            "  - LAPACK is enabled (usually provided by MKL)\n",
            "  - NNPACK is enabled\n",
            "  - CPU capability usage: AVX2\n",
            "  - CUDA Runtime 12.1\n",
            "  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_90,code=sm_90\n",
            "  - CuDNN 8.9.2\n",
            "  - Magma 2.6.1\n",
            "  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=12.1, CUDNN_VERSION=8.9.2, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.0, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, \n",
            "\n",
            "    TorchVision: 0.16.0+cu121\n",
            "    OpenCV: 4.8.0\n",
            "    MMEngine: 0.10.3\n",
            "\n",
            "Runtime environment:\n",
            "    cudnn_benchmark: False\n",
            "    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}\n",
            "    dist_cfg: {'backend': 'nccl'}\n",
            "    seed: 474524625\n",
            "    diff_rank_seed: False\n",
            "    deterministic: False\n",
            "    Distributed launcher: none\n",
            "    Distributed training: False\n",
            "    GPU number: 1\n",
            "------------------------------------------------------------\n",
            "\n",
            "02/09 10:29:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Config:\n",
            "ann_file_train = 'data/kinetics400/kinetics400_train_list_videos.txt'\n",
            "ann_file_val = 'data/kinetics400/kinetics400_val_list_videos.txt'\n",
            "auto_scale_lr = dict(base_batch_size=128, enable=False)\n",
            "data_root = 'data/kinetics400/videos_train'\n",
            "data_root_val = 'data/kinetics400/videos_val'\n",
            "dataset_type = 'VideoDataset'\n",
            "default_hooks = dict(\n",
            "    checkpoint=dict(\n",
            "        interval=4, max_keep_ckpts=3, save_best='auto', type='CheckpointHook'),\n",
            "    logger=dict(ignore_last=False, interval=20, type='LoggerHook'),\n",
            "    param_scheduler=dict(type='ParamSchedulerHook'),\n",
            "    runtime_info=dict(type='RuntimeInfoHook'),\n",
            "    sampler_seed=dict(type='DistSamplerSeedHook'),\n",
            "    sync_buffers=dict(type='SyncBuffersHook'),\n",
            "    timer=dict(type='IterTimerHook'))\n",
            "default_scope = 'mmaction'\n",
            "env_cfg = dict(\n",
            "    cudnn_benchmark=False,\n",
            "    dist_cfg=dict(backend='nccl'),\n",
            "    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))\n",
            "file_client_args = dict(io_backend='disk')\n",
            "launcher = 'none'\n",
            "load_from = None\n",
            "log_level = 'INFO'\n",
            "log_processor = dict(by_epoch=True, type='LogProcessor', window_size=20)\n",
            "model = dict(\n",
            "    backbone=dict(\n",
            "        conv1_kernel=(\n",
            "            1,\n",
            "            7,\n",
            "            7,\n",
            "        ),\n",
            "        conv1_stride_t=1,\n",
            "        depth=50,\n",
            "        inflate=(\n",
            "            0,\n",
            "            0,\n",
            "            1,\n",
            "            1,\n",
            "        ),\n",
            "        lateral=False,\n",
            "        norm_eval=False,\n",
            "        pool1_stride_t=1,\n",
            "        pretrained='https://download.pytorch.org/models/resnet50-11ad3fa6.pth',\n",
            "        type='ResNet3dSlowOnly'),\n",
            "    cls_head=dict(\n",
            "        average_clips='prob',\n",
            "        dropout_ratio=0.5,\n",
            "        in_channels=2048,\n",
            "        num_classes=400,\n",
            "        spatial_type='avg',\n",
            "        type='I3DHead'),\n",
            "    data_preprocessor=dict(\n",
            "        format_shape='NCTHW',\n",
            "        mean=[\n",
            "            123.675,\n",
            "            116.28,\n",
            "            103.53,\n",
            "        ],\n",
            "        std=[\n",
            "            58.395,\n",
            "            57.12,\n",
            "            57.375,\n",
            "        ],\n",
            "        type='ActionDataPreprocessor'),\n",
            "    type='Recognizer3D')\n",
            "optim_wrapper = dict(\n",
            "    clip_grad=dict(max_norm=40, norm_type=2),\n",
            "    optimizer=dict(lr=0.02, momentum=0.9, type='SGD', weight_decay=0.0001))\n",
            "param_scheduler = [\n",
            "    dict(begin=0, by_epoch=True, end=10, start_factor=0.1, type='LinearLR'),\n",
            "    dict(\n",
            "        begin=10,\n",
            "        by_epoch=True,\n",
            "        end=150,\n",
            "        gamma=0.1,\n",
            "        milestones=[\n",
            "            90,\n",
            "            130,\n",
            "        ],\n",
            "        type='MultiStepLR'),\n",
            "]\n",
            "randomness = dict(deterministic=False, diff_rank_seed=False, seed=None)\n",
            "resume = False\n",
            "test_cfg = dict(type='TestLoop')\n",
            "test_dataloader = dict(\n",
            "    batch_size=1,\n",
            "    dataset=dict(\n",
            "        ann_file='data/kinetics400/kinetics400_val_list_videos.txt',\n",
            "        data_prefix=dict(video='data/kinetics400/videos_val'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=4,\n",
            "                frame_interval=16,\n",
            "                num_clips=10,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=256, type='ThreeCrop'),\n",
            "            dict(input_format='NCTHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "test_evaluator = dict(type='AccMetric')\n",
            "test_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(\n",
            "        clip_len=4,\n",
            "        frame_interval=16,\n",
            "        num_clips=10,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=256, type='ThreeCrop'),\n",
            "    dict(input_format='NCTHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "train_cfg = dict(\n",
            "    max_epochs=150, type='EpochBasedTrainLoop', val_begin=1, val_interval=5)\n",
            "train_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='data/kinetics400/kinetics400_train_list_videos.txt',\n",
            "        data_prefix=dict(video='data/kinetics400/videos_train'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=4,\n",
            "                frame_interval=16,\n",
            "                num_clips=1,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(type='RandomResizedCrop'),\n",
            "            dict(keep_ratio=False, scale=(\n",
            "                224,\n",
            "                224,\n",
            "            ), type='Resize'),\n",
            "            dict(flip_ratio=0.5, type='Flip'),\n",
            "            dict(input_format='NCTHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=True, type='DefaultSampler'))\n",
            "train_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(clip_len=4, frame_interval=16, num_clips=1, type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(type='RandomResizedCrop'),\n",
            "    dict(keep_ratio=False, scale=(\n",
            "        224,\n",
            "        224,\n",
            "    ), type='Resize'),\n",
            "    dict(flip_ratio=0.5, type='Flip'),\n",
            "    dict(input_format='NCTHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "val_cfg = dict(type='ValLoop')\n",
            "val_dataloader = dict(\n",
            "    batch_size=16,\n",
            "    dataset=dict(\n",
            "        ann_file='data/kinetics400/kinetics400_val_list_videos.txt',\n",
            "        data_prefix=dict(video='data/kinetics400/videos_val'),\n",
            "        pipeline=[\n",
            "            dict(io_backend='disk', type='DecordInit'),\n",
            "            dict(\n",
            "                clip_len=4,\n",
            "                frame_interval=16,\n",
            "                num_clips=1,\n",
            "                test_mode=True,\n",
            "                type='SampleFrames'),\n",
            "            dict(type='DecordDecode'),\n",
            "            dict(scale=(\n",
            "                -1,\n",
            "                256,\n",
            "            ), type='Resize'),\n",
            "            dict(crop_size=224, type='CenterCrop'),\n",
            "            dict(input_format='NCTHW', type='FormatShape'),\n",
            "            dict(type='PackActionInputs'),\n",
            "        ],\n",
            "        test_mode=True,\n",
            "        type='VideoDataset'),\n",
            "    num_workers=8,\n",
            "    persistent_workers=True,\n",
            "    sampler=dict(shuffle=False, type='DefaultSampler'))\n",
            "val_evaluator = dict(type='AccMetric')\n",
            "val_pipeline = [\n",
            "    dict(io_backend='disk', type='DecordInit'),\n",
            "    dict(\n",
            "        clip_len=4,\n",
            "        frame_interval=16,\n",
            "        num_clips=1,\n",
            "        test_mode=True,\n",
            "        type='SampleFrames'),\n",
            "    dict(type='DecordDecode'),\n",
            "    dict(scale=(\n",
            "        -1,\n",
            "        256,\n",
            "    ), type='Resize'),\n",
            "    dict(crop_size=224, type='CenterCrop'),\n",
            "    dict(input_format='NCTHW', type='FormatShape'),\n",
            "    dict(type='PackActionInputs'),\n",
            "]\n",
            "vis_backends = [\n",
            "    dict(type='LocalVisBackend'),\n",
            "]\n",
            "visualizer = dict(\n",
            "    type='ActionVisualizer', vis_backends=[\n",
            "        dict(type='LocalVisBackend'),\n",
            "    ])\n",
            "work_dir = './work_dirs/no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb'\n",
            "\n",
            "02/09 10:29:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Distributed training is not used, all SyncBatchNorm (SyncBN) layers in the model will be automatically reverted to BatchNormXd layers if they are used.\n",
            "02/09 10:29:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Hooks will be executed in the following order:\n",
            "before_run:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "before_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_train_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) DistSamplerSeedHook                \n",
            " -------------------- \n",
            "before_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_train_iter:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_train_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_val_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(NORMAL      ) SyncBuffersHook                    \n",
            " -------------------- \n",
            "before_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_val_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_val_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            "(LOW         ) ParamSchedulerHook                 \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "after_val:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_train:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(VERY_LOW    ) CheckpointHook                     \n",
            " -------------------- \n",
            "before_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "before_test_epoch:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "before_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            " -------------------- \n",
            "after_test_iter:\n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test_epoch:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            "(NORMAL      ) IterTimerHook                      \n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "after_test:\n",
            "(VERY_HIGH   ) RuntimeInfoHook                    \n",
            " -------------------- \n",
            "after_run:\n",
            "(BELOW_NORMAL) LoggerHook                         \n",
            " -------------------- \n",
            "02/09 10:29:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - load model from: https://download.pytorch.org/models/resnet50-11ad3fa6.pth\n",
            "Loads checkpoint by http backend from path: https://download.pytorch.org/models/resnet50-11ad3fa6.pth\n",
            "Downloading: \"https://download.pytorch.org/models/resnet50-11ad3fa6.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-11ad3fa6.pth\n",
            "100% 97.8M/97.8M [00:01<00:00, 88.0MB/s]\n",
            "02/09 10:29:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - These parameters in the 2d checkpoint are not loaded: {'fc.bias', 'fc.weight'}\n",
            "02/09 10:29:26 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"FileClient\" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io\n",
            "02/09 10:29:26 - mmengine - \u001b[5m\u001b[4m\u001b[33mWARNING\u001b[0m - \"HardDiskBackend\" is the alias of \"LocalBackend\" and the former will be deprecated in future.\n",
            "02/09 10:29:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Checkpoints will be saved to /content/mmaction2/work_dirs/no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb.\n",
            "02/09 10:29:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][ 20/166]  lr: 2.0000e-03  eta: 2:46:29  time: 0.4015  data_time: 0.0587  memory: 5737  grad_norm: 8.4360  loss: 4.5796  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 4.5796\n",
            "02/09 10:29:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][ 40/166]  lr: 2.0000e-03  eta: 2:22:04  time: 0.2843  data_time: 0.0160  memory: 5737  grad_norm: 7.8047  loss: 0.9789  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.9789\n",
            "02/09 10:29:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][ 60/166]  lr: 2.0000e-03  eta: 2:13:53  time: 0.2844  data_time: 0.0158  memory: 5737  grad_norm: 6.1192  loss: 0.6602  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6602\n",
            "02/09 10:29:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][ 80/166]  lr: 2.0000e-03  eta: 2:09:44  time: 0.2843  data_time: 0.0156  memory: 5737  grad_norm: 6.0112  loss: 0.6419  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6419\n",
            "02/09 10:29:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][100/166]  lr: 2.0000e-03  eta: 2:07:13  time: 0.2844  data_time: 0.0157  memory: 5737  grad_norm: 6.2536  loss: 0.6675  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6675\n",
            "02/09 10:30:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][120/166]  lr: 2.0000e-03  eta: 2:05:35  time: 0.2855  data_time: 0.0161  memory: 5737  grad_norm: 6.1091  loss: 0.6068  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6068\n",
            "02/09 10:30:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][140/166]  lr: 2.0000e-03  eta: 2:04:23  time: 0.2855  data_time: 0.0161  memory: 5737  grad_norm: 7.1149  loss: 0.6265  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6265\n",
            "02/09 10:30:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][160/166]  lr: 2.0000e-03  eta: 2:03:23  time: 0.2841  data_time: 0.0152  memory: 5737  grad_norm: 6.6360  loss: 0.5909  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5909\n",
            "02/09 10:30:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:30:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [1][166/166]  lr: 2.0000e-03  eta: 2:03:03  time: 0.2815  data_time: 0.0144  memory: 5737  grad_norm: 6.8018  loss: 0.5972  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.5972\n",
            "02/09 10:30:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][ 20/166]  lr: 4.0000e-03  eta: 2:03:53  time: 0.3195  data_time: 0.0491  memory: 5737  grad_norm: 7.2380  loss: 0.6152  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6152\n",
            "02/09 10:30:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][ 40/166]  lr: 4.0000e-03  eta: 2:03:08  time: 0.2848  data_time: 0.0156  memory: 5737  grad_norm: 7.7500  loss: 0.5748  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5748\n",
            "02/09 10:30:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][ 60/166]  lr: 4.0000e-03  eta: 2:02:31  time: 0.2848  data_time: 0.0159  memory: 5737  grad_norm: 7.9649  loss: 0.5839  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5839\n",
            "02/09 10:30:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][ 80/166]  lr: 4.0000e-03  eta: 2:02:02  time: 0.2864  data_time: 0.0168  memory: 5737  grad_norm: 8.2950  loss: 0.6605  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6605\n",
            "02/09 10:30:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][100/166]  lr: 4.0000e-03  eta: 2:01:33  time: 0.2845  data_time: 0.0153  memory: 5737  grad_norm: 8.1858  loss: 0.6122  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6122\n",
            "02/09 10:30:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][120/166]  lr: 4.0000e-03  eta: 2:01:09  time: 0.2859  data_time: 0.0162  memory: 5737  grad_norm: 8.5709  loss: 0.6690  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6690\n",
            "02/09 10:30:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][140/166]  lr: 4.0000e-03  eta: 2:00:47  time: 0.2851  data_time: 0.0152  memory: 5737  grad_norm: 8.7465  loss: 0.7102  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.7102\n",
            "02/09 10:31:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][160/166]  lr: 4.0000e-03  eta: 2:00:26  time: 0.2847  data_time: 0.0155  memory: 5737  grad_norm: 7.8364  loss: 0.6923  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6923\n",
            "02/09 10:31:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:31:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [2][166/166]  lr: 4.0000e-03  eta: 2:00:17  time: 0.2826  data_time: 0.0149  memory: 5737  grad_norm: 7.7717  loss: 0.6613  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.6613\n",
            "02/09 10:31:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][ 20/166]  lr: 6.0000e-03  eta: 2:00:50  time: 0.3216  data_time: 0.0500  memory: 5737  grad_norm: 7.3827  loss: 0.6084  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6084\n",
            "02/09 10:31:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][ 40/166]  lr: 6.0000e-03  eta: 2:00:31  time: 0.2855  data_time: 0.0162  memory: 5737  grad_norm: 8.0484  loss: 0.5722  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5722\n",
            "02/09 10:31:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][ 60/166]  lr: 6.0000e-03  eta: 2:00:13  time: 0.2849  data_time: 0.0154  memory: 5737  grad_norm: 7.9433  loss: 0.6521  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6521\n",
            "02/09 10:31:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][ 80/166]  lr: 6.0000e-03  eta: 1:59:58  time: 0.2867  data_time: 0.0166  memory: 5737  grad_norm: 7.9187  loss: 0.6874  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6874\n",
            "02/09 10:31:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][100/166]  lr: 6.0000e-03  eta: 1:59:42  time: 0.2853  data_time: 0.0155  memory: 5737  grad_norm: 7.4664  loss: 0.5986  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5986\n",
            "02/09 10:31:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][120/166]  lr: 6.0000e-03  eta: 1:59:28  time: 0.2859  data_time: 0.0162  memory: 5737  grad_norm: 7.5797  loss: 0.6209  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6209\n",
            "02/09 10:31:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][140/166]  lr: 6.0000e-03  eta: 1:59:14  time: 0.2856  data_time: 0.0160  memory: 5737  grad_norm: 7.0711  loss: 0.6604  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6604\n",
            "02/09 10:31:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][160/166]  lr: 6.0000e-03  eta: 1:59:01  time: 0.2853  data_time: 0.0158  memory: 5737  grad_norm: 6.3210  loss: 0.5722  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5722\n",
            "02/09 10:31:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:31:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [3][166/166]  lr: 6.0000e-03  eta: 1:58:55  time: 0.2828  data_time: 0.0150  memory: 5737  grad_norm: 6.8371  loss: 0.6311  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6311\n",
            "02/09 10:31:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][ 20/166]  lr: 8.0000e-03  eta: 1:59:07  time: 0.3112  data_time: 0.0399  memory: 5737  grad_norm: 6.9336  loss: 0.6024  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6024\n",
            "02/09 10:32:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][ 40/166]  lr: 8.0000e-03  eta: 1:58:55  time: 0.2870  data_time: 0.0163  memory: 5737  grad_norm: 6.8409  loss: 0.5944  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5944\n",
            "02/09 10:32:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][ 60/166]  lr: 8.0000e-03  eta: 1:58:43  time: 0.2859  data_time: 0.0161  memory: 5737  grad_norm: 7.0087  loss: 0.5978  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5978\n",
            "02/09 10:32:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][ 80/166]  lr: 8.0000e-03  eta: 1:58:32  time: 0.2857  data_time: 0.0156  memory: 5737  grad_norm: 7.3253  loss: 0.6918  top1_acc: 0.4375  top5_acc: 1.0000  loss_cls: 0.6918\n",
            "02/09 10:32:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][100/166]  lr: 8.0000e-03  eta: 1:58:20  time: 0.2854  data_time: 0.0155  memory: 5737  grad_norm: 6.8044  loss: 0.6425  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6425\n",
            "02/09 10:32:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][120/166]  lr: 8.0000e-03  eta: 1:58:09  time: 0.2853  data_time: 0.0156  memory: 5737  grad_norm: 6.3297  loss: 0.6737  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6737\n",
            "02/09 10:32:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][140/166]  lr: 8.0000e-03  eta: 1:57:58  time: 0.2849  data_time: 0.0153  memory: 5737  grad_norm: 6.3388  loss: 0.7152  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.7152\n",
            "02/09 10:32:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][160/166]  lr: 8.0000e-03  eta: 1:57:47  time: 0.2849  data_time: 0.0154  memory: 5737  grad_norm: 6.0208  loss: 0.6744  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6744\n",
            "02/09 10:32:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:32:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [4][166/166]  lr: 8.0000e-03  eta: 1:57:42  time: 0.2829  data_time: 0.0152  memory: 5737  grad_norm: 6.1468  loss: 0.6734  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.6734\n",
            "02/09 10:32:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 4 epochs\n",
            "02/09 10:32:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][ 20/166]  lr: 1.0000e-02  eta: 1:57:54  time: 0.3166  data_time: 0.0451  memory: 5737  grad_norm: 5.7796  loss: 0.6441  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6441\n",
            "02/09 10:32:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][ 40/166]  lr: 1.0000e-02  eta: 1:57:44  time: 0.2853  data_time: 0.0158  memory: 5737  grad_norm: 5.8316  loss: 0.6363  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6363\n",
            "02/09 10:32:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][ 60/166]  lr: 1.0000e-02  eta: 1:57:33  time: 0.2848  data_time: 0.0152  memory: 5737  grad_norm: 5.3783  loss: 0.6285  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6285\n",
            "02/09 10:33:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][ 80/166]  lr: 1.0000e-02  eta: 1:57:23  time: 0.2856  data_time: 0.0158  memory: 5737  grad_norm: 5.2797  loss: 0.6040  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6040\n",
            "02/09 10:33:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][100/166]  lr: 1.0000e-02  eta: 1:57:13  time: 0.2846  data_time: 0.0151  memory: 5737  grad_norm: 5.5252  loss: 0.6446  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6446\n",
            "02/09 10:33:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][120/166]  lr: 1.0000e-02  eta: 1:57:04  time: 0.2859  data_time: 0.0159  memory: 5737  grad_norm: 5.1860  loss: 0.6240  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6240\n",
            "02/09 10:33:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][140/166]  lr: 1.0000e-02  eta: 1:56:54  time: 0.2850  data_time: 0.0155  memory: 5737  grad_norm: 5.1524  loss: 0.6184  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6184\n",
            "02/09 10:33:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][160/166]  lr: 1.0000e-02  eta: 1:56:45  time: 0.2851  data_time: 0.0158  memory: 5737  grad_norm: 5.2508  loss: 0.6836  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6836\n",
            "02/09 10:33:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:33:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [5][166/166]  lr: 1.0000e-02  eta: 1:56:41  time: 0.2825  data_time: 0.0149  memory: 5737  grad_norm: 5.1818  loss: 0.7117  top1_acc: 0.5714  top5_acc: 1.0000  loss_cls: 0.7117\n",
            "02/09 10:33:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)   [5][20/21]    eta: 0:00:00  time: 0.1563  data_time: 0.0700  memory: 991  \n",
            "02/09 10:33:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [5][21/21]    acc/top1: 0.6627  acc/top5: 1.0000  acc/mean1: 0.6443  data_time: 0.0668  time: 0.1519\n",
            "02/09 10:33:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.6627 acc/top1 at 5 epoch is saved to best_acc_top1_epoch_5.pth.\n",
            "02/09 10:33:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][ 20/166]  lr: 1.2000e-02  eta: 1:56:51  time: 0.3193  data_time: 0.0466  memory: 5737  grad_norm: 4.5208  loss: 0.6011  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6011\n",
            "02/09 10:33:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][ 40/166]  lr: 1.2000e-02  eta: 1:56:42  time: 0.2856  data_time: 0.0160  memory: 5737  grad_norm: 4.9234  loss: 0.6156  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6156\n",
            "02/09 10:33:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][ 60/166]  lr: 1.2000e-02  eta: 1:56:33  time: 0.2860  data_time: 0.0160  memory: 5737  grad_norm: 4.8063  loss: 0.5592  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5592\n",
            "02/09 10:33:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][ 80/166]  lr: 1.2000e-02  eta: 1:56:24  time: 0.2851  data_time: 0.0155  memory: 5737  grad_norm: 5.4232  loss: 0.6264  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6264\n",
            "02/09 10:34:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][100/166]  lr: 1.2000e-02  eta: 1:56:16  time: 0.2862  data_time: 0.0159  memory: 5737  grad_norm: 4.9819  loss: 0.6305  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6305\n",
            "02/09 10:34:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][120/166]  lr: 1.2000e-02  eta: 1:56:07  time: 0.2858  data_time: 0.0157  memory: 5737  grad_norm: 4.6468  loss: 0.5798  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5798\n",
            "02/09 10:34:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][140/166]  lr: 1.2000e-02  eta: 1:55:59  time: 0.2859  data_time: 0.0160  memory: 5737  grad_norm: 4.7234  loss: 0.6467  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6467\n",
            "02/09 10:34:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][160/166]  lr: 1.2000e-02  eta: 1:55:50  time: 0.2851  data_time: 0.0157  memory: 5737  grad_norm: 4.5594  loss: 0.6340  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6340\n",
            "02/09 10:34:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:34:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [6][166/166]  lr: 1.2000e-02  eta: 1:55:47  time: 0.2829  data_time: 0.0154  memory: 5737  grad_norm: 4.7689  loss: 0.6385  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.6385\n",
            "02/09 10:34:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:34:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][ 20/166]  lr: 1.4000e-02  eta: 1:55:53  time: 0.3171  data_time: 0.0451  memory: 5737  grad_norm: 4.4302  loss: 0.6390  top1_acc: 0.4375  top5_acc: 1.0000  loss_cls: 0.6390\n",
            "02/09 10:34:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][ 40/166]  lr: 1.4000e-02  eta: 1:55:45  time: 0.2851  data_time: 0.0153  memory: 5737  grad_norm: 4.4479  loss: 0.6105  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6105\n",
            "02/09 10:34:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][ 60/166]  lr: 1.4000e-02  eta: 1:55:37  time: 0.2862  data_time: 0.0162  memory: 5737  grad_norm: 4.5956  loss: 0.6079  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6079\n",
            "02/09 10:34:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][ 80/166]  lr: 1.4000e-02  eta: 1:55:28  time: 0.2849  data_time: 0.0150  memory: 5737  grad_norm: 4.4655  loss: 0.5728  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5728\n",
            "02/09 10:34:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][100/166]  lr: 1.4000e-02  eta: 1:55:21  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 4.6133  loss: 0.6366  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6366\n",
            "02/09 10:34:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][120/166]  lr: 1.4000e-02  eta: 1:55:12  time: 0.2847  data_time: 0.0150  memory: 5737  grad_norm: 3.9323  loss: 0.6169  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6169\n",
            "02/09 10:35:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][140/166]  lr: 1.4000e-02  eta: 1:55:04  time: 0.2855  data_time: 0.0154  memory: 5737  grad_norm: 4.4006  loss: 0.7372  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.7372\n",
            "02/09 10:35:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][160/166]  lr: 1.4000e-02  eta: 1:54:56  time: 0.2849  data_time: 0.0152  memory: 5737  grad_norm: 3.6953  loss: 0.6097  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6097\n",
            "02/09 10:35:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:35:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [7][166/166]  lr: 1.4000e-02  eta: 1:54:53  time: 0.2812  data_time: 0.0137  memory: 5737  grad_norm: 3.8156  loss: 0.6122  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.6122\n",
            "02/09 10:35:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][ 20/166]  lr: 1.6000e-02  eta: 1:55:00  time: 0.3222  data_time: 0.0503  memory: 5737  grad_norm: 3.8882  loss: 0.6116  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6116\n",
            "02/09 10:35:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][ 40/166]  lr: 1.6000e-02  eta: 1:54:52  time: 0.2866  data_time: 0.0163  memory: 5737  grad_norm: 3.9373  loss: 0.5737  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5737\n",
            "02/09 10:35:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][ 60/166]  lr: 1.6000e-02  eta: 1:54:44  time: 0.2861  data_time: 0.0158  memory: 5737  grad_norm: 4.0802  loss: 0.5660  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5660\n",
            "02/09 10:35:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][ 80/166]  lr: 1.6000e-02  eta: 1:54:37  time: 0.2857  data_time: 0.0157  memory: 5737  grad_norm: 3.7825  loss: 0.6149  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6149\n",
            "02/09 10:35:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][100/166]  lr: 1.6000e-02  eta: 1:54:29  time: 0.2856  data_time: 0.0155  memory: 5737  grad_norm: 3.8226  loss: 0.6050  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6050\n",
            "02/09 10:35:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][120/166]  lr: 1.6000e-02  eta: 1:54:21  time: 0.2854  data_time: 0.0155  memory: 5737  grad_norm: 4.0721  loss: 0.6502  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6502\n",
            "02/09 10:35:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][140/166]  lr: 1.6000e-02  eta: 1:54:13  time: 0.2853  data_time: 0.0152  memory: 5737  grad_norm: 3.9322  loss: 0.6544  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6544\n",
            "02/09 10:35:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][160/166]  lr: 1.6000e-02  eta: 1:54:06  time: 0.2848  data_time: 0.0153  memory: 5737  grad_norm: 3.4326  loss: 0.6056  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6056\n",
            "02/09 10:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [8][166/166]  lr: 1.6000e-02  eta: 1:54:03  time: 0.2818  data_time: 0.0141  memory: 5737  grad_norm: 3.5194  loss: 0.6283  top1_acc: 0.5714  top5_acc: 1.0000  loss_cls: 0.6283\n",
            "02/09 10:35:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 8 epochs\n",
            "02/09 10:36:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][ 20/166]  lr: 1.8000e-02  eta: 1:54:08  time: 0.3223  data_time: 0.0505  memory: 5737  grad_norm: 3.6305  loss: 0.6448  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6448\n",
            "02/09 10:36:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][ 40/166]  lr: 1.8000e-02  eta: 1:54:00  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 3.7807  loss: 0.6972  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6972\n",
            "02/09 10:36:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][ 60/166]  lr: 1.8000e-02  eta: 1:53:53  time: 0.2847  data_time: 0.0149  memory: 5737  grad_norm: 3.5192  loss: 0.5914  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5914\n",
            "02/09 10:36:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][ 80/166]  lr: 1.8000e-02  eta: 1:53:45  time: 0.2854  data_time: 0.0155  memory: 5737  grad_norm: 3.4866  loss: 0.6622  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6622\n",
            "02/09 10:36:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][100/166]  lr: 1.8000e-02  eta: 1:53:38  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 3.3764  loss: 0.6215  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.6215\n",
            "02/09 10:36:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][120/166]  lr: 1.8000e-02  eta: 1:53:31  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 3.5289  loss: 0.6393  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6393\n",
            "02/09 10:36:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][140/166]  lr: 1.8000e-02  eta: 1:53:23  time: 0.2853  data_time: 0.0156  memory: 5737  grad_norm: 3.0332  loss: 0.5887  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5887\n",
            "02/09 10:36:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][160/166]  lr: 1.8000e-02  eta: 1:53:16  time: 0.2849  data_time: 0.0157  memory: 5737  grad_norm: 3.1370  loss: 0.5697  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5697\n",
            "02/09 10:36:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:36:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)   [9][166/166]  lr: 1.8000e-02  eta: 1:53:13  time: 0.2820  data_time: 0.0147  memory: 5737  grad_norm: 3.1557  loss: 0.5659  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.5659\n",
            "02/09 10:36:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][ 20/166]  lr: 2.0000e-02  eta: 1:53:14  time: 0.3144  data_time: 0.0421  memory: 5737  grad_norm: 3.4192  loss: 0.6138  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6138\n",
            "02/09 10:36:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][ 40/166]  lr: 2.0000e-02  eta: 1:53:07  time: 0.2856  data_time: 0.0157  memory: 5737  grad_norm: 4.0992  loss: 0.6247  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.6247\n",
            "02/09 10:37:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][ 60/166]  lr: 2.0000e-02  eta: 1:53:00  time: 0.2860  data_time: 0.0158  memory: 5737  grad_norm: 3.6657  loss: 0.6171  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6171\n",
            "02/09 10:37:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][ 80/166]  lr: 2.0000e-02  eta: 1:52:53  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 3.5980  loss: 0.6320  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6320\n",
            "02/09 10:37:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][100/166]  lr: 2.0000e-02  eta: 1:52:45  time: 0.2849  data_time: 0.0152  memory: 5737  grad_norm: 3.3893  loss: 0.6876  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6876\n",
            "02/09 10:37:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][120/166]  lr: 2.0000e-02  eta: 1:52:38  time: 0.2864  data_time: 0.0163  memory: 5737  grad_norm: 3.0175  loss: 0.6373  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6373\n",
            "02/09 10:37:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][140/166]  lr: 2.0000e-02  eta: 1:52:31  time: 0.2852  data_time: 0.0153  memory: 5737  grad_norm: 3.0760  loss: 0.5832  top1_acc: 0.4375  top5_acc: 1.0000  loss_cls: 0.5832\n",
            "02/09 10:37:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][160/166]  lr: 2.0000e-02  eta: 1:52:24  time: 0.2849  data_time: 0.0153  memory: 5737  grad_norm: 3.0272  loss: 0.6267  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6267\n",
            "02/09 10:37:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:37:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [10][166/166]  lr: 2.0000e-02  eta: 1:52:21  time: 0.2820  data_time: 0.0144  memory: 5737  grad_norm: 3.0084  loss: 0.5929  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.5929\n",
            "02/09 10:37:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [10][20/21]    eta: 0:00:00  time: 0.1396  data_time: 0.0548  memory: 991  \n",
            "02/09 10:37:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [10][21/21]    acc/top1: 0.6416  acc/top5: 1.0000  acc/mean1: 0.6314  data_time: 0.0501  time: 0.1327\n",
            "02/09 10:37:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][ 20/166]  lr: 2.0000e-02  eta: 1:52:21  time: 0.3118  data_time: 0.0409  memory: 5737  grad_norm: 3.0229  loss: 0.5690  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5690\n",
            "02/09 10:37:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][ 40/166]  lr: 2.0000e-02  eta: 1:52:14  time: 0.2852  data_time: 0.0154  memory: 5737  grad_norm: 3.2942  loss: 0.6193  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.6193\n",
            "02/09 10:37:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][ 60/166]  lr: 2.0000e-02  eta: 1:52:07  time: 0.2860  data_time: 0.0158  memory: 5737  grad_norm: 3.1419  loss: 0.6141  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6141\n",
            "02/09 10:38:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][ 80/166]  lr: 2.0000e-02  eta: 1:52:00  time: 0.2851  data_time: 0.0155  memory: 5737  grad_norm: 2.9160  loss: 0.6478  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6478\n",
            "02/09 10:38:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][100/166]  lr: 2.0000e-02  eta: 1:51:53  time: 0.2872  data_time: 0.0166  memory: 5737  grad_norm: 2.8942  loss: 0.6318  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.6318\n",
            "02/09 10:38:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][120/166]  lr: 2.0000e-02  eta: 1:51:46  time: 0.2843  data_time: 0.0151  memory: 5737  grad_norm: 2.9106  loss: 0.6471  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6471\n",
            "02/09 10:38:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][140/166]  lr: 2.0000e-02  eta: 1:51:39  time: 0.2858  data_time: 0.0157  memory: 5737  grad_norm: 2.8954  loss: 0.6119  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.6119\n",
            "02/09 10:38:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][160/166]  lr: 2.0000e-02  eta: 1:51:32  time: 0.2850  data_time: 0.0154  memory: 5737  grad_norm: 2.6737  loss: 0.5753  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5753\n",
            "02/09 10:38:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:38:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [11][166/166]  lr: 2.0000e-02  eta: 1:51:29  time: 0.2819  data_time: 0.0141  memory: 5737  grad_norm: 2.6873  loss: 0.5798  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.5798\n",
            "02/09 10:38:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][ 20/166]  lr: 2.0000e-02  eta: 1:51:32  time: 0.3222  data_time: 0.0515  memory: 5737  grad_norm: 2.6804  loss: 0.5897  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5897\n",
            "02/09 10:38:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][ 40/166]  lr: 2.0000e-02  eta: 1:51:27  time: 0.2955  data_time: 0.0153  memory: 5737  grad_norm: 3.0285  loss: 0.5941  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5941\n",
            "02/09 10:38:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][ 60/166]  lr: 2.0000e-02  eta: 1:51:20  time: 0.2861  data_time: 0.0163  memory: 5737  grad_norm: 2.8282  loss: 0.5536  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5536\n",
            "02/09 10:38:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][ 80/166]  lr: 2.0000e-02  eta: 1:51:14  time: 0.2866  data_time: 0.0165  memory: 5737  grad_norm: 2.7484  loss: 0.5817  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5817\n",
            "02/09 10:38:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][100/166]  lr: 2.0000e-02  eta: 1:51:07  time: 0.2857  data_time: 0.0159  memory: 5737  grad_norm: 2.7044  loss: 0.6149  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6149\n",
            "02/09 10:38:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][120/166]  lr: 2.0000e-02  eta: 1:51:00  time: 0.2858  data_time: 0.0155  memory: 5737  grad_norm: 2.7914  loss: 0.5587  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5587\n",
            "02/09 10:39:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][140/166]  lr: 2.0000e-02  eta: 1:50:53  time: 0.2863  data_time: 0.0161  memory: 5737  grad_norm: 2.9342  loss: 0.5726  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5726\n",
            "02/09 10:39:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][160/166]  lr: 2.0000e-02  eta: 1:50:46  time: 0.2841  data_time: 0.0148  memory: 5737  grad_norm: 2.8588  loss: 0.5582  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5582\n",
            "02/09 10:39:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:39:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [12][166/166]  lr: 2.0000e-02  eta: 1:50:43  time: 0.2814  data_time: 0.0141  memory: 5737  grad_norm: 2.9090  loss: 0.5607  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.5607\n",
            "02/09 10:39:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 12 epochs\n",
            "02/09 10:39:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:39:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][ 20/166]  lr: 2.0000e-02  eta: 1:50:44  time: 0.3198  data_time: 0.0484  memory: 5737  grad_norm: 2.8901  loss: 0.5276  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5276\n",
            "02/09 10:39:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][ 40/166]  lr: 2.0000e-02  eta: 1:50:38  time: 0.2853  data_time: 0.0155  memory: 5737  grad_norm: 3.2129  loss: 0.6340  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.6340\n",
            "02/09 10:39:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][ 60/166]  lr: 2.0000e-02  eta: 1:50:31  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 2.4450  loss: 0.5799  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5799\n",
            "02/09 10:39:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][ 80/166]  lr: 2.0000e-02  eta: 1:50:24  time: 0.2848  data_time: 0.0151  memory: 5737  grad_norm: 2.4815  loss: 0.5921  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5921\n",
            "02/09 10:39:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][100/166]  lr: 2.0000e-02  eta: 1:50:17  time: 0.2864  data_time: 0.0160  memory: 5737  grad_norm: 2.7324  loss: 0.5768  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5768\n",
            "02/09 10:39:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][120/166]  lr: 2.0000e-02  eta: 1:50:10  time: 0.2857  data_time: 0.0157  memory: 5737  grad_norm: 2.5398  loss: 0.5467  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5467\n",
            "02/09 10:39:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][140/166]  lr: 2.0000e-02  eta: 1:50:04  time: 0.2852  data_time: 0.0154  memory: 5737  grad_norm: 2.4995  loss: 0.5626  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5626\n",
            "02/09 10:40:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][160/166]  lr: 2.0000e-02  eta: 1:49:57  time: 0.2847  data_time: 0.0151  memory: 5737  grad_norm: 2.7771  loss: 0.6553  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6553\n",
            "02/09 10:40:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:40:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [13][166/166]  lr: 2.0000e-02  eta: 1:49:54  time: 0.2820  data_time: 0.0145  memory: 5737  grad_norm: 2.6412  loss: 0.6062  top1_acc: 0.5714  top5_acc: 1.0000  loss_cls: 0.6062\n",
            "02/09 10:40:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][ 20/166]  lr: 2.0000e-02  eta: 1:49:53  time: 0.3127  data_time: 0.0407  memory: 5737  grad_norm: 2.5777  loss: 0.5651  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5651\n",
            "02/09 10:40:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][ 40/166]  lr: 2.0000e-02  eta: 1:49:46  time: 0.2847  data_time: 0.0151  memory: 5737  grad_norm: 3.0770  loss: 0.6268  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.6268\n",
            "02/09 10:40:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][ 60/166]  lr: 2.0000e-02  eta: 1:49:39  time: 0.2860  data_time: 0.0160  memory: 5737  grad_norm: 2.5600  loss: 0.5560  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5560\n",
            "02/09 10:40:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][ 80/166]  lr: 2.0000e-02  eta: 1:49:33  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 2.6065  loss: 0.5100  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5100\n",
            "02/09 10:40:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][100/166]  lr: 2.0000e-02  eta: 1:49:26  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 2.8081  loss: 0.5606  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5606\n",
            "02/09 10:40:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][120/166]  lr: 2.0000e-02  eta: 1:49:20  time: 0.2861  data_time: 0.0157  memory: 5737  grad_norm: 2.4426  loss: 0.5241  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.5241\n",
            "02/09 10:40:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][140/166]  lr: 2.0000e-02  eta: 1:49:13  time: 0.2854  data_time: 0.0156  memory: 5737  grad_norm: 2.7609  loss: 0.5605  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5605\n",
            "02/09 10:40:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][160/166]  lr: 2.0000e-02  eta: 1:49:06  time: 0.2845  data_time: 0.0150  memory: 5737  grad_norm: 2.7501  loss: 0.5437  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5437\n",
            "02/09 10:40:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:40:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [14][166/166]  lr: 2.0000e-02  eta: 1:49:04  time: 0.2815  data_time: 0.0139  memory: 5737  grad_norm: 2.7215  loss: 0.5144  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.5144\n",
            "02/09 10:40:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][ 20/166]  lr: 2.0000e-02  eta: 1:49:03  time: 0.3167  data_time: 0.0457  memory: 5737  grad_norm: 2.6323  loss: 0.5169  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.5169\n",
            "02/09 10:41:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][ 40/166]  lr: 2.0000e-02  eta: 1:48:57  time: 0.2871  data_time: 0.0168  memory: 5737  grad_norm: 2.4394  loss: 0.4481  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4481\n",
            "02/09 10:41:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][ 60/166]  lr: 2.0000e-02  eta: 1:48:50  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 2.8836  loss: 0.5471  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5471\n",
            "02/09 10:41:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][ 80/166]  lr: 2.0000e-02  eta: 1:48:43  time: 0.2852  data_time: 0.0151  memory: 5737  grad_norm: 2.6297  loss: 0.5374  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5374\n",
            "02/09 10:41:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][100/166]  lr: 2.0000e-02  eta: 1:48:37  time: 0.2845  data_time: 0.0149  memory: 5737  grad_norm: 2.4374  loss: 0.5243  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5243\n",
            "02/09 10:41:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][120/166]  lr: 2.0000e-02  eta: 1:48:30  time: 0.2876  data_time: 0.0170  memory: 5737  grad_norm: 2.7020  loss: 0.5642  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.5642\n",
            "02/09 10:41:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][140/166]  lr: 2.0000e-02  eta: 1:48:24  time: 0.2868  data_time: 0.0168  memory: 5737  grad_norm: 2.5227  loss: 0.5475  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5475\n",
            "02/09 10:41:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][160/166]  lr: 2.0000e-02  eta: 1:48:18  time: 0.2859  data_time: 0.0163  memory: 5737  grad_norm: 2.3866  loss: 0.4895  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4895\n",
            "02/09 10:41:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:41:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [15][166/166]  lr: 2.0000e-02  eta: 1:48:15  time: 0.2835  data_time: 0.0154  memory: 5737  grad_norm: 2.4944  loss: 0.4965  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.4965\n",
            "02/09 10:41:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [15][20/21]    eta: 0:00:00  time: 0.1399  data_time: 0.0552  memory: 991  \n",
            "02/09 10:41:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [15][21/21]    acc/top1: 0.7108  acc/top5: 1.0000  acc/mean1: 0.7032  data_time: 0.0505  time: 0.1329\n",
            "02/09 10:41:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb/best_acc_top1_epoch_5.pth is removed\n",
            "02/09 10:41:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7108 acc/top1 at 15 epoch is saved to best_acc_top1_epoch_15.pth.\n",
            "02/09 10:41:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][ 20/166]  lr: 2.0000e-02  eta: 1:48:14  time: 0.3181  data_time: 0.0460  memory: 5737  grad_norm: 2.5929  loss: 0.5289  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5289\n",
            "02/09 10:41:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][ 40/166]  lr: 2.0000e-02  eta: 1:48:08  time: 0.2858  data_time: 0.0159  memory: 5737  grad_norm: 2.7775  loss: 0.5765  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5765\n",
            "02/09 10:41:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][ 60/166]  lr: 2.0000e-02  eta: 1:48:01  time: 0.2864  data_time: 0.0160  memory: 5737  grad_norm: 2.6509  loss: 0.5187  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5187\n",
            "02/09 10:42:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][ 80/166]  lr: 2.0000e-02  eta: 1:47:55  time: 0.2850  data_time: 0.0150  memory: 5737  grad_norm: 2.7771  loss: 0.4717  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4717\n",
            "02/09 10:42:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][100/166]  lr: 2.0000e-02  eta: 1:47:48  time: 0.2869  data_time: 0.0163  memory: 5737  grad_norm: 2.7530  loss: 0.5251  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5251\n",
            "02/09 10:42:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][120/166]  lr: 2.0000e-02  eta: 1:47:42  time: 0.2859  data_time: 0.0158  memory: 5737  grad_norm: 2.5489  loss: 0.5516  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5516\n",
            "02/09 10:42:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][140/166]  lr: 2.0000e-02  eta: 1:47:35  time: 0.2859  data_time: 0.0157  memory: 5737  grad_norm: 2.7261  loss: 0.5250  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5250\n",
            "02/09 10:42:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][160/166]  lr: 2.0000e-02  eta: 1:47:29  time: 0.2853  data_time: 0.0152  memory: 5737  grad_norm: 2.5283  loss: 0.5569  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5569\n",
            "02/09 10:42:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:42:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [16][166/166]  lr: 2.0000e-02  eta: 1:47:26  time: 0.2825  data_time: 0.0145  memory: 5737  grad_norm: 2.4221  loss: 0.5279  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.5279\n",
            "02/09 10:42:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 16 epochs\n",
            "02/09 10:42:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][ 20/166]  lr: 2.0000e-02  eta: 1:47:25  time: 0.3146  data_time: 0.0427  memory: 5737  grad_norm: 2.5982  loss: 0.4880  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4880\n",
            "02/09 10:42:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][ 40/166]  lr: 2.0000e-02  eta: 1:47:18  time: 0.2858  data_time: 0.0160  memory: 5737  grad_norm: 2.5160  loss: 0.4902  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4902\n",
            "02/09 10:42:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][ 60/166]  lr: 2.0000e-02  eta: 1:47:12  time: 0.2870  data_time: 0.0164  memory: 5737  grad_norm: 2.6979  loss: 0.5777  top1_acc: 0.3750  top5_acc: 1.0000  loss_cls: 0.5777\n",
            "02/09 10:42:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][ 80/166]  lr: 2.0000e-02  eta: 1:47:05  time: 0.2851  data_time: 0.0152  memory: 5737  grad_norm: 2.5229  loss: 0.5532  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5532\n",
            "02/09 10:43:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][100/166]  lr: 2.0000e-02  eta: 1:46:59  time: 0.2871  data_time: 0.0169  memory: 5737  grad_norm: 2.4244  loss: 0.5037  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5037\n",
            "02/09 10:43:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][120/166]  lr: 2.0000e-02  eta: 1:46:53  time: 0.2866  data_time: 0.0164  memory: 5737  grad_norm: 2.3239  loss: 0.4323  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4323\n",
            "02/09 10:43:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][140/166]  lr: 2.0000e-02  eta: 1:46:46  time: 0.2859  data_time: 0.0159  memory: 5737  grad_norm: 2.9340  loss: 0.5743  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5743\n",
            "02/09 10:43:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][160/166]  lr: 2.0000e-02  eta: 1:46:40  time: 0.2847  data_time: 0.0150  memory: 5737  grad_norm: 2.4506  loss: 0.5014  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.5014\n",
            "02/09 10:43:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:43:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [17][166/166]  lr: 2.0000e-02  eta: 1:46:38  time: 0.2822  data_time: 0.0142  memory: 5737  grad_norm: 2.5202  loss: 0.5055  top1_acc: 0.5714  top5_acc: 1.0000  loss_cls: 0.5055\n",
            "02/09 10:43:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][ 20/166]  lr: 2.0000e-02  eta: 1:46:36  time: 0.3174  data_time: 0.0438  memory: 5737  grad_norm: 2.8047  loss: 0.5250  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5250\n",
            "02/09 10:43:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][ 40/166]  lr: 2.0000e-02  eta: 1:46:30  time: 0.2858  data_time: 0.0162  memory: 5737  grad_norm: 2.8802  loss: 0.5345  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5345\n",
            "02/09 10:43:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][ 60/166]  lr: 2.0000e-02  eta: 1:46:23  time: 0.2857  data_time: 0.0159  memory: 5737  grad_norm: 2.4310  loss: 0.5069  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5069\n",
            "02/09 10:43:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][ 80/166]  lr: 2.0000e-02  eta: 1:46:17  time: 0.2849  data_time: 0.0150  memory: 5737  grad_norm: 2.6785  loss: 0.5808  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.5808\n",
            "02/09 10:43:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][100/166]  lr: 2.0000e-02  eta: 1:46:10  time: 0.2875  data_time: 0.0171  memory: 5737  grad_norm: 2.1515  loss: 0.4603  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4603\n",
            "02/09 10:43:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][120/166]  lr: 2.0000e-02  eta: 1:46:04  time: 0.2855  data_time: 0.0154  memory: 5737  grad_norm: 2.6983  loss: 0.5663  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5663\n",
            "02/09 10:43:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][140/166]  lr: 2.0000e-02  eta: 1:45:58  time: 0.2874  data_time: 0.0168  memory: 5737  grad_norm: 2.2793  loss: 0.5060  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.5060\n",
            "02/09 10:44:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][160/166]  lr: 2.0000e-02  eta: 1:45:51  time: 0.2847  data_time: 0.0151  memory: 5737  grad_norm: 2.5525  loss: 0.4960  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4960\n",
            "02/09 10:44:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:44:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [18][166/166]  lr: 2.0000e-02  eta: 1:45:49  time: 0.2821  data_time: 0.0143  memory: 5737  grad_norm: 2.3931  loss: 0.4521  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.4521\n",
            "02/09 10:44:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:44:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][ 20/166]  lr: 2.0000e-02  eta: 1:45:48  time: 0.3196  data_time: 0.0482  memory: 5737  grad_norm: 2.7526  loss: 0.4786  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4786\n",
            "02/09 10:44:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][ 40/166]  lr: 2.0000e-02  eta: 1:45:41  time: 0.2848  data_time: 0.0153  memory: 5737  grad_norm: 2.5271  loss: 0.4658  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4658\n",
            "02/09 10:44:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][ 60/166]  lr: 2.0000e-02  eta: 1:45:35  time: 0.2863  data_time: 0.0165  memory: 5737  grad_norm: 2.6336  loss: 0.5387  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5387\n",
            "02/09 10:44:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][ 80/166]  lr: 2.0000e-02  eta: 1:45:28  time: 0.2856  data_time: 0.0157  memory: 5737  grad_norm: 2.4044  loss: 0.4580  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4580\n",
            "02/09 10:44:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][100/166]  lr: 2.0000e-02  eta: 1:45:22  time: 0.2853  data_time: 0.0153  memory: 5737  grad_norm: 2.8444  loss: 0.4847  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4847\n",
            "02/09 10:44:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][120/166]  lr: 2.0000e-02  eta: 1:45:16  time: 0.2860  data_time: 0.0157  memory: 5737  grad_norm: 3.2470  loss: 0.5886  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5886\n",
            "02/09 10:44:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][140/166]  lr: 2.0000e-02  eta: 1:45:09  time: 0.2865  data_time: 0.0161  memory: 5737  grad_norm: 2.6406  loss: 0.5606  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5606\n",
            "02/09 10:44:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][160/166]  lr: 2.0000e-02  eta: 1:45:03  time: 0.2846  data_time: 0.0151  memory: 5737  grad_norm: 2.4130  loss: 0.4789  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.4789\n",
            "02/09 10:44:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:44:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [19][166/166]  lr: 2.0000e-02  eta: 1:45:00  time: 0.2815  data_time: 0.0139  memory: 5737  grad_norm: 2.4328  loss: 0.4581  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.4581\n",
            "02/09 10:45:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][ 20/166]  lr: 2.0000e-02  eta: 1:44:59  time: 0.3203  data_time: 0.0476  memory: 5737  grad_norm: 2.6580  loss: 0.5508  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5508\n",
            "02/09 10:45:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][ 40/166]  lr: 2.0000e-02  eta: 1:44:53  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 2.3555  loss: 0.5295  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5295\n",
            "02/09 10:45:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][ 60/166]  lr: 2.0000e-02  eta: 1:44:46  time: 0.2862  data_time: 0.0159  memory: 5737  grad_norm: 2.5639  loss: 0.5106  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5106\n",
            "02/09 10:45:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][ 80/166]  lr: 2.0000e-02  eta: 1:44:40  time: 0.2866  data_time: 0.0163  memory: 5737  grad_norm: 2.2955  loss: 0.4111  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4111\n",
            "02/09 10:45:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][100/166]  lr: 2.0000e-02  eta: 1:44:34  time: 0.2857  data_time: 0.0156  memory: 5737  grad_norm: 2.6426  loss: 0.4829  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4829\n",
            "02/09 10:45:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][120/166]  lr: 2.0000e-02  eta: 1:44:28  time: 0.2871  data_time: 0.0169  memory: 5737  grad_norm: 2.7255  loss: 0.5229  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.5229\n",
            "02/09 10:45:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][140/166]  lr: 2.0000e-02  eta: 1:44:21  time: 0.2856  data_time: 0.0158  memory: 5737  grad_norm: 2.6203  loss: 0.4765  top1_acc: 0.5000  top5_acc: 1.0000  loss_cls: 0.4765\n",
            "02/09 10:45:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][160/166]  lr: 2.0000e-02  eta: 1:44:15  time: 0.2852  data_time: 0.0157  memory: 5737  grad_norm: 2.5429  loss: 0.4626  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4626\n",
            "02/09 10:45:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:45:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [20][166/166]  lr: 2.0000e-02  eta: 1:44:13  time: 0.2820  data_time: 0.0144  memory: 5737  grad_norm: 2.5203  loss: 0.4417  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.4417\n",
            "02/09 10:45:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 20 epochs\n",
            "02/09 10:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [20][20/21]    eta: 0:00:00  time: 0.1403  data_time: 0.0546  memory: 991  \n",
            "02/09 10:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [20][21/21]    acc/top1: 0.7139  acc/top5: 1.0000  acc/mean1: 0.7088  data_time: 0.0500  time: 0.1334\n",
            "02/09 10:45:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb/best_acc_top1_epoch_15.pth is removed\n",
            "02/09 10:45:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7139 acc/top1 at 20 epoch is saved to best_acc_top1_epoch_20.pth.\n",
            "02/09 10:45:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][ 20/166]  lr: 2.0000e-02  eta: 1:44:11  time: 0.3248  data_time: 0.0527  memory: 5737  grad_norm: 2.7025  loss: 0.4463  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4463\n",
            "02/09 10:46:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][ 40/166]  lr: 2.0000e-02  eta: 1:44:05  time: 0.2870  data_time: 0.0165  memory: 5737  grad_norm: 3.2551  loss: 0.5658  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5658\n",
            "02/09 10:46:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][ 60/166]  lr: 2.0000e-02  eta: 1:43:59  time: 0.2866  data_time: 0.0164  memory: 5737  grad_norm: 2.7565  loss: 0.4404  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4404\n",
            "02/09 10:46:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][ 80/166]  lr: 2.0000e-02  eta: 1:43:53  time: 0.2857  data_time: 0.0158  memory: 5737  grad_norm: 3.0002  loss: 0.4961  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4961\n",
            "02/09 10:46:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][100/166]  lr: 2.0000e-02  eta: 1:43:46  time: 0.2864  data_time: 0.0164  memory: 5737  grad_norm: 2.6865  loss: 0.5135  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5135\n",
            "02/09 10:46:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][120/166]  lr: 2.0000e-02  eta: 1:43:40  time: 0.2854  data_time: 0.0153  memory: 5737  grad_norm: 2.6353  loss: 0.4582  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4582\n",
            "02/09 10:46:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][140/166]  lr: 2.0000e-02  eta: 1:43:34  time: 0.2861  data_time: 0.0157  memory: 5737  grad_norm: 2.8587  loss: 0.5531  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.5531\n",
            "02/09 10:46:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][160/166]  lr: 2.0000e-02  eta: 1:43:27  time: 0.2839  data_time: 0.0144  memory: 5737  grad_norm: 2.0911  loss: 0.4613  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4613\n",
            "02/09 10:46:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:46:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [21][166/166]  lr: 2.0000e-02  eta: 1:43:25  time: 0.2817  data_time: 0.0138  memory: 5737  grad_norm: 2.3194  loss: 0.4849  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.4849\n",
            "02/09 10:46:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][ 20/166]  lr: 2.0000e-02  eta: 1:43:22  time: 0.3160  data_time: 0.0439  memory: 5737  grad_norm: 2.4455  loss: 0.4670  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4670\n",
            "02/09 10:46:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][ 40/166]  lr: 2.0000e-02  eta: 1:43:16  time: 0.2850  data_time: 0.0152  memory: 5737  grad_norm: 2.2579  loss: 0.4290  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4290\n",
            "02/09 10:46:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][ 60/166]  lr: 2.0000e-02  eta: 1:43:10  time: 0.2864  data_time: 0.0159  memory: 5737  grad_norm: 2.6422  loss: 0.4340  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4340\n",
            "02/09 10:47:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][ 80/166]  lr: 2.0000e-02  eta: 1:43:03  time: 0.2853  data_time: 0.0152  memory: 5737  grad_norm: 2.9634  loss: 0.5260  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5260\n",
            "02/09 10:47:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][100/166]  lr: 2.0000e-02  eta: 1:42:57  time: 0.2861  data_time: 0.0158  memory: 5737  grad_norm: 2.5380  loss: 0.4455  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4455\n",
            "02/09 10:47:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][120/166]  lr: 2.0000e-02  eta: 1:42:51  time: 0.2856  data_time: 0.0158  memory: 5737  grad_norm: 2.7889  loss: 0.5001  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5001\n",
            "02/09 10:47:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][140/166]  lr: 2.0000e-02  eta: 1:42:45  time: 0.2869  data_time: 0.0168  memory: 5737  grad_norm: 2.7512  loss: 0.4709  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4709\n",
            "02/09 10:47:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][160/166]  lr: 2.0000e-02  eta: 1:42:38  time: 0.2844  data_time: 0.0150  memory: 5737  grad_norm: 2.8212  loss: 0.5517  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5517\n",
            "02/09 10:47:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:47:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [22][166/166]  lr: 2.0000e-02  eta: 1:42:36  time: 0.2819  data_time: 0.0144  memory: 5737  grad_norm: 2.9247  loss: 0.5538  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.5538\n",
            "02/09 10:47:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][ 20/166]  lr: 2.0000e-02  eta: 1:42:34  time: 0.3215  data_time: 0.0493  memory: 5737  grad_norm: 2.0148  loss: 0.3855  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3855\n",
            "02/09 10:47:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][ 40/166]  lr: 2.0000e-02  eta: 1:42:28  time: 0.2862  data_time: 0.0158  memory: 5737  grad_norm: 2.4674  loss: 0.4342  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4342\n",
            "02/09 10:47:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][ 60/166]  lr: 2.0000e-02  eta: 1:42:22  time: 0.2866  data_time: 0.0162  memory: 5737  grad_norm: 2.6087  loss: 0.4890  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4890\n",
            "02/09 10:47:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][ 80/166]  lr: 2.0000e-02  eta: 1:42:15  time: 0.2855  data_time: 0.0157  memory: 5737  grad_norm: 2.6823  loss: 0.5257  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5257\n",
            "02/09 10:47:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][100/166]  lr: 2.0000e-02  eta: 1:42:09  time: 0.2861  data_time: 0.0158  memory: 5737  grad_norm: 2.6585  loss: 0.5195  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5195\n",
            "02/09 10:47:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][120/166]  lr: 2.0000e-02  eta: 1:42:03  time: 0.2860  data_time: 0.0158  memory: 5737  grad_norm: 2.4835  loss: 0.4326  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4326\n",
            "02/09 10:48:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][140/166]  lr: 2.0000e-02  eta: 1:41:57  time: 0.2868  data_time: 0.0166  memory: 5737  grad_norm: 2.6446  loss: 0.4071  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4071\n",
            "02/09 10:48:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][160/166]  lr: 2.0000e-02  eta: 1:41:50  time: 0.2842  data_time: 0.0149  memory: 5737  grad_norm: 2.7531  loss: 0.4979  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.4979\n",
            "02/09 10:48:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:48:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [23][166/166]  lr: 2.0000e-02  eta: 1:41:48  time: 0.2820  data_time: 0.0143  memory: 5737  grad_norm: 2.6155  loss: 0.4910  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.4910\n",
            "02/09 10:48:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][ 20/166]  lr: 2.0000e-02  eta: 1:41:45  time: 0.3148  data_time: 0.0431  memory: 5737  grad_norm: 2.4721  loss: 0.4438  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4438\n",
            "02/09 10:48:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][ 40/166]  lr: 2.0000e-02  eta: 1:41:39  time: 0.2852  data_time: 0.0152  memory: 5737  grad_norm: 2.7086  loss: 0.4783  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.4783\n",
            "02/09 10:48:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][ 60/166]  lr: 2.0000e-02  eta: 1:41:33  time: 0.2865  data_time: 0.0161  memory: 5737  grad_norm: 3.1601  loss: 0.5563  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.5563\n",
            "02/09 10:48:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][ 80/166]  lr: 2.0000e-02  eta: 1:41:26  time: 0.2852  data_time: 0.0152  memory: 5737  grad_norm: 2.2089  loss: 0.4523  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.4523\n",
            "02/09 10:48:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][100/166]  lr: 2.0000e-02  eta: 1:41:20  time: 0.2862  data_time: 0.0158  memory: 5737  grad_norm: 2.4969  loss: 0.4694  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4694\n",
            "02/09 10:48:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][120/166]  lr: 2.0000e-02  eta: 1:41:14  time: 0.2861  data_time: 0.0157  memory: 5737  grad_norm: 2.6121  loss: 0.4273  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4273\n",
            "02/09 10:48:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][140/166]  lr: 2.0000e-02  eta: 1:41:08  time: 0.2869  data_time: 0.0163  memory: 5737  grad_norm: 2.6131  loss: 0.4752  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4752\n",
            "02/09 10:48:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][160/166]  lr: 2.0000e-02  eta: 1:41:02  time: 0.2846  data_time: 0.0151  memory: 5737  grad_norm: 2.5965  loss: 0.5446  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.5446\n",
            "02/09 10:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [24][166/166]  lr: 2.0000e-02  eta: 1:41:00  time: 0.2820  data_time: 0.0142  memory: 5737  grad_norm: 2.5474  loss: 0.5615  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.5615\n",
            "02/09 10:49:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 24 epochs\n",
            "02/09 10:49:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:49:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][ 20/166]  lr: 2.0000e-02  eta: 1:40:57  time: 0.3174  data_time: 0.0446  memory: 5737  grad_norm: 2.0476  loss: 0.4233  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4233\n",
            "02/09 10:49:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][ 40/166]  lr: 2.0000e-02  eta: 1:40:51  time: 0.2873  data_time: 0.0172  memory: 5737  grad_norm: 2.7785  loss: 0.4561  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.4561\n",
            "02/09 10:49:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][ 60/166]  lr: 2.0000e-02  eta: 1:40:44  time: 0.2867  data_time: 0.0165  memory: 5737  grad_norm: 2.5428  loss: 0.3943  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3943\n",
            "02/09 10:49:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][ 80/166]  lr: 2.0000e-02  eta: 1:40:38  time: 0.2851  data_time: 0.0151  memory: 5737  grad_norm: 2.8856  loss: 0.4594  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4594\n",
            "02/09 10:49:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][100/166]  lr: 2.0000e-02  eta: 1:40:32  time: 0.2887  data_time: 0.0178  memory: 5737  grad_norm: 2.2785  loss: 0.3952  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3952\n",
            "02/09 10:49:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][120/166]  lr: 2.0000e-02  eta: 1:40:26  time: 0.2865  data_time: 0.0161  memory: 5737  grad_norm: 2.6998  loss: 0.4849  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4849\n",
            "02/09 10:49:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][140/166]  lr: 2.0000e-02  eta: 1:40:20  time: 0.2908  data_time: 0.0194  memory: 5737  grad_norm: 2.3886  loss: 0.3747  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3747\n",
            "02/09 10:49:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][160/166]  lr: 2.0000e-02  eta: 1:40:14  time: 0.2853  data_time: 0.0154  memory: 5737  grad_norm: 2.5854  loss: 0.4103  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4103\n",
            "02/09 10:49:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:49:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [25][166/166]  lr: 2.0000e-02  eta: 1:40:12  time: 0.2825  data_time: 0.0143  memory: 5737  grad_norm: 2.7615  loss: 0.4830  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.4830\n",
            "02/09 10:49:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [25][20/21]    eta: 0:00:00  time: 0.1445  data_time: 0.0592  memory: 991  \n",
            "02/09 10:49:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [25][21/21]    acc/top1: 0.6717  acc/top5: 1.0000  acc/mean1: 0.6656  data_time: 0.0541  time: 0.1371\n",
            "02/09 10:49:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][ 20/166]  lr: 2.0000e-02  eta: 1:40:10  time: 0.3268  data_time: 0.0535  memory: 5737  grad_norm: 2.3542  loss: 0.4313  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4313\n",
            "02/09 10:50:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][ 40/166]  lr: 2.0000e-02  eta: 1:40:04  time: 0.2867  data_time: 0.0166  memory: 5737  grad_norm: 2.6008  loss: 0.4329  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4329\n",
            "02/09 10:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][ 60/166]  lr: 2.0000e-02  eta: 1:39:58  time: 0.2885  data_time: 0.0176  memory: 5737  grad_norm: 2.5447  loss: 0.4324  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4324\n",
            "02/09 10:50:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][ 80/166]  lr: 2.0000e-02  eta: 1:39:52  time: 0.2870  data_time: 0.0165  memory: 5737  grad_norm: 2.6312  loss: 0.4736  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4736\n",
            "02/09 10:50:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][100/166]  lr: 2.0000e-02  eta: 1:39:46  time: 0.2874  data_time: 0.0168  memory: 5737  grad_norm: 2.6702  loss: 0.4874  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4874\n",
            "02/09 10:50:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][120/166]  lr: 2.0000e-02  eta: 1:39:40  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 2.1602  loss: 0.4132  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4132\n",
            "02/09 10:50:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][140/166]  lr: 2.0000e-02  eta: 1:39:34  time: 0.2874  data_time: 0.0168  memory: 5737  grad_norm: 2.8472  loss: 0.4655  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4655\n",
            "02/09 10:50:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][160/166]  lr: 2.0000e-02  eta: 1:39:27  time: 0.2857  data_time: 0.0160  memory: 5737  grad_norm: 2.5391  loss: 0.4156  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4156\n",
            "02/09 10:50:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:50:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [26][166/166]  lr: 2.0000e-02  eta: 1:39:25  time: 0.2828  data_time: 0.0150  memory: 5737  grad_norm: 2.5065  loss: 0.3810  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3810\n",
            "02/09 10:50:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][ 20/166]  lr: 2.0000e-02  eta: 1:39:22  time: 0.3161  data_time: 0.0432  memory: 5737  grad_norm: 2.8197  loss: 0.4623  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4623\n",
            "02/09 10:50:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][ 40/166]  lr: 2.0000e-02  eta: 1:39:16  time: 0.2855  data_time: 0.0156  memory: 5737  grad_norm: 2.5342  loss: 0.4255  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4255\n",
            "02/09 10:50:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][ 60/166]  lr: 2.0000e-02  eta: 1:39:10  time: 0.2868  data_time: 0.0166  memory: 5737  grad_norm: 2.5234  loss: 0.4032  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4032\n",
            "02/09 10:51:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][ 80/166]  lr: 2.0000e-02  eta: 1:39:04  time: 0.2864  data_time: 0.0163  memory: 5737  grad_norm: 2.6263  loss: 0.4535  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4535\n",
            "02/09 10:51:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][100/166]  lr: 2.0000e-02  eta: 1:38:58  time: 0.2881  data_time: 0.0173  memory: 5737  grad_norm: 2.6370  loss: 0.4586  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4586\n",
            "02/09 10:51:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][120/166]  lr: 2.0000e-02  eta: 1:38:52  time: 0.2859  data_time: 0.0159  memory: 5737  grad_norm: 2.2835  loss: 0.3858  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3858\n",
            "02/09 10:51:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][140/166]  lr: 2.0000e-02  eta: 1:38:45  time: 0.2871  data_time: 0.0169  memory: 5737  grad_norm: 2.7058  loss: 0.5101  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.5101\n",
            "02/09 10:51:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][160/166]  lr: 2.0000e-02  eta: 1:38:39  time: 0.2847  data_time: 0.0150  memory: 5737  grad_norm: 2.5113  loss: 0.4366  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4366\n",
            "02/09 10:51:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:51:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [27][166/166]  lr: 2.0000e-02  eta: 1:38:37  time: 0.2825  data_time: 0.0145  memory: 5737  grad_norm: 2.4403  loss: 0.4254  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.4254\n",
            "02/09 10:51:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][ 20/166]  lr: 2.0000e-02  eta: 1:38:34  time: 0.3201  data_time: 0.0482  memory: 5737  grad_norm: 2.3740  loss: 0.3410  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3410\n",
            "02/09 10:51:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][ 40/166]  lr: 2.0000e-02  eta: 1:38:28  time: 0.2867  data_time: 0.0163  memory: 5737  grad_norm: 2.8231  loss: 0.4596  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4596\n",
            "02/09 10:51:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][ 60/166]  lr: 2.0000e-02  eta: 1:38:22  time: 0.2871  data_time: 0.0167  memory: 5737  grad_norm: 2.7150  loss: 0.4458  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4458\n",
            "02/09 10:51:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][ 80/166]  lr: 2.0000e-02  eta: 1:38:16  time: 0.2870  data_time: 0.0168  memory: 5737  grad_norm: 2.7941  loss: 0.4251  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4251\n",
            "02/09 10:51:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][100/166]  lr: 2.0000e-02  eta: 1:38:10  time: 0.2868  data_time: 0.0167  memory: 5737  grad_norm: 3.0931  loss: 0.4762  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4762\n",
            "02/09 10:52:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][120/166]  lr: 2.0000e-02  eta: 1:38:04  time: 0.2866  data_time: 0.0165  memory: 5737  grad_norm: 2.4440  loss: 0.4058  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4058\n",
            "02/09 10:52:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][140/166]  lr: 2.0000e-02  eta: 1:37:58  time: 0.2865  data_time: 0.0163  memory: 5737  grad_norm: 2.8203  loss: 0.4379  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4379\n",
            "02/09 10:52:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][160/166]  lr: 2.0000e-02  eta: 1:37:52  time: 0.2859  data_time: 0.0159  memory: 5737  grad_norm: 2.7082  loss: 0.3679  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3679\n",
            "02/09 10:52:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:52:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [28][166/166]  lr: 2.0000e-02  eta: 1:37:49  time: 0.2823  data_time: 0.0144  memory: 5737  grad_norm: 2.9474  loss: 0.3977  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3977\n",
            "02/09 10:52:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 28 epochs\n",
            "02/09 10:52:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][ 20/166]  lr: 2.0000e-02  eta: 1:37:47  time: 0.3261  data_time: 0.0550  memory: 5737  grad_norm: 3.0707  loss: 0.4890  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4890\n",
            "02/09 10:52:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][ 40/166]  lr: 2.0000e-02  eta: 1:37:41  time: 0.2866  data_time: 0.0163  memory: 5737  grad_norm: 2.4339  loss: 0.4021  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4021\n",
            "02/09 10:52:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][ 60/166]  lr: 2.0000e-02  eta: 1:37:35  time: 0.2877  data_time: 0.0168  memory: 5737  grad_norm: 2.8178  loss: 0.4206  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4206\n",
            "02/09 10:52:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][ 80/166]  lr: 2.0000e-02  eta: 1:37:29  time: 0.2867  data_time: 0.0164  memory: 5737  grad_norm: 3.0495  loss: 0.4857  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4857\n",
            "02/09 10:52:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][100/166]  lr: 2.0000e-02  eta: 1:37:23  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 2.8139  loss: 0.4970  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4970\n",
            "02/09 10:52:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][120/166]  lr: 2.0000e-02  eta: 1:37:16  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 2.7425  loss: 0.5162  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.5162\n",
            "02/09 10:52:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][140/166]  lr: 2.0000e-02  eta: 1:37:10  time: 0.2855  data_time: 0.0155  memory: 5737  grad_norm: 2.4747  loss: 0.4758  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4758\n",
            "02/09 10:53:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][160/166]  lr: 2.0000e-02  eta: 1:37:04  time: 0.2849  data_time: 0.0153  memory: 5737  grad_norm: 2.2693  loss: 0.4726  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4726\n",
            "02/09 10:53:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:53:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [29][166/166]  lr: 2.0000e-02  eta: 1:37:02  time: 0.2816  data_time: 0.0139  memory: 5737  grad_norm: 2.2619  loss: 0.4715  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.4715\n",
            "02/09 10:53:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][ 20/166]  lr: 2.0000e-02  eta: 1:36:59  time: 0.3222  data_time: 0.0508  memory: 5737  grad_norm: 2.1367  loss: 0.4061  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4061\n",
            "02/09 10:53:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][ 40/166]  lr: 2.0000e-02  eta: 1:36:53  time: 0.2850  data_time: 0.0150  memory: 5737  grad_norm: 2.0624  loss: 0.3299  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3299\n",
            "02/09 10:53:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][ 60/166]  lr: 2.0000e-02  eta: 1:36:46  time: 0.2856  data_time: 0.0158  memory: 5737  grad_norm: 2.6116  loss: 0.4278  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4278\n",
            "02/09 10:53:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][ 80/166]  lr: 2.0000e-02  eta: 1:36:40  time: 0.2858  data_time: 0.0159  memory: 5737  grad_norm: 2.5359  loss: 0.4133  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4133\n",
            "02/09 10:53:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][100/166]  lr: 2.0000e-02  eta: 1:36:34  time: 0.2868  data_time: 0.0165  memory: 5737  grad_norm: 2.9163  loss: 0.4624  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4624\n",
            "02/09 10:53:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][120/166]  lr: 2.0000e-02  eta: 1:36:28  time: 0.2864  data_time: 0.0163  memory: 5737  grad_norm: 2.7260  loss: 0.4657  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4657\n",
            "02/09 10:53:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][140/166]  lr: 2.0000e-02  eta: 1:36:22  time: 0.2856  data_time: 0.0159  memory: 5737  grad_norm: 2.6580  loss: 0.4770  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4770\n",
            "02/09 10:53:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][160/166]  lr: 2.0000e-02  eta: 1:36:16  time: 0.2851  data_time: 0.0155  memory: 5737  grad_norm: 2.3609  loss: 0.4214  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4214\n",
            "02/09 10:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:53:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [30][166/166]  lr: 2.0000e-02  eta: 1:36:14  time: 0.2816  data_time: 0.0140  memory: 5737  grad_norm: 2.5793  loss: 0.4668  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.4668\n",
            "02/09 10:53:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [30][20/21]    eta: 0:00:00  time: 0.1387  data_time: 0.0536  memory: 991  \n",
            "02/09 10:53:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [30][21/21]    acc/top1: 0.7229  acc/top5: 1.0000  acc/mean1: 0.7261  data_time: 0.0491  time: 0.1319\n",
            "02/09 10:53:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb/best_acc_top1_epoch_20.pth is removed\n",
            "02/09 10:53:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7229 acc/top1 at 30 epoch is saved to best_acc_top1_epoch_30.pth.\n",
            "02/09 10:54:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:54:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][ 20/166]  lr: 2.0000e-02  eta: 1:36:10  time: 0.3172  data_time: 0.0452  memory: 5737  grad_norm: 2.4218  loss: 0.4512  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4512\n",
            "02/09 10:54:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][ 40/166]  lr: 2.0000e-02  eta: 1:36:04  time: 0.2850  data_time: 0.0158  memory: 5737  grad_norm: 2.3171  loss: 0.4137  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4137\n",
            "02/09 10:54:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][ 60/166]  lr: 2.0000e-02  eta: 1:35:58  time: 0.2868  data_time: 0.0170  memory: 5737  grad_norm: 2.7642  loss: 0.4073  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4073\n",
            "02/09 10:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][ 80/166]  lr: 2.0000e-02  eta: 1:35:52  time: 0.2860  data_time: 0.0161  memory: 5737  grad_norm: 2.5219  loss: 0.3733  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3733\n",
            "02/09 10:54:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][100/166]  lr: 2.0000e-02  eta: 1:35:46  time: 0.2869  data_time: 0.0167  memory: 5737  grad_norm: 2.5936  loss: 0.3496  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3496\n",
            "02/09 10:54:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][120/166]  lr: 2.0000e-02  eta: 1:35:40  time: 0.2859  data_time: 0.0161  memory: 5737  grad_norm: 2.8606  loss: 0.3704  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3704\n",
            "02/09 10:54:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][140/166]  lr: 2.0000e-02  eta: 1:35:33  time: 0.2848  data_time: 0.0151  memory: 5737  grad_norm: 2.8944  loss: 0.3955  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3955\n",
            "02/09 10:54:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][160/166]  lr: 2.0000e-02  eta: 1:35:27  time: 0.2833  data_time: 0.0144  memory: 5737  grad_norm: 3.0217  loss: 0.5000  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.5000\n",
            "02/09 10:54:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:54:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [31][166/166]  lr: 2.0000e-02  eta: 1:35:25  time: 0.2810  data_time: 0.0138  memory: 5737  grad_norm: 2.7737  loss: 0.5050  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.5050\n",
            "02/09 10:54:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][ 20/166]  lr: 2.0000e-02  eta: 1:35:21  time: 0.3145  data_time: 0.0437  memory: 5737  grad_norm: 2.1433  loss: 0.3771  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3771\n",
            "02/09 10:54:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][ 40/166]  lr: 2.0000e-02  eta: 1:35:15  time: 0.2856  data_time: 0.0157  memory: 5737  grad_norm: 2.5224  loss: 0.3541  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3541\n",
            "02/09 10:55:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][ 60/166]  lr: 2.0000e-02  eta: 1:35:09  time: 0.2872  data_time: 0.0167  memory: 5737  grad_norm: 2.5190  loss: 0.4218  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4218\n",
            "02/09 10:55:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][ 80/166]  lr: 2.0000e-02  eta: 1:35:03  time: 0.2856  data_time: 0.0158  memory: 5737  grad_norm: 2.5921  loss: 0.4153  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4153\n",
            "02/09 10:55:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][100/166]  lr: 2.0000e-02  eta: 1:34:57  time: 0.2864  data_time: 0.0162  memory: 5737  grad_norm: 2.5455  loss: 0.4084  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4084\n",
            "02/09 10:55:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][120/166]  lr: 2.0000e-02  eta: 1:34:51  time: 0.2856  data_time: 0.0157  memory: 5737  grad_norm: 2.4414  loss: 0.3835  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3835\n",
            "02/09 10:55:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][140/166]  lr: 2.0000e-02  eta: 1:34:45  time: 0.2855  data_time: 0.0156  memory: 5737  grad_norm: 2.8077  loss: 0.4710  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4710\n",
            "02/09 10:55:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][160/166]  lr: 2.0000e-02  eta: 1:34:38  time: 0.2844  data_time: 0.0150  memory: 5737  grad_norm: 2.4254  loss: 0.4225  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4225\n",
            "02/09 10:55:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:55:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [32][166/166]  lr: 2.0000e-02  eta: 1:34:36  time: 0.2826  data_time: 0.0151  memory: 5737  grad_norm: 2.3995  loss: 0.4194  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.4194\n",
            "02/09 10:55:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 32 epochs\n",
            "02/09 10:55:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][ 20/166]  lr: 2.0000e-02  eta: 1:34:33  time: 0.3186  data_time: 0.0481  memory: 5737  grad_norm: 2.3439  loss: 0.3879  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3879\n",
            "02/09 10:55:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][ 40/166]  lr: 2.0000e-02  eta: 1:34:27  time: 0.2843  data_time: 0.0151  memory: 5737  grad_norm: 2.5059  loss: 0.4033  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4033\n",
            "02/09 10:55:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][ 60/166]  lr: 2.0000e-02  eta: 1:34:21  time: 0.2863  data_time: 0.0161  memory: 5737  grad_norm: 2.4209  loss: 0.3727  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3727\n",
            "02/09 10:55:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][ 80/166]  lr: 2.0000e-02  eta: 1:34:14  time: 0.2851  data_time: 0.0152  memory: 5737  grad_norm: 2.5429  loss: 0.4082  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4082\n",
            "02/09 10:56:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][100/166]  lr: 2.0000e-02  eta: 1:34:08  time: 0.2868  data_time: 0.0166  memory: 5737  grad_norm: 2.2798  loss: 0.3616  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3616\n",
            "02/09 10:56:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][120/166]  lr: 2.0000e-02  eta: 1:34:02  time: 0.2846  data_time: 0.0150  memory: 5737  grad_norm: 2.7232  loss: 0.3964  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.3964\n",
            "02/09 10:56:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][140/166]  lr: 2.0000e-02  eta: 1:33:56  time: 0.2873  data_time: 0.0171  memory: 5737  grad_norm: 2.6811  loss: 0.4328  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4328\n",
            "02/09 10:56:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][160/166]  lr: 2.0000e-02  eta: 1:33:50  time: 0.2847  data_time: 0.0153  memory: 5737  grad_norm: 2.4575  loss: 0.4129  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4129\n",
            "02/09 10:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [33][166/166]  lr: 2.0000e-02  eta: 1:33:48  time: 0.2825  data_time: 0.0148  memory: 5737  grad_norm: 2.5021  loss: 0.4169  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.4169\n",
            "02/09 10:56:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][ 20/166]  lr: 2.0000e-02  eta: 1:33:44  time: 0.3162  data_time: 0.0440  memory: 5737  grad_norm: 2.8262  loss: 0.4354  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4354\n",
            "02/09 10:56:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][ 40/166]  lr: 2.0000e-02  eta: 1:33:38  time: 0.2853  data_time: 0.0160  memory: 5737  grad_norm: 2.4154  loss: 0.4007  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4007\n",
            "02/09 10:56:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][ 60/166]  lr: 2.0000e-02  eta: 1:33:32  time: 0.2863  data_time: 0.0163  memory: 5737  grad_norm: 2.5386  loss: 0.4212  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4212\n",
            "02/09 10:56:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][ 80/166]  lr: 2.0000e-02  eta: 1:33:26  time: 0.2863  data_time: 0.0164  memory: 5737  grad_norm: 2.3013  loss: 0.3749  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3749\n",
            "02/09 10:56:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][100/166]  lr: 2.0000e-02  eta: 1:33:20  time: 0.2858  data_time: 0.0161  memory: 5737  grad_norm: 2.5271  loss: 0.3832  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3832\n",
            "02/09 10:56:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][120/166]  lr: 2.0000e-02  eta: 1:33:14  time: 0.2849  data_time: 0.0151  memory: 5737  grad_norm: 2.4304  loss: 0.4026  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4026\n",
            "02/09 10:57:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][140/166]  lr: 2.0000e-02  eta: 1:33:08  time: 0.2857  data_time: 0.0156  memory: 5737  grad_norm: 2.3822  loss: 0.3457  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3457\n",
            "02/09 10:57:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][160/166]  lr: 2.0000e-02  eta: 1:33:01  time: 0.2848  data_time: 0.0157  memory: 5737  grad_norm: 3.0307  loss: 0.4358  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4358\n",
            "02/09 10:57:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:57:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [34][166/166]  lr: 2.0000e-02  eta: 1:33:00  time: 0.2826  data_time: 0.0150  memory: 5737  grad_norm: 2.7714  loss: 0.4319  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4319\n",
            "02/09 10:57:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][ 20/166]  lr: 2.0000e-02  eta: 1:32:56  time: 0.3170  data_time: 0.0451  memory: 5737  grad_norm: 2.4734  loss: 0.4159  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4159\n",
            "02/09 10:57:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][ 40/166]  lr: 2.0000e-02  eta: 1:32:49  time: 0.2857  data_time: 0.0155  memory: 5737  grad_norm: 2.6803  loss: 0.4329  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4329\n",
            "02/09 10:57:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][ 60/166]  lr: 2.0000e-02  eta: 1:32:43  time: 0.2855  data_time: 0.0157  memory: 5737  grad_norm: 2.6135  loss: 0.4351  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4351\n",
            "02/09 10:57:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][ 80/166]  lr: 2.0000e-02  eta: 1:32:37  time: 0.2854  data_time: 0.0158  memory: 5737  grad_norm: 2.3387  loss: 0.3763  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3763\n",
            "02/09 10:57:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][100/166]  lr: 2.0000e-02  eta: 1:32:31  time: 0.2855  data_time: 0.0158  memory: 5737  grad_norm: 2.4429  loss: 0.4299  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4299\n",
            "02/09 10:57:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][120/166]  lr: 2.0000e-02  eta: 1:32:25  time: 0.2852  data_time: 0.0154  memory: 5737  grad_norm: 2.3239  loss: 0.4073  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.4073\n",
            "02/09 10:57:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][140/166]  lr: 2.0000e-02  eta: 1:32:19  time: 0.2852  data_time: 0.0152  memory: 5737  grad_norm: 2.1709  loss: 0.3667  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3667\n",
            "02/09 10:57:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][160/166]  lr: 2.0000e-02  eta: 1:32:13  time: 0.2837  data_time: 0.0144  memory: 5737  grad_norm: 2.3126  loss: 0.3919  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3919\n",
            "02/09 10:58:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:58:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [35][166/166]  lr: 2.0000e-02  eta: 1:32:11  time: 0.2810  data_time: 0.0136  memory: 5737  grad_norm: 2.5476  loss: 0.4293  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.4293\n",
            "02/09 10:58:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [35][20/21]    eta: 0:00:00  time: 0.1388  data_time: 0.0540  memory: 991  \n",
            "02/09 10:58:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [35][21/21]    acc/top1: 0.7259  acc/top5: 1.0000  acc/mean1: 0.7309  data_time: 0.0494  time: 0.1320\n",
            "02/09 10:58:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb/best_acc_top1_epoch_30.pth is removed\n",
            "02/09 10:58:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7259 acc/top1 at 35 epoch is saved to best_acc_top1_epoch_35.pth.\n",
            "02/09 10:58:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][ 20/166]  lr: 2.0000e-02  eta: 1:32:07  time: 0.3201  data_time: 0.0482  memory: 5737  grad_norm: 2.1059  loss: 0.3299  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3299\n",
            "02/09 10:58:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][ 40/166]  lr: 2.0000e-02  eta: 1:32:01  time: 0.2842  data_time: 0.0149  memory: 5737  grad_norm: 2.4566  loss: 0.3255  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3255\n",
            "02/09 10:58:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][ 60/166]  lr: 2.0000e-02  eta: 1:31:55  time: 0.2854  data_time: 0.0159  memory: 5737  grad_norm: 3.1122  loss: 0.3914  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3914\n",
            "02/09 10:58:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][ 80/166]  lr: 2.0000e-02  eta: 1:31:49  time: 0.2846  data_time: 0.0152  memory: 5737  grad_norm: 2.7338  loss: 0.3724  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3724\n",
            "02/09 10:58:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][100/166]  lr: 2.0000e-02  eta: 1:31:43  time: 0.2871  data_time: 0.0169  memory: 5737  grad_norm: 3.1515  loss: 0.4282  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4282\n",
            "02/09 10:58:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][120/166]  lr: 2.0000e-02  eta: 1:31:37  time: 0.2859  data_time: 0.0161  memory: 5737  grad_norm: 2.7023  loss: 0.4154  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4154\n",
            "02/09 10:58:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][140/166]  lr: 2.0000e-02  eta: 1:31:31  time: 0.2875  data_time: 0.0171  memory: 5737  grad_norm: 2.2606  loss: 0.3662  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3662\n",
            "02/09 10:58:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][160/166]  lr: 2.0000e-02  eta: 1:31:25  time: 0.2843  data_time: 0.0149  memory: 5737  grad_norm: 2.4764  loss: 0.3599  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.3599\n",
            "02/09 10:58:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:58:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [36][166/166]  lr: 2.0000e-02  eta: 1:31:23  time: 0.2820  data_time: 0.0145  memory: 5737  grad_norm: 2.6174  loss: 0.3767  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.3767\n",
            "02/09 10:58:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 36 epochs\n",
            "02/09 10:58:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][ 20/166]  lr: 2.0000e-02  eta: 1:31:19  time: 0.3263  data_time: 0.0540  memory: 5737  grad_norm: 2.7587  loss: 0.3639  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3639\n",
            "02/09 10:59:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:59:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][ 40/166]  lr: 2.0000e-02  eta: 1:31:13  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 2.1723  loss: 0.3009  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3009\n",
            "02/09 10:59:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][ 60/166]  lr: 2.0000e-02  eta: 1:31:07  time: 0.2853  data_time: 0.0156  memory: 5737  grad_norm: 2.8054  loss: 0.4314  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4314\n",
            "02/09 10:59:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][ 80/166]  lr: 2.0000e-02  eta: 1:31:01  time: 0.2845  data_time: 0.0149  memory: 5737  grad_norm: 2.5002  loss: 0.3990  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3990\n",
            "02/09 10:59:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][100/166]  lr: 2.0000e-02  eta: 1:30:55  time: 0.2857  data_time: 0.0160  memory: 5737  grad_norm: 2.5382  loss: 0.3310  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3310\n",
            "02/09 10:59:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][120/166]  lr: 2.0000e-02  eta: 1:30:49  time: 0.2854  data_time: 0.0157  memory: 5737  grad_norm: 2.9644  loss: 0.4678  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4678\n",
            "02/09 10:59:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][140/166]  lr: 2.0000e-02  eta: 1:30:43  time: 0.2867  data_time: 0.0167  memory: 5737  grad_norm: 2.6071  loss: 0.4433  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4433\n",
            "02/09 10:59:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][160/166]  lr: 2.0000e-02  eta: 1:30:37  time: 0.2841  data_time: 0.0152  memory: 5737  grad_norm: 2.4678  loss: 0.4187  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4187\n",
            "02/09 10:59:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 10:59:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [37][166/166]  lr: 2.0000e-02  eta: 1:30:35  time: 0.2815  data_time: 0.0144  memory: 5737  grad_norm: 2.2958  loss: 0.4125  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.4125\n",
            "02/09 10:59:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][ 20/166]  lr: 2.0000e-02  eta: 1:30:31  time: 0.3193  data_time: 0.0474  memory: 5737  grad_norm: 2.3644  loss: 0.3686  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3686\n",
            "02/09 10:59:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][ 40/166]  lr: 2.0000e-02  eta: 1:30:25  time: 0.2851  data_time: 0.0155  memory: 5737  grad_norm: 2.2896  loss: 0.3242  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3242\n",
            "02/09 10:59:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][ 60/166]  lr: 2.0000e-02  eta: 1:30:19  time: 0.2861  data_time: 0.0160  memory: 5737  grad_norm: 2.5228  loss: 0.3672  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.3672\n",
            "02/09 11:00:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][ 80/166]  lr: 2.0000e-02  eta: 1:30:13  time: 0.2862  data_time: 0.0163  memory: 5737  grad_norm: 2.2674  loss: 0.3406  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3406\n",
            "02/09 11:00:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][100/166]  lr: 2.0000e-02  eta: 1:30:07  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 2.3656  loss: 0.3790  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3790\n",
            "02/09 11:00:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][120/166]  lr: 2.0000e-02  eta: 1:30:00  time: 0.2854  data_time: 0.0157  memory: 5737  grad_norm: 2.4440  loss: 0.3613  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3613\n",
            "02/09 11:00:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][140/166]  lr: 2.0000e-02  eta: 1:29:54  time: 0.2850  data_time: 0.0153  memory: 5737  grad_norm: 2.5507  loss: 0.3459  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3459\n",
            "02/09 11:00:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][160/166]  lr: 2.0000e-02  eta: 1:29:48  time: 0.2840  data_time: 0.0149  memory: 5737  grad_norm: 2.5944  loss: 0.3431  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3431\n",
            "02/09 11:00:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:00:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [38][166/166]  lr: 2.0000e-02  eta: 1:29:46  time: 0.2817  data_time: 0.0142  memory: 5737  grad_norm: 2.8958  loss: 0.3742  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.3742\n",
            "02/09 11:00:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][ 20/166]  lr: 2.0000e-02  eta: 1:29:42  time: 0.3221  data_time: 0.0514  memory: 5737  grad_norm: 2.9585  loss: 0.4182  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.4182\n",
            "02/09 11:00:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][ 40/166]  lr: 2.0000e-02  eta: 1:29:36  time: 0.2851  data_time: 0.0156  memory: 5737  grad_norm: 2.5282  loss: 0.4205  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4205\n",
            "02/09 11:00:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][ 60/166]  lr: 2.0000e-02  eta: 1:29:30  time: 0.2859  data_time: 0.0161  memory: 5737  grad_norm: 2.3023  loss: 0.3617  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3617\n",
            "02/09 11:00:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][ 80/166]  lr: 2.0000e-02  eta: 1:29:24  time: 0.2851  data_time: 0.0156  memory: 5737  grad_norm: 2.0376  loss: 0.2873  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2873\n",
            "02/09 11:00:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][100/166]  lr: 2.0000e-02  eta: 1:29:18  time: 0.2865  data_time: 0.0163  memory: 5737  grad_norm: 2.6988  loss: 0.3866  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3866\n",
            "02/09 11:01:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][120/166]  lr: 2.0000e-02  eta: 1:29:12  time: 0.2865  data_time: 0.0164  memory: 5737  grad_norm: 2.2589  loss: 0.3384  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3384\n",
            "02/09 11:01:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][140/166]  lr: 2.0000e-02  eta: 1:29:06  time: 0.2864  data_time: 0.0165  memory: 5737  grad_norm: 2.8200  loss: 0.4085  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4085\n",
            "02/09 11:01:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][160/166]  lr: 2.0000e-02  eta: 1:29:00  time: 0.2849  data_time: 0.0154  memory: 5737  grad_norm: 2.5639  loss: 0.4527  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4527\n",
            "02/09 11:01:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:01:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [39][166/166]  lr: 2.0000e-02  eta: 1:28:58  time: 0.2817  data_time: 0.0141  memory: 5737  grad_norm: 2.4311  loss: 0.4471  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.4471\n",
            "02/09 11:01:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][ 20/166]  lr: 2.0000e-02  eta: 1:28:54  time: 0.3162  data_time: 0.0443  memory: 5737  grad_norm: 2.1708  loss: 0.3575  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3575\n",
            "02/09 11:01:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][ 40/166]  lr: 2.0000e-02  eta: 1:28:48  time: 0.2847  data_time: 0.0150  memory: 5737  grad_norm: 2.4943  loss: 0.3695  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3695\n",
            "02/09 11:01:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][ 60/166]  lr: 2.0000e-02  eta: 1:28:42  time: 0.2858  data_time: 0.0157  memory: 5737  grad_norm: 2.4591  loss: 0.3056  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3056\n",
            "02/09 11:01:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][ 80/166]  lr: 2.0000e-02  eta: 1:28:36  time: 0.2854  data_time: 0.0157  memory: 5737  grad_norm: 2.8589  loss: 0.3380  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3380\n",
            "02/09 11:01:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][100/166]  lr: 2.0000e-02  eta: 1:28:30  time: 0.2857  data_time: 0.0161  memory: 5737  grad_norm: 2.6917  loss: 0.3539  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3539\n",
            "02/09 11:01:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][120/166]  lr: 2.0000e-02  eta: 1:28:24  time: 0.2857  data_time: 0.0159  memory: 5737  grad_norm: 2.8755  loss: 0.4259  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4259\n",
            "02/09 11:01:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][140/166]  lr: 2.0000e-02  eta: 1:28:18  time: 0.2857  data_time: 0.0161  memory: 5737  grad_norm: 2.4946  loss: 0.4033  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4033\n",
            "02/09 11:02:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][160/166]  lr: 2.0000e-02  eta: 1:28:12  time: 0.2845  data_time: 0.0150  memory: 5737  grad_norm: 2.4456  loss: 0.3936  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.3936\n",
            "02/09 11:02:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:02:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [40][166/166]  lr: 2.0000e-02  eta: 1:28:10  time: 0.2816  data_time: 0.0141  memory: 5737  grad_norm: 2.6383  loss: 0.4106  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.4106\n",
            "02/09 11:02:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 40 epochs\n",
            "02/09 11:02:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [40][20/21]    eta: 0:00:00  time: 0.1372  data_time: 0.0523  memory: 991  \n",
            "02/09 11:02:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [40][21/21]    acc/top1: 0.7440  acc/top5: 1.0000  acc/mean1: 0.7434  data_time: 0.0479  time: 0.1305\n",
            "02/09 11:02:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb/best_acc_top1_epoch_35.pth is removed\n",
            "02/09 11:02:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7440 acc/top1 at 40 epoch is saved to best_acc_top1_epoch_40.pth.\n",
            "02/09 11:02:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][ 20/166]  lr: 2.0000e-02  eta: 1:28:06  time: 0.3211  data_time: 0.0509  memory: 5737  grad_norm: 2.1560  loss: 0.3062  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3062\n",
            "02/09 11:02:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][ 40/166]  lr: 2.0000e-02  eta: 1:28:00  time: 0.2841  data_time: 0.0153  memory: 5737  grad_norm: 2.5369  loss: 0.3476  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3476\n",
            "02/09 11:02:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][ 60/166]  lr: 2.0000e-02  eta: 1:27:53  time: 0.2845  data_time: 0.0153  memory: 5737  grad_norm: 2.6869  loss: 0.4007  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4007\n",
            "02/09 11:02:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][ 80/166]  lr: 2.0000e-02  eta: 1:27:47  time: 0.2852  data_time: 0.0154  memory: 5737  grad_norm: 2.3077  loss: 0.3506  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3506\n",
            "02/09 11:02:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][100/166]  lr: 2.0000e-02  eta: 1:27:41  time: 0.2852  data_time: 0.0153  memory: 5737  grad_norm: 2.3581  loss: 0.3603  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3603\n",
            "02/09 11:02:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][120/166]  lr: 2.0000e-02  eta: 1:27:35  time: 0.2849  data_time: 0.0154  memory: 5737  grad_norm: 2.4743  loss: 0.3462  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3462\n",
            "02/09 11:02:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][140/166]  lr: 2.0000e-02  eta: 1:27:29  time: 0.2850  data_time: 0.0152  memory: 5737  grad_norm: 2.5865  loss: 0.3669  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3669\n",
            "02/09 11:02:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][160/166]  lr: 2.0000e-02  eta: 1:27:23  time: 0.2837  data_time: 0.0145  memory: 5737  grad_norm: 2.6466  loss: 0.3492  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3492\n",
            "02/09 11:02:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:02:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [41][166/166]  lr: 2.0000e-02  eta: 1:27:21  time: 0.2817  data_time: 0.0141  memory: 5737  grad_norm: 2.8077  loss: 0.3868  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.3868\n",
            "02/09 11:03:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][ 20/166]  lr: 2.0000e-02  eta: 1:27:18  time: 0.3320  data_time: 0.0589  memory: 5737  grad_norm: 2.7076  loss: 0.4606  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4606\n",
            "02/09 11:03:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][ 40/166]  lr: 2.0000e-02  eta: 1:27:12  time: 0.2840  data_time: 0.0146  memory: 5737  grad_norm: 2.0444  loss: 0.3300  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3300\n",
            "02/09 11:03:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][ 60/166]  lr: 2.0000e-02  eta: 1:27:06  time: 0.2854  data_time: 0.0158  memory: 5737  grad_norm: 2.4723  loss: 0.3051  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.3051\n",
            "02/09 11:03:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][ 80/166]  lr: 2.0000e-02  eta: 1:26:59  time: 0.2843  data_time: 0.0148  memory: 5737  grad_norm: 2.6992  loss: 0.3376  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3376\n",
            "02/09 11:03:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][100/166]  lr: 2.0000e-02  eta: 1:26:53  time: 0.2866  data_time: 0.0167  memory: 5737  grad_norm: 2.8824  loss: 0.4296  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.4296\n",
            "02/09 11:03:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][120/166]  lr: 2.0000e-02  eta: 1:26:47  time: 0.2850  data_time: 0.0156  memory: 5737  grad_norm: 2.1542  loss: 0.3216  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3216\n",
            "02/09 11:03:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][140/166]  lr: 2.0000e-02  eta: 1:26:41  time: 0.2865  data_time: 0.0165  memory: 5737  grad_norm: 2.4730  loss: 0.3742  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3742\n",
            "02/09 11:03:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][160/166]  lr: 2.0000e-02  eta: 1:26:35  time: 0.2844  data_time: 0.0152  memory: 5737  grad_norm: 2.5954  loss: 0.3618  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3618\n",
            "02/09 11:03:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:03:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [42][166/166]  lr: 2.0000e-02  eta: 1:26:33  time: 0.2821  data_time: 0.0146  memory: 5737  grad_norm: 2.5561  loss: 0.3353  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.3353\n",
            "02/09 11:03:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][ 20/166]  lr: 2.0000e-02  eta: 1:26:30  time: 0.3250  data_time: 0.0535  memory: 5737  grad_norm: 2.3705  loss: 0.2848  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2848\n",
            "02/09 11:03:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:03:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][ 40/166]  lr: 2.0000e-02  eta: 1:26:24  time: 0.2856  data_time: 0.0157  memory: 5737  grad_norm: 2.8255  loss: 0.3215  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3215\n",
            "02/09 11:04:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][ 60/166]  lr: 2.0000e-02  eta: 1:26:18  time: 0.2867  data_time: 0.0164  memory: 5737  grad_norm: 2.5667  loss: 0.3172  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3172\n",
            "02/09 11:04:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][ 80/166]  lr: 2.0000e-02  eta: 1:26:12  time: 0.2851  data_time: 0.0156  memory: 5737  grad_norm: 2.7377  loss: 0.3290  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3290\n",
            "02/09 11:04:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][100/166]  lr: 2.0000e-02  eta: 1:26:06  time: 0.2859  data_time: 0.0162  memory: 5737  grad_norm: 3.1494  loss: 0.4045  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4045\n",
            "02/09 11:04:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][120/166]  lr: 2.0000e-02  eta: 1:26:00  time: 0.2857  data_time: 0.0159  memory: 5737  grad_norm: 2.4531  loss: 0.3739  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3739\n",
            "02/09 11:04:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][140/166]  lr: 2.0000e-02  eta: 1:25:54  time: 0.2858  data_time: 0.0156  memory: 5737  grad_norm: 2.3676  loss: 0.3806  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3806\n",
            "02/09 11:04:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][160/166]  lr: 2.0000e-02  eta: 1:25:47  time: 0.2835  data_time: 0.0142  memory: 5737  grad_norm: 2.4565  loss: 0.3536  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3536\n",
            "02/09 11:04:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:04:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [43][166/166]  lr: 2.0000e-02  eta: 1:25:45  time: 0.2810  data_time: 0.0135  memory: 5737  grad_norm: 2.4802  loss: 0.3425  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.3425\n",
            "02/09 11:04:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][ 20/166]  lr: 2.0000e-02  eta: 1:25:41  time: 0.3225  data_time: 0.0512  memory: 5737  grad_norm: 2.4107  loss: 0.3190  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3190\n",
            "02/09 11:04:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][ 40/166]  lr: 2.0000e-02  eta: 1:25:35  time: 0.2850  data_time: 0.0153  memory: 5737  grad_norm: 2.4669  loss: 0.3470  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3470\n",
            "02/09 11:04:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][ 60/166]  lr: 2.0000e-02  eta: 1:25:29  time: 0.2857  data_time: 0.0163  memory: 5737  grad_norm: 2.4999  loss: 0.3801  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3801\n",
            "02/09 11:04:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][ 80/166]  lr: 2.0000e-02  eta: 1:25:23  time: 0.2851  data_time: 0.0156  memory: 5737  grad_norm: 2.4312  loss: 0.3743  top1_acc: 0.4375  top5_acc: 1.0000  loss_cls: 0.3743\n",
            "02/09 11:05:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][100/166]  lr: 2.0000e-02  eta: 1:25:17  time: 0.2865  data_time: 0.0165  memory: 5737  grad_norm: 2.3628  loss: 0.3252  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3252\n",
            "02/09 11:05:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][120/166]  lr: 2.0000e-02  eta: 1:25:11  time: 0.2841  data_time: 0.0148  memory: 5737  grad_norm: 2.2864  loss: 0.3176  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.3176\n",
            "02/09 11:05:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][140/166]  lr: 2.0000e-02  eta: 1:25:05  time: 0.2859  data_time: 0.0158  memory: 5737  grad_norm: 2.5567  loss: 0.3581  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3581\n",
            "02/09 11:05:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][160/166]  lr: 2.0000e-02  eta: 1:24:59  time: 0.2837  data_time: 0.0148  memory: 5737  grad_norm: 2.9719  loss: 0.3732  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3732\n",
            "02/09 11:05:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:05:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [44][166/166]  lr: 2.0000e-02  eta: 1:24:57  time: 0.2810  data_time: 0.0138  memory: 5737  grad_norm: 2.9726  loss: 0.3750  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3750\n",
            "02/09 11:05:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 44 epochs\n",
            "02/09 11:05:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][ 20/166]  lr: 2.0000e-02  eta: 1:24:53  time: 0.3165  data_time: 0.0446  memory: 5737  grad_norm: 2.3198  loss: 0.3124  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3124\n",
            "02/09 11:05:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][ 40/166]  lr: 2.0000e-02  eta: 1:24:47  time: 0.2850  data_time: 0.0153  memory: 5737  grad_norm: 2.6839  loss: 0.3500  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3500\n",
            "02/09 11:05:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][ 60/166]  lr: 2.0000e-02  eta: 1:24:41  time: 0.2864  data_time: 0.0163  memory: 5737  grad_norm: 2.6084  loss: 0.3525  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3525\n",
            "02/09 11:05:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][ 80/166]  lr: 2.0000e-02  eta: 1:24:35  time: 0.2845  data_time: 0.0155  memory: 5737  grad_norm: 2.6366  loss: 0.4024  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.4024\n",
            "02/09 11:05:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][100/166]  lr: 2.0000e-02  eta: 1:24:29  time: 0.2862  data_time: 0.0162  memory: 5737  grad_norm: 2.5047  loss: 0.3404  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3404\n",
            "02/09 11:05:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][120/166]  lr: 2.0000e-02  eta: 1:24:23  time: 0.2853  data_time: 0.0156  memory: 5737  grad_norm: 2.5742  loss: 0.3563  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3563\n",
            "02/09 11:06:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][140/166]  lr: 2.0000e-02  eta: 1:24:17  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 2.1128  loss: 0.2744  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2744\n",
            "02/09 11:06:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][160/166]  lr: 2.0000e-02  eta: 1:24:11  time: 0.2842  data_time: 0.0149  memory: 5737  grad_norm: 2.7707  loss: 0.3794  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3794\n",
            "02/09 11:06:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:06:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [45][166/166]  lr: 2.0000e-02  eta: 1:24:09  time: 0.2812  data_time: 0.0139  memory: 5737  grad_norm: 2.5994  loss: 0.3620  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3620\n",
            "02/09 11:06:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [45][20/21]    eta: 0:00:00  time: 0.1393  data_time: 0.0528  memory: 991  \n",
            "02/09 11:06:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [45][21/21]    acc/top1: 0.7410  acc/top5: 1.0000  acc/mean1: 0.7330  data_time: 0.0484  time: 0.1324\n",
            "02/09 11:06:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][ 20/166]  lr: 2.0000e-02  eta: 1:24:04  time: 0.3200  data_time: 0.0487  memory: 5737  grad_norm: 2.1794  loss: 0.3073  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3073\n",
            "02/09 11:06:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][ 40/166]  lr: 2.0000e-02  eta: 1:23:58  time: 0.2840  data_time: 0.0146  memory: 5737  grad_norm: 2.7600  loss: 0.3548  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3548\n",
            "02/09 11:06:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][ 60/166]  lr: 2.0000e-02  eta: 1:23:52  time: 0.2862  data_time: 0.0162  memory: 5737  grad_norm: 2.4521  loss: 0.3034  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3034\n",
            "02/09 11:06:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][ 80/166]  lr: 2.0000e-02  eta: 1:23:46  time: 0.2850  data_time: 0.0155  memory: 5737  grad_norm: 2.6081  loss: 0.3370  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3370\n",
            "02/09 11:06:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][100/166]  lr: 2.0000e-02  eta: 1:23:40  time: 0.2860  data_time: 0.0158  memory: 5737  grad_norm: 2.1886  loss: 0.2745  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2745\n",
            "02/09 11:06:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][120/166]  lr: 2.0000e-02  eta: 1:23:34  time: 0.2844  data_time: 0.0149  memory: 5737  grad_norm: 2.6712  loss: 0.3162  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3162\n",
            "02/09 11:06:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][140/166]  lr: 2.0000e-02  eta: 1:23:28  time: 0.2860  data_time: 0.0161  memory: 5737  grad_norm: 2.5637  loss: 0.3021  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3021\n",
            "02/09 11:07:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][160/166]  lr: 2.0000e-02  eta: 1:23:22  time: 0.2831  data_time: 0.0140  memory: 5737  grad_norm: 3.0453  loss: 0.3828  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3828\n",
            "02/09 11:07:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:07:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [46][166/166]  lr: 2.0000e-02  eta: 1:23:20  time: 0.2810  data_time: 0.0135  memory: 5737  grad_norm: 3.1731  loss: 0.4011  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.4011\n",
            "02/09 11:07:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][ 20/166]  lr: 2.0000e-02  eta: 1:23:16  time: 0.3204  data_time: 0.0486  memory: 5737  grad_norm: 2.7519  loss: 0.4371  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4371\n",
            "02/09 11:07:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][ 40/166]  lr: 2.0000e-02  eta: 1:23:10  time: 0.2856  data_time: 0.0156  memory: 5737  grad_norm: 2.2725  loss: 0.3647  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3647\n",
            "02/09 11:07:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][ 60/166]  lr: 2.0000e-02  eta: 1:23:04  time: 0.2859  data_time: 0.0158  memory: 5737  grad_norm: 2.3941  loss: 0.3181  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3181\n",
            "02/09 11:07:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][ 80/166]  lr: 2.0000e-02  eta: 1:22:58  time: 0.2852  data_time: 0.0156  memory: 5737  grad_norm: 2.4638  loss: 0.2961  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2961\n",
            "02/09 11:07:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][100/166]  lr: 2.0000e-02  eta: 1:22:52  time: 0.2858  data_time: 0.0159  memory: 5737  grad_norm: 3.0041  loss: 0.3652  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3652\n",
            "02/09 11:07:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][120/166]  lr: 2.0000e-02  eta: 1:22:46  time: 0.2846  data_time: 0.0152  memory: 5737  grad_norm: 2.3591  loss: 0.3188  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3188\n",
            "02/09 11:07:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][140/166]  lr: 2.0000e-02  eta: 1:22:40  time: 0.2866  data_time: 0.0164  memory: 5737  grad_norm: 2.7964  loss: 0.3996  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.3996\n",
            "02/09 11:07:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][160/166]  lr: 2.0000e-02  eta: 1:22:34  time: 0.2844  data_time: 0.0150  memory: 5737  grad_norm: 2.8612  loss: 0.3476  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3476\n",
            "02/09 11:07:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:07:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [47][166/166]  lr: 2.0000e-02  eta: 1:22:32  time: 0.2819  data_time: 0.0143  memory: 5737  grad_norm: 3.0082  loss: 0.3669  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.3669\n",
            "02/09 11:07:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][ 20/166]  lr: 2.0000e-02  eta: 1:22:28  time: 0.3172  data_time: 0.0453  memory: 5737  grad_norm: 2.6562  loss: 0.3315  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3315\n",
            "02/09 11:08:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][ 40/166]  lr: 2.0000e-02  eta: 1:22:22  time: 0.2854  data_time: 0.0157  memory: 5737  grad_norm: 2.5262  loss: 0.3242  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3242\n",
            "02/09 11:08:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][ 60/166]  lr: 2.0000e-02  eta: 1:22:16  time: 0.2864  data_time: 0.0161  memory: 5737  grad_norm: 2.8412  loss: 0.3740  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3740\n",
            "02/09 11:08:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][ 80/166]  lr: 2.0000e-02  eta: 1:22:10  time: 0.2850  data_time: 0.0152  memory: 5737  grad_norm: 2.3783  loss: 0.3317  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3317\n",
            "02/09 11:08:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][100/166]  lr: 2.0000e-02  eta: 1:22:04  time: 0.2857  data_time: 0.0161  memory: 5737  grad_norm: 2.6457  loss: 0.3745  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3745\n",
            "02/09 11:08:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][120/166]  lr: 2.0000e-02  eta: 1:21:58  time: 0.2853  data_time: 0.0155  memory: 5737  grad_norm: 2.3330  loss: 0.3252  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3252\n",
            "02/09 11:08:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][140/166]  lr: 2.0000e-02  eta: 1:21:52  time: 0.2854  data_time: 0.0155  memory: 5737  grad_norm: 2.2657  loss: 0.2978  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2978\n",
            "02/09 11:08:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][160/166]  lr: 2.0000e-02  eta: 1:21:46  time: 0.2837  data_time: 0.0148  memory: 5737  grad_norm: 2.5796  loss: 0.3171  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3171\n",
            "02/09 11:08:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:08:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [48][166/166]  lr: 2.0000e-02  eta: 1:21:44  time: 0.2818  data_time: 0.0142  memory: 5737  grad_norm: 3.0416  loss: 0.3555  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3555\n",
            "02/09 11:08:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 48 epochs\n",
            "02/09 11:08:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][ 20/166]  lr: 2.0000e-02  eta: 1:21:39  time: 0.3227  data_time: 0.0510  memory: 5737  grad_norm: 2.8924  loss: 0.3237  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3237\n",
            "02/09 11:08:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:08:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][ 40/166]  lr: 2.0000e-02  eta: 1:21:33  time: 0.2851  data_time: 0.0156  memory: 5737  grad_norm: 2.6462  loss: 0.3265  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3265\n",
            "02/09 11:08:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][ 60/166]  lr: 2.0000e-02  eta: 1:21:28  time: 0.2862  data_time: 0.0163  memory: 5737  grad_norm: 2.1611  loss: 0.2768  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2768\n",
            "02/09 11:09:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][ 80/166]  lr: 2.0000e-02  eta: 1:21:22  time: 0.2857  data_time: 0.0158  memory: 5737  grad_norm: 2.4552  loss: 0.3103  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3103\n",
            "02/09 11:09:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][100/166]  lr: 2.0000e-02  eta: 1:21:16  time: 0.2862  data_time: 0.0163  memory: 5737  grad_norm: 2.4226  loss: 0.3137  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3137\n",
            "02/09 11:09:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][120/166]  lr: 2.0000e-02  eta: 1:21:10  time: 0.2854  data_time: 0.0157  memory: 5737  grad_norm: 2.3878  loss: 0.2590  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2590\n",
            "02/09 11:09:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][140/166]  lr: 2.0000e-02  eta: 1:21:04  time: 0.2859  data_time: 0.0161  memory: 5737  grad_norm: 3.1737  loss: 0.4238  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4238\n",
            "02/09 11:09:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][160/166]  lr: 2.0000e-02  eta: 1:20:58  time: 0.2843  data_time: 0.0155  memory: 5737  grad_norm: 2.6020  loss: 0.3766  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3766\n",
            "02/09 11:09:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:09:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [49][166/166]  lr: 2.0000e-02  eta: 1:20:56  time: 0.2819  data_time: 0.0148  memory: 5737  grad_norm: 2.5613  loss: 0.3635  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3635\n",
            "02/09 11:09:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][ 20/166]  lr: 2.0000e-02  eta: 1:20:51  time: 0.3180  data_time: 0.0464  memory: 5737  grad_norm: 2.3679  loss: 0.3403  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3403\n",
            "02/09 11:09:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][ 40/166]  lr: 2.0000e-02  eta: 1:20:45  time: 0.2855  data_time: 0.0158  memory: 5737  grad_norm: 2.4938  loss: 0.3058  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3058\n",
            "02/09 11:09:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][ 60/166]  lr: 2.0000e-02  eta: 1:20:39  time: 0.2864  data_time: 0.0166  memory: 5737  grad_norm: 2.5590  loss: 0.3287  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3287\n",
            "02/09 11:09:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][ 80/166]  lr: 2.0000e-02  eta: 1:20:33  time: 0.2852  data_time: 0.0155  memory: 5737  grad_norm: 2.4557  loss: 0.2924  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2924\n",
            "02/09 11:09:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][100/166]  lr: 2.0000e-02  eta: 1:20:27  time: 0.2878  data_time: 0.0174  memory: 5737  grad_norm: 2.6348  loss: 0.3416  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3416\n",
            "02/09 11:10:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][120/166]  lr: 2.0000e-02  eta: 1:20:21  time: 0.2861  data_time: 0.0159  memory: 5737  grad_norm: 2.4844  loss: 0.3260  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3260\n",
            "02/09 11:10:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][140/166]  lr: 2.0000e-02  eta: 1:20:16  time: 0.2861  data_time: 0.0159  memory: 5737  grad_norm: 2.5869  loss: 0.3443  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3443\n",
            "02/09 11:10:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][160/166]  lr: 2.0000e-02  eta: 1:20:10  time: 0.2838  data_time: 0.0147  memory: 5737  grad_norm: 2.4588  loss: 0.3393  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3393\n",
            "02/09 11:10:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:10:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [50][166/166]  lr: 2.0000e-02  eta: 1:20:08  time: 0.2819  data_time: 0.0144  memory: 5737  grad_norm: 2.4776  loss: 0.3348  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.3348\n",
            "02/09 11:10:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [50][20/21]    eta: 0:00:00  time: 0.1395  data_time: 0.0532  memory: 991  \n",
            "02/09 11:10:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [50][21/21]    acc/top1: 0.7259  acc/top5: 1.0000  acc/mean1: 0.7245  data_time: 0.0487  time: 0.1326\n",
            "02/09 11:10:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][ 20/166]  lr: 2.0000e-02  eta: 1:20:03  time: 0.3243  data_time: 0.0518  memory: 5737  grad_norm: 2.6448  loss: 0.3021  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3021\n",
            "02/09 11:10:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][ 40/166]  lr: 2.0000e-02  eta: 1:19:57  time: 0.2848  data_time: 0.0155  memory: 5737  grad_norm: 2.5531  loss: 0.3116  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3116\n",
            "02/09 11:10:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][ 60/166]  lr: 2.0000e-02  eta: 1:19:51  time: 0.2864  data_time: 0.0167  memory: 5737  grad_norm: 2.5385  loss: 0.3351  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3351\n",
            "02/09 11:10:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][ 80/166]  lr: 2.0000e-02  eta: 1:19:45  time: 0.2850  data_time: 0.0154  memory: 5737  grad_norm: 2.4013  loss: 0.3144  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3144\n",
            "02/09 11:10:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][100/166]  lr: 2.0000e-02  eta: 1:19:39  time: 0.2868  data_time: 0.0166  memory: 5737  grad_norm: 2.7761  loss: 0.3239  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.3239\n",
            "02/09 11:10:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][120/166]  lr: 2.0000e-02  eta: 1:19:33  time: 0.2854  data_time: 0.0158  memory: 5737  grad_norm: 2.2678  loss: 0.2993  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2993\n",
            "02/09 11:10:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][140/166]  lr: 2.0000e-02  eta: 1:19:28  time: 0.2852  data_time: 0.0154  memory: 5737  grad_norm: 2.6839  loss: 0.3693  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3693\n",
            "02/09 11:11:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][160/166]  lr: 2.0000e-02  eta: 1:19:22  time: 0.2849  data_time: 0.0155  memory: 5737  grad_norm: 2.5742  loss: 0.3158  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.3158\n",
            "02/09 11:11:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:11:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [51][166/166]  lr: 2.0000e-02  eta: 1:19:20  time: 0.2823  data_time: 0.0147  memory: 5737  grad_norm: 2.5320  loss: 0.3292  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3292\n",
            "02/09 11:11:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][ 20/166]  lr: 2.0000e-02  eta: 1:19:15  time: 0.3193  data_time: 0.0480  memory: 5737  grad_norm: 2.4683  loss: 0.2995  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2995\n",
            "02/09 11:11:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][ 40/166]  lr: 2.0000e-02  eta: 1:19:09  time: 0.2900  data_time: 0.0156  memory: 5737  grad_norm: 2.2480  loss: 0.2696  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2696\n",
            "02/09 11:11:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][ 60/166]  lr: 2.0000e-02  eta: 1:19:03  time: 0.2858  data_time: 0.0158  memory: 5737  grad_norm: 2.4315  loss: 0.2890  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2890\n",
            "02/09 11:11:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][ 80/166]  lr: 2.0000e-02  eta: 1:18:57  time: 0.2850  data_time: 0.0154  memory: 5737  grad_norm: 2.6806  loss: 0.3133  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3133\n",
            "02/09 11:11:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][100/166]  lr: 2.0000e-02  eta: 1:18:51  time: 0.2856  data_time: 0.0159  memory: 5737  grad_norm: 2.5607  loss: 0.3373  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3373\n",
            "02/09 11:11:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][120/166]  lr: 2.0000e-02  eta: 1:18:45  time: 0.2849  data_time: 0.0152  memory: 5737  grad_norm: 2.3315  loss: 0.3426  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3426\n",
            "02/09 11:11:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][140/166]  lr: 2.0000e-02  eta: 1:18:39  time: 0.2864  data_time: 0.0165  memory: 5737  grad_norm: 2.6327  loss: 0.3111  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3111\n",
            "02/09 11:11:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][160/166]  lr: 2.0000e-02  eta: 1:18:33  time: 0.2838  data_time: 0.0147  memory: 5737  grad_norm: 2.5163  loss: 0.3090  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3090\n",
            "02/09 11:11:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:11:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [52][166/166]  lr: 2.0000e-02  eta: 1:18:32  time: 0.2817  data_time: 0.0144  memory: 5737  grad_norm: 2.4595  loss: 0.3043  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3043\n",
            "02/09 11:11:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 52 epochs\n",
            "02/09 11:12:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][ 20/166]  lr: 2.0000e-02  eta: 1:18:27  time: 0.3193  data_time: 0.0474  memory: 5737  grad_norm: 2.2562  loss: 0.2686  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.2686\n",
            "02/09 11:12:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][ 40/166]  lr: 2.0000e-02  eta: 1:18:21  time: 0.2859  data_time: 0.0163  memory: 5737  grad_norm: 2.5295  loss: 0.2563  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.2563\n",
            "02/09 11:12:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][ 60/166]  lr: 2.0000e-02  eta: 1:18:15  time: 0.2864  data_time: 0.0162  memory: 5737  grad_norm: 2.7489  loss: 0.2914  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2914\n",
            "02/09 11:12:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][ 80/166]  lr: 2.0000e-02  eta: 1:18:09  time: 0.2845  data_time: 0.0154  memory: 5737  grad_norm: 3.0674  loss: 0.3816  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3816\n",
            "02/09 11:12:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][100/166]  lr: 2.0000e-02  eta: 1:18:03  time: 0.2856  data_time: 0.0156  memory: 5737  grad_norm: 2.4918  loss: 0.2925  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2925\n",
            "02/09 11:12:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][120/166]  lr: 2.0000e-02  eta: 1:17:57  time: 0.2845  data_time: 0.0151  memory: 5737  grad_norm: 2.5687  loss: 0.3145  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3145\n",
            "02/09 11:12:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][140/166]  lr: 2.0000e-02  eta: 1:17:51  time: 0.2854  data_time: 0.0156  memory: 5737  grad_norm: 2.6512  loss: 0.2910  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2910\n",
            "02/09 11:12:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][160/166]  lr: 2.0000e-02  eta: 1:17:45  time: 0.2834  data_time: 0.0142  memory: 5737  grad_norm: 3.2892  loss: 0.3480  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.3480\n",
            "02/09 11:12:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:12:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [53][166/166]  lr: 2.0000e-02  eta: 1:17:43  time: 0.2815  data_time: 0.0140  memory: 5737  grad_norm: 3.2601  loss: 0.3479  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.3479\n",
            "02/09 11:12:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][ 20/166]  lr: 2.0000e-02  eta: 1:17:38  time: 0.3163  data_time: 0.0443  memory: 5737  grad_norm: 2.9562  loss: 0.4069  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.4069\n",
            "02/09 11:12:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][ 40/166]  lr: 2.0000e-02  eta: 1:17:32  time: 0.2844  data_time: 0.0146  memory: 5737  grad_norm: 2.2885  loss: 0.3351  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3351\n",
            "02/09 11:13:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][ 60/166]  lr: 2.0000e-02  eta: 1:17:27  time: 0.2857  data_time: 0.0156  memory: 5737  grad_norm: 2.4930  loss: 0.3225  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3225\n",
            "02/09 11:13:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][ 80/166]  lr: 2.0000e-02  eta: 1:17:21  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 1.9799  loss: 0.2569  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2569\n",
            "02/09 11:13:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][100/166]  lr: 2.0000e-02  eta: 1:17:15  time: 0.2866  data_time: 0.0166  memory: 5737  grad_norm: 2.5788  loss: 0.3684  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3684\n",
            "02/09 11:13:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][120/166]  lr: 2.0000e-02  eta: 1:17:09  time: 0.2852  data_time: 0.0157  memory: 5737  grad_norm: 2.1190  loss: 0.2972  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2972\n",
            "02/09 11:13:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][140/166]  lr: 2.0000e-02  eta: 1:17:03  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 2.4233  loss: 0.3139  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3139\n",
            "02/09 11:13:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][160/166]  lr: 2.0000e-02  eta: 1:16:57  time: 0.2837  data_time: 0.0145  memory: 5737  grad_norm: 2.6420  loss: 0.3682  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3682\n",
            "02/09 11:13:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:13:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [54][166/166]  lr: 2.0000e-02  eta: 1:16:55  time: 0.2808  data_time: 0.0135  memory: 5737  grad_norm: 2.4492  loss: 0.3373  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3373\n",
            "02/09 11:13:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][ 20/166]  lr: 2.0000e-02  eta: 1:16:50  time: 0.3154  data_time: 0.0436  memory: 5737  grad_norm: 2.6000  loss: 0.3150  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3150\n",
            "02/09 11:13:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:13:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][ 40/166]  lr: 2.0000e-02  eta: 1:16:44  time: 0.2841  data_time: 0.0146  memory: 5737  grad_norm: 2.7330  loss: 0.2939  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2939\n",
            "02/09 11:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][ 60/166]  lr: 2.0000e-02  eta: 1:16:38  time: 0.2865  data_time: 0.0165  memory: 5737  grad_norm: 2.7412  loss: 0.3431  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3431\n",
            "02/09 11:13:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][ 80/166]  lr: 2.0000e-02  eta: 1:16:32  time: 0.2850  data_time: 0.0153  memory: 5737  grad_norm: 2.6805  loss: 0.3599  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3599\n",
            "02/09 11:14:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][100/166]  lr: 2.0000e-02  eta: 1:16:26  time: 0.2857  data_time: 0.0159  memory: 5737  grad_norm: 2.1172  loss: 0.2739  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2739\n",
            "02/09 11:14:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][120/166]  lr: 2.0000e-02  eta: 1:16:20  time: 0.2858  data_time: 0.0158  memory: 5737  grad_norm: 2.7563  loss: 0.3279  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3279\n",
            "02/09 11:14:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][140/166]  lr: 2.0000e-02  eta: 1:16:14  time: 0.2850  data_time: 0.0152  memory: 5737  grad_norm: 2.6518  loss: 0.3115  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3115\n",
            "02/09 11:14:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][160/166]  lr: 2.0000e-02  eta: 1:16:08  time: 0.2845  data_time: 0.0152  memory: 5737  grad_norm: 2.7931  loss: 0.3154  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3154\n",
            "02/09 11:14:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:14:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [55][166/166]  lr: 2.0000e-02  eta: 1:16:07  time: 0.2814  data_time: 0.0141  memory: 5737  grad_norm: 3.0423  loss: 0.3622  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3622\n",
            "02/09 11:14:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [55][20/21]    eta: 0:00:00  time: 0.1422  data_time: 0.0588  memory: 991  \n",
            "02/09 11:14:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [55][21/21]    acc/top1: 0.7349  acc/top5: 1.0000  acc/mean1: 0.7205  data_time: 0.0538  time: 0.1350\n",
            "02/09 11:14:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][ 20/166]  lr: 2.0000e-02  eta: 1:16:02  time: 0.3182  data_time: 0.0472  memory: 5737  grad_norm: 3.0811  loss: 0.4111  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.4111\n",
            "02/09 11:14:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][ 40/166]  lr: 2.0000e-02  eta: 1:15:56  time: 0.2849  data_time: 0.0154  memory: 5737  grad_norm: 2.1274  loss: 0.3324  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3324\n",
            "02/09 11:14:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][ 60/166]  lr: 2.0000e-02  eta: 1:15:50  time: 0.2860  data_time: 0.0160  memory: 5737  grad_norm: 2.2341  loss: 0.3191  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3191\n",
            "02/09 11:14:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][ 80/166]  lr: 2.0000e-02  eta: 1:15:44  time: 0.2859  data_time: 0.0159  memory: 5737  grad_norm: 2.1685  loss: 0.2945  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2945\n",
            "02/09 11:14:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][100/166]  lr: 2.0000e-02  eta: 1:15:38  time: 0.2863  data_time: 0.0163  memory: 5737  grad_norm: 2.4466  loss: 0.2943  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2943\n",
            "02/09 11:14:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][120/166]  lr: 2.0000e-02  eta: 1:15:32  time: 0.2851  data_time: 0.0157  memory: 5737  grad_norm: 2.4538  loss: 0.3148  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3148\n",
            "02/09 11:15:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][140/166]  lr: 2.0000e-02  eta: 1:15:26  time: 0.2868  data_time: 0.0165  memory: 5737  grad_norm: 2.8617  loss: 0.3662  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3662\n",
            "02/09 11:15:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][160/166]  lr: 2.0000e-02  eta: 1:15:20  time: 0.2841  data_time: 0.0151  memory: 5737  grad_norm: 2.1108  loss: 0.2749  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.2749\n",
            "02/09 11:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [56][166/166]  lr: 2.0000e-02  eta: 1:15:18  time: 0.2811  data_time: 0.0138  memory: 5737  grad_norm: 2.1939  loss: 0.2715  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.2715\n",
            "02/09 11:15:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 56 epochs\n",
            "02/09 11:15:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][ 20/166]  lr: 2.0000e-02  eta: 1:15:13  time: 0.3153  data_time: 0.0431  memory: 5737  grad_norm: 2.3281  loss: 0.2437  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2437\n",
            "02/09 11:15:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][ 40/166]  lr: 2.0000e-02  eta: 1:15:08  time: 0.2863  data_time: 0.0165  memory: 5737  grad_norm: 2.9399  loss: 0.3174  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3174\n",
            "02/09 11:15:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][ 60/166]  lr: 2.0000e-02  eta: 1:15:02  time: 0.2860  data_time: 0.0162  memory: 5737  grad_norm: 2.5521  loss: 0.3098  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3098\n",
            "02/09 11:15:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][ 80/166]  lr: 2.0000e-02  eta: 1:14:56  time: 0.2855  data_time: 0.0157  memory: 5737  grad_norm: 2.6830  loss: 0.3135  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3135\n",
            "02/09 11:15:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][100/166]  lr: 2.0000e-02  eta: 1:14:50  time: 0.2851  data_time: 0.0155  memory: 5737  grad_norm: 2.6230  loss: 0.2854  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2854\n",
            "02/09 11:15:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][120/166]  lr: 2.0000e-02  eta: 1:14:44  time: 0.2845  data_time: 0.0150  memory: 5737  grad_norm: 2.6432  loss: 0.3094  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3094\n",
            "02/09 11:15:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][140/166]  lr: 2.0000e-02  eta: 1:14:38  time: 0.2858  data_time: 0.0157  memory: 5737  grad_norm: 2.7231  loss: 0.3015  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3015\n",
            "02/09 11:15:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][160/166]  lr: 2.0000e-02  eta: 1:14:32  time: 0.2842  data_time: 0.0149  memory: 5737  grad_norm: 2.7511  loss: 0.3348  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3348\n",
            "02/09 11:15:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:15:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [57][166/166]  lr: 2.0000e-02  eta: 1:14:30  time: 0.2812  data_time: 0.0138  memory: 5737  grad_norm: 2.6456  loss: 0.3365  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.3365\n",
            "02/09 11:16:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][ 20/166]  lr: 2.0000e-02  eta: 1:14:25  time: 0.3157  data_time: 0.0439  memory: 5737  grad_norm: 2.1802  loss: 0.2991  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2991\n",
            "02/09 11:16:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][ 40/166]  lr: 2.0000e-02  eta: 1:14:19  time: 0.2849  data_time: 0.0151  memory: 5737  grad_norm: 2.3759  loss: 0.2944  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2944\n",
            "02/09 11:16:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][ 60/166]  lr: 2.0000e-02  eta: 1:14:13  time: 0.2859  data_time: 0.0157  memory: 5737  grad_norm: 2.3459  loss: 0.3021  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3021\n",
            "02/09 11:16:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][ 80/166]  lr: 2.0000e-02  eta: 1:14:07  time: 0.2851  data_time: 0.0153  memory: 5737  grad_norm: 2.2392  loss: 0.2585  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2585\n",
            "02/09 11:16:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][100/166]  lr: 2.0000e-02  eta: 1:14:01  time: 0.2853  data_time: 0.0154  memory: 5737  grad_norm: 2.6327  loss: 0.3686  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3686\n",
            "02/09 11:16:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][120/166]  lr: 2.0000e-02  eta: 1:13:55  time: 0.2850  data_time: 0.0153  memory: 5737  grad_norm: 2.5247  loss: 0.3465  top1_acc: 0.5625  top5_acc: 1.0000  loss_cls: 0.3465\n",
            "02/09 11:16:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][140/166]  lr: 2.0000e-02  eta: 1:13:50  time: 0.2866  data_time: 0.0165  memory: 5737  grad_norm: 2.5438  loss: 0.3131  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3131\n",
            "02/09 11:16:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][160/166]  lr: 2.0000e-02  eta: 1:13:44  time: 0.2837  data_time: 0.0145  memory: 5737  grad_norm: 2.4251  loss: 0.3015  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3015\n",
            "02/09 11:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:16:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [58][166/166]  lr: 2.0000e-02  eta: 1:13:42  time: 0.2817  data_time: 0.0139  memory: 5737  grad_norm: 2.4662  loss: 0.3076  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3076\n",
            "02/09 11:16:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][ 20/166]  lr: 2.0000e-02  eta: 1:13:37  time: 0.3199  data_time: 0.0483  memory: 5737  grad_norm: 2.2081  loss: 0.2568  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2568\n",
            "02/09 11:16:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][ 40/166]  lr: 2.0000e-02  eta: 1:13:31  time: 0.2839  data_time: 0.0145  memory: 5737  grad_norm: 2.5240  loss: 0.3100  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3100\n",
            "02/09 11:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][ 60/166]  lr: 2.0000e-02  eta: 1:13:25  time: 0.2856  data_time: 0.0157  memory: 5737  grad_norm: 2.4417  loss: 0.2657  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2657\n",
            "02/09 11:17:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][ 80/166]  lr: 2.0000e-02  eta: 1:13:19  time: 0.2857  data_time: 0.0158  memory: 5737  grad_norm: 2.3579  loss: 0.2878  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2878\n",
            "02/09 11:17:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][100/166]  lr: 2.0000e-02  eta: 1:13:13  time: 0.2864  data_time: 0.0163  memory: 5737  grad_norm: 2.2915  loss: 0.2992  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.2992\n",
            "02/09 11:17:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][120/166]  lr: 2.0000e-02  eta: 1:13:07  time: 0.2852  data_time: 0.0158  memory: 5737  grad_norm: 2.5249  loss: 0.3365  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3365\n",
            "02/09 11:17:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][140/166]  lr: 2.0000e-02  eta: 1:13:01  time: 0.2860  data_time: 0.0163  memory: 5737  grad_norm: 2.5292  loss: 0.3521  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3521\n",
            "02/09 11:17:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][160/166]  lr: 2.0000e-02  eta: 1:12:55  time: 0.2836  data_time: 0.0146  memory: 5737  grad_norm: 2.4227  loss: 0.3020  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3020\n",
            "02/09 11:17:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:17:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [59][166/166]  lr: 2.0000e-02  eta: 1:12:54  time: 0.2804  data_time: 0.0133  memory: 5737  grad_norm: 2.3587  loss: 0.2820  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.2820\n",
            "02/09 11:17:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][ 20/166]  lr: 2.0000e-02  eta: 1:12:49  time: 0.3146  data_time: 0.0427  memory: 5737  grad_norm: 2.3324  loss: 0.2819  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2819\n",
            "02/09 11:17:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][ 40/166]  lr: 2.0000e-02  eta: 1:12:43  time: 0.2847  data_time: 0.0152  memory: 5737  grad_norm: 2.5031  loss: 0.3191  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3191\n",
            "02/09 11:17:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][ 60/166]  lr: 2.0000e-02  eta: 1:12:37  time: 0.2864  data_time: 0.0164  memory: 5737  grad_norm: 3.1113  loss: 0.3678  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3678\n",
            "02/09 11:17:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][ 80/166]  lr: 2.0000e-02  eta: 1:12:31  time: 0.2867  data_time: 0.0168  memory: 5737  grad_norm: 2.3794  loss: 0.2992  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2992\n",
            "02/09 11:18:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][100/166]  lr: 2.0000e-02  eta: 1:12:25  time: 0.2863  data_time: 0.0164  memory: 5737  grad_norm: 2.2899  loss: 0.2711  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2711\n",
            "02/09 11:18:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][120/166]  lr: 2.0000e-02  eta: 1:12:19  time: 0.2862  data_time: 0.0162  memory: 5737  grad_norm: 2.8002  loss: 0.3148  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3148\n",
            "02/09 11:18:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][140/166]  lr: 2.0000e-02  eta: 1:12:13  time: 0.2859  data_time: 0.0157  memory: 5737  grad_norm: 2.4595  loss: 0.2684  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2684\n",
            "02/09 11:18:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][160/166]  lr: 2.0000e-02  eta: 1:12:07  time: 0.2862  data_time: 0.0166  memory: 5737  grad_norm: 2.5172  loss: 0.3193  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3193\n",
            "02/09 11:18:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:18:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [60][166/166]  lr: 2.0000e-02  eta: 1:12:05  time: 0.2830  data_time: 0.0154  memory: 5737  grad_norm: 2.5741  loss: 0.3015  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3015\n",
            "02/09 11:18:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 60 epochs\n",
            "02/09 11:18:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [60][20/21]    eta: 0:00:00  time: 0.1387  data_time: 0.0538  memory: 991  \n",
            "02/09 11:18:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [60][21/21]    acc/top1: 0.7530  acc/top5: 1.0000  acc/mean1: 0.7507  data_time: 0.0492  time: 0.1319\n",
            "02/09 11:18:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb/best_acc_top1_epoch_40.pth is removed\n",
            "02/09 11:18:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7530 acc/top1 at 60 epoch is saved to best_acc_top1_epoch_60.pth.\n",
            "02/09 11:18:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][ 20/166]  lr: 2.0000e-02  eta: 1:12:01  time: 0.3212  data_time: 0.0503  memory: 5737  grad_norm: 2.3577  loss: 0.2883  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2883\n",
            "02/09 11:18:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:18:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][ 40/166]  lr: 2.0000e-02  eta: 1:11:55  time: 0.2851  data_time: 0.0156  memory: 5737  grad_norm: 2.6665  loss: 0.3577  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3577\n",
            "02/09 11:18:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][ 60/166]  lr: 2.0000e-02  eta: 1:11:49  time: 0.2860  data_time: 0.0160  memory: 5737  grad_norm: 2.0501  loss: 0.2562  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2562\n",
            "02/09 11:18:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][ 80/166]  lr: 2.0000e-02  eta: 1:11:43  time: 0.2859  data_time: 0.0158  memory: 5737  grad_norm: 2.1662  loss: 0.2369  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2369\n",
            "02/09 11:18:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][100/166]  lr: 2.0000e-02  eta: 1:11:37  time: 0.2854  data_time: 0.0157  memory: 5737  grad_norm: 2.5068  loss: 0.2463  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2463\n",
            "02/09 11:19:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][120/166]  lr: 2.0000e-02  eta: 1:11:31  time: 0.2846  data_time: 0.0150  memory: 5737  grad_norm: 2.6702  loss: 0.2962  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2962\n",
            "02/09 11:19:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][140/166]  lr: 2.0000e-02  eta: 1:11:25  time: 0.2857  data_time: 0.0158  memory: 5737  grad_norm: 2.9588  loss: 0.3291  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3291\n",
            "02/09 11:19:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][160/166]  lr: 2.0000e-02  eta: 1:11:19  time: 0.2835  data_time: 0.0146  memory: 5737  grad_norm: 2.6248  loss: 0.3135  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3135\n",
            "02/09 11:19:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:19:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [61][166/166]  lr: 2.0000e-02  eta: 1:11:17  time: 0.2813  data_time: 0.0139  memory: 5737  grad_norm: 2.8132  loss: 0.3527  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.3527\n",
            "02/09 11:19:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][ 20/166]  lr: 2.0000e-02  eta: 1:11:12  time: 0.3250  data_time: 0.0523  memory: 5737  grad_norm: 2.0007  loss: 0.2579  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.2579\n",
            "02/09 11:19:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][ 40/166]  lr: 2.0000e-02  eta: 1:11:07  time: 0.2851  data_time: 0.0155  memory: 5737  grad_norm: 2.2815  loss: 0.2604  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2604\n",
            "02/09 11:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][ 60/166]  lr: 2.0000e-02  eta: 1:11:01  time: 0.2859  data_time: 0.0161  memory: 5737  grad_norm: 2.4599  loss: 0.2378  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.2378\n",
            "02/09 11:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][ 80/166]  lr: 2.0000e-02  eta: 1:10:55  time: 0.2854  data_time: 0.0155  memory: 5737  grad_norm: 2.7638  loss: 0.3287  top1_acc: 0.6250  top5_acc: 1.0000  loss_cls: 0.3287\n",
            "02/09 11:19:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][100/166]  lr: 2.0000e-02  eta: 1:10:49  time: 0.2862  data_time: 0.0163  memory: 5737  grad_norm: 2.3294  loss: 0.2661  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2661\n",
            "02/09 11:19:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][120/166]  lr: 2.0000e-02  eta: 1:10:43  time: 0.2843  data_time: 0.0148  memory: 5737  grad_norm: 2.3435  loss: 0.3006  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3006\n",
            "02/09 11:19:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][140/166]  lr: 2.0000e-02  eta: 1:10:37  time: 0.2869  data_time: 0.0171  memory: 5737  grad_norm: 2.4406  loss: 0.2682  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2682\n",
            "02/09 11:20:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][160/166]  lr: 2.0000e-02  eta: 1:10:31  time: 0.2844  data_time: 0.0150  memory: 5737  grad_norm: 2.9199  loss: 0.3626  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3626\n",
            "02/09 11:20:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:20:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [62][166/166]  lr: 2.0000e-02  eta: 1:10:29  time: 0.2819  data_time: 0.0142  memory: 5737  grad_norm: 2.7069  loss: 0.3077  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3077\n",
            "02/09 11:20:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][ 20/166]  lr: 2.0000e-02  eta: 1:10:24  time: 0.3176  data_time: 0.0454  memory: 5737  grad_norm: 2.1342  loss: 0.2572  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2572\n",
            "02/09 11:20:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][ 40/166]  lr: 2.0000e-02  eta: 1:10:18  time: 0.2852  data_time: 0.0159  memory: 5737  grad_norm: 2.5117  loss: 0.2802  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2802\n",
            "02/09 11:20:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][ 60/166]  lr: 2.0000e-02  eta: 1:10:12  time: 0.2864  data_time: 0.0166  memory: 5737  grad_norm: 2.5191  loss: 0.2745  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2745\n",
            "02/09 11:20:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][ 80/166]  lr: 2.0000e-02  eta: 1:10:07  time: 0.2852  data_time: 0.0154  memory: 5737  grad_norm: 2.6407  loss: 0.3003  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3003\n",
            "02/09 11:20:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][100/166]  lr: 2.0000e-02  eta: 1:10:01  time: 0.2856  data_time: 0.0158  memory: 5737  grad_norm: 2.4382  loss: 0.2708  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2708\n",
            "02/09 11:20:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][120/166]  lr: 2.0000e-02  eta: 1:09:55  time: 0.2848  data_time: 0.0148  memory: 5737  grad_norm: 2.6914  loss: 0.3010  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3010\n",
            "02/09 11:20:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][140/166]  lr: 2.0000e-02  eta: 1:09:49  time: 0.2853  data_time: 0.0156  memory: 5737  grad_norm: 2.5685  loss: 0.2838  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2838\n",
            "02/09 11:20:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][160/166]  lr: 2.0000e-02  eta: 1:09:43  time: 0.2840  data_time: 0.0148  memory: 5737  grad_norm: 2.7801  loss: 0.2827  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2827\n",
            "02/09 11:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:20:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [63][166/166]  lr: 2.0000e-02  eta: 1:09:41  time: 0.2821  data_time: 0.0143  memory: 5737  grad_norm: 2.7715  loss: 0.2918  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.2918\n",
            "02/09 11:20:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][ 20/166]  lr: 2.0000e-02  eta: 1:09:36  time: 0.3144  data_time: 0.0430  memory: 5737  grad_norm: 2.5256  loss: 0.2829  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2829\n",
            "02/09 11:21:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][ 40/166]  lr: 2.0000e-02  eta: 1:09:30  time: 0.2851  data_time: 0.0154  memory: 5737  grad_norm: 2.4488  loss: 0.2823  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2823\n",
            "02/09 11:21:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][ 60/166]  lr: 2.0000e-02  eta: 1:09:24  time: 0.2865  data_time: 0.0165  memory: 5737  grad_norm: 2.4324  loss: 0.2866  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2866\n",
            "02/09 11:21:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][ 80/166]  lr: 2.0000e-02  eta: 1:09:18  time: 0.2857  data_time: 0.0156  memory: 5737  grad_norm: 2.3568  loss: 0.2521  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2521\n",
            "02/09 11:21:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][100/166]  lr: 2.0000e-02  eta: 1:09:12  time: 0.2865  data_time: 0.0166  memory: 5737  grad_norm: 2.6811  loss: 0.2493  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2493\n",
            "02/09 11:21:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][120/166]  lr: 2.0000e-02  eta: 1:09:06  time: 0.2853  data_time: 0.0159  memory: 5737  grad_norm: 3.6369  loss: 0.4171  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.4171\n",
            "02/09 11:21:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][140/166]  lr: 2.0000e-02  eta: 1:09:01  time: 0.2854  data_time: 0.0155  memory: 5737  grad_norm: 2.3354  loss: 0.3521  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3521\n",
            "02/09 11:21:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][160/166]  lr: 2.0000e-02  eta: 1:08:55  time: 0.2847  data_time: 0.0157  memory: 5737  grad_norm: 2.1525  loss: 0.2826  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2826\n",
            "02/09 11:21:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:21:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [64][166/166]  lr: 2.0000e-02  eta: 1:08:53  time: 0.2821  data_time: 0.0149  memory: 5737  grad_norm: 2.2244  loss: 0.2946  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.2946\n",
            "02/09 11:21:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 64 epochs\n",
            "02/09 11:21:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][ 20/166]  lr: 2.0000e-02  eta: 1:08:48  time: 0.3163  data_time: 0.0458  memory: 5737  grad_norm: 2.0497  loss: 0.2362  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2362\n",
            "02/09 11:21:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][ 40/166]  lr: 2.0000e-02  eta: 1:08:42  time: 0.2843  data_time: 0.0152  memory: 5737  grad_norm: 1.9014  loss: 0.2012  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2012\n",
            "02/09 11:21:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][ 60/166]  lr: 2.0000e-02  eta: 1:08:36  time: 0.2866  data_time: 0.0164  memory: 5737  grad_norm: 2.6438  loss: 0.3257  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3257\n",
            "02/09 11:22:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][ 80/166]  lr: 2.0000e-02  eta: 1:08:30  time: 0.2857  data_time: 0.0160  memory: 5737  grad_norm: 2.3105  loss: 0.2644  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2644\n",
            "02/09 11:22:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][100/166]  lr: 2.0000e-02  eta: 1:08:24  time: 0.2855  data_time: 0.0158  memory: 5737  grad_norm: 3.1423  loss: 0.3679  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3679\n",
            "02/09 11:22:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][120/166]  lr: 2.0000e-02  eta: 1:08:18  time: 0.2852  data_time: 0.0151  memory: 5737  grad_norm: 2.7369  loss: 0.3456  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3456\n",
            "02/09 11:22:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][140/166]  lr: 2.0000e-02  eta: 1:08:12  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 2.1450  loss: 0.2773  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2773\n",
            "02/09 11:22:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][160/166]  lr: 2.0000e-02  eta: 1:08:06  time: 0.2839  data_time: 0.0149  memory: 5737  grad_norm: 2.5505  loss: 0.2903  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2903\n",
            "02/09 11:22:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:22:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [65][166/166]  lr: 2.0000e-02  eta: 1:08:05  time: 0.2815  data_time: 0.0142  memory: 5737  grad_norm: 2.6248  loss: 0.2987  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2987\n",
            "02/09 11:22:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [65][20/21]    eta: 0:00:00  time: 0.1402  data_time: 0.0535  memory: 991  \n",
            "02/09 11:22:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [65][21/21]    acc/top1: 0.7470  acc/top5: 1.0000  acc/mean1: 0.7415  data_time: 0.0489  time: 0.1332\n",
            "02/09 11:22:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][ 20/166]  lr: 2.0000e-02  eta: 1:08:00  time: 0.3235  data_time: 0.0521  memory: 5737  grad_norm: 2.3774  loss: 0.2775  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2775\n",
            "02/09 11:22:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][ 40/166]  lr: 2.0000e-02  eta: 1:07:54  time: 0.2849  data_time: 0.0156  memory: 5737  grad_norm: 2.2189  loss: 0.2501  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2501\n",
            "02/09 11:22:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][ 60/166]  lr: 2.0000e-02  eta: 1:07:48  time: 0.2858  data_time: 0.0160  memory: 5737  grad_norm: 2.4212  loss: 0.2708  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2708\n",
            "02/09 11:22:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][ 80/166]  lr: 2.0000e-02  eta: 1:07:42  time: 0.2852  data_time: 0.0155  memory: 5737  grad_norm: 2.5595  loss: 0.3227  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3227\n",
            "02/09 11:23:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][100/166]  lr: 2.0000e-02  eta: 1:07:36  time: 0.2868  data_time: 0.0162  memory: 5737  grad_norm: 2.1080  loss: 0.2514  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2514\n",
            "02/09 11:23:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][120/166]  lr: 2.0000e-02  eta: 1:07:30  time: 0.2846  data_time: 0.0147  memory: 5737  grad_norm: 2.4974  loss: 0.2507  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2507\n",
            "02/09 11:23:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][140/166]  lr: 2.0000e-02  eta: 1:07:24  time: 0.2853  data_time: 0.0154  memory: 5737  grad_norm: 2.5288  loss: 0.2722  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2722\n",
            "02/09 11:23:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][160/166]  lr: 2.0000e-02  eta: 1:07:18  time: 0.2844  data_time: 0.0154  memory: 5737  grad_norm: 2.5747  loss: 0.3310  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3310\n",
            "02/09 11:23:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:23:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [66][166/166]  lr: 2.0000e-02  eta: 1:07:17  time: 0.2823  data_time: 0.0150  memory: 5737  grad_norm: 2.3069  loss: 0.2760  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.2760\n",
            "02/09 11:23:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][ 20/166]  lr: 2.0000e-02  eta: 1:07:11  time: 0.3178  data_time: 0.0470  memory: 5737  grad_norm: 2.5367  loss: 0.2948  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2948\n",
            "02/09 11:23:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][ 40/166]  lr: 2.0000e-02  eta: 1:07:06  time: 0.2856  data_time: 0.0156  memory: 5737  grad_norm: 2.4227  loss: 0.3437  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3437\n",
            "02/09 11:23:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:23:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][ 60/166]  lr: 2.0000e-02  eta: 1:07:00  time: 0.2855  data_time: 0.0158  memory: 5737  grad_norm: 2.0212  loss: 0.2317  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2317\n",
            "02/09 11:23:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][ 80/166]  lr: 2.0000e-02  eta: 1:06:54  time: 0.2847  data_time: 0.0153  memory: 5737  grad_norm: 2.9875  loss: 0.3606  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3606\n",
            "02/09 11:23:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][100/166]  lr: 2.0000e-02  eta: 1:06:48  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 2.5544  loss: 0.3178  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3178\n",
            "02/09 11:23:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][120/166]  lr: 2.0000e-02  eta: 1:06:42  time: 0.2853  data_time: 0.0154  memory: 5737  grad_norm: 2.6172  loss: 0.2656  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2656\n",
            "02/09 11:24:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][140/166]  lr: 2.0000e-02  eta: 1:06:36  time: 0.2861  data_time: 0.0162  memory: 5737  grad_norm: 2.7573  loss: 0.3309  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3309\n",
            "02/09 11:24:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][160/166]  lr: 2.0000e-02  eta: 1:06:30  time: 0.2844  data_time: 0.0150  memory: 5737  grad_norm: 2.5206  loss: 0.2807  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2807\n",
            "02/09 11:24:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:24:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [67][166/166]  lr: 2.0000e-02  eta: 1:06:28  time: 0.2824  data_time: 0.0148  memory: 5737  grad_norm: 2.4558  loss: 0.2956  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.2956\n",
            "02/09 11:24:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][ 20/166]  lr: 2.0000e-02  eta: 1:06:23  time: 0.3145  data_time: 0.0429  memory: 5737  grad_norm: 2.2226  loss: 0.2631  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2631\n",
            "02/09 11:24:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][ 40/166]  lr: 2.0000e-02  eta: 1:06:17  time: 0.2849  data_time: 0.0153  memory: 5737  grad_norm: 2.4768  loss: 0.3035  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3035\n",
            "02/09 11:24:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][ 60/166]  lr: 2.0000e-02  eta: 1:06:11  time: 0.2857  data_time: 0.0160  memory: 5737  grad_norm: 2.4160  loss: 0.2898  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2898\n",
            "02/09 11:24:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][ 80/166]  lr: 2.0000e-02  eta: 1:06:06  time: 0.2845  data_time: 0.0148  memory: 5737  grad_norm: 2.5680  loss: 0.2601  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2601\n",
            "02/09 11:24:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][100/166]  lr: 2.0000e-02  eta: 1:06:00  time: 0.2855  data_time: 0.0159  memory: 5737  grad_norm: 2.6895  loss: 0.3069  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3069\n",
            "02/09 11:24:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][120/166]  lr: 2.0000e-02  eta: 1:05:54  time: 0.2845  data_time: 0.0150  memory: 5737  grad_norm: 2.5584  loss: 0.2832  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2832\n",
            "02/09 11:24:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][140/166]  lr: 2.0000e-02  eta: 1:05:48  time: 0.2853  data_time: 0.0154  memory: 5737  grad_norm: 3.0128  loss: 0.2927  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2927\n",
            "02/09 11:24:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][160/166]  lr: 2.0000e-02  eta: 1:05:42  time: 0.2841  data_time: 0.0146  memory: 5737  grad_norm: 2.6526  loss: 0.3137  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3137\n",
            "02/09 11:24:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:24:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [68][166/166]  lr: 2.0000e-02  eta: 1:05:40  time: 0.2812  data_time: 0.0140  memory: 5737  grad_norm: 2.3782  loss: 0.3018  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3018\n",
            "02/09 11:24:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 68 epochs\n",
            "02/09 11:25:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][ 20/166]  lr: 2.0000e-02  eta: 1:05:35  time: 0.3191  data_time: 0.0475  memory: 5737  grad_norm: 2.0977  loss: 0.2674  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2674\n",
            "02/09 11:25:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][ 40/166]  lr: 2.0000e-02  eta: 1:05:29  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 2.6029  loss: 0.2700  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2700\n",
            "02/09 11:25:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][ 60/166]  lr: 2.0000e-02  eta: 1:05:23  time: 0.2857  data_time: 0.0157  memory: 5737  grad_norm: 2.5956  loss: 0.2481  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2481\n",
            "02/09 11:25:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][ 80/166]  lr: 2.0000e-02  eta: 1:05:17  time: 0.2863  data_time: 0.0161  memory: 5737  grad_norm: 2.6990  loss: 0.2853  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2853\n",
            "02/09 11:25:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][100/166]  lr: 2.0000e-02  eta: 1:05:12  time: 0.2870  data_time: 0.0168  memory: 5737  grad_norm: 2.7177  loss: 0.2860  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2860\n",
            "02/09 11:25:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][120/166]  lr: 2.0000e-02  eta: 1:05:06  time: 0.2849  data_time: 0.0153  memory: 5737  grad_norm: 2.9489  loss: 0.3053  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3053\n",
            "02/09 11:25:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][140/166]  lr: 2.0000e-02  eta: 1:05:00  time: 0.2864  data_time: 0.0162  memory: 5737  grad_norm: 3.0100  loss: 0.3150  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3150\n",
            "02/09 11:25:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][160/166]  lr: 2.0000e-02  eta: 1:04:54  time: 0.2842  data_time: 0.0151  memory: 5737  grad_norm: 2.5904  loss: 0.3118  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3118\n",
            "02/09 11:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:25:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [69][166/166]  lr: 2.0000e-02  eta: 1:04:52  time: 0.2819  data_time: 0.0144  memory: 5737  grad_norm: 2.5528  loss: 0.2999  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2999\n",
            "02/09 11:25:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][ 20/166]  lr: 2.0000e-02  eta: 1:04:47  time: 0.3192  data_time: 0.0480  memory: 5737  grad_norm: 2.3798  loss: 0.2735  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2735\n",
            "02/09 11:25:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][ 40/166]  lr: 2.0000e-02  eta: 1:04:41  time: 0.2853  data_time: 0.0157  memory: 5737  grad_norm: 2.2372  loss: 0.2731  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2731\n",
            "02/09 11:26:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][ 60/166]  lr: 2.0000e-02  eta: 1:04:35  time: 0.2862  data_time: 0.0164  memory: 5737  grad_norm: 2.5032  loss: 0.2680  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2680\n",
            "02/09 11:26:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][ 80/166]  lr: 2.0000e-02  eta: 1:04:29  time: 0.2850  data_time: 0.0155  memory: 5737  grad_norm: 2.3645  loss: 0.2695  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2695\n",
            "02/09 11:26:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][100/166]  lr: 2.0000e-02  eta: 1:04:23  time: 0.2855  data_time: 0.0157  memory: 5737  grad_norm: 2.4259  loss: 0.2422  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2422\n",
            "02/09 11:26:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][120/166]  lr: 2.0000e-02  eta: 1:04:18  time: 0.2844  data_time: 0.0149  memory: 5737  grad_norm: 2.6653  loss: 0.2778  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2778\n",
            "02/09 11:26:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][140/166]  lr: 2.0000e-02  eta: 1:04:12  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 2.3647  loss: 0.2554  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2554\n",
            "02/09 11:26:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][160/166]  lr: 2.0000e-02  eta: 1:04:06  time: 0.2848  data_time: 0.0155  memory: 5737  grad_norm: 2.1886  loss: 0.2346  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2346\n",
            "02/09 11:26:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:26:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [70][166/166]  lr: 2.0000e-02  eta: 1:04:04  time: 0.2817  data_time: 0.0142  memory: 5737  grad_norm: 2.4573  loss: 0.2554  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.2554\n",
            "02/09 11:26:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [70][20/21]    eta: 0:00:00  time: 0.1408  data_time: 0.0551  memory: 991  \n",
            "02/09 11:26:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [70][21/21]    acc/top1: 0.7651  acc/top5: 1.0000  acc/mean1: 0.7636  data_time: 0.0504  time: 0.1337\n",
            "02/09 11:26:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb/best_acc_top1_epoch_60.pth is removed\n",
            "02/09 11:26:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7651 acc/top1 at 70 epoch is saved to best_acc_top1_epoch_70.pth.\n",
            "02/09 11:26:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][ 20/166]  lr: 2.0000e-02  eta: 1:03:59  time: 0.3227  data_time: 0.0506  memory: 5737  grad_norm: 2.3141  loss: 0.2312  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2312\n",
            "02/09 11:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][ 40/166]  lr: 2.0000e-02  eta: 1:03:53  time: 0.2850  data_time: 0.0154  memory: 5737  grad_norm: 2.9237  loss: 0.3243  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3243\n",
            "02/09 11:26:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][ 60/166]  lr: 2.0000e-02  eta: 1:03:47  time: 0.2867  data_time: 0.0165  memory: 5737  grad_norm: 2.4410  loss: 0.3138  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3138\n",
            "02/09 11:27:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][ 80/166]  lr: 2.0000e-02  eta: 1:03:41  time: 0.2852  data_time: 0.0155  memory: 5737  grad_norm: 2.4110  loss: 0.2863  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2863\n",
            "02/09 11:27:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][100/166]  lr: 2.0000e-02  eta: 1:03:35  time: 0.2863  data_time: 0.0165  memory: 5737  grad_norm: 2.1786  loss: 0.2259  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2259\n",
            "02/09 11:27:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][120/166]  lr: 2.0000e-02  eta: 1:03:30  time: 0.2850  data_time: 0.0154  memory: 5737  grad_norm: 2.7044  loss: 0.3078  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3078\n",
            "02/09 11:27:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][140/166]  lr: 2.0000e-02  eta: 1:03:24  time: 0.2860  data_time: 0.0162  memory: 5737  grad_norm: 2.5165  loss: 0.2775  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2775\n",
            "02/09 11:27:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][160/166]  lr: 2.0000e-02  eta: 1:03:18  time: 0.2838  data_time: 0.0146  memory: 5737  grad_norm: 2.4488  loss: 0.2783  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2783\n",
            "02/09 11:27:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:27:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [71][166/166]  lr: 2.0000e-02  eta: 1:03:16  time: 0.2813  data_time: 0.0139  memory: 5737  grad_norm: 2.3682  loss: 0.2852  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.2852\n",
            "02/09 11:27:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][ 20/166]  lr: 2.0000e-02  eta: 1:03:11  time: 0.3213  data_time: 0.0469  memory: 5737  grad_norm: 1.8821  loss: 0.2149  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2149\n",
            "02/09 11:27:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][ 40/166]  lr: 2.0000e-02  eta: 1:03:05  time: 0.2853  data_time: 0.0153  memory: 5737  grad_norm: 2.3116  loss: 0.2362  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2362\n",
            "02/09 11:27:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][ 60/166]  lr: 2.0000e-02  eta: 1:02:59  time: 0.2864  data_time: 0.0167  memory: 5737  grad_norm: 2.4781  loss: 0.2700  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2700\n",
            "02/09 11:27:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][ 80/166]  lr: 2.0000e-02  eta: 1:02:53  time: 0.2854  data_time: 0.0158  memory: 5737  grad_norm: 2.5609  loss: 0.2663  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2663\n",
            "02/09 11:27:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][100/166]  lr: 2.0000e-02  eta: 1:02:47  time: 0.2865  data_time: 0.0162  memory: 5737  grad_norm: 2.5567  loss: 0.2428  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2428\n",
            "02/09 11:27:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][120/166]  lr: 2.0000e-02  eta: 1:02:41  time: 0.2854  data_time: 0.0156  memory: 5737  grad_norm: 2.8543  loss: 0.2926  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2926\n",
            "02/09 11:28:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][140/166]  lr: 2.0000e-02  eta: 1:02:36  time: 0.2869  data_time: 0.0166  memory: 5737  grad_norm: 2.3688  loss: 0.2792  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2792\n",
            "02/09 11:28:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][160/166]  lr: 2.0000e-02  eta: 1:02:30  time: 0.2840  data_time: 0.0150  memory: 5737  grad_norm: 2.3120  loss: 0.2664  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2664\n",
            "02/09 11:28:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:28:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [72][166/166]  lr: 2.0000e-02  eta: 1:02:28  time: 0.2821  data_time: 0.0147  memory: 5737  grad_norm: 2.2578  loss: 0.2655  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.2655\n",
            "02/09 11:28:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 72 epochs\n",
            "02/09 11:28:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][ 20/166]  lr: 2.0000e-02  eta: 1:02:23  time: 0.3181  data_time: 0.0459  memory: 5737  grad_norm: 2.2992  loss: 0.2480  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2480\n",
            "02/09 11:28:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][ 40/166]  lr: 2.0000e-02  eta: 1:02:17  time: 0.2850  data_time: 0.0154  memory: 5737  grad_norm: 2.6855  loss: 0.2622  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2622\n",
            "02/09 11:28:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:28:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][ 60/166]  lr: 2.0000e-02  eta: 1:02:11  time: 0.2852  data_time: 0.0153  memory: 5737  grad_norm: 2.7341  loss: 0.2755  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2755\n",
            "02/09 11:28:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][ 80/166]  lr: 2.0000e-02  eta: 1:02:05  time: 0.2857  data_time: 0.0158  memory: 5737  grad_norm: 2.7382  loss: 0.3199  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3199\n",
            "02/09 11:28:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][100/166]  lr: 2.0000e-02  eta: 1:01:59  time: 0.2858  data_time: 0.0159  memory: 5737  grad_norm: 2.4128  loss: 0.2595  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2595\n",
            "02/09 11:28:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][120/166]  lr: 2.0000e-02  eta: 1:01:53  time: 0.2853  data_time: 0.0155  memory: 5737  grad_norm: 2.7977  loss: 0.3332  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.3332\n",
            "02/09 11:28:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][140/166]  lr: 2.0000e-02  eta: 1:01:47  time: 0.2861  data_time: 0.0160  memory: 5737  grad_norm: 2.5400  loss: 0.2974  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2974\n",
            "02/09 11:29:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][160/166]  lr: 2.0000e-02  eta: 1:01:42  time: 0.2839  data_time: 0.0150  memory: 5737  grad_norm: 2.0899  loss: 0.2303  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2303\n",
            "02/09 11:29:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:29:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [73][166/166]  lr: 2.0000e-02  eta: 1:01:40  time: 0.2817  data_time: 0.0146  memory: 5737  grad_norm: 2.3626  loss: 0.2507  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.2507\n",
            "02/09 11:29:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][ 20/166]  lr: 2.0000e-02  eta: 1:01:35  time: 0.3172  data_time: 0.0455  memory: 5737  grad_norm: 2.5885  loss: 0.2439  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2439\n",
            "02/09 11:29:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][ 40/166]  lr: 2.0000e-02  eta: 1:01:29  time: 0.2861  data_time: 0.0160  memory: 5737  grad_norm: 2.5849  loss: 0.3016  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3016\n",
            "02/09 11:29:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][ 60/166]  lr: 2.0000e-02  eta: 1:01:23  time: 0.2858  data_time: 0.0161  memory: 5737  grad_norm: 2.6539  loss: 0.3100  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3100\n",
            "02/09 11:29:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][ 80/166]  lr: 2.0000e-02  eta: 1:01:17  time: 0.2858  data_time: 0.0161  memory: 5737  grad_norm: 2.3143  loss: 0.2526  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2526\n",
            "02/09 11:29:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][100/166]  lr: 2.0000e-02  eta: 1:01:11  time: 0.2861  data_time: 0.0163  memory: 5737  grad_norm: 2.2309  loss: 0.2744  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2744\n",
            "02/09 11:29:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][120/166]  lr: 2.0000e-02  eta: 1:01:05  time: 0.2843  data_time: 0.0147  memory: 5737  grad_norm: 2.1449  loss: 0.2661  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2661\n",
            "02/09 11:29:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][140/166]  lr: 2.0000e-02  eta: 1:00:59  time: 0.2870  data_time: 0.0167  memory: 5737  grad_norm: 2.5871  loss: 0.3273  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3273\n",
            "02/09 11:29:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][160/166]  lr: 2.0000e-02  eta: 1:00:53  time: 0.2849  data_time: 0.0154  memory: 5737  grad_norm: 2.1279  loss: 0.2469  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2469\n",
            "02/09 11:29:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:29:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [74][166/166]  lr: 2.0000e-02  eta: 1:00:52  time: 0.2818  data_time: 0.0145  memory: 5737  grad_norm: 2.6385  loss: 0.3157  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.3157\n",
            "02/09 11:29:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][ 20/166]  lr: 2.0000e-02  eta: 1:00:46  time: 0.3201  data_time: 0.0487  memory: 5737  grad_norm: 1.8516  loss: 0.2056  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2056\n",
            "02/09 11:30:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][ 40/166]  lr: 2.0000e-02  eta: 1:00:41  time: 0.2855  data_time: 0.0157  memory: 5737  grad_norm: 2.5092  loss: 0.2870  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2870\n",
            "02/09 11:30:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][ 60/166]  lr: 2.0000e-02  eta: 1:00:35  time: 0.2866  data_time: 0.0166  memory: 5737  grad_norm: 2.3045  loss: 0.2555  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2555\n",
            "02/09 11:30:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][ 80/166]  lr: 2.0000e-02  eta: 1:00:29  time: 0.2860  data_time: 0.0166  memory: 5737  grad_norm: 1.7514  loss: 0.1731  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1731\n",
            "02/09 11:30:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][100/166]  lr: 2.0000e-02  eta: 1:00:23  time: 0.2863  data_time: 0.0160  memory: 5737  grad_norm: 2.6680  loss: 0.3062  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3062\n",
            "02/09 11:30:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][120/166]  lr: 2.0000e-02  eta: 1:00:17  time: 0.2854  data_time: 0.0161  memory: 5737  grad_norm: 2.4661  loss: 0.3066  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3066\n",
            "02/09 11:30:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][140/166]  lr: 2.0000e-02  eta: 1:00:11  time: 0.2859  data_time: 0.0160  memory: 5737  grad_norm: 2.5153  loss: 0.3001  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3001\n",
            "02/09 11:30:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][160/166]  lr: 2.0000e-02  eta: 1:00:05  time: 0.2848  data_time: 0.0154  memory: 5737  grad_norm: 2.4387  loss: 0.2499  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2499\n",
            "02/09 11:30:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:30:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [75][166/166]  lr: 2.0000e-02  eta: 1:00:04  time: 0.2818  data_time: 0.0142  memory: 5737  grad_norm: 2.3413  loss: 0.2440  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.2440\n",
            "02/09 11:30:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [75][20/21]    eta: 0:00:00  time: 0.1413  data_time: 0.0552  memory: 991  \n",
            "02/09 11:30:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [75][21/21]    acc/top1: 0.7319  acc/top5: 1.0000  acc/mean1: 0.7273  data_time: 0.0505  time: 0.1342\n",
            "02/09 11:30:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][ 20/166]  lr: 2.0000e-02  eta: 0:59:58  time: 0.3183  data_time: 0.0470  memory: 5737  grad_norm: 1.9897  loss: 0.2140  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2140\n",
            "02/09 11:30:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][ 40/166]  lr: 2.0000e-02  eta: 0:59:53  time: 0.2860  data_time: 0.0156  memory: 5737  grad_norm: 2.8480  loss: 0.2693  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2693\n",
            "02/09 11:30:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][ 60/166]  lr: 2.0000e-02  eta: 0:59:47  time: 0.2861  data_time: 0.0161  memory: 5737  grad_norm: 2.4255  loss: 0.2523  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2523\n",
            "02/09 11:31:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][ 80/166]  lr: 2.0000e-02  eta: 0:59:41  time: 0.2849  data_time: 0.0151  memory: 5737  grad_norm: 2.4571  loss: 0.2702  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2702\n",
            "02/09 11:31:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][100/166]  lr: 2.0000e-02  eta: 0:59:35  time: 0.2870  data_time: 0.0168  memory: 5737  grad_norm: 2.2558  loss: 0.2460  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2460\n",
            "02/09 11:31:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][120/166]  lr: 2.0000e-02  eta: 0:59:29  time: 0.2843  data_time: 0.0145  memory: 5737  grad_norm: 2.7445  loss: 0.2886  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2886\n",
            "02/09 11:31:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][140/166]  lr: 2.0000e-02  eta: 0:59:23  time: 0.2865  data_time: 0.0162  memory: 5737  grad_norm: 2.6984  loss: 0.2749  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2749\n",
            "02/09 11:31:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][160/166]  lr: 2.0000e-02  eta: 0:59:17  time: 0.2837  data_time: 0.0143  memory: 5737  grad_norm: 2.4389  loss: 0.2771  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2771\n",
            "02/09 11:31:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:31:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [76][166/166]  lr: 2.0000e-02  eta: 0:59:16  time: 0.2811  data_time: 0.0138  memory: 5737  grad_norm: 2.4298  loss: 0.2761  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.2761\n",
            "02/09 11:31:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 76 epochs\n",
            "02/09 11:31:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][ 20/166]  lr: 2.0000e-02  eta: 0:59:10  time: 0.3187  data_time: 0.0465  memory: 5737  grad_norm: 2.3856  loss: 0.2472  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2472\n",
            "02/09 11:31:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][ 40/166]  lr: 2.0000e-02  eta: 0:59:04  time: 0.2848  data_time: 0.0152  memory: 5737  grad_norm: 2.2496  loss: 0.2530  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2530\n",
            "02/09 11:31:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][ 60/166]  lr: 2.0000e-02  eta: 0:58:59  time: 0.2864  data_time: 0.0161  memory: 5737  grad_norm: 2.5086  loss: 0.3135  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3135\n",
            "02/09 11:31:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][ 80/166]  lr: 2.0000e-02  eta: 0:58:53  time: 0.2846  data_time: 0.0150  memory: 5737  grad_norm: 2.5387  loss: 0.2723  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2723\n",
            "02/09 11:31:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][100/166]  lr: 2.0000e-02  eta: 0:58:47  time: 0.2855  data_time: 0.0155  memory: 5737  grad_norm: 2.0946  loss: 0.2579  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2579\n",
            "02/09 11:32:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][120/166]  lr: 2.0000e-02  eta: 0:58:41  time: 0.2855  data_time: 0.0158  memory: 5737  grad_norm: 2.4740  loss: 0.2704  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2704\n",
            "02/09 11:32:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][140/166]  lr: 2.0000e-02  eta: 0:58:35  time: 0.2861  data_time: 0.0162  memory: 5737  grad_norm: 2.1133  loss: 0.2304  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2304\n",
            "02/09 11:32:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][160/166]  lr: 2.0000e-02  eta: 0:58:29  time: 0.2845  data_time: 0.0149  memory: 5737  grad_norm: 2.6443  loss: 0.2954  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2954\n",
            "02/09 11:32:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:32:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [77][166/166]  lr: 2.0000e-02  eta: 0:58:27  time: 0.2820  data_time: 0.0143  memory: 5737  grad_norm: 2.5815  loss: 0.3014  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.3014\n",
            "02/09 11:32:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][ 20/166]  lr: 2.0000e-02  eta: 0:58:22  time: 0.3184  data_time: 0.0463  memory: 5737  grad_norm: 2.2182  loss: 0.2542  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2542\n",
            "02/09 11:32:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][ 40/166]  lr: 2.0000e-02  eta: 0:58:16  time: 0.2850  data_time: 0.0153  memory: 5737  grad_norm: 2.0233  loss: 0.2441  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2441\n",
            "02/09 11:32:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][ 60/166]  lr: 2.0000e-02  eta: 0:58:10  time: 0.2851  data_time: 0.0153  memory: 5737  grad_norm: 2.0770  loss: 0.2118  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2118\n",
            "02/09 11:32:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][ 80/166]  lr: 2.0000e-02  eta: 0:58:05  time: 0.2856  data_time: 0.0152  memory: 5737  grad_norm: 2.1657  loss: 0.2331  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2331\n",
            "02/09 11:32:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][100/166]  lr: 2.0000e-02  eta: 0:57:59  time: 0.2872  data_time: 0.0166  memory: 5737  grad_norm: 2.5795  loss: 0.2999  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2999\n",
            "02/09 11:32:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][120/166]  lr: 2.0000e-02  eta: 0:57:53  time: 0.2846  data_time: 0.0148  memory: 5737  grad_norm: 2.0581  loss: 0.2146  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2146\n",
            "02/09 11:32:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][140/166]  lr: 2.0000e-02  eta: 0:57:47  time: 0.2862  data_time: 0.0159  memory: 5737  grad_norm: 2.8335  loss: 0.3019  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.3019\n",
            "02/09 11:33:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][160/166]  lr: 2.0000e-02  eta: 0:57:41  time: 0.2865  data_time: 0.0166  memory: 5737  grad_norm: 2.4367  loss: 0.2563  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2563\n",
            "02/09 11:33:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:33:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [78][166/166]  lr: 2.0000e-02  eta: 0:57:39  time: 0.2840  data_time: 0.0161  memory: 5737  grad_norm: 2.3714  loss: 0.2272  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.2272\n",
            "02/09 11:33:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][ 20/166]  lr: 2.0000e-02  eta: 0:57:34  time: 0.3180  data_time: 0.0470  memory: 5737  grad_norm: 2.0415  loss: 0.2278  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2278\n",
            "02/09 11:33:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][ 40/166]  lr: 2.0000e-02  eta: 0:57:28  time: 0.2852  data_time: 0.0153  memory: 5737  grad_norm: 2.3538  loss: 0.2502  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2502\n",
            "02/09 11:33:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:33:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][ 60/166]  lr: 2.0000e-02  eta: 0:57:22  time: 0.2858  data_time: 0.0158  memory: 5737  grad_norm: 2.1320  loss: 0.2263  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2263\n",
            "02/09 11:33:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][ 80/166]  lr: 2.0000e-02  eta: 0:57:16  time: 0.2848  data_time: 0.0149  memory: 5737  grad_norm: 2.6181  loss: 0.2820  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2820\n",
            "02/09 11:33:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][100/166]  lr: 2.0000e-02  eta: 0:57:11  time: 0.2865  data_time: 0.0162  memory: 5737  grad_norm: 2.4916  loss: 0.2608  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2608\n",
            "02/09 11:33:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][120/166]  lr: 2.0000e-02  eta: 0:57:05  time: 0.2860  data_time: 0.0157  memory: 5737  grad_norm: 2.6939  loss: 0.2771  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2771\n",
            "02/09 11:33:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][140/166]  lr: 2.0000e-02  eta: 0:56:59  time: 0.2858  data_time: 0.0155  memory: 5737  grad_norm: 2.4090  loss: 0.2768  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2768\n",
            "02/09 11:33:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][160/166]  lr: 2.0000e-02  eta: 0:56:53  time: 0.2843  data_time: 0.0150  memory: 5737  grad_norm: 2.2744  loss: 0.2370  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2370\n",
            "02/09 11:33:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:33:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [79][166/166]  lr: 2.0000e-02  eta: 0:56:51  time: 0.2811  data_time: 0.0138  memory: 5737  grad_norm: 2.7817  loss: 0.2903  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.2903\n",
            "02/09 11:33:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][ 20/166]  lr: 2.0000e-02  eta: 0:56:46  time: 0.3170  data_time: 0.0449  memory: 5737  grad_norm: 2.4532  loss: 0.2605  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2605\n",
            "02/09 11:34:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][ 40/166]  lr: 2.0000e-02  eta: 0:56:40  time: 0.2855  data_time: 0.0154  memory: 5737  grad_norm: 2.3373  loss: 0.2340  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.2340\n",
            "02/09 11:34:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][ 60/166]  lr: 2.0000e-02  eta: 0:56:34  time: 0.2859  data_time: 0.0160  memory: 5737  grad_norm: 2.4236  loss: 0.2645  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2645\n",
            "02/09 11:34:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][ 80/166]  lr: 2.0000e-02  eta: 0:56:28  time: 0.2854  data_time: 0.0153  memory: 5737  grad_norm: 2.3616  loss: 0.2386  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2386\n",
            "02/09 11:34:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][100/166]  lr: 2.0000e-02  eta: 0:56:22  time: 0.2854  data_time: 0.0155  memory: 5737  grad_norm: 2.3145  loss: 0.2420  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2420\n",
            "02/09 11:34:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][120/166]  lr: 2.0000e-02  eta: 0:56:17  time: 0.2855  data_time: 0.0155  memory: 5737  grad_norm: 2.6184  loss: 0.2803  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2803\n",
            "02/09 11:34:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][140/166]  lr: 2.0000e-02  eta: 0:56:11  time: 0.2848  data_time: 0.0150  memory: 5737  grad_norm: 2.2623  loss: 0.2471  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2471\n",
            "02/09 11:34:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][160/166]  lr: 2.0000e-02  eta: 0:56:05  time: 0.2842  data_time: 0.0147  memory: 5737  grad_norm: 2.6353  loss: 0.2534  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2534\n",
            "02/09 11:34:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:34:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [80][166/166]  lr: 2.0000e-02  eta: 0:56:03  time: 0.2810  data_time: 0.0134  memory: 5737  grad_norm: 2.6854  loss: 0.2599  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2599\n",
            "02/09 11:34:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 80 epochs\n",
            "02/09 11:34:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [80][20/21]    eta: 0:00:00  time: 0.1407  data_time: 0.0551  memory: 991  \n",
            "02/09 11:34:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [80][21/21]    acc/top1: 0.7500  acc/top5: 1.0000  acc/mean1: 0.7511  data_time: 0.0504  time: 0.1337\n",
            "02/09 11:34:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][ 20/166]  lr: 2.0000e-02  eta: 0:55:58  time: 0.3169  data_time: 0.0447  memory: 5737  grad_norm: 2.0739  loss: 0.1917  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1917\n",
            "02/09 11:34:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][ 40/166]  lr: 2.0000e-02  eta: 0:55:52  time: 0.2846  data_time: 0.0148  memory: 5737  grad_norm: 2.8184  loss: 0.2705  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2705\n",
            "02/09 11:35:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][ 60/166]  lr: 2.0000e-02  eta: 0:55:46  time: 0.2858  data_time: 0.0160  memory: 5737  grad_norm: 2.3696  loss: 0.2693  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2693\n",
            "02/09 11:35:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][ 80/166]  lr: 2.0000e-02  eta: 0:55:40  time: 0.2847  data_time: 0.0148  memory: 5737  grad_norm: 2.1403  loss: 0.2172  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2172\n",
            "02/09 11:35:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][100/166]  lr: 2.0000e-02  eta: 0:55:34  time: 0.2861  data_time: 0.0159  memory: 5737  grad_norm: 2.8437  loss: 0.2721  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2721\n",
            "02/09 11:35:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][120/166]  lr: 2.0000e-02  eta: 0:55:28  time: 0.2850  data_time: 0.0153  memory: 5737  grad_norm: 2.6983  loss: 0.2661  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2661\n",
            "02/09 11:35:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][140/166]  lr: 2.0000e-02  eta: 0:55:23  time: 0.2863  data_time: 0.0160  memory: 5737  grad_norm: 2.5440  loss: 0.2562  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2562\n",
            "02/09 11:35:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][160/166]  lr: 2.0000e-02  eta: 0:55:17  time: 0.2832  data_time: 0.0142  memory: 5737  grad_norm: 2.1372  loss: 0.2195  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2195\n",
            "02/09 11:35:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:35:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [81][166/166]  lr: 2.0000e-02  eta: 0:55:15  time: 0.2808  data_time: 0.0135  memory: 5737  grad_norm: 2.6525  loss: 0.2745  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.2745\n",
            "02/09 11:35:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][ 20/166]  lr: 2.0000e-02  eta: 0:55:10  time: 0.3179  data_time: 0.0465  memory: 5737  grad_norm: 2.0970  loss: 0.1966  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1966\n",
            "02/09 11:35:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][ 40/166]  lr: 2.0000e-02  eta: 0:55:04  time: 0.2858  data_time: 0.0157  memory: 5737  grad_norm: 2.3498  loss: 0.2512  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2512\n",
            "02/09 11:35:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][ 60/166]  lr: 2.0000e-02  eta: 0:54:58  time: 0.2870  data_time: 0.0166  memory: 5737  grad_norm: 2.4390  loss: 0.2580  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2580\n",
            "02/09 11:35:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][ 80/166]  lr: 2.0000e-02  eta: 0:54:52  time: 0.2851  data_time: 0.0153  memory: 5737  grad_norm: 2.3938  loss: 0.2623  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2623\n",
            "02/09 11:36:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][100/166]  lr: 2.0000e-02  eta: 0:54:46  time: 0.2860  data_time: 0.0158  memory: 5737  grad_norm: 2.1827  loss: 0.2244  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2244\n",
            "02/09 11:36:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][120/166]  lr: 2.0000e-02  eta: 0:54:40  time: 0.2852  data_time: 0.0155  memory: 5737  grad_norm: 2.3806  loss: 0.2679  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.2679\n",
            "02/09 11:36:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][140/166]  lr: 2.0000e-02  eta: 0:54:34  time: 0.2863  data_time: 0.0161  memory: 5737  grad_norm: 2.0637  loss: 0.2469  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2469\n",
            "02/09 11:36:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][160/166]  lr: 2.0000e-02  eta: 0:54:29  time: 0.2843  data_time: 0.0150  memory: 5737  grad_norm: 1.8975  loss: 0.1839  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1839\n",
            "02/09 11:36:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:36:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [82][166/166]  lr: 2.0000e-02  eta: 0:54:27  time: 0.2819  data_time: 0.0144  memory: 5737  grad_norm: 2.1209  loss: 0.2187  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.2187\n",
            "02/09 11:36:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][ 20/166]  lr: 2.0000e-02  eta: 0:54:21  time: 0.3156  data_time: 0.0436  memory: 5737  grad_norm: 2.5748  loss: 0.2697  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2697\n",
            "02/09 11:36:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][ 40/166]  lr: 2.0000e-02  eta: 0:54:16  time: 0.2850  data_time: 0.0152  memory: 5737  grad_norm: 2.4221  loss: 0.2815  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2815\n",
            "02/09 11:36:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][ 60/166]  lr: 2.0000e-02  eta: 0:54:10  time: 0.2853  data_time: 0.0152  memory: 5737  grad_norm: 2.3168  loss: 0.2429  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2429\n",
            "02/09 11:36:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][ 80/166]  lr: 2.0000e-02  eta: 0:54:04  time: 0.2856  data_time: 0.0156  memory: 5737  grad_norm: 2.8589  loss: 0.2442  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2442\n",
            "02/09 11:36:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][100/166]  lr: 2.0000e-02  eta: 0:53:58  time: 0.2869  data_time: 0.0165  memory: 5737  grad_norm: 2.6427  loss: 0.2618  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2618\n",
            "02/09 11:36:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][120/166]  lr: 2.0000e-02  eta: 0:53:52  time: 0.2853  data_time: 0.0155  memory: 5737  grad_norm: 2.4342  loss: 0.2934  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2934\n",
            "02/09 11:37:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][140/166]  lr: 2.0000e-02  eta: 0:53:46  time: 0.2862  data_time: 0.0159  memory: 5737  grad_norm: 2.4716  loss: 0.2689  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2689\n",
            "02/09 11:37:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][160/166]  lr: 2.0000e-02  eta: 0:53:40  time: 0.2841  data_time: 0.0149  memory: 5737  grad_norm: 2.3586  loss: 0.2547  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2547\n",
            "02/09 11:37:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:37:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [83][166/166]  lr: 2.0000e-02  eta: 0:53:39  time: 0.2812  data_time: 0.0139  memory: 5737  grad_norm: 2.3569  loss: 0.2675  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.2675\n",
            "02/09 11:37:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][ 20/166]  lr: 2.0000e-02  eta: 0:53:33  time: 0.3177  data_time: 0.0458  memory: 5737  grad_norm: 2.4172  loss: 0.2365  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2365\n",
            "02/09 11:37:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][ 40/166]  lr: 2.0000e-02  eta: 0:53:27  time: 0.2854  data_time: 0.0154  memory: 5737  grad_norm: 2.1899  loss: 0.2203  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2203\n",
            "02/09 11:37:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][ 60/166]  lr: 2.0000e-02  eta: 0:53:22  time: 0.2865  data_time: 0.0162  memory: 5737  grad_norm: 2.5541  loss: 0.2576  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2576\n",
            "02/09 11:37:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][ 80/166]  lr: 2.0000e-02  eta: 0:53:16  time: 0.2864  data_time: 0.0160  memory: 5737  grad_norm: 2.3957  loss: 0.1988  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1988\n",
            "02/09 11:37:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][100/166]  lr: 2.0000e-02  eta: 0:53:10  time: 0.2860  data_time: 0.0157  memory: 5737  grad_norm: 2.4797  loss: 0.2410  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2410\n",
            "02/09 11:37:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][120/166]  lr: 2.0000e-02  eta: 0:53:04  time: 0.2860  data_time: 0.0157  memory: 5737  grad_norm: 2.7514  loss: 0.2916  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2916\n",
            "02/09 11:37:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][140/166]  lr: 2.0000e-02  eta: 0:52:58  time: 0.2865  data_time: 0.0163  memory: 5737  grad_norm: 2.4220  loss: 0.2430  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2430\n",
            "02/09 11:37:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][160/166]  lr: 2.0000e-02  eta: 0:52:52  time: 0.2844  data_time: 0.0147  memory: 5737  grad_norm: 2.4185  loss: 0.2620  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2620\n",
            "02/09 11:37:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:37:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [84][166/166]  lr: 2.0000e-02  eta: 0:52:51  time: 0.2808  data_time: 0.0135  memory: 5737  grad_norm: 2.0776  loss: 0.2153  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.2153\n",
            "02/09 11:37:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 84 epochs\n",
            "02/09 11:38:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][ 20/166]  lr: 2.0000e-02  eta: 0:52:45  time: 0.3187  data_time: 0.0473  memory: 5737  grad_norm: 2.2782  loss: 0.2113  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2113\n",
            "02/09 11:38:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][ 40/166]  lr: 2.0000e-02  eta: 0:52:39  time: 0.2848  data_time: 0.0148  memory: 5737  grad_norm: 2.0421  loss: 0.1899  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1899\n",
            "02/09 11:38:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:38:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][ 60/166]  lr: 2.0000e-02  eta: 0:52:34  time: 0.2866  data_time: 0.0165  memory: 5737  grad_norm: 2.3924  loss: 0.2101  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2101\n",
            "02/09 11:38:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][ 80/166]  lr: 2.0000e-02  eta: 0:52:28  time: 0.2860  data_time: 0.0163  memory: 5737  grad_norm: 2.6630  loss: 0.2621  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2621\n",
            "02/09 11:38:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][100/166]  lr: 2.0000e-02  eta: 0:52:22  time: 0.2864  data_time: 0.0161  memory: 5737  grad_norm: 2.6251  loss: 0.2696  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2696\n",
            "02/09 11:38:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][120/166]  lr: 2.0000e-02  eta: 0:52:16  time: 0.2858  data_time: 0.0153  memory: 5737  grad_norm: 2.6649  loss: 0.2875  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2875\n",
            "02/09 11:38:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][140/166]  lr: 2.0000e-02  eta: 0:52:10  time: 0.2855  data_time: 0.0157  memory: 5737  grad_norm: 2.2728  loss: 0.2560  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2560\n",
            "02/09 11:38:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][160/166]  lr: 2.0000e-02  eta: 0:52:04  time: 0.2850  data_time: 0.0153  memory: 5737  grad_norm: 2.7637  loss: 0.3125  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3125\n",
            "02/09 11:38:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:38:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [85][166/166]  lr: 2.0000e-02  eta: 0:52:03  time: 0.2820  data_time: 0.0143  memory: 5737  grad_norm: 2.5225  loss: 0.2890  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.2890\n",
            "02/09 11:38:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [85][20/21]    eta: 0:00:00  time: 0.1412  data_time: 0.0556  memory: 991  \n",
            "02/09 11:38:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [85][21/21]    acc/top1: 0.7620  acc/top5: 1.0000  acc/mean1: 0.7540  data_time: 0.0509  time: 0.1341\n",
            "02/09 11:38:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][ 20/166]  lr: 2.0000e-02  eta: 0:51:57  time: 0.3155  data_time: 0.0433  memory: 5737  grad_norm: 2.6284  loss: 0.2812  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2812\n",
            "02/09 11:39:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][ 40/166]  lr: 2.0000e-02  eta: 0:51:51  time: 0.2853  data_time: 0.0159  memory: 5737  grad_norm: 2.1950  loss: 0.2309  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2309\n",
            "02/09 11:39:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][ 60/166]  lr: 2.0000e-02  eta: 0:51:46  time: 0.2871  data_time: 0.0169  memory: 5737  grad_norm: 2.6451  loss: 0.2458  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2458\n",
            "02/09 11:39:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][ 80/166]  lr: 2.0000e-02  eta: 0:51:40  time: 0.2847  data_time: 0.0156  memory: 5737  grad_norm: 2.7154  loss: 0.2438  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2438\n",
            "02/09 11:39:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][100/166]  lr: 2.0000e-02  eta: 0:51:34  time: 0.2862  data_time: 0.0159  memory: 5737  grad_norm: 2.4332  loss: 0.2360  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2360\n",
            "02/09 11:39:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][120/166]  lr: 2.0000e-02  eta: 0:51:28  time: 0.2845  data_time: 0.0149  memory: 5737  grad_norm: 2.7084  loss: 0.3166  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3166\n",
            "02/09 11:39:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][140/166]  lr: 2.0000e-02  eta: 0:51:22  time: 0.2858  data_time: 0.0157  memory: 5737  grad_norm: 2.1972  loss: 0.2421  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2421\n",
            "02/09 11:39:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][160/166]  lr: 2.0000e-02  eta: 0:51:16  time: 0.2842  data_time: 0.0150  memory: 5737  grad_norm: 2.1513  loss: 0.2601  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2601\n",
            "02/09 11:39:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:39:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [86][166/166]  lr: 2.0000e-02  eta: 0:51:14  time: 0.2822  data_time: 0.0147  memory: 5737  grad_norm: 2.3525  loss: 0.2703  top1_acc: 0.7143  top5_acc: 1.0000  loss_cls: 0.2703\n",
            "02/09 11:39:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][ 20/166]  lr: 2.0000e-02  eta: 0:51:09  time: 0.3247  data_time: 0.0534  memory: 5737  grad_norm: 2.1117  loss: 0.2211  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2211\n",
            "02/09 11:39:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][ 40/166]  lr: 2.0000e-02  eta: 0:51:03  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 2.2874  loss: 0.2221  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2221\n",
            "02/09 11:39:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][ 60/166]  lr: 2.0000e-02  eta: 0:50:58  time: 0.2867  data_time: 0.0162  memory: 5737  grad_norm: 2.3596  loss: 0.2593  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.2593\n",
            "02/09 11:40:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][ 80/166]  lr: 2.0000e-02  eta: 0:50:52  time: 0.2851  data_time: 0.0154  memory: 5737  grad_norm: 2.2070  loss: 0.2287  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2287\n",
            "02/09 11:40:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][100/166]  lr: 2.0000e-02  eta: 0:50:46  time: 0.2867  data_time: 0.0162  memory: 5737  grad_norm: 1.8581  loss: 0.1764  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1764\n",
            "02/09 11:40:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][120/166]  lr: 2.0000e-02  eta: 0:50:40  time: 0.2856  data_time: 0.0158  memory: 5737  grad_norm: 3.3922  loss: 0.2592  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2592\n",
            "02/09 11:40:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][140/166]  lr: 2.0000e-02  eta: 0:50:34  time: 0.2867  data_time: 0.0165  memory: 5737  grad_norm: 2.6580  loss: 0.2664  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2664\n",
            "02/09 11:40:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][160/166]  lr: 2.0000e-02  eta: 0:50:28  time: 0.2847  data_time: 0.0154  memory: 5737  grad_norm: 2.4736  loss: 0.2433  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2433\n",
            "02/09 11:40:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:40:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [87][166/166]  lr: 2.0000e-02  eta: 0:50:27  time: 0.2821  data_time: 0.0146  memory: 5737  grad_norm: 2.9099  loss: 0.3003  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.3003\n",
            "02/09 11:40:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][ 20/166]  lr: 2.0000e-02  eta: 0:50:21  time: 0.3090  data_time: 0.0382  memory: 5737  grad_norm: 2.6384  loss: 0.3345  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3345\n",
            "02/09 11:40:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][ 40/166]  lr: 2.0000e-02  eta: 0:50:15  time: 0.2845  data_time: 0.0147  memory: 5737  grad_norm: 1.8973  loss: 0.2330  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2330\n",
            "02/09 11:40:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][ 60/166]  lr: 2.0000e-02  eta: 0:50:09  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 2.0378  loss: 0.2053  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2053\n",
            "02/09 11:40:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][ 80/166]  lr: 2.0000e-02  eta: 0:50:03  time: 0.2856  data_time: 0.0158  memory: 5737  grad_norm: 2.1219  loss: 0.2090  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2090\n",
            "02/09 11:40:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][100/166]  lr: 2.0000e-02  eta: 0:49:58  time: 0.2870  data_time: 0.0164  memory: 5737  grad_norm: 2.6728  loss: 0.2890  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2890\n",
            "02/09 11:40:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][120/166]  lr: 2.0000e-02  eta: 0:49:52  time: 0.2853  data_time: 0.0156  memory: 5737  grad_norm: 3.3481  loss: 0.3478  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.3478\n",
            "02/09 11:41:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][140/166]  lr: 2.0000e-02  eta: 0:49:46  time: 0.2869  data_time: 0.0164  memory: 5737  grad_norm: 2.3503  loss: 0.2864  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2864\n",
            "02/09 11:41:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][160/166]  lr: 2.0000e-02  eta: 0:49:40  time: 0.2842  data_time: 0.0146  memory: 5737  grad_norm: 2.1665  loss: 0.2712  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2712\n",
            "02/09 11:41:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:41:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [88][166/166]  lr: 2.0000e-02  eta: 0:49:38  time: 0.2811  data_time: 0.0137  memory: 5737  grad_norm: 2.1246  loss: 0.2507  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2507\n",
            "02/09 11:41:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 88 epochs\n",
            "02/09 11:41:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][ 20/166]  lr: 2.0000e-02  eta: 0:49:33  time: 0.3198  data_time: 0.0470  memory: 5737  grad_norm: 2.3359  loss: 0.2504  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2504\n",
            "02/09 11:41:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][ 40/166]  lr: 2.0000e-02  eta: 0:49:27  time: 0.2859  data_time: 0.0161  memory: 5737  grad_norm: 2.2008  loss: 0.2312  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2312\n",
            "02/09 11:41:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][ 60/166]  lr: 2.0000e-02  eta: 0:49:21  time: 0.2857  data_time: 0.0158  memory: 5737  grad_norm: 2.6045  loss: 0.2605  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2605\n",
            "02/09 11:41:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][ 80/166]  lr: 2.0000e-02  eta: 0:49:15  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 1.7816  loss: 0.2037  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2037\n",
            "02/09 11:41:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][100/166]  lr: 2.0000e-02  eta: 0:49:10  time: 0.2864  data_time: 0.0163  memory: 5737  grad_norm: 2.2638  loss: 0.2122  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2122\n",
            "02/09 11:41:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][120/166]  lr: 2.0000e-02  eta: 0:49:04  time: 0.2847  data_time: 0.0150  memory: 5737  grad_norm: 2.1539  loss: 0.2094  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2094\n",
            "02/09 11:41:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][140/166]  lr: 2.0000e-02  eta: 0:48:58  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 2.3964  loss: 0.2704  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2704\n",
            "02/09 11:42:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][160/166]  lr: 2.0000e-02  eta: 0:48:52  time: 0.2845  data_time: 0.0153  memory: 5737  grad_norm: 2.3308  loss: 0.2197  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.2197\n",
            "02/09 11:42:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:42:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [89][166/166]  lr: 2.0000e-02  eta: 0:48:50  time: 0.2816  data_time: 0.0142  memory: 5737  grad_norm: 2.1613  loss: 0.2111  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.2111\n",
            "02/09 11:42:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][ 20/166]  lr: 2.0000e-02  eta: 0:48:45  time: 0.3180  data_time: 0.0464  memory: 5737  grad_norm: 2.4753  loss: 0.2165  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2165\n",
            "02/09 11:42:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][ 40/166]  lr: 2.0000e-02  eta: 0:48:39  time: 0.2846  data_time: 0.0150  memory: 5737  grad_norm: 2.4627  loss: 0.2119  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2119\n",
            "02/09 11:42:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][ 60/166]  lr: 2.0000e-02  eta: 0:48:33  time: 0.2870  data_time: 0.0166  memory: 5737  grad_norm: 2.3762  loss: 0.2145  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2145\n",
            "02/09 11:42:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][ 80/166]  lr: 2.0000e-02  eta: 0:48:27  time: 0.2860  data_time: 0.0161  memory: 5737  grad_norm: 2.4266  loss: 0.2243  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2243\n",
            "02/09 11:42:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][100/166]  lr: 2.0000e-02  eta: 0:48:22  time: 0.2857  data_time: 0.0159  memory: 5737  grad_norm: 2.6009  loss: 0.2310  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2310\n",
            "02/09 11:42:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][120/166]  lr: 2.0000e-02  eta: 0:48:16  time: 0.2848  data_time: 0.0151  memory: 5737  grad_norm: 2.4454  loss: 0.2035  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2035\n",
            "02/09 11:42:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][140/166]  lr: 2.0000e-02  eta: 0:48:10  time: 0.2855  data_time: 0.0154  memory: 5737  grad_norm: 2.6991  loss: 0.3031  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.3031\n",
            "02/09 11:42:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][160/166]  lr: 2.0000e-02  eta: 0:48:04  time: 0.2839  data_time: 0.0147  memory: 5737  grad_norm: 2.1522  loss: 0.2301  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2301\n",
            "02/09 11:42:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:42:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [90][166/166]  lr: 2.0000e-02  eta: 0:48:02  time: 0.2810  data_time: 0.0135  memory: 5737  grad_norm: 2.0597  loss: 0.2181  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2181\n",
            "02/09 11:42:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [90][20/21]    eta: 0:00:00  time: 0.1393  data_time: 0.0542  memory: 991  \n",
            "02/09 11:42:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [90][21/21]    acc/top1: 0.7620  acc/top5: 1.0000  acc/mean1: 0.7604  data_time: 0.0496  time: 0.1324\n",
            "02/09 11:42:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][ 20/166]  lr: 2.0000e-02  eta: 0:47:57  time: 0.3198  data_time: 0.0476  memory: 5737  grad_norm: 2.4055  loss: 0.2694  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2694\n",
            "02/09 11:43:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][ 40/166]  lr: 2.0000e-02  eta: 0:47:51  time: 0.2862  data_time: 0.0164  memory: 5737  grad_norm: 2.1478  loss: 0.2217  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2217\n",
            "02/09 11:43:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:43:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][ 60/166]  lr: 2.0000e-02  eta: 0:47:45  time: 0.2860  data_time: 0.0156  memory: 5737  grad_norm: 2.3090  loss: 0.2336  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2336\n",
            "02/09 11:43:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][ 80/166]  lr: 2.0000e-02  eta: 0:47:39  time: 0.2848  data_time: 0.0151  memory: 5737  grad_norm: 2.5196  loss: 0.2105  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2105\n",
            "02/09 11:43:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][100/166]  lr: 2.0000e-02  eta: 0:47:33  time: 0.2866  data_time: 0.0166  memory: 5737  grad_norm: 2.5289  loss: 0.2396  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2396\n",
            "02/09 11:43:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][120/166]  lr: 2.0000e-02  eta: 0:47:28  time: 0.2845  data_time: 0.0148  memory: 5737  grad_norm: 2.5627  loss: 0.2391  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2391\n",
            "02/09 11:43:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][140/166]  lr: 2.0000e-02  eta: 0:47:22  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 2.6267  loss: 0.2362  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2362\n",
            "02/09 11:43:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][160/166]  lr: 2.0000e-02  eta: 0:47:16  time: 0.2846  data_time: 0.0153  memory: 5737  grad_norm: 2.5167  loss: 0.2147  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2147\n",
            "02/09 11:43:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:43:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [91][166/166]  lr: 2.0000e-02  eta: 0:47:14  time: 0.2823  data_time: 0.0149  memory: 5737  grad_norm: 2.8674  loss: 0.2672  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.2672\n",
            "02/09 11:43:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][ 20/166]  lr: 2.0000e-02  eta: 0:47:09  time: 0.3181  data_time: 0.0459  memory: 5737  grad_norm: 2.1710  loss: 0.2169  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2169\n",
            "02/09 11:43:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][ 40/166]  lr: 2.0000e-02  eta: 0:47:03  time: 0.2849  data_time: 0.0156  memory: 5737  grad_norm: 2.3363  loss: 0.2357  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2357\n",
            "02/09 11:43:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][ 60/166]  lr: 2.0000e-02  eta: 0:46:57  time: 0.2862  data_time: 0.0162  memory: 5737  grad_norm: 2.0156  loss: 0.1617  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1617\n",
            "02/09 11:44:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][ 80/166]  lr: 2.0000e-02  eta: 0:46:51  time: 0.2866  data_time: 0.0163  memory: 5737  grad_norm: 2.1363  loss: 0.1984  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1984\n",
            "02/09 11:44:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][100/166]  lr: 2.0000e-02  eta: 0:46:45  time: 0.2870  data_time: 0.0166  memory: 5737  grad_norm: 2.5638  loss: 0.2638  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2638\n",
            "02/09 11:44:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][120/166]  lr: 2.0000e-02  eta: 0:46:40  time: 0.2862  data_time: 0.0162  memory: 5737  grad_norm: 2.4115  loss: 0.2681  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2681\n",
            "02/09 11:44:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][140/166]  lr: 2.0000e-02  eta: 0:46:34  time: 0.2878  data_time: 0.0170  memory: 5737  grad_norm: 2.1076  loss: 0.2513  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2513\n",
            "02/09 11:44:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][160/166]  lr: 2.0000e-02  eta: 0:46:28  time: 0.2839  data_time: 0.0148  memory: 5737  grad_norm: 1.9214  loss: 0.2234  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2234\n",
            "02/09 11:44:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:44:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [92][166/166]  lr: 2.0000e-02  eta: 0:46:26  time: 0.2819  data_time: 0.0143  memory: 5737  grad_norm: 1.8945  loss: 0.1955  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.1955\n",
            "02/09 11:44:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 92 epochs\n",
            "02/09 11:44:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][ 20/166]  lr: 2.0000e-02  eta: 0:46:21  time: 0.3180  data_time: 0.0466  memory: 5737  grad_norm: 2.1880  loss: 0.2167  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2167\n",
            "02/09 11:44:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][ 40/166]  lr: 2.0000e-02  eta: 0:46:15  time: 0.2852  data_time: 0.0156  memory: 5737  grad_norm: 2.2871  loss: 0.2184  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2184\n",
            "02/09 11:44:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][ 60/166]  lr: 2.0000e-02  eta: 0:46:09  time: 0.2868  data_time: 0.0166  memory: 5737  grad_norm: 2.3059  loss: 0.2145  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2145\n",
            "02/09 11:44:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][ 80/166]  lr: 2.0000e-02  eta: 0:46:03  time: 0.2861  data_time: 0.0162  memory: 5737  grad_norm: 2.3560  loss: 0.2202  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2202\n",
            "02/09 11:44:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][100/166]  lr: 2.0000e-02  eta: 0:45:57  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 2.2547  loss: 0.2116  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2116\n",
            "02/09 11:45:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][120/166]  lr: 2.0000e-02  eta: 0:45:52  time: 0.2855  data_time: 0.0155  memory: 5737  grad_norm: 2.3543  loss: 0.2381  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2381\n",
            "02/09 11:45:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][140/166]  lr: 2.0000e-02  eta: 0:45:46  time: 0.2875  data_time: 0.0172  memory: 5737  grad_norm: 2.2192  loss: 0.2184  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2184\n",
            "02/09 11:45:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][160/166]  lr: 2.0000e-02  eta: 0:45:40  time: 0.2853  data_time: 0.0158  memory: 5737  grad_norm: 1.7226  loss: 0.1767  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1767\n",
            "02/09 11:45:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:45:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [93][166/166]  lr: 2.0000e-02  eta: 0:45:38  time: 0.2828  data_time: 0.0151  memory: 5737  grad_norm: 1.8447  loss: 0.1791  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.1791\n",
            "02/09 11:45:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][ 20/166]  lr: 2.0000e-02  eta: 0:45:33  time: 0.3176  data_time: 0.0457  memory: 5737  grad_norm: 2.5373  loss: 0.2007  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2007\n",
            "02/09 11:45:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][ 40/166]  lr: 2.0000e-02  eta: 0:45:27  time: 0.2853  data_time: 0.0153  memory: 5737  grad_norm: 2.0382  loss: 0.2100  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2100\n",
            "02/09 11:45:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][ 60/166]  lr: 2.0000e-02  eta: 0:45:21  time: 0.2856  data_time: 0.0158  memory: 5737  grad_norm: 2.4679  loss: 0.2659  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2659\n",
            "02/09 11:45:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][ 80/166]  lr: 2.0000e-02  eta: 0:45:15  time: 0.2851  data_time: 0.0155  memory: 5737  grad_norm: 2.0153  loss: 0.1989  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1989\n",
            "02/09 11:45:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][100/166]  lr: 2.0000e-02  eta: 0:45:09  time: 0.2865  data_time: 0.0166  memory: 5737  grad_norm: 2.2523  loss: 0.2161  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2161\n",
            "02/09 11:45:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][120/166]  lr: 2.0000e-02  eta: 0:45:03  time: 0.2847  data_time: 0.0148  memory: 5737  grad_norm: 2.7288  loss: 0.2340  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.2340\n",
            "02/09 11:45:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][140/166]  lr: 2.0000e-02  eta: 0:44:58  time: 0.2864  data_time: 0.0161  memory: 5737  grad_norm: 2.1472  loss: 0.1977  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.1977\n",
            "02/09 11:46:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][160/166]  lr: 2.0000e-02  eta: 0:44:52  time: 0.2857  data_time: 0.0161  memory: 5737  grad_norm: 2.7689  loss: 0.2752  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2752\n",
            "02/09 11:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:46:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [94][166/166]  lr: 2.0000e-02  eta: 0:44:50  time: 0.2835  data_time: 0.0156  memory: 5737  grad_norm: 2.3397  loss: 0.2599  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.2599\n",
            "02/09 11:46:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][ 20/166]  lr: 2.0000e-02  eta: 0:44:45  time: 0.3160  data_time: 0.0445  memory: 5737  grad_norm: 1.9522  loss: 0.2032  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.2032\n",
            "02/09 11:46:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][ 40/166]  lr: 2.0000e-02  eta: 0:44:39  time: 0.2854  data_time: 0.0155  memory: 5737  grad_norm: 2.3849  loss: 0.2254  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2254\n",
            "02/09 11:46:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][ 60/166]  lr: 2.0000e-02  eta: 0:44:33  time: 0.2863  data_time: 0.0163  memory: 5737  grad_norm: 2.0652  loss: 0.2015  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2015\n",
            "02/09 11:46:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][ 80/166]  lr: 2.0000e-02  eta: 0:44:27  time: 0.2857  data_time: 0.0161  memory: 5737  grad_norm: 1.9846  loss: 0.2114  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2114\n",
            "02/09 11:46:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][100/166]  lr: 2.0000e-02  eta: 0:44:21  time: 0.2865  data_time: 0.0161  memory: 5737  grad_norm: 2.6222  loss: 0.2417  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2417\n",
            "02/09 11:46:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][120/166]  lr: 2.0000e-02  eta: 0:44:15  time: 0.2865  data_time: 0.0161  memory: 5737  grad_norm: 2.9072  loss: 0.3177  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.3177\n",
            "02/09 11:46:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][140/166]  lr: 2.0000e-02  eta: 0:44:10  time: 0.2865  data_time: 0.0163  memory: 5737  grad_norm: 2.6104  loss: 0.2862  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2862\n",
            "02/09 11:46:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][160/166]  lr: 2.0000e-02  eta: 0:44:04  time: 0.2857  data_time: 0.0158  memory: 5737  grad_norm: 2.1478  loss: 0.2357  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2357\n",
            "02/09 11:46:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:46:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [95][166/166]  lr: 2.0000e-02  eta: 0:44:02  time: 0.2822  data_time: 0.0144  memory: 5737  grad_norm: 2.1257  loss: 0.2417  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.2417\n",
            "02/09 11:46:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val)  [95][20/21]    eta: 0:00:00  time: 0.1403  data_time: 0.0540  memory: 991  \n",
            "02/09 11:46:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [95][21/21]    acc/top1: 0.7892  acc/top5: 1.0000  acc/mean1: 0.7846  data_time: 0.0494  time: 0.1333\n",
            "02/09 11:46:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The previous best checkpoint /content/mmaction2/work_dirs/no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb/best_acc_top1_epoch_70.pth is removed\n",
            "02/09 11:46:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - The best checkpoint with 0.7892 acc/top1 at 95 epoch is saved to best_acc_top1_epoch_95.pth.\n",
            "02/09 11:47:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][ 20/166]  lr: 2.0000e-02  eta: 0:43:57  time: 0.3229  data_time: 0.0507  memory: 5737  grad_norm: 2.0388  loss: 0.1681  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1681\n",
            "02/09 11:47:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][ 40/166]  lr: 2.0000e-02  eta: 0:43:51  time: 0.2860  data_time: 0.0161  memory: 5737  grad_norm: 2.5239  loss: 0.2220  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2220\n",
            "02/09 11:47:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][ 60/166]  lr: 2.0000e-02  eta: 0:43:45  time: 0.2857  data_time: 0.0157  memory: 5737  grad_norm: 2.4697  loss: 0.2153  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2153\n",
            "02/09 11:47:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][ 80/166]  lr: 2.0000e-02  eta: 0:43:39  time: 0.2846  data_time: 0.0153  memory: 5737  grad_norm: 2.4929  loss: 0.2302  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2302\n",
            "02/09 11:47:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][100/166]  lr: 2.0000e-02  eta: 0:43:33  time: 0.2852  data_time: 0.0154  memory: 5737  grad_norm: 2.6374  loss: 0.2611  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2611\n",
            "02/09 11:47:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][120/166]  lr: 2.0000e-02  eta: 0:43:27  time: 0.2852  data_time: 0.0156  memory: 5737  grad_norm: 2.3238  loss: 0.2795  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2795\n",
            "02/09 11:47:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][140/166]  lr: 2.0000e-02  eta: 0:43:22  time: 0.2871  data_time: 0.0168  memory: 5737  grad_norm: 1.8167  loss: 0.1945  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1945\n",
            "02/09 11:47:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][160/166]  lr: 2.0000e-02  eta: 0:43:16  time: 0.2841  data_time: 0.0148  memory: 5737  grad_norm: 2.3854  loss: 0.2451  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2451\n",
            "02/09 11:47:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:47:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [96][166/166]  lr: 2.0000e-02  eta: 0:43:14  time: 0.2811  data_time: 0.0136  memory: 5737  grad_norm: 2.3295  loss: 0.2547  top1_acc: 0.6429  top5_acc: 1.0000  loss_cls: 0.2547\n",
            "02/09 11:47:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 96 epochs\n",
            "02/09 11:47:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][ 20/166]  lr: 2.0000e-02  eta: 0:43:08  time: 0.3188  data_time: 0.0457  memory: 5737  grad_norm: 2.0422  loss: 0.1720  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1720\n",
            "02/09 11:47:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][ 40/166]  lr: 2.0000e-02  eta: 0:43:03  time: 0.2855  data_time: 0.0162  memory: 5737  grad_norm: 2.6526  loss: 0.2273  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2273\n",
            "02/09 11:48:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][ 60/166]  lr: 2.0000e-02  eta: 0:42:57  time: 0.2868  data_time: 0.0165  memory: 5737  grad_norm: 2.3662  loss: 0.2350  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2350\n",
            "02/09 11:48:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:48:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][ 80/166]  lr: 2.0000e-02  eta: 0:42:51  time: 0.2848  data_time: 0.0149  memory: 5737  grad_norm: 2.4269  loss: 0.2371  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2371\n",
            "02/09 11:48:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][100/166]  lr: 2.0000e-02  eta: 0:42:45  time: 0.2865  data_time: 0.0158  memory: 5737  grad_norm: 2.2195  loss: 0.2347  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2347\n",
            "02/09 11:48:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][120/166]  lr: 2.0000e-02  eta: 0:42:39  time: 0.2856  data_time: 0.0159  memory: 5737  grad_norm: 2.5420  loss: 0.2105  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2105\n",
            "02/09 11:48:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][140/166]  lr: 2.0000e-02  eta: 0:42:34  time: 0.2863  data_time: 0.0160  memory: 5737  grad_norm: 2.5847  loss: 0.2255  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2255\n",
            "02/09 11:48:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][160/166]  lr: 2.0000e-02  eta: 0:42:28  time: 0.2844  data_time: 0.0151  memory: 5737  grad_norm: 2.7323  loss: 0.2554  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2554\n",
            "02/09 11:48:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:48:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [97][166/166]  lr: 2.0000e-02  eta: 0:42:26  time: 0.2824  data_time: 0.0147  memory: 5737  grad_norm: 3.1430  loss: 0.2842  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.2842\n",
            "02/09 11:48:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][ 20/166]  lr: 2.0000e-02  eta: 0:42:20  time: 0.3222  data_time: 0.0503  memory: 5737  grad_norm: 2.4065  loss: 0.2442  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2442\n",
            "02/09 11:48:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][ 40/166]  lr: 2.0000e-02  eta: 0:42:15  time: 0.2859  data_time: 0.0161  memory: 5737  grad_norm: 2.0999  loss: 0.2089  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2089\n",
            "02/09 11:48:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][ 60/166]  lr: 2.0000e-02  eta: 0:42:09  time: 0.2868  data_time: 0.0169  memory: 5737  grad_norm: 2.0803  loss: 0.2007  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2007\n",
            "02/09 11:48:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][ 80/166]  lr: 2.0000e-02  eta: 0:42:03  time: 0.2851  data_time: 0.0154  memory: 5737  grad_norm: 2.0621  loss: 0.1664  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1664\n",
            "02/09 11:49:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][100/166]  lr: 2.0000e-02  eta: 0:41:57  time: 0.2875  data_time: 0.0169  memory: 5737  grad_norm: 2.8802  loss: 0.2816  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2816\n",
            "02/09 11:49:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][120/166]  lr: 2.0000e-02  eta: 0:41:51  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 2.7679  loss: 0.3342  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.3342\n",
            "02/09 11:49:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][140/166]  lr: 2.0000e-02  eta: 0:41:46  time: 0.2859  data_time: 0.0158  memory: 5737  grad_norm: 2.3167  loss: 0.2508  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2508\n",
            "02/09 11:49:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][160/166]  lr: 2.0000e-02  eta: 0:41:40  time: 0.2851  data_time: 0.0152  memory: 5737  grad_norm: 2.3495  loss: 0.2298  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2298\n",
            "02/09 11:49:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:49:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [98][166/166]  lr: 2.0000e-02  eta: 0:41:38  time: 0.2825  data_time: 0.0144  memory: 5737  grad_norm: 2.1601  loss: 0.2230  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2230\n",
            "02/09 11:49:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][ 20/166]  lr: 2.0000e-02  eta: 0:41:32  time: 0.3183  data_time: 0.0467  memory: 5737  grad_norm: 2.1740  loss: 0.2255  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2255\n",
            "02/09 11:49:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][ 40/166]  lr: 2.0000e-02  eta: 0:41:27  time: 0.2865  data_time: 0.0162  memory: 5737  grad_norm: 2.1601  loss: 0.2258  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2258\n",
            "02/09 11:49:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][ 60/166]  lr: 2.0000e-02  eta: 0:41:21  time: 0.2864  data_time: 0.0163  memory: 5737  grad_norm: 1.8523  loss: 0.1655  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1655\n",
            "02/09 11:49:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][ 80/166]  lr: 2.0000e-02  eta: 0:41:15  time: 0.2858  data_time: 0.0157  memory: 5737  grad_norm: 2.0971  loss: 0.1629  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1629\n",
            "02/09 11:49:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][100/166]  lr: 2.0000e-02  eta: 0:41:09  time: 0.2870  data_time: 0.0164  memory: 5737  grad_norm: 2.9586  loss: 0.2634  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2634\n",
            "02/09 11:49:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][120/166]  lr: 2.0000e-02  eta: 0:41:03  time: 0.2857  data_time: 0.0161  memory: 5737  grad_norm: 2.3515  loss: 0.2413  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2413\n",
            "02/09 11:50:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][140/166]  lr: 2.0000e-02  eta: 0:40:58  time: 0.2854  data_time: 0.0154  memory: 5737  grad_norm: 2.2488  loss: 0.2015  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.2015\n",
            "02/09 11:50:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][160/166]  lr: 2.0000e-02  eta: 0:40:52  time: 0.2843  data_time: 0.0148  memory: 5737  grad_norm: 2.6458  loss: 0.2613  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2613\n",
            "02/09 11:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:50:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train)  [99][166/166]  lr: 2.0000e-02  eta: 0:40:50  time: 0.2818  data_time: 0.0140  memory: 5737  grad_norm: 2.4970  loss: 0.2739  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.2739\n",
            "02/09 11:50:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][ 20/166]  lr: 2.0000e-02  eta: 0:40:44  time: 0.3125  data_time: 0.0404  memory: 5737  grad_norm: 2.0408  loss: 0.2006  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2006\n",
            "02/09 11:50:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][ 40/166]  lr: 2.0000e-02  eta: 0:40:39  time: 0.2860  data_time: 0.0160  memory: 5737  grad_norm: 2.4939  loss: 0.2722  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2722\n",
            "02/09 11:50:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][ 60/166]  lr: 2.0000e-02  eta: 0:40:33  time: 0.2861  data_time: 0.0161  memory: 5737  grad_norm: 2.0119  loss: 0.1648  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1648\n",
            "02/09 11:50:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][ 80/166]  lr: 2.0000e-02  eta: 0:40:27  time: 0.2861  data_time: 0.0161  memory: 5737  grad_norm: 2.1553  loss: 0.1871  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1871\n",
            "02/09 11:50:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][100/166]  lr: 2.0000e-02  eta: 0:40:21  time: 0.2867  data_time: 0.0166  memory: 5737  grad_norm: 1.9307  loss: 0.1707  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.1707\n",
            "02/09 11:50:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][120/166]  lr: 2.0000e-02  eta: 0:40:15  time: 0.2858  data_time: 0.0158  memory: 5737  grad_norm: 2.3243  loss: 0.2551  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.2551\n",
            "02/09 11:50:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][140/166]  lr: 2.0000e-02  eta: 0:40:09  time: 0.2853  data_time: 0.0154  memory: 5737  grad_norm: 2.2761  loss: 0.2513  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.2513\n",
            "02/09 11:50:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][160/166]  lr: 2.0000e-02  eta: 0:40:04  time: 0.2855  data_time: 0.0160  memory: 5737  grad_norm: 2.1640  loss: 0.2272  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2272\n",
            "02/09 11:50:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:50:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [100][166/166]  lr: 2.0000e-02  eta: 0:40:02  time: 0.2824  data_time: 0.0150  memory: 5737  grad_norm: 2.6191  loss: 0.2702  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.2702\n",
            "02/09 11:50:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 100 epochs\n",
            "02/09 11:51:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [100][20/21]    eta: 0:00:00  time: 0.1387  data_time: 0.0545  memory: 991  \n",
            "02/09 11:51:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [100][21/21]    acc/top1: 0.7470  acc/top5: 1.0000  acc/mean1: 0.7350  data_time: 0.0499  time: 0.1319\n",
            "02/09 11:51:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][ 20/166]  lr: 2.0000e-03  eta: 0:39:56  time: 0.3195  data_time: 0.0460  memory: 5737  grad_norm: 2.0441  loss: 0.1899  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1899\n",
            "02/09 11:51:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][ 40/166]  lr: 2.0000e-03  eta: 0:39:50  time: 0.2851  data_time: 0.0152  memory: 5737  grad_norm: 2.1233  loss: 0.2073  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2073\n",
            "02/09 11:51:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][ 60/166]  lr: 2.0000e-03  eta: 0:39:45  time: 0.2865  data_time: 0.0162  memory: 5737  grad_norm: 1.7189  loss: 0.1583  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1583\n",
            "02/09 11:51:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][ 80/166]  lr: 2.0000e-03  eta: 0:39:39  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 2.0686  loss: 0.1883  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1883\n",
            "02/09 11:51:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][100/166]  lr: 2.0000e-03  eta: 0:39:33  time: 0.2868  data_time: 0.0164  memory: 5737  grad_norm: 1.9189  loss: 0.1745  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1745\n",
            "02/09 11:51:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][120/166]  lr: 2.0000e-03  eta: 0:39:27  time: 0.2858  data_time: 0.0159  memory: 5737  grad_norm: 1.9729  loss: 0.1723  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1723\n",
            "02/09 11:51:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][140/166]  lr: 2.0000e-03  eta: 0:39:21  time: 0.2865  data_time: 0.0161  memory: 5737  grad_norm: 1.6516  loss: 0.1620  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1620\n",
            "02/09 11:51:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][160/166]  lr: 2.0000e-03  eta: 0:39:16  time: 0.2837  data_time: 0.0145  memory: 5737  grad_norm: 2.3227  loss: 0.2171  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.2171\n",
            "02/09 11:51:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:51:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [101][166/166]  lr: 2.0000e-03  eta: 0:39:14  time: 0.2810  data_time: 0.0138  memory: 5737  grad_norm: 2.0049  loss: 0.1749  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.1749\n",
            "02/09 11:51:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][ 20/166]  lr: 2.0000e-03  eta: 0:39:08  time: 0.3203  data_time: 0.0481  memory: 5737  grad_norm: 1.6218  loss: 0.1672  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1672\n",
            "02/09 11:52:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][ 40/166]  lr: 2.0000e-03  eta: 0:39:02  time: 0.2860  data_time: 0.0162  memory: 5737  grad_norm: 1.5701  loss: 0.1639  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1639\n",
            "02/09 11:52:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][ 60/166]  lr: 2.0000e-03  eta: 0:38:57  time: 0.2871  data_time: 0.0166  memory: 5737  grad_norm: 1.6931  loss: 0.1676  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1676\n",
            "02/09 11:52:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][ 80/166]  lr: 2.0000e-03  eta: 0:38:51  time: 0.2849  data_time: 0.0152  memory: 5737  grad_norm: 1.7286  loss: 0.1790  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1790\n",
            "02/09 11:52:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][100/166]  lr: 2.0000e-03  eta: 0:38:45  time: 0.2868  data_time: 0.0166  memory: 5737  grad_norm: 1.4713  loss: 0.1370  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.1370\n",
            "02/09 11:52:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][120/166]  lr: 2.0000e-03  eta: 0:38:39  time: 0.2851  data_time: 0.0154  memory: 5737  grad_norm: 2.0320  loss: 0.1537  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1537\n",
            "02/09 11:52:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][140/166]  lr: 2.0000e-03  eta: 0:38:33  time: 0.2861  data_time: 0.0159  memory: 5737  grad_norm: 1.6213  loss: 0.1356  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1356\n",
            "02/09 11:52:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][160/166]  lr: 2.0000e-03  eta: 0:38:27  time: 0.2843  data_time: 0.0151  memory: 5737  grad_norm: 1.9236  loss: 0.1755  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1755\n",
            "02/09 11:52:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:52:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [102][166/166]  lr: 2.0000e-03  eta: 0:38:26  time: 0.2816  data_time: 0.0140  memory: 5737  grad_norm: 2.1578  loss: 0.2099  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.2099\n",
            "02/09 11:52:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][ 20/166]  lr: 2.0000e-03  eta: 0:38:20  time: 0.3198  data_time: 0.0482  memory: 5737  grad_norm: 2.0919  loss: 0.1854  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1854\n",
            "02/09 11:52:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][ 40/166]  lr: 2.0000e-03  eta: 0:38:14  time: 0.2854  data_time: 0.0158  memory: 5737  grad_norm: 1.9724  loss: 0.1652  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1652\n",
            "02/09 11:52:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][ 60/166]  lr: 2.0000e-03  eta: 0:38:09  time: 0.2862  data_time: 0.0159  memory: 5737  grad_norm: 1.5622  loss: 0.1601  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1601\n",
            "02/09 11:52:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:53:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][ 80/166]  lr: 2.0000e-03  eta: 0:38:03  time: 0.2852  data_time: 0.0153  memory: 5737  grad_norm: 1.3845  loss: 0.1207  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1207\n",
            "02/09 11:53:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][100/166]  lr: 2.0000e-03  eta: 0:37:57  time: 0.2866  data_time: 0.0166  memory: 5737  grad_norm: 1.5930  loss: 0.1385  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.1385\n",
            "02/09 11:53:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][120/166]  lr: 2.0000e-03  eta: 0:37:51  time: 0.2865  data_time: 0.0163  memory: 5737  grad_norm: 1.5765  loss: 0.1396  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1396\n",
            "02/09 11:53:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][140/166]  lr: 2.0000e-03  eta: 0:37:45  time: 0.2866  data_time: 0.0161  memory: 5737  grad_norm: 1.6922  loss: 0.1710  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1710\n",
            "02/09 11:53:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][160/166]  lr: 2.0000e-03  eta: 0:37:39  time: 0.2840  data_time: 0.0150  memory: 5737  grad_norm: 1.9315  loss: 0.1519  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1519\n",
            "02/09 11:53:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:53:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [103][166/166]  lr: 2.0000e-03  eta: 0:37:38  time: 0.2820  data_time: 0.0148  memory: 5737  grad_norm: 1.8347  loss: 0.1468  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.1468\n",
            "02/09 11:53:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][ 20/166]  lr: 2.0000e-03  eta: 0:37:32  time: 0.3153  data_time: 0.0446  memory: 5737  grad_norm: 1.6227  loss: 0.1397  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1397\n",
            "02/09 11:53:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][ 40/166]  lr: 2.0000e-03  eta: 0:37:26  time: 0.2849  data_time: 0.0151  memory: 5737  grad_norm: 1.9249  loss: 0.1382  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1382\n",
            "02/09 11:53:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][ 60/166]  lr: 2.0000e-03  eta: 0:37:20  time: 0.2867  data_time: 0.0164  memory: 5737  grad_norm: 1.6255  loss: 0.1474  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.1474\n",
            "02/09 11:53:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][ 80/166]  lr: 2.0000e-03  eta: 0:37:15  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 1.7428  loss: 0.1411  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1411\n",
            "02/09 11:53:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][100/166]  lr: 2.0000e-03  eta: 0:37:09  time: 0.2871  data_time: 0.0167  memory: 5737  grad_norm: 1.5814  loss: 0.1390  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1390\n",
            "02/09 11:54:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][120/166]  lr: 2.0000e-03  eta: 0:37:03  time: 0.2858  data_time: 0.0160  memory: 5737  grad_norm: 2.0102  loss: 0.1605  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1605\n",
            "02/09 11:54:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][140/166]  lr: 2.0000e-03  eta: 0:36:57  time: 0.2860  data_time: 0.0161  memory: 5737  grad_norm: 2.2408  loss: 0.1635  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1635\n",
            "02/09 11:54:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][160/166]  lr: 2.0000e-03  eta: 0:36:51  time: 0.2846  data_time: 0.0152  memory: 5737  grad_norm: 1.8496  loss: 0.1661  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1661\n",
            "02/09 11:54:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:54:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [104][166/166]  lr: 2.0000e-03  eta: 0:36:50  time: 0.2830  data_time: 0.0152  memory: 5737  grad_norm: 1.8785  loss: 0.1516  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1516\n",
            "02/09 11:54:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 104 epochs\n",
            "02/09 11:54:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][ 20/166]  lr: 2.0000e-03  eta: 0:36:44  time: 0.3149  data_time: 0.0431  memory: 5737  grad_norm: 1.6636  loss: 0.1287  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1287\n",
            "02/09 11:54:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][ 40/166]  lr: 2.0000e-03  eta: 0:36:38  time: 0.2866  data_time: 0.0165  memory: 5737  grad_norm: 2.0686  loss: 0.1740  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1740\n",
            "02/09 11:54:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][ 60/166]  lr: 2.0000e-03  eta: 0:36:32  time: 0.2871  data_time: 0.0168  memory: 5737  grad_norm: 1.8144  loss: 0.1453  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1453\n",
            "02/09 11:54:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][ 80/166]  lr: 2.0000e-03  eta: 0:36:27  time: 0.2857  data_time: 0.0153  memory: 5737  grad_norm: 1.7339  loss: 0.1638  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1638\n",
            "02/09 11:54:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][100/166]  lr: 2.0000e-03  eta: 0:36:21  time: 0.2862  data_time: 0.0159  memory: 5737  grad_norm: 1.7219  loss: 0.1592  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1592\n",
            "02/09 11:54:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][120/166]  lr: 2.0000e-03  eta: 0:36:15  time: 0.2861  data_time: 0.0160  memory: 5737  grad_norm: 1.3286  loss: 0.1066  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1066\n",
            "02/09 11:54:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][140/166]  lr: 2.0000e-03  eta: 0:36:09  time: 0.2857  data_time: 0.0159  memory: 5737  grad_norm: 1.5776  loss: 0.1241  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1241\n",
            "02/09 11:55:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][160/166]  lr: 2.0000e-03  eta: 0:36:03  time: 0.2854  data_time: 0.0154  memory: 5737  grad_norm: 2.0688  loss: 0.1772  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1772\n",
            "02/09 11:55:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:55:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [105][166/166]  lr: 2.0000e-03  eta: 0:36:02  time: 0.2824  data_time: 0.0142  memory: 5737  grad_norm: 1.9118  loss: 0.1608  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.1608\n",
            "02/09 11:55:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [105][20/21]    eta: 0:00:00  time: 0.1411  data_time: 0.0569  memory: 991  \n",
            "02/09 11:55:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [105][21/21]    acc/top1: 0.7681  acc/top5: 1.0000  acc/mean1: 0.7612  data_time: 0.0520  time: 0.1340\n",
            "02/09 11:55:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][ 20/166]  lr: 2.0000e-03  eta: 0:35:56  time: 0.3152  data_time: 0.0433  memory: 5737  grad_norm: 1.7959  loss: 0.1720  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1720\n",
            "02/09 11:55:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][ 40/166]  lr: 2.0000e-03  eta: 0:35:50  time: 0.2868  data_time: 0.0168  memory: 5737  grad_norm: 2.0883  loss: 0.1837  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1837\n",
            "02/09 11:55:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][ 60/166]  lr: 2.0000e-03  eta: 0:35:44  time: 0.2865  data_time: 0.0167  memory: 5737  grad_norm: 1.8232  loss: 0.1535  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.1535\n",
            "02/09 11:55:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][ 80/166]  lr: 2.0000e-03  eta: 0:35:39  time: 0.2858  data_time: 0.0159  memory: 5737  grad_norm: 1.5240  loss: 0.1274  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1274\n",
            "02/09 11:55:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][100/166]  lr: 2.0000e-03  eta: 0:35:33  time: 0.2860  data_time: 0.0160  memory: 5737  grad_norm: 1.7965  loss: 0.1523  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1523\n",
            "02/09 11:55:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][120/166]  lr: 2.0000e-03  eta: 0:35:27  time: 0.2870  data_time: 0.0167  memory: 5737  grad_norm: 1.6939  loss: 0.1221  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1221\n",
            "02/09 11:55:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][140/166]  lr: 2.0000e-03  eta: 0:35:21  time: 0.2868  data_time: 0.0163  memory: 5737  grad_norm: 1.5462  loss: 0.1429  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1429\n",
            "02/09 11:55:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][160/166]  lr: 2.0000e-03  eta: 0:35:15  time: 0.2845  data_time: 0.0151  memory: 5737  grad_norm: 1.4914  loss: 0.1156  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1156\n",
            "02/09 11:55:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:55:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [106][166/166]  lr: 2.0000e-03  eta: 0:35:14  time: 0.2824  data_time: 0.0146  memory: 5737  grad_norm: 1.6611  loss: 0.1300  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.1300\n",
            "02/09 11:56:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][ 20/166]  lr: 2.0000e-03  eta: 0:35:08  time: 0.3182  data_time: 0.0466  memory: 5737  grad_norm: 1.5786  loss: 0.1539  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1539\n",
            "02/09 11:56:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][ 40/166]  lr: 2.0000e-03  eta: 0:35:02  time: 0.2866  data_time: 0.0160  memory: 5737  grad_norm: 1.6286  loss: 0.1323  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1323\n",
            "02/09 11:56:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][ 60/166]  lr: 2.0000e-03  eta: 0:34:56  time: 0.2881  data_time: 0.0173  memory: 5737  grad_norm: 1.1330  loss: 0.0887  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0887\n",
            "02/09 11:56:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][ 80/166]  lr: 2.0000e-03  eta: 0:34:51  time: 0.2874  data_time: 0.0168  memory: 5737  grad_norm: 1.3693  loss: 0.1093  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1093\n",
            "02/09 11:56:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][100/166]  lr: 2.0000e-03  eta: 0:34:45  time: 0.2879  data_time: 0.0173  memory: 5737  grad_norm: 1.6885  loss: 0.1368  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1368\n",
            "02/09 11:56:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][120/166]  lr: 2.0000e-03  eta: 0:34:39  time: 0.2855  data_time: 0.0155  memory: 5737  grad_norm: 1.4841  loss: 0.1104  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1104\n",
            "02/09 11:56:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][140/166]  lr: 2.0000e-03  eta: 0:34:33  time: 0.2866  data_time: 0.0165  memory: 5737  grad_norm: 2.0955  loss: 0.1605  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1605\n",
            "02/09 11:56:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][160/166]  lr: 2.0000e-03  eta: 0:34:27  time: 0.2857  data_time: 0.0164  memory: 5737  grad_norm: 1.4826  loss: 0.0970  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0970\n",
            "02/09 11:56:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:56:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [107][166/166]  lr: 2.0000e-03  eta: 0:34:26  time: 0.2832  data_time: 0.0154  memory: 5737  grad_norm: 1.4121  loss: 0.1020  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1020\n",
            "02/09 11:56:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][ 20/166]  lr: 2.0000e-03  eta: 0:34:20  time: 0.3227  data_time: 0.0510  memory: 5737  grad_norm: 1.7340  loss: 0.1416  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1416\n",
            "02/09 11:56:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][ 40/166]  lr: 2.0000e-03  eta: 0:34:14  time: 0.2863  data_time: 0.0163  memory: 5737  grad_norm: 1.6542  loss: 0.1144  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1144\n",
            "02/09 11:57:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][ 60/166]  lr: 2.0000e-03  eta: 0:34:08  time: 0.2866  data_time: 0.0164  memory: 5737  grad_norm: 2.0079  loss: 0.1515  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1515\n",
            "02/09 11:57:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][ 80/166]  lr: 2.0000e-03  eta: 0:34:03  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 1.6120  loss: 0.1235  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1235\n",
            "02/09 11:57:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][100/166]  lr: 2.0000e-03  eta: 0:33:57  time: 0.2871  data_time: 0.0164  memory: 5737  grad_norm: 1.5789  loss: 0.0895  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.0895\n",
            "02/09 11:57:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][120/166]  lr: 2.0000e-03  eta: 0:33:51  time: 0.2862  data_time: 0.0158  memory: 5737  grad_norm: 1.6735  loss: 0.1266  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1266\n",
            "02/09 11:57:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][140/166]  lr: 2.0000e-03  eta: 0:33:45  time: 0.2848  data_time: 0.0151  memory: 5737  grad_norm: 1.7525  loss: 0.1077  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1077\n",
            "02/09 11:57:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][160/166]  lr: 2.0000e-03  eta: 0:33:39  time: 0.2845  data_time: 0.0150  memory: 5737  grad_norm: 1.3985  loss: 0.0926  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0926\n",
            "02/09 11:57:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:57:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [108][166/166]  lr: 2.0000e-03  eta: 0:33:38  time: 0.2816  data_time: 0.0140  memory: 5737  grad_norm: 1.2436  loss: 0.0767  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0767\n",
            "02/09 11:57:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 108 epochs\n",
            "02/09 11:57:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][ 20/166]  lr: 2.0000e-03  eta: 0:33:32  time: 0.3188  data_time: 0.0465  memory: 5737  grad_norm: 1.9366  loss: 0.1252  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1252\n",
            "02/09 11:57:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][ 40/166]  lr: 2.0000e-03  eta: 0:33:26  time: 0.2854  data_time: 0.0154  memory: 5737  grad_norm: 1.4745  loss: 0.0940  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0940\n",
            "02/09 11:57:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][ 60/166]  lr: 2.0000e-03  eta: 0:33:20  time: 0.2874  data_time: 0.0166  memory: 5737  grad_norm: 1.5272  loss: 0.1211  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1211\n",
            "02/09 11:57:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:57:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][ 80/166]  lr: 2.0000e-03  eta: 0:33:15  time: 0.2868  data_time: 0.0167  memory: 5737  grad_norm: 1.9868  loss: 0.1367  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1367\n",
            "02/09 11:58:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][100/166]  lr: 2.0000e-03  eta: 0:33:09  time: 0.2871  data_time: 0.0167  memory: 5737  grad_norm: 1.7113  loss: 0.1360  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1360\n",
            "02/09 11:58:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][120/166]  lr: 2.0000e-03  eta: 0:33:03  time: 0.2859  data_time: 0.0158  memory: 5737  grad_norm: 1.7520  loss: 0.1341  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1341\n",
            "02/09 11:58:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][140/166]  lr: 2.0000e-03  eta: 0:32:57  time: 0.2863  data_time: 0.0161  memory: 5737  grad_norm: 1.8812  loss: 0.1365  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1365\n",
            "02/09 11:58:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][160/166]  lr: 2.0000e-03  eta: 0:32:51  time: 0.2848  data_time: 0.0153  memory: 5737  grad_norm: 1.7958  loss: 0.1157  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1157\n",
            "02/09 11:58:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:58:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [109][166/166]  lr: 2.0000e-03  eta: 0:32:50  time: 0.2817  data_time: 0.0141  memory: 5737  grad_norm: 2.1593  loss: 0.1561  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.1561\n",
            "02/09 11:58:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][ 20/166]  lr: 2.0000e-03  eta: 0:32:44  time: 0.3181  data_time: 0.0462  memory: 5737  grad_norm: 1.6906  loss: 0.1241  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1241\n",
            "02/09 11:58:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][ 40/166]  lr: 2.0000e-03  eta: 0:32:38  time: 0.2852  data_time: 0.0153  memory: 5737  grad_norm: 1.9271  loss: 0.1515  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1515\n",
            "02/09 11:58:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][ 60/166]  lr: 2.0000e-03  eta: 0:32:32  time: 0.2860  data_time: 0.0162  memory: 5737  grad_norm: 2.0860  loss: 0.1234  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1234\n",
            "02/09 11:58:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][ 80/166]  lr: 2.0000e-03  eta: 0:32:26  time: 0.2857  data_time: 0.0158  memory: 5737  grad_norm: 1.6144  loss: 0.1321  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1321\n",
            "02/09 11:58:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][100/166]  lr: 2.0000e-03  eta: 0:32:21  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 1.8098  loss: 0.1486  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1486\n",
            "02/09 11:58:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][120/166]  lr: 2.0000e-03  eta: 0:32:15  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 1.4177  loss: 0.0913  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0913\n",
            "02/09 11:59:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][140/166]  lr: 2.0000e-03  eta: 0:32:09  time: 0.2857  data_time: 0.0158  memory: 5737  grad_norm: 1.9268  loss: 0.1435  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1435\n",
            "02/09 11:59:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][160/166]  lr: 2.0000e-03  eta: 0:32:03  time: 0.2862  data_time: 0.0162  memory: 5737  grad_norm: 2.1759  loss: 0.1635  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1635\n",
            "02/09 11:59:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:59:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [110][166/166]  lr: 2.0000e-03  eta: 0:32:01  time: 0.2825  data_time: 0.0146  memory: 5737  grad_norm: 2.0655  loss: 0.1497  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1497\n",
            "02/09 11:59:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [110][20/21]    eta: 0:00:00  time: 0.1409  data_time: 0.0540  memory: 991  \n",
            "02/09 11:59:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [110][21/21]    acc/top1: 0.7681  acc/top5: 1.0000  acc/mean1: 0.7612  data_time: 0.0494  time: 0.1338\n",
            "02/09 11:59:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][ 20/166]  lr: 2.0000e-03  eta: 0:31:56  time: 0.3171  data_time: 0.0441  memory: 5737  grad_norm: 1.3691  loss: 0.1043  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1043\n",
            "02/09 11:59:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][ 40/166]  lr: 2.0000e-03  eta: 0:31:50  time: 0.2846  data_time: 0.0149  memory: 5737  grad_norm: 1.5913  loss: 0.0984  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0984\n",
            "02/09 11:59:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][ 60/166]  lr: 2.0000e-03  eta: 0:31:44  time: 0.2860  data_time: 0.0161  memory: 5737  grad_norm: 1.4516  loss: 0.1052  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1052\n",
            "02/09 11:59:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][ 80/166]  lr: 2.0000e-03  eta: 0:31:38  time: 0.2849  data_time: 0.0152  memory: 5737  grad_norm: 1.7095  loss: 0.1148  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1148\n",
            "02/09 11:59:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][100/166]  lr: 2.0000e-03  eta: 0:31:33  time: 0.2859  data_time: 0.0162  memory: 5737  grad_norm: 1.5716  loss: 0.0898  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0898\n",
            "02/09 11:59:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][120/166]  lr: 2.0000e-03  eta: 0:31:27  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 1.5511  loss: 0.1219  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.1219\n",
            "02/09 11:59:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][140/166]  lr: 2.0000e-03  eta: 0:31:21  time: 0.2867  data_time: 0.0165  memory: 5737  grad_norm: 1.7165  loss: 0.1417  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1417\n",
            "02/09 11:59:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][160/166]  lr: 2.0000e-03  eta: 0:31:15  time: 0.2861  data_time: 0.0165  memory: 5737  grad_norm: 1.8606  loss: 0.1158  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1158\n",
            "02/09 11:59:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 11:59:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [111][166/166]  lr: 2.0000e-03  eta: 0:31:13  time: 0.2846  data_time: 0.0166  memory: 5737  grad_norm: 1.9437  loss: 0.1219  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.1219\n",
            "02/09 12:00:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][ 20/166]  lr: 2.0000e-03  eta: 0:31:08  time: 0.3203  data_time: 0.0484  memory: 5737  grad_norm: 1.6387  loss: 0.1194  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1194\n",
            "02/09 12:00:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][ 40/166]  lr: 2.0000e-03  eta: 0:31:02  time: 0.2863  data_time: 0.0163  memory: 5737  grad_norm: 1.6172  loss: 0.1542  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1542\n",
            "02/09 12:00:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][ 60/166]  lr: 2.0000e-03  eta: 0:30:56  time: 0.2874  data_time: 0.0172  memory: 5737  grad_norm: 1.4862  loss: 0.0999  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0999\n",
            "02/09 12:00:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][ 80/166]  lr: 2.0000e-03  eta: 0:30:50  time: 0.2861  data_time: 0.0158  memory: 5737  grad_norm: 1.9090  loss: 0.1242  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1242\n",
            "02/09 12:00:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][100/166]  lr: 2.0000e-03  eta: 0:30:45  time: 0.2874  data_time: 0.0169  memory: 5737  grad_norm: 2.1716  loss: 0.1660  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1660\n",
            "02/09 12:00:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][120/166]  lr: 2.0000e-03  eta: 0:30:39  time: 0.2853  data_time: 0.0153  memory: 5737  grad_norm: 2.0283  loss: 0.1387  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1387\n",
            "02/09 12:00:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][140/166]  lr: 2.0000e-03  eta: 0:30:33  time: 0.2864  data_time: 0.0162  memory: 5737  grad_norm: 1.7672  loss: 0.1402  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1402\n",
            "02/09 12:00:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][160/166]  lr: 2.0000e-03  eta: 0:30:27  time: 0.2854  data_time: 0.0155  memory: 5737  grad_norm: 1.8261  loss: 0.1329  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1329\n",
            "02/09 12:00:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:00:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [112][166/166]  lr: 2.0000e-03  eta: 0:30:25  time: 0.2822  data_time: 0.0143  memory: 5737  grad_norm: 1.7295  loss: 0.1270  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.1270\n",
            "02/09 12:00:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 112 epochs\n",
            "02/09 12:00:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][ 20/166]  lr: 2.0000e-03  eta: 0:30:20  time: 0.3225  data_time: 0.0516  memory: 5737  grad_norm: 1.5260  loss: 0.1075  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1075\n",
            "02/09 12:01:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][ 40/166]  lr: 2.0000e-03  eta: 0:30:14  time: 0.2856  data_time: 0.0153  memory: 5737  grad_norm: 1.9124  loss: 0.1472  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1472\n",
            "02/09 12:01:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][ 60/166]  lr: 2.0000e-03  eta: 0:30:08  time: 0.2874  data_time: 0.0170  memory: 5737  grad_norm: 1.3518  loss: 0.1024  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1024\n",
            "02/09 12:01:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][ 80/166]  lr: 2.0000e-03  eta: 0:30:02  time: 0.2858  data_time: 0.0159  memory: 5737  grad_norm: 1.5743  loss: 0.1322  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1322\n",
            "02/09 12:01:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][100/166]  lr: 2.0000e-03  eta: 0:29:57  time: 0.2869  data_time: 0.0166  memory: 5737  grad_norm: 1.5185  loss: 0.1296  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1296\n",
            "02/09 12:01:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][120/166]  lr: 2.0000e-03  eta: 0:29:51  time: 0.2870  data_time: 0.0166  memory: 5737  grad_norm: 1.4082  loss: 0.1151  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1151\n",
            "02/09 12:01:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][140/166]  lr: 2.0000e-03  eta: 0:29:45  time: 0.2885  data_time: 0.0176  memory: 5737  grad_norm: 1.4403  loss: 0.0857  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0857\n",
            "02/09 12:01:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][160/166]  lr: 2.0000e-03  eta: 0:29:39  time: 0.2850  data_time: 0.0157  memory: 5737  grad_norm: 1.5601  loss: 0.1153  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1153\n",
            "02/09 12:01:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:01:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [113][166/166]  lr: 2.0000e-03  eta: 0:29:37  time: 0.2822  data_time: 0.0148  memory: 5737  grad_norm: 1.5343  loss: 0.1085  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1085\n",
            "02/09 12:01:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][ 20/166]  lr: 2.0000e-03  eta: 0:29:32  time: 0.3175  data_time: 0.0453  memory: 5737  grad_norm: 1.8229  loss: 0.1174  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1174\n",
            "02/09 12:01:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][ 40/166]  lr: 2.0000e-03  eta: 0:29:26  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 2.1375  loss: 0.1381  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1381\n",
            "02/09 12:01:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][ 60/166]  lr: 2.0000e-03  eta: 0:29:20  time: 0.2861  data_time: 0.0159  memory: 5737  grad_norm: 1.7759  loss: 0.1540  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1540\n",
            "02/09 12:02:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][ 80/166]  lr: 2.0000e-03  eta: 0:29:14  time: 0.2862  data_time: 0.0162  memory: 5737  grad_norm: 1.6556  loss: 0.1365  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1365\n",
            "02/09 12:02:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][100/166]  lr: 2.0000e-03  eta: 0:29:09  time: 0.2869  data_time: 0.0166  memory: 5737  grad_norm: 1.9824  loss: 0.1150  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1150\n",
            "02/09 12:02:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][120/166]  lr: 2.0000e-03  eta: 0:29:03  time: 0.2855  data_time: 0.0156  memory: 5737  grad_norm: 1.8521  loss: 0.1547  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1547\n",
            "02/09 12:02:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][140/166]  lr: 2.0000e-03  eta: 0:28:57  time: 0.2862  data_time: 0.0163  memory: 5737  grad_norm: 1.6898  loss: 0.1132  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1132\n",
            "02/09 12:02:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][160/166]  lr: 2.0000e-03  eta: 0:28:51  time: 0.2855  data_time: 0.0161  memory: 5737  grad_norm: 1.6661  loss: 0.1170  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1170\n",
            "02/09 12:02:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:02:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [114][166/166]  lr: 2.0000e-03  eta: 0:28:49  time: 0.2825  data_time: 0.0151  memory: 5737  grad_norm: 1.6952  loss: 0.0990  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0990\n",
            "02/09 12:02:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][ 20/166]  lr: 2.0000e-03  eta: 0:28:44  time: 0.3181  data_time: 0.0458  memory: 5737  grad_norm: 1.5158  loss: 0.1033  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1033\n",
            "02/09 12:02:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][ 40/166]  lr: 2.0000e-03  eta: 0:28:38  time: 0.2861  data_time: 0.0160  memory: 5737  grad_norm: 1.7297  loss: 0.1185  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1185\n",
            "02/09 12:02:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][ 60/166]  lr: 2.0000e-03  eta: 0:28:32  time: 0.2859  data_time: 0.0161  memory: 5737  grad_norm: 1.5636  loss: 0.1258  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1258\n",
            "02/09 12:02:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:02:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][ 80/166]  lr: 2.0000e-03  eta: 0:28:26  time: 0.2859  data_time: 0.0162  memory: 5737  grad_norm: 1.7541  loss: 0.1455  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1455\n",
            "02/09 12:02:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][100/166]  lr: 2.0000e-03  eta: 0:28:21  time: 0.2861  data_time: 0.0161  memory: 5737  grad_norm: 1.7122  loss: 0.1306  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1306\n",
            "02/09 12:02:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][120/166]  lr: 2.0000e-03  eta: 0:28:15  time: 0.2861  data_time: 0.0161  memory: 5737  grad_norm: 2.0598  loss: 0.1593  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1593\n",
            "02/09 12:03:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][140/166]  lr: 2.0000e-03  eta: 0:28:09  time: 0.2853  data_time: 0.0154  memory: 5737  grad_norm: 1.5055  loss: 0.1065  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1065\n",
            "02/09 12:03:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][160/166]  lr: 2.0000e-03  eta: 0:28:03  time: 0.2852  data_time: 0.0155  memory: 5737  grad_norm: 1.9374  loss: 0.1277  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1277\n",
            "02/09 12:03:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:03:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [115][166/166]  lr: 2.0000e-03  eta: 0:28:01  time: 0.2814  data_time: 0.0139  memory: 5737  grad_norm: 1.6893  loss: 0.1011  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1011\n",
            "02/09 12:03:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [115][20/21]    eta: 0:00:00  time: 0.1401  data_time: 0.0558  memory: 991  \n",
            "02/09 12:03:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [115][21/21]    acc/top1: 0.7831  acc/top5: 1.0000  acc/mean1: 0.7758  data_time: 0.0510  time: 0.1331\n",
            "02/09 12:03:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][ 20/166]  lr: 2.0000e-03  eta: 0:27:56  time: 0.3169  data_time: 0.0443  memory: 5737  grad_norm: 1.7273  loss: 0.1119  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1119\n",
            "02/09 12:03:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][ 40/166]  lr: 2.0000e-03  eta: 0:27:50  time: 0.2856  data_time: 0.0158  memory: 5737  grad_norm: 1.5977  loss: 0.0985  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0985\n",
            "02/09 12:03:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][ 60/166]  lr: 2.0000e-03  eta: 0:27:44  time: 0.2863  data_time: 0.0164  memory: 5737  grad_norm: 1.4114  loss: 0.0857  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0857\n",
            "02/09 12:03:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][ 80/166]  lr: 2.0000e-03  eta: 0:27:38  time: 0.2858  data_time: 0.0159  memory: 5737  grad_norm: 2.1896  loss: 0.1788  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1788\n",
            "02/09 12:03:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][100/166]  lr: 2.0000e-03  eta: 0:27:32  time: 0.2872  data_time: 0.0170  memory: 5737  grad_norm: 1.5312  loss: 0.1104  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1104\n",
            "02/09 12:03:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][120/166]  lr: 2.0000e-03  eta: 0:27:27  time: 0.2858  data_time: 0.0156  memory: 5737  grad_norm: 1.8395  loss: 0.1428  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1428\n",
            "02/09 12:03:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][140/166]  lr: 2.0000e-03  eta: 0:27:21  time: 0.2870  data_time: 0.0168  memory: 5737  grad_norm: 1.8383  loss: 0.1319  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1319\n",
            "02/09 12:04:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][160/166]  lr: 2.0000e-03  eta: 0:27:15  time: 0.2838  data_time: 0.0144  memory: 5737  grad_norm: 1.5792  loss: 0.0929  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0929\n",
            "02/09 12:04:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:04:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [116][166/166]  lr: 2.0000e-03  eta: 0:27:13  time: 0.2821  data_time: 0.0141  memory: 5737  grad_norm: 1.4908  loss: 0.0957  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.0957\n",
            "02/09 12:04:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 116 epochs\n",
            "02/09 12:04:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][ 20/166]  lr: 2.0000e-03  eta: 0:27:08  time: 0.3243  data_time: 0.0516  memory: 5737  grad_norm: 1.4249  loss: 0.1030  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1030\n",
            "02/09 12:04:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][ 40/166]  lr: 2.0000e-03  eta: 0:27:02  time: 0.2858  data_time: 0.0159  memory: 5737  grad_norm: 1.3210  loss: 0.0940  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0940\n",
            "02/09 12:04:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][ 60/166]  lr: 2.0000e-03  eta: 0:26:56  time: 0.2867  data_time: 0.0164  memory: 5737  grad_norm: 2.0830  loss: 0.1529  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1529\n",
            "02/09 12:04:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][ 80/166]  lr: 2.0000e-03  eta: 0:26:50  time: 0.2857  data_time: 0.0158  memory: 5737  grad_norm: 1.8765  loss: 0.1399  top1_acc: 0.7500  top5_acc: 1.0000  loss_cls: 0.1399\n",
            "02/09 12:04:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][100/166]  lr: 2.0000e-03  eta: 0:26:44  time: 0.2857  data_time: 0.0159  memory: 5737  grad_norm: 1.6595  loss: 0.1033  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1033\n",
            "02/09 12:04:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][120/166]  lr: 2.0000e-03  eta: 0:26:39  time: 0.2845  data_time: 0.0149  memory: 5737  grad_norm: 1.8955  loss: 0.1347  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1347\n",
            "02/09 12:04:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][140/166]  lr: 2.0000e-03  eta: 0:26:33  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 1.4629  loss: 0.1110  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1110\n",
            "02/09 12:04:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][160/166]  lr: 2.0000e-03  eta: 0:26:27  time: 0.2841  data_time: 0.0149  memory: 5737  grad_norm: 1.8317  loss: 0.1197  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1197\n",
            "02/09 12:04:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:04:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [117][166/166]  lr: 2.0000e-03  eta: 0:26:25  time: 0.2822  data_time: 0.0147  memory: 5737  grad_norm: 2.1305  loss: 0.1384  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1384\n",
            "02/09 12:04:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][ 20/166]  lr: 2.0000e-03  eta: 0:26:20  time: 0.3150  data_time: 0.0420  memory: 5737  grad_norm: 1.6315  loss: 0.1184  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1184\n",
            "02/09 12:05:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][ 40/166]  lr: 2.0000e-03  eta: 0:26:14  time: 0.2859  data_time: 0.0159  memory: 5737  grad_norm: 1.3935  loss: 0.0864  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0864\n",
            "02/09 12:05:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][ 60/166]  lr: 2.0000e-03  eta: 0:26:08  time: 0.2869  data_time: 0.0167  memory: 5737  grad_norm: 1.9780  loss: 0.1385  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1385\n",
            "02/09 12:05:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][ 80/166]  lr: 2.0000e-03  eta: 0:26:02  time: 0.2857  data_time: 0.0160  memory: 5737  grad_norm: 1.5506  loss: 0.1040  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1040\n",
            "02/09 12:05:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][100/166]  lr: 2.0000e-03  eta: 0:25:56  time: 0.2871  data_time: 0.0168  memory: 5737  grad_norm: 2.0094  loss: 0.1278  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1278\n",
            "02/09 12:05:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][120/166]  lr: 2.0000e-03  eta: 0:25:51  time: 0.2848  data_time: 0.0150  memory: 5737  grad_norm: 2.2132  loss: 0.1732  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1732\n",
            "02/09 12:05:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][140/166]  lr: 2.0000e-03  eta: 0:25:45  time: 0.2874  data_time: 0.0168  memory: 5737  grad_norm: 1.9601  loss: 0.1216  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1216\n",
            "02/09 12:05:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][160/166]  lr: 2.0000e-03  eta: 0:25:39  time: 0.2845  data_time: 0.0149  memory: 5737  grad_norm: 1.8103  loss: 0.1283  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1283\n",
            "02/09 12:05:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:05:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [118][166/166]  lr: 2.0000e-03  eta: 0:25:37  time: 0.2821  data_time: 0.0142  memory: 5737  grad_norm: 2.0050  loss: 0.1408  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1408\n",
            "02/09 12:05:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][ 20/166]  lr: 2.0000e-03  eta: 0:25:32  time: 0.3145  data_time: 0.0427  memory: 5737  grad_norm: 1.6790  loss: 0.1155  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1155\n",
            "02/09 12:05:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][ 40/166]  lr: 2.0000e-03  eta: 0:25:26  time: 0.2856  data_time: 0.0157  memory: 5737  grad_norm: 1.1371  loss: 0.0830  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0830\n",
            "02/09 12:05:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][ 60/166]  lr: 2.0000e-03  eta: 0:25:20  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 1.6432  loss: 0.1131  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1131\n",
            "02/09 12:06:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][ 80/166]  lr: 2.0000e-03  eta: 0:25:14  time: 0.2867  data_time: 0.0163  memory: 5737  grad_norm: 1.8556  loss: 0.1314  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1314\n",
            "02/09 12:06:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][100/166]  lr: 2.0000e-03  eta: 0:25:08  time: 0.2867  data_time: 0.0169  memory: 5737  grad_norm: 1.8689  loss: 0.1320  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1320\n",
            "02/09 12:06:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][120/166]  lr: 2.0000e-03  eta: 0:25:02  time: 0.2854  data_time: 0.0152  memory: 5737  grad_norm: 1.7632  loss: 0.1138  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1138\n",
            "02/09 12:06:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][140/166]  lr: 2.0000e-03  eta: 0:24:57  time: 0.2861  data_time: 0.0160  memory: 5737  grad_norm: 1.6492  loss: 0.0922  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0922\n",
            "02/09 12:06:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][160/166]  lr: 2.0000e-03  eta: 0:24:51  time: 0.2848  data_time: 0.0154  memory: 5737  grad_norm: 1.6586  loss: 0.1122  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1122\n",
            "02/09 12:06:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:06:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [119][166/166]  lr: 2.0000e-03  eta: 0:24:49  time: 0.2821  data_time: 0.0146  memory: 5737  grad_norm: 1.7636  loss: 0.1161  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1161\n",
            "02/09 12:06:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][ 20/166]  lr: 2.0000e-03  eta: 0:24:43  time: 0.3139  data_time: 0.0422  memory: 5737  grad_norm: 1.4481  loss: 0.0959  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0959\n",
            "02/09 12:06:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][ 40/166]  lr: 2.0000e-03  eta: 0:24:38  time: 0.2853  data_time: 0.0155  memory: 5737  grad_norm: 1.0738  loss: 0.0700  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0700\n",
            "02/09 12:06:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][ 60/166]  lr: 2.0000e-03  eta: 0:24:32  time: 0.2871  data_time: 0.0165  memory: 5737  grad_norm: 1.9733  loss: 0.1319  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1319\n",
            "02/09 12:06:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][ 80/166]  lr: 2.0000e-03  eta: 0:24:26  time: 0.2873  data_time: 0.0171  memory: 5737  grad_norm: 1.6587  loss: 0.1084  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1084\n",
            "02/09 12:06:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][100/166]  lr: 2.0000e-03  eta: 0:24:20  time: 0.2846  data_time: 0.0149  memory: 5737  grad_norm: 1.4086  loss: 0.0955  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0955\n",
            "02/09 12:07:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][120/166]  lr: 2.0000e-03  eta: 0:24:14  time: 0.2858  data_time: 0.0157  memory: 5737  grad_norm: 1.7272  loss: 0.1188  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1188\n",
            "02/09 12:07:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][140/166]  lr: 2.0000e-03  eta: 0:24:09  time: 0.2857  data_time: 0.0155  memory: 5737  grad_norm: 2.1155  loss: 0.1585  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1585\n",
            "02/09 12:07:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][160/166]  lr: 2.0000e-03  eta: 0:24:03  time: 0.2859  data_time: 0.0163  memory: 5737  grad_norm: 1.7860  loss: 0.1248  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1248\n",
            "02/09 12:07:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:07:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [120][166/166]  lr: 2.0000e-03  eta: 0:24:01  time: 0.2831  data_time: 0.0154  memory: 5737  grad_norm: 1.7797  loss: 0.1243  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1243\n",
            "02/09 12:07:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 120 epochs\n",
            "02/09 12:07:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [120][20/21]    eta: 0:00:00  time: 0.1411  data_time: 0.0553  memory: 991  \n",
            "02/09 12:07:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [120][21/21]    acc/top1: 0.7651  acc/top5: 1.0000  acc/mean1: 0.7588  data_time: 0.0506  time: 0.1341\n",
            "02/09 12:07:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][ 20/166]  lr: 2.0000e-03  eta: 0:23:55  time: 0.3153  data_time: 0.0415  memory: 5737  grad_norm: 2.1010  loss: 0.1470  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1470\n",
            "02/09 12:07:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][ 40/166]  lr: 2.0000e-03  eta: 0:23:50  time: 0.2854  data_time: 0.0155  memory: 5737  grad_norm: 1.7276  loss: 0.1286  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1286\n",
            "02/09 12:07:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][ 60/166]  lr: 2.0000e-03  eta: 0:23:44  time: 0.2861  data_time: 0.0158  memory: 5737  grad_norm: 1.7939  loss: 0.1320  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1320\n",
            "02/09 12:07:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:07:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][ 80/166]  lr: 2.0000e-03  eta: 0:23:38  time: 0.2858  data_time: 0.0157  memory: 5737  grad_norm: 1.2965  loss: 0.0867  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0867\n",
            "02/09 12:07:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][100/166]  lr: 2.0000e-03  eta: 0:23:32  time: 0.2869  data_time: 0.0167  memory: 5737  grad_norm: 1.7730  loss: 0.1236  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1236\n",
            "02/09 12:07:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][120/166]  lr: 2.0000e-03  eta: 0:23:26  time: 0.2852  data_time: 0.0154  memory: 5737  grad_norm: 1.8282  loss: 0.1438  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1438\n",
            "02/09 12:08:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][140/166]  lr: 2.0000e-03  eta: 0:23:21  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 1.2927  loss: 0.0744  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0744\n",
            "02/09 12:08:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][160/166]  lr: 2.0000e-03  eta: 0:23:15  time: 0.2843  data_time: 0.0150  memory: 5737  grad_norm: 1.2055  loss: 0.0786  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0786\n",
            "02/09 12:08:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:08:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [121][166/166]  lr: 2.0000e-03  eta: 0:23:13  time: 0.2817  data_time: 0.0143  memory: 5737  grad_norm: 1.2743  loss: 0.0798  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0798\n",
            "02/09 12:08:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][ 20/166]  lr: 2.0000e-03  eta: 0:23:07  time: 0.3188  data_time: 0.0481  memory: 5737  grad_norm: 1.5918  loss: 0.0952  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0952\n",
            "02/09 12:08:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][ 40/166]  lr: 2.0000e-03  eta: 0:23:01  time: 0.2860  data_time: 0.0162  memory: 5737  grad_norm: 1.9383  loss: 0.1255  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1255\n",
            "02/09 12:08:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][ 60/166]  lr: 2.0000e-03  eta: 0:22:56  time: 0.2870  data_time: 0.0168  memory: 5737  grad_norm: 1.9524  loss: 0.1386  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1386\n",
            "02/09 12:08:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][ 80/166]  lr: 2.0000e-03  eta: 0:22:50  time: 0.2860  data_time: 0.0158  memory: 5737  grad_norm: 1.5472  loss: 0.0934  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0934\n",
            "02/09 12:08:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][100/166]  lr: 2.0000e-03  eta: 0:22:44  time: 0.2864  data_time: 0.0162  memory: 5737  grad_norm: 1.8808  loss: 0.1164  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1164\n",
            "02/09 12:08:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][120/166]  lr: 2.0000e-03  eta: 0:22:38  time: 0.2866  data_time: 0.0166  memory: 5737  grad_norm: 1.5337  loss: 0.0990  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0990\n",
            "02/09 12:08:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][140/166]  lr: 2.0000e-03  eta: 0:22:32  time: 0.2866  data_time: 0.0163  memory: 5737  grad_norm: 1.6985  loss: 0.1018  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1018\n",
            "02/09 12:08:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][160/166]  lr: 2.0000e-03  eta: 0:22:27  time: 0.2845  data_time: 0.0150  memory: 5737  grad_norm: 1.2559  loss: 0.0846  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0846\n",
            "02/09 12:08:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:08:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [122][166/166]  lr: 2.0000e-03  eta: 0:22:25  time: 0.2823  data_time: 0.0146  memory: 5737  grad_norm: 1.2739  loss: 0.0870  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0870\n",
            "02/09 12:09:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][ 20/166]  lr: 2.0000e-03  eta: 0:22:19  time: 0.3158  data_time: 0.0443  memory: 5737  grad_norm: 1.4676  loss: 0.0839  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0839\n",
            "02/09 12:09:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][ 40/166]  lr: 2.0000e-03  eta: 0:22:13  time: 0.2861  data_time: 0.0162  memory: 5737  grad_norm: 1.4680  loss: 0.0956  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0956\n",
            "02/09 12:09:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][ 60/166]  lr: 2.0000e-03  eta: 0:22:08  time: 0.2868  data_time: 0.0167  memory: 5737  grad_norm: 2.1001  loss: 0.1290  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1290\n",
            "02/09 12:09:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][ 80/166]  lr: 2.0000e-03  eta: 0:22:02  time: 0.2859  data_time: 0.0159  memory: 5737  grad_norm: 1.7664  loss: 0.1227  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1227\n",
            "02/09 12:09:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][100/166]  lr: 2.0000e-03  eta: 0:21:56  time: 0.2876  data_time: 0.0173  memory: 5737  grad_norm: 1.8764  loss: 0.1404  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1404\n",
            "02/09 12:09:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][120/166]  lr: 2.0000e-03  eta: 0:21:50  time: 0.2842  data_time: 0.0147  memory: 5737  grad_norm: 1.6120  loss: 0.0954  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0954\n",
            "02/09 12:09:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][140/166]  lr: 2.0000e-03  eta: 0:21:44  time: 0.2864  data_time: 0.0160  memory: 5737  grad_norm: 1.9017  loss: 0.1324  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1324\n",
            "02/09 12:09:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][160/166]  lr: 2.0000e-03  eta: 0:21:39  time: 0.2840  data_time: 0.0150  memory: 5737  grad_norm: 1.8341  loss: 0.1116  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1116\n",
            "02/09 12:09:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:09:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [123][166/166]  lr: 2.0000e-03  eta: 0:21:37  time: 0.2817  data_time: 0.0143  memory: 5737  grad_norm: 2.0323  loss: 0.1359  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.1359\n",
            "02/09 12:09:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][ 20/166]  lr: 2.0000e-03  eta: 0:21:31  time: 0.3177  data_time: 0.0460  memory: 5737  grad_norm: 1.6727  loss: 0.1035  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1035\n",
            "02/09 12:09:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][ 40/166]  lr: 2.0000e-03  eta: 0:21:25  time: 0.2858  data_time: 0.0158  memory: 5737  grad_norm: 1.2366  loss: 0.0604  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0604\n",
            "02/09 12:10:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][ 60/166]  lr: 2.0000e-03  eta: 0:21:20  time: 0.2872  data_time: 0.0166  memory: 5737  grad_norm: 1.3332  loss: 0.0739  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0739\n",
            "02/09 12:10:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][ 80/166]  lr: 2.0000e-03  eta: 0:21:14  time: 0.2856  data_time: 0.0156  memory: 5737  grad_norm: 1.5591  loss: 0.0863  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0863\n",
            "02/09 12:10:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][100/166]  lr: 2.0000e-03  eta: 0:21:08  time: 0.2861  data_time: 0.0159  memory: 5737  grad_norm: 1.6356  loss: 0.1087  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1087\n",
            "02/09 12:10:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][120/166]  lr: 2.0000e-03  eta: 0:21:02  time: 0.2870  data_time: 0.0165  memory: 5737  grad_norm: 1.7013  loss: 0.0986  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0986\n",
            "02/09 12:10:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][140/166]  lr: 2.0000e-03  eta: 0:20:56  time: 0.2879  data_time: 0.0174  memory: 5737  grad_norm: 1.9447  loss: 0.1114  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1114\n",
            "02/09 12:10:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][160/166]  lr: 2.0000e-03  eta: 0:20:51  time: 0.2855  data_time: 0.0155  memory: 5737  grad_norm: 1.8421  loss: 0.1067  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1067\n",
            "02/09 12:10:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:10:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [124][166/166]  lr: 2.0000e-03  eta: 0:20:49  time: 0.2819  data_time: 0.0141  memory: 5737  grad_norm: 1.6581  loss: 0.1010  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.1010\n",
            "02/09 12:10:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 124 epochs\n",
            "02/09 12:10:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][ 20/166]  lr: 2.0000e-03  eta: 0:20:43  time: 0.3164  data_time: 0.0449  memory: 5737  grad_norm: 1.8356  loss: 0.1088  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1088\n",
            "02/09 12:10:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][ 40/166]  lr: 2.0000e-03  eta: 0:20:37  time: 0.2854  data_time: 0.0158  memory: 5737  grad_norm: 1.6002  loss: 0.1167  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1167\n",
            "02/09 12:10:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][ 60/166]  lr: 2.0000e-03  eta: 0:20:32  time: 0.2861  data_time: 0.0163  memory: 5737  grad_norm: 1.5422  loss: 0.0905  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0905\n",
            "02/09 12:10:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][ 80/166]  lr: 2.0000e-03  eta: 0:20:26  time: 0.2861  data_time: 0.0162  memory: 5737  grad_norm: 1.3996  loss: 0.0851  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0851\n",
            "02/09 12:11:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][100/166]  lr: 2.0000e-03  eta: 0:20:20  time: 0.2860  data_time: 0.0162  memory: 5737  grad_norm: 1.2069  loss: 0.0724  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.0724\n",
            "02/09 12:11:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][120/166]  lr: 2.0000e-03  eta: 0:20:14  time: 0.2870  data_time: 0.0170  memory: 5737  grad_norm: 1.3666  loss: 0.0890  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0890\n",
            "02/09 12:11:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][140/166]  lr: 2.0000e-03  eta: 0:20:08  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 1.3860  loss: 0.0873  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0873\n",
            "02/09 12:11:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][160/166]  lr: 2.0000e-03  eta: 0:20:03  time: 0.2843  data_time: 0.0148  memory: 5737  grad_norm: 1.6633  loss: 0.0955  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0955\n",
            "02/09 12:11:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:11:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [125][166/166]  lr: 2.0000e-03  eta: 0:20:01  time: 0.2808  data_time: 0.0134  memory: 5737  grad_norm: 2.0975  loss: 0.1057  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.1057\n",
            "02/09 12:11:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [125][20/21]    eta: 0:00:00  time: 0.1420  data_time: 0.0552  memory: 991  \n",
            "02/09 12:11:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [125][21/21]    acc/top1: 0.7651  acc/top5: 1.0000  acc/mean1: 0.7584  data_time: 0.0505  time: 0.1349\n",
            "02/09 12:11:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][ 20/166]  lr: 2.0000e-03  eta: 0:19:55  time: 0.3173  data_time: 0.0458  memory: 5737  grad_norm: 1.6165  loss: 0.0879  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0879\n",
            "02/09 12:11:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][ 40/166]  lr: 2.0000e-03  eta: 0:19:49  time: 0.2855  data_time: 0.0156  memory: 5737  grad_norm: 1.8196  loss: 0.0978  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.0978\n",
            "02/09 12:11:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][ 60/166]  lr: 2.0000e-03  eta: 0:19:43  time: 0.2862  data_time: 0.0163  memory: 5737  grad_norm: 1.4541  loss: 0.0807  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0807\n",
            "02/09 12:11:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][ 80/166]  lr: 2.0000e-03  eta: 0:19:38  time: 0.2850  data_time: 0.0153  memory: 5737  grad_norm: 1.7426  loss: 0.0911  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0911\n",
            "02/09 12:11:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][100/166]  lr: 2.0000e-03  eta: 0:19:32  time: 0.2881  data_time: 0.0174  memory: 5737  grad_norm: 1.6636  loss: 0.1115  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1115\n",
            "02/09 12:11:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][120/166]  lr: 2.0000e-03  eta: 0:19:26  time: 0.2860  data_time: 0.0162  memory: 5737  grad_norm: 1.9569  loss: 0.1197  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1197\n",
            "02/09 12:12:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][140/166]  lr: 2.0000e-03  eta: 0:19:20  time: 0.2883  data_time: 0.0176  memory: 5737  grad_norm: 1.3368  loss: 0.0870  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0870\n",
            "02/09 12:12:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][160/166]  lr: 2.0000e-03  eta: 0:19:14  time: 0.2836  data_time: 0.0144  memory: 5737  grad_norm: 1.3356  loss: 0.0809  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0809\n",
            "02/09 12:12:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:12:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [126][166/166]  lr: 2.0000e-03  eta: 0:19:13  time: 0.2812  data_time: 0.0136  memory: 5737  grad_norm: 1.3340  loss: 0.0944  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.0944\n",
            "02/09 12:12:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][ 20/166]  lr: 2.0000e-03  eta: 0:19:07  time: 0.3185  data_time: 0.0466  memory: 5737  grad_norm: 1.6911  loss: 0.0797  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0797\n",
            "02/09 12:12:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][ 40/166]  lr: 2.0000e-03  eta: 0:19:01  time: 0.2864  data_time: 0.0162  memory: 5737  grad_norm: 1.8415  loss: 0.1113  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1113\n",
            "02/09 12:12:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][ 60/166]  lr: 2.0000e-03  eta: 0:18:55  time: 0.2864  data_time: 0.0166  memory: 5737  grad_norm: 1.4949  loss: 0.1048  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1048\n",
            "02/09 12:12:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][ 80/166]  lr: 2.0000e-03  eta: 0:18:50  time: 0.2860  data_time: 0.0158  memory: 5737  grad_norm: 1.7360  loss: 0.1038  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1038\n",
            "02/09 12:12:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:12:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][100/166]  lr: 2.0000e-03  eta: 0:18:44  time: 0.2860  data_time: 0.0158  memory: 5737  grad_norm: 1.5575  loss: 0.0928  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0928\n",
            "02/09 12:12:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][120/166]  lr: 2.0000e-03  eta: 0:18:38  time: 0.2858  data_time: 0.0157  memory: 5737  grad_norm: 1.7776  loss: 0.1212  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1212\n",
            "02/09 12:12:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][140/166]  lr: 2.0000e-03  eta: 0:18:32  time: 0.2858  data_time: 0.0159  memory: 5737  grad_norm: 1.4493  loss: 0.0767  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0767\n",
            "02/09 12:12:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][160/166]  lr: 2.0000e-03  eta: 0:18:26  time: 0.2849  data_time: 0.0155  memory: 5737  grad_norm: 1.2995  loss: 0.0796  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0796\n",
            "02/09 12:13:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:13:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [127][166/166]  lr: 2.0000e-03  eta: 0:18:25  time: 0.2827  data_time: 0.0149  memory: 5737  grad_norm: 1.4171  loss: 0.0838  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0838\n",
            "02/09 12:13:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][ 20/166]  lr: 2.0000e-03  eta: 0:18:19  time: 0.3158  data_time: 0.0444  memory: 5737  grad_norm: 1.4184  loss: 0.0802  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0802\n",
            "02/09 12:13:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][ 40/166]  lr: 2.0000e-03  eta: 0:18:13  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 1.8154  loss: 0.1175  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.1175\n",
            "02/09 12:13:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][ 60/166]  lr: 2.0000e-03  eta: 0:18:07  time: 0.2870  data_time: 0.0166  memory: 5737  grad_norm: 1.7515  loss: 0.0947  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0947\n",
            "02/09 12:13:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][ 80/166]  lr: 2.0000e-03  eta: 0:18:02  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 1.9391  loss: 0.0939  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0939\n",
            "02/09 12:13:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][100/166]  lr: 2.0000e-03  eta: 0:17:56  time: 0.2881  data_time: 0.0174  memory: 5737  grad_norm: 1.4056  loss: 0.0703  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.0703\n",
            "02/09 12:13:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][120/166]  lr: 2.0000e-03  eta: 0:17:50  time: 0.2850  data_time: 0.0152  memory: 5737  grad_norm: 1.7915  loss: 0.1153  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1153\n",
            "02/09 12:13:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][140/166]  lr: 2.0000e-03  eta: 0:17:44  time: 0.2863  data_time: 0.0161  memory: 5737  grad_norm: 1.4061  loss: 0.0822  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0822\n",
            "02/09 12:13:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][160/166]  lr: 2.0000e-03  eta: 0:17:38  time: 0.2844  data_time: 0.0153  memory: 5737  grad_norm: 1.4026  loss: 0.0772  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0772\n",
            "02/09 12:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [128][166/166]  lr: 2.0000e-03  eta: 0:17:37  time: 0.2814  data_time: 0.0142  memory: 5737  grad_norm: 1.9479  loss: 0.1135  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1135\n",
            "02/09 12:13:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 128 epochs\n",
            "02/09 12:13:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][ 20/166]  lr: 2.0000e-03  eta: 0:17:31  time: 0.3176  data_time: 0.0465  memory: 5737  grad_norm: 2.2922  loss: 0.1164  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1164\n",
            "02/09 12:14:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][ 40/166]  lr: 2.0000e-03  eta: 0:17:25  time: 0.2864  data_time: 0.0163  memory: 5737  grad_norm: 1.5368  loss: 0.0819  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0819\n",
            "02/09 12:14:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][ 60/166]  lr: 2.0000e-03  eta: 0:17:19  time: 0.2868  data_time: 0.0162  memory: 5737  grad_norm: 1.8054  loss: 0.1169  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1169\n",
            "02/09 12:14:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][ 80/166]  lr: 2.0000e-03  eta: 0:17:14  time: 0.2849  data_time: 0.0154  memory: 5737  grad_norm: 2.2173  loss: 0.1243  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.1243\n",
            "02/09 12:14:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][100/166]  lr: 2.0000e-03  eta: 0:17:08  time: 0.2858  data_time: 0.0159  memory: 5737  grad_norm: 1.5764  loss: 0.1039  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1039\n",
            "02/09 12:14:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][120/166]  lr: 2.0000e-03  eta: 0:17:02  time: 0.2858  data_time: 0.0160  memory: 5737  grad_norm: 1.9214  loss: 0.1021  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1021\n",
            "02/09 12:14:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][140/166]  lr: 2.0000e-03  eta: 0:16:56  time: 0.2864  data_time: 0.0159  memory: 5737  grad_norm: 2.1033  loss: 0.1115  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1115\n",
            "02/09 12:14:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][160/166]  lr: 2.0000e-03  eta: 0:16:50  time: 0.2851  data_time: 0.0155  memory: 5737  grad_norm: 1.7011  loss: 0.0977  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0977\n",
            "02/09 12:14:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:14:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [129][166/166]  lr: 2.0000e-03  eta: 0:16:49  time: 0.2824  data_time: 0.0146  memory: 5737  grad_norm: 1.6216  loss: 0.1011  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1011\n",
            "02/09 12:14:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][ 20/166]  lr: 2.0000e-03  eta: 0:16:43  time: 0.3191  data_time: 0.0469  memory: 5737  grad_norm: 1.3756  loss: 0.0807  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0807\n",
            "02/09 12:14:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][ 40/166]  lr: 2.0000e-03  eta: 0:16:37  time: 0.2851  data_time: 0.0153  memory: 5737  grad_norm: 1.5729  loss: 0.0914  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0914\n",
            "02/09 12:14:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][ 60/166]  lr: 2.0000e-03  eta: 0:16:31  time: 0.2869  data_time: 0.0165  memory: 5737  grad_norm: 2.0676  loss: 0.1422  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1422\n",
            "02/09 12:15:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][ 80/166]  lr: 2.0000e-03  eta: 0:16:25  time: 0.2858  data_time: 0.0158  memory: 5737  grad_norm: 2.1458  loss: 0.1349  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1349\n",
            "02/09 12:15:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][100/166]  lr: 2.0000e-03  eta: 0:16:20  time: 0.2857  data_time: 0.0154  memory: 5737  grad_norm: 1.0690  loss: 0.0724  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0724\n",
            "02/09 12:15:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][120/166]  lr: 2.0000e-03  eta: 0:16:14  time: 0.2857  data_time: 0.0157  memory: 5737  grad_norm: 1.6434  loss: 0.1095  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.1095\n",
            "02/09 12:15:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][140/166]  lr: 2.0000e-03  eta: 0:16:08  time: 0.2857  data_time: 0.0158  memory: 5737  grad_norm: 1.8093  loss: 0.1235  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1235\n",
            "02/09 12:15:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][160/166]  lr: 2.0000e-03  eta: 0:16:02  time: 0.2854  data_time: 0.0158  memory: 5737  grad_norm: 1.6525  loss: 0.1108  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1108\n",
            "02/09 12:15:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:15:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [130][166/166]  lr: 2.0000e-03  eta: 0:16:01  time: 0.2819  data_time: 0.0142  memory: 5737  grad_norm: 1.6187  loss: 0.0957  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0957\n",
            "02/09 12:15:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [130][20/21]    eta: 0:00:00  time: 0.1420  data_time: 0.0578  memory: 991  \n",
            "02/09 12:15:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [130][21/21]    acc/top1: 0.7620  acc/top5: 1.0000  acc/mean1: 0.7536  data_time: 0.0528  time: 0.1349\n",
            "02/09 12:15:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][ 20/166]  lr: 2.0000e-03  eta: 0:15:55  time: 0.3175  data_time: 0.0449  memory: 5737  grad_norm: 1.5180  loss: 0.0782  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0782\n",
            "02/09 12:15:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][ 40/166]  lr: 2.0000e-03  eta: 0:15:49  time: 0.2847  data_time: 0.0148  memory: 5737  grad_norm: 1.8007  loss: 0.1025  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1025\n",
            "02/09 12:15:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][ 60/166]  lr: 2.0000e-03  eta: 0:15:43  time: 0.2865  data_time: 0.0164  memory: 5737  grad_norm: 1.6560  loss: 0.1126  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1126\n",
            "02/09 12:15:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][ 80/166]  lr: 2.0000e-03  eta: 0:15:37  time: 0.2864  data_time: 0.0161  memory: 5737  grad_norm: 2.0688  loss: 0.1676  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1676\n",
            "02/09 12:15:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][100/166]  lr: 2.0000e-03  eta: 0:15:32  time: 0.2866  data_time: 0.0164  memory: 5737  grad_norm: 2.2929  loss: 0.1420  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1420\n",
            "02/09 12:16:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][120/166]  lr: 2.0000e-03  eta: 0:15:26  time: 0.2859  data_time: 0.0157  memory: 5737  grad_norm: 1.3256  loss: 0.0855  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.0855\n",
            "02/09 12:16:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][140/166]  lr: 2.0000e-03  eta: 0:15:20  time: 0.2876  data_time: 0.0174  memory: 5737  grad_norm: 1.5833  loss: 0.0988  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0988\n",
            "02/09 12:16:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][160/166]  lr: 2.0000e-03  eta: 0:15:14  time: 0.2856  data_time: 0.0158  memory: 5737  grad_norm: 1.1010  loss: 0.0588  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0588\n",
            "02/09 12:16:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:16:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [131][166/166]  lr: 2.0000e-03  eta: 0:15:12  time: 0.2839  data_time: 0.0159  memory: 5737  grad_norm: 1.1217  loss: 0.0706  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0706\n",
            "02/09 12:16:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][ 20/166]  lr: 2.0000e-03  eta: 0:15:07  time: 0.3151  data_time: 0.0440  memory: 5737  grad_norm: 1.7018  loss: 0.0923  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.0923\n",
            "02/09 12:16:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][ 40/166]  lr: 2.0000e-03  eta: 0:15:01  time: 0.2853  data_time: 0.0155  memory: 5737  grad_norm: 1.6608  loss: 0.1037  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1037\n",
            "02/09 12:16:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][ 60/166]  lr: 2.0000e-03  eta: 0:14:55  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 1.3106  loss: 0.0999  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0999\n",
            "02/09 12:16:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][ 80/166]  lr: 2.0000e-03  eta: 0:14:49  time: 0.2862  data_time: 0.0157  memory: 5737  grad_norm: 1.2532  loss: 0.0741  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0741\n",
            "02/09 12:16:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][100/166]  lr: 2.0000e-03  eta: 0:14:44  time: 0.2861  data_time: 0.0156  memory: 5737  grad_norm: 1.5664  loss: 0.1031  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1031\n",
            "02/09 12:16:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][120/166]  lr: 2.0000e-03  eta: 0:14:38  time: 0.2865  data_time: 0.0161  memory: 5737  grad_norm: 1.3784  loss: 0.0768  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0768\n",
            "02/09 12:16:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][140/166]  lr: 2.0000e-03  eta: 0:14:32  time: 0.2866  data_time: 0.0161  memory: 5737  grad_norm: 1.8864  loss: 0.0999  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0999\n",
            "02/09 12:17:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][160/166]  lr: 2.0000e-03  eta: 0:14:26  time: 0.2844  data_time: 0.0149  memory: 5737  grad_norm: 2.3398  loss: 0.1387  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1387\n",
            "02/09 12:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [132][166/166]  lr: 2.0000e-03  eta: 0:14:24  time: 0.2820  data_time: 0.0141  memory: 5737  grad_norm: 2.3294  loss: 0.1229  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.1229\n",
            "02/09 12:17:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 132 epochs\n",
            "02/09 12:17:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][ 20/166]  lr: 2.0000e-03  eta: 0:14:19  time: 0.3185  data_time: 0.0459  memory: 5737  grad_norm: 1.7179  loss: 0.1047  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1047\n",
            "02/09 12:17:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][ 40/166]  lr: 2.0000e-03  eta: 0:14:13  time: 0.2865  data_time: 0.0160  memory: 5737  grad_norm: 1.5760  loss: 0.0914  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0914\n",
            "02/09 12:17:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][ 60/166]  lr: 2.0000e-03  eta: 0:14:07  time: 0.2864  data_time: 0.0160  memory: 5737  grad_norm: 1.4180  loss: 0.0816  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0816\n",
            "02/09 12:17:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][ 80/166]  lr: 2.0000e-03  eta: 0:14:01  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 1.7998  loss: 0.1156  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.1156\n",
            "02/09 12:17:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:17:35 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][100/166]  lr: 2.0000e-03  eta: 0:13:56  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 1.7437  loss: 0.0848  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0848\n",
            "02/09 12:17:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][120/166]  lr: 2.0000e-03  eta: 0:13:50  time: 0.2863  data_time: 0.0159  memory: 5737  grad_norm: 1.7043  loss: 0.1083  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.1083\n",
            "02/09 12:17:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][140/166]  lr: 2.0000e-03  eta: 0:13:44  time: 0.2881  data_time: 0.0173  memory: 5737  grad_norm: 2.4131  loss: 0.1532  top1_acc: 0.6875  top5_acc: 1.0000  loss_cls: 0.1532\n",
            "02/09 12:17:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][160/166]  lr: 2.0000e-03  eta: 0:13:38  time: 0.2848  data_time: 0.0150  memory: 5737  grad_norm: 1.5492  loss: 0.0860  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0860\n",
            "02/09 12:17:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:17:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [133][166/166]  lr: 2.0000e-03  eta: 0:13:36  time: 0.2821  data_time: 0.0144  memory: 5737  grad_norm: 2.0625  loss: 0.1196  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.1196\n",
            "02/09 12:18:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][ 20/166]  lr: 2.0000e-03  eta: 0:13:31  time: 0.3156  data_time: 0.0425  memory: 5737  grad_norm: 1.2550  loss: 0.0680  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0680\n",
            "02/09 12:18:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][ 40/166]  lr: 2.0000e-03  eta: 0:13:25  time: 0.2870  data_time: 0.0168  memory: 5737  grad_norm: 1.9349  loss: 0.1018  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1018\n",
            "02/09 12:18:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][ 60/166]  lr: 2.0000e-03  eta: 0:13:19  time: 0.2867  data_time: 0.0161  memory: 5737  grad_norm: 1.5068  loss: 0.0941  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0941\n",
            "02/09 12:18:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][ 80/166]  lr: 2.0000e-03  eta: 0:13:13  time: 0.2858  data_time: 0.0155  memory: 5737  grad_norm: 1.3504  loss: 0.1006  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1006\n",
            "02/09 12:18:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][100/166]  lr: 2.0000e-03  eta: 0:13:07  time: 0.2867  data_time: 0.0162  memory: 5737  grad_norm: 1.7610  loss: 0.1194  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1194\n",
            "02/09 12:18:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][120/166]  lr: 2.0000e-03  eta: 0:13:02  time: 0.2859  data_time: 0.0158  memory: 5737  grad_norm: 1.5321  loss: 0.0984  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0984\n",
            "02/09 12:18:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][140/166]  lr: 2.0000e-03  eta: 0:12:56  time: 0.2859  data_time: 0.0156  memory: 5737  grad_norm: 2.1130  loss: 0.1156  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1156\n",
            "02/09 12:18:40 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][160/166]  lr: 2.0000e-03  eta: 0:12:50  time: 0.2849  data_time: 0.0154  memory: 5737  grad_norm: 1.8482  loss: 0.0970  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0970\n",
            "02/09 12:18:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:18:41 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [134][166/166]  lr: 2.0000e-03  eta: 0:12:48  time: 0.2819  data_time: 0.0144  memory: 5737  grad_norm: 1.8069  loss: 0.1073  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1073\n",
            "02/09 12:18:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][ 20/166]  lr: 2.0000e-03  eta: 0:12:43  time: 0.3250  data_time: 0.0536  memory: 5737  grad_norm: 1.5298  loss: 0.0910  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0910\n",
            "02/09 12:18:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][ 40/166]  lr: 2.0000e-03  eta: 0:12:37  time: 0.2867  data_time: 0.0164  memory: 5737  grad_norm: 1.5917  loss: 0.0884  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0884\n",
            "02/09 12:18:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][ 60/166]  lr: 2.0000e-03  eta: 0:12:31  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 1.5930  loss: 0.0933  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0933\n",
            "02/09 12:19:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][ 80/166]  lr: 2.0000e-03  eta: 0:12:25  time: 0.2864  data_time: 0.0161  memory: 5737  grad_norm: 1.2711  loss: 0.0892  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0892\n",
            "02/09 12:19:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][100/166]  lr: 2.0000e-03  eta: 0:12:19  time: 0.2866  data_time: 0.0161  memory: 5737  grad_norm: 1.9240  loss: 0.1212  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1212\n",
            "02/09 12:19:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][120/166]  lr: 2.0000e-03  eta: 0:12:14  time: 0.2864  data_time: 0.0163  memory: 5737  grad_norm: 2.0439  loss: 0.1063  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1063\n",
            "02/09 12:19:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][140/166]  lr: 2.0000e-03  eta: 0:12:08  time: 0.2859  data_time: 0.0157  memory: 5737  grad_norm: 1.5428  loss: 0.0871  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0871\n",
            "02/09 12:19:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][160/166]  lr: 2.0000e-03  eta: 0:12:02  time: 0.2849  data_time: 0.0150  memory: 5737  grad_norm: 1.7386  loss: 0.0847  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0847\n",
            "02/09 12:19:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:19:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [135][166/166]  lr: 2.0000e-03  eta: 0:12:00  time: 0.2829  data_time: 0.0147  memory: 5737  grad_norm: 1.4020  loss: 0.0787  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.0787\n",
            "02/09 12:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [135][20/21]    eta: 0:00:00  time: 0.1394  data_time: 0.0548  memory: 991  \n",
            "02/09 12:19:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [135][21/21]    acc/top1: 0.7801  acc/top5: 1.0000  acc/mean1: 0.7749  data_time: 0.0501  time: 0.1324\n",
            "02/09 12:19:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][ 20/166]  lr: 2.0000e-03  eta: 0:11:55  time: 0.3158  data_time: 0.0433  memory: 5737  grad_norm: 1.7464  loss: 0.1263  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1263\n",
            "02/09 12:19:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][ 40/166]  lr: 2.0000e-03  eta: 0:11:49  time: 0.2854  data_time: 0.0160  memory: 5737  grad_norm: 1.5336  loss: 0.0857  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0857\n",
            "02/09 12:19:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][ 60/166]  lr: 2.0000e-03  eta: 0:11:43  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 1.4538  loss: 0.0650  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0650\n",
            "02/09 12:19:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][ 80/166]  lr: 2.0000e-03  eta: 0:11:37  time: 0.2853  data_time: 0.0154  memory: 5737  grad_norm: 1.4313  loss: 0.0816  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0816\n",
            "02/09 12:20:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][100/166]  lr: 2.0000e-03  eta: 0:11:31  time: 0.2875  data_time: 0.0170  memory: 5737  grad_norm: 2.3190  loss: 0.1294  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1294\n",
            "02/09 12:20:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][120/166]  lr: 2.0000e-03  eta: 0:11:26  time: 0.2865  data_time: 0.0165  memory: 5737  grad_norm: 1.8554  loss: 0.0880  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0880\n",
            "02/09 12:20:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][140/166]  lr: 2.0000e-03  eta: 0:11:20  time: 0.2862  data_time: 0.0161  memory: 5737  grad_norm: 1.4619  loss: 0.0803  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0803\n",
            "02/09 12:20:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][160/166]  lr: 2.0000e-03  eta: 0:11:14  time: 0.2851  data_time: 0.0157  memory: 5737  grad_norm: 1.7470  loss: 0.1091  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1091\n",
            "02/09 12:20:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:20:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [136][166/166]  lr: 2.0000e-03  eta: 0:11:12  time: 0.2827  data_time: 0.0150  memory: 5737  grad_norm: 1.8537  loss: 0.1203  top1_acc: 0.8571  top5_acc: 1.0000  loss_cls: 0.1203\n",
            "02/09 12:20:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 136 epochs\n",
            "02/09 12:20:28 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][ 20/166]  lr: 2.0000e-03  eta: 0:11:07  time: 0.3197  data_time: 0.0482  memory: 5737  grad_norm: 1.4056  loss: 0.0656  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0656\n",
            "02/09 12:20:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][ 40/166]  lr: 2.0000e-03  eta: 0:11:01  time: 0.2857  data_time: 0.0157  memory: 5737  grad_norm: 1.4882  loss: 0.0903  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0903\n",
            "02/09 12:20:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][ 60/166]  lr: 2.0000e-03  eta: 0:10:55  time: 0.2874  data_time: 0.0170  memory: 5737  grad_norm: 2.1043  loss: 0.1138  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1138\n",
            "02/09 12:20:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][ 80/166]  lr: 2.0000e-03  eta: 0:10:49  time: 0.2850  data_time: 0.0151  memory: 5737  grad_norm: 1.9038  loss: 0.1022  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1022\n",
            "02/09 12:20:51 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][100/166]  lr: 2.0000e-03  eta: 0:10:43  time: 0.2876  data_time: 0.0171  memory: 5737  grad_norm: 1.7066  loss: 0.1103  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1103\n",
            "02/09 12:20:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][120/166]  lr: 2.0000e-03  eta: 0:10:38  time: 0.2856  data_time: 0.0157  memory: 5737  grad_norm: 1.7458  loss: 0.0985  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0985\n",
            "02/09 12:21:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][140/166]  lr: 2.0000e-03  eta: 0:10:32  time: 0.2875  data_time: 0.0169  memory: 5737  grad_norm: 1.4844  loss: 0.0861  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0861\n",
            "02/09 12:21:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][160/166]  lr: 2.0000e-03  eta: 0:10:26  time: 0.2849  data_time: 0.0150  memory: 5737  grad_norm: 2.1132  loss: 0.1065  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1065\n",
            "02/09 12:21:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:21:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [137][166/166]  lr: 2.0000e-03  eta: 0:10:24  time: 0.2822  data_time: 0.0144  memory: 5737  grad_norm: 1.9615  loss: 0.1052  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1052\n",
            "02/09 12:21:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][ 20/166]  lr: 2.0000e-03  eta: 0:10:18  time: 0.3204  data_time: 0.0480  memory: 5737  grad_norm: 1.6102  loss: 0.0882  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0882\n",
            "02/09 12:21:22 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][ 40/166]  lr: 2.0000e-03  eta: 0:10:13  time: 0.2857  data_time: 0.0157  memory: 5737  grad_norm: 2.0536  loss: 0.1102  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1102\n",
            "02/09 12:21:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][ 60/166]  lr: 2.0000e-03  eta: 0:10:07  time: 0.2873  data_time: 0.0169  memory: 5737  grad_norm: 1.7959  loss: 0.0872  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.0872\n",
            "02/09 12:21:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][ 80/166]  lr: 2.0000e-03  eta: 0:10:01  time: 0.2866  data_time: 0.0162  memory: 5737  grad_norm: 2.1131  loss: 0.1307  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1307\n",
            "02/09 12:21:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][100/166]  lr: 2.0000e-03  eta: 0:09:55  time: 0.2877  data_time: 0.0174  memory: 5737  grad_norm: 1.9354  loss: 0.0962  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0962\n",
            "02/09 12:21:45 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][120/166]  lr: 2.0000e-03  eta: 0:09:49  time: 0.2847  data_time: 0.0148  memory: 5737  grad_norm: 1.6436  loss: 0.0897  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0897\n",
            "02/09 12:21:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][140/166]  lr: 2.0000e-03  eta: 0:09:44  time: 0.2860  data_time: 0.0157  memory: 5737  grad_norm: 1.6031  loss: 0.0877  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0877\n",
            "02/09 12:21:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][160/166]  lr: 2.0000e-03  eta: 0:09:38  time: 0.2843  data_time: 0.0149  memory: 5737  grad_norm: 1.4804  loss: 0.0826  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0826\n",
            "02/09 12:21:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:21:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [138][166/166]  lr: 2.0000e-03  eta: 0:09:36  time: 0.2826  data_time: 0.0148  memory: 5737  grad_norm: 1.6911  loss: 0.1043  top1_acc: 0.7857  top5_acc: 1.0000  loss_cls: 0.1043\n",
            "02/09 12:22:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][ 20/166]  lr: 2.0000e-03  eta: 0:09:30  time: 0.3189  data_time: 0.0466  memory: 5737  grad_norm: 1.5323  loss: 0.0913  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0913\n",
            "02/09 12:22:10 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][ 40/166]  lr: 2.0000e-03  eta: 0:09:25  time: 0.2856  data_time: 0.0156  memory: 5737  grad_norm: 1.9366  loss: 0.1226  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1226\n",
            "02/09 12:22:16 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][ 60/166]  lr: 2.0000e-03  eta: 0:09:19  time: 0.2878  data_time: 0.0172  memory: 5737  grad_norm: 1.2539  loss: 0.0719  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0719\n",
            "02/09 12:22:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][ 80/166]  lr: 2.0000e-03  eta: 0:09:13  time: 0.2864  data_time: 0.0163  memory: 5737  grad_norm: 1.9511  loss: 0.1145  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1145\n",
            "02/09 12:22:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:22:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][100/166]  lr: 2.0000e-03  eta: 0:09:07  time: 0.2878  data_time: 0.0175  memory: 5737  grad_norm: 2.1220  loss: 0.1401  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1401\n",
            "02/09 12:22:33 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][120/166]  lr: 2.0000e-03  eta: 0:09:01  time: 0.2855  data_time: 0.0155  memory: 5737  grad_norm: 1.8022  loss: 0.1068  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1068\n",
            "02/09 12:22:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][140/166]  lr: 2.0000e-03  eta: 0:08:56  time: 0.2863  data_time: 0.0159  memory: 5737  grad_norm: 1.8848  loss: 0.0992  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0992\n",
            "02/09 12:22:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][160/166]  lr: 2.0000e-03  eta: 0:08:50  time: 0.2850  data_time: 0.0151  memory: 5737  grad_norm: 1.2857  loss: 0.0777  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0777\n",
            "02/09 12:22:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:22:46 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [139][166/166]  lr: 2.0000e-03  eta: 0:08:48  time: 0.2825  data_time: 0.0145  memory: 5737  grad_norm: 1.2675  loss: 0.0724  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0724\n",
            "02/09 12:22:52 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][ 20/166]  lr: 2.0000e-03  eta: 0:08:42  time: 0.3154  data_time: 0.0438  memory: 5737  grad_norm: 1.0986  loss: 0.0522  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0522\n",
            "02/09 12:22:58 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][ 40/166]  lr: 2.0000e-03  eta: 0:08:37  time: 0.2857  data_time: 0.0155  memory: 5737  grad_norm: 1.1929  loss: 0.0691  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0691\n",
            "02/09 12:23:04 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][ 60/166]  lr: 2.0000e-03  eta: 0:08:31  time: 0.2863  data_time: 0.0160  memory: 5737  grad_norm: 2.3337  loss: 0.1288  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1288\n",
            "02/09 12:23:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][ 80/166]  lr: 2.0000e-03  eta: 0:08:25  time: 0.2865  data_time: 0.0161  memory: 5737  grad_norm: 1.5130  loss: 0.0724  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0724\n",
            "02/09 12:23:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][100/166]  lr: 2.0000e-03  eta: 0:08:19  time: 0.2868  data_time: 0.0165  memory: 5737  grad_norm: 1.2573  loss: 0.0699  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0699\n",
            "02/09 12:23:21 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][120/166]  lr: 2.0000e-03  eta: 0:08:13  time: 0.2853  data_time: 0.0150  memory: 5737  grad_norm: 1.3893  loss: 0.0752  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.0752\n",
            "02/09 12:23:27 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][140/166]  lr: 2.0000e-03  eta: 0:08:08  time: 0.2861  data_time: 0.0157  memory: 5737  grad_norm: 1.7562  loss: 0.1080  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1080\n",
            "02/09 12:23:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][160/166]  lr: 2.0000e-03  eta: 0:08:02  time: 0.2847  data_time: 0.0151  memory: 5737  grad_norm: 1.5814  loss: 0.0897  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0897\n",
            "02/09 12:23:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:23:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [140][166/166]  lr: 2.0000e-03  eta: 0:08:00  time: 0.2824  data_time: 0.0146  memory: 5737  grad_norm: 1.6626  loss: 0.0852  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0852\n",
            "02/09 12:23:34 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 140 epochs\n",
            "02/09 12:23:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [140][20/21]    eta: 0:00:00  time: 0.1394  data_time: 0.0544  memory: 991  \n",
            "02/09 12:23:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [140][21/21]    acc/top1: 0.7651  acc/top5: 1.0000  acc/mean1: 0.7588  data_time: 0.0497  time: 0.1325\n",
            "02/09 12:23:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][ 20/166]  lr: 2.0000e-04  eta: 0:07:54  time: 0.3242  data_time: 0.0522  memory: 5737  grad_norm: 1.4919  loss: 0.0837  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0837\n",
            "02/09 12:23:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][ 40/166]  lr: 2.0000e-04  eta: 0:07:49  time: 0.2853  data_time: 0.0157  memory: 5737  grad_norm: 1.5969  loss: 0.0876  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0876\n",
            "02/09 12:23:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][ 60/166]  lr: 2.0000e-04  eta: 0:07:43  time: 0.2863  data_time: 0.0161  memory: 5737  grad_norm: 1.8877  loss: 0.1000  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1000\n",
            "02/09 12:24:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][ 80/166]  lr: 2.0000e-04  eta: 0:07:37  time: 0.2858  data_time: 0.0160  memory: 5737  grad_norm: 1.3722  loss: 0.0796  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0796\n",
            "02/09 12:24:07 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][100/166]  lr: 2.0000e-04  eta: 0:07:31  time: 0.2874  data_time: 0.0166  memory: 5737  grad_norm: 1.4687  loss: 0.0968  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0968\n",
            "02/09 12:24:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][120/166]  lr: 2.0000e-04  eta: 0:07:25  time: 0.2847  data_time: 0.0147  memory: 5737  grad_norm: 1.5030  loss: 0.0875  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0875\n",
            "02/09 12:24:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][140/166]  lr: 2.0000e-04  eta: 0:07:20  time: 0.2879  data_time: 0.0170  memory: 5737  grad_norm: 1.7675  loss: 0.0988  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0988\n",
            "02/09 12:24:24 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][160/166]  lr: 2.0000e-04  eta: 0:07:14  time: 0.2851  data_time: 0.0156  memory: 5737  grad_norm: 1.6165  loss: 0.1214  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1214\n",
            "02/09 12:24:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:24:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [141][166/166]  lr: 2.0000e-04  eta: 0:07:12  time: 0.2826  data_time: 0.0149  memory: 5737  grad_norm: 1.7816  loss: 0.1157  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1157\n",
            "02/09 12:24:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][ 20/166]  lr: 2.0000e-04  eta: 0:07:06  time: 0.3157  data_time: 0.0436  memory: 5737  grad_norm: 1.4789  loss: 0.0826  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0826\n",
            "02/09 12:24:38 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][ 40/166]  lr: 2.0000e-04  eta: 0:07:00  time: 0.2859  data_time: 0.0155  memory: 5737  grad_norm: 1.3134  loss: 0.0749  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0749\n",
            "02/09 12:24:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][ 60/166]  lr: 2.0000e-04  eta: 0:06:55  time: 0.2866  data_time: 0.0163  memory: 5737  grad_norm: 1.5963  loss: 0.1008  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1008\n",
            "02/09 12:24:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][ 80/166]  lr: 2.0000e-04  eta: 0:06:49  time: 0.2864  data_time: 0.0159  memory: 5737  grad_norm: 1.3388  loss: 0.0908  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0908\n",
            "02/09 12:24:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][100/166]  lr: 2.0000e-04  eta: 0:06:43  time: 0.2870  data_time: 0.0164  memory: 5737  grad_norm: 1.7927  loss: 0.0966  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0966\n",
            "02/09 12:25:01 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][120/166]  lr: 2.0000e-04  eta: 0:06:37  time: 0.2861  data_time: 0.0158  memory: 5737  grad_norm: 1.7173  loss: 0.1021  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1021\n",
            "02/09 12:25:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][140/166]  lr: 2.0000e-04  eta: 0:06:31  time: 0.2868  data_time: 0.0165  memory: 5737  grad_norm: 1.5327  loss: 0.0930  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0930\n",
            "02/09 12:25:12 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][160/166]  lr: 2.0000e-04  eta: 0:06:26  time: 0.2838  data_time: 0.0143  memory: 5737  grad_norm: 1.6181  loss: 0.0944  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0944\n",
            "02/09 12:25:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:25:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [142][166/166]  lr: 2.0000e-04  eta: 0:06:24  time: 0.2820  data_time: 0.0140  memory: 5737  grad_norm: 1.5034  loss: 0.0885  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0885\n",
            "02/09 12:25:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][ 20/166]  lr: 2.0000e-04  eta: 0:06:18  time: 0.3207  data_time: 0.0492  memory: 5737  grad_norm: 1.6961  loss: 0.1117  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1117\n",
            "02/09 12:25:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][ 40/166]  lr: 2.0000e-04  eta: 0:06:12  time: 0.2856  data_time: 0.0157  memory: 5737  grad_norm: 1.7499  loss: 0.1090  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1090\n",
            "02/09 12:25:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][ 60/166]  lr: 2.0000e-04  eta: 0:06:07  time: 0.2869  data_time: 0.0162  memory: 5737  grad_norm: 1.4639  loss: 0.0769  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0769\n",
            "02/09 12:25:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][ 80/166]  lr: 2.0000e-04  eta: 0:06:01  time: 0.2861  data_time: 0.0157  memory: 5737  grad_norm: 0.9403  loss: 0.0546  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0546\n",
            "02/09 12:25:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][100/166]  lr: 2.0000e-04  eta: 0:05:55  time: 0.2870  data_time: 0.0163  memory: 5737  grad_norm: 1.8968  loss: 0.1010  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1010\n",
            "02/09 12:25:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][120/166]  lr: 2.0000e-04  eta: 0:05:49  time: 0.2860  data_time: 0.0160  memory: 5737  grad_norm: 2.0683  loss: 0.1123  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1123\n",
            "02/09 12:25:55 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][140/166]  lr: 2.0000e-04  eta: 0:05:43  time: 0.2874  data_time: 0.0168  memory: 5737  grad_norm: 1.6849  loss: 0.0913  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0913\n",
            "02/09 12:26:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][160/166]  lr: 2.0000e-04  eta: 0:05:38  time: 0.2846  data_time: 0.0149  memory: 5737  grad_norm: 1.9222  loss: 0.1100  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1100\n",
            "02/09 12:26:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:26:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [143][166/166]  lr: 2.0000e-04  eta: 0:05:36  time: 0.2829  data_time: 0.0149  memory: 5737  grad_norm: 1.9221  loss: 0.0992  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.0992\n",
            "02/09 12:26:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][ 20/166]  lr: 2.0000e-04  eta: 0:05:30  time: 0.3185  data_time: 0.0458  memory: 5737  grad_norm: 1.1535  loss: 0.0694  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0694\n",
            "02/09 12:26:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][ 40/166]  lr: 2.0000e-04  eta: 0:05:24  time: 0.2849  data_time: 0.0150  memory: 5737  grad_norm: 1.5861  loss: 0.0956  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0956\n",
            "02/09 12:26:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][ 60/166]  lr: 2.0000e-04  eta: 0:05:19  time: 0.2866  data_time: 0.0163  memory: 5737  grad_norm: 1.5810  loss: 0.1030  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1030\n",
            "02/09 12:26:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][ 80/166]  lr: 2.0000e-04  eta: 0:05:13  time: 0.2861  data_time: 0.0161  memory: 5737  grad_norm: 1.7224  loss: 0.1038  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1038\n",
            "02/09 12:26:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][100/166]  lr: 2.0000e-04  eta: 0:05:07  time: 0.2866  data_time: 0.0162  memory: 5737  grad_norm: 1.6047  loss: 0.0825  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0825\n",
            "02/09 12:26:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][120/166]  lr: 2.0000e-04  eta: 0:05:01  time: 0.2853  data_time: 0.0153  memory: 5737  grad_norm: 1.4469  loss: 0.0914  top1_acc: 0.8125  top5_acc: 1.0000  loss_cls: 0.0914\n",
            "02/09 12:26:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][140/166]  lr: 2.0000e-04  eta: 0:04:55  time: 0.2869  data_time: 0.0162  memory: 5737  grad_norm: 1.6958  loss: 0.1120  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1120\n",
            "02/09 12:26:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][160/166]  lr: 2.0000e-04  eta: 0:04:50  time: 0.2859  data_time: 0.0160  memory: 5737  grad_norm: 1.7705  loss: 0.0853  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0853\n",
            "02/09 12:26:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:26:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [144][166/166]  lr: 2.0000e-04  eta: 0:04:48  time: 0.2823  data_time: 0.0145  memory: 5737  grad_norm: 1.6301  loss: 0.0793  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.0793\n",
            "02/09 12:26:50 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 144 epochs\n",
            "02/09 12:26:57 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][ 20/166]  lr: 2.0000e-04  eta: 0:04:42  time: 0.3268  data_time: 0.0555  memory: 5737  grad_norm: 1.9411  loss: 0.1193  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1193\n",
            "02/09 12:27:03 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][ 40/166]  lr: 2.0000e-04  eta: 0:04:36  time: 0.2865  data_time: 0.0163  memory: 5737  grad_norm: 1.6860  loss: 0.1074  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1074\n",
            "02/09 12:27:09 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][ 60/166]  lr: 2.0000e-04  eta: 0:04:30  time: 0.2872  data_time: 0.0169  memory: 5737  grad_norm: 2.0835  loss: 0.1029  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1029\n",
            "02/09 12:27:15 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][ 80/166]  lr: 2.0000e-04  eta: 0:04:25  time: 0.2847  data_time: 0.0150  memory: 5737  grad_norm: 2.0264  loss: 0.1021  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1021\n",
            "02/09 12:27:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:27:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][100/166]  lr: 2.0000e-04  eta: 0:04:19  time: 0.2871  data_time: 0.0166  memory: 5737  grad_norm: 1.4497  loss: 0.0836  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0836\n",
            "02/09 12:27:26 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][120/166]  lr: 2.0000e-04  eta: 0:04:13  time: 0.2860  data_time: 0.0158  memory: 5737  grad_norm: 1.1524  loss: 0.0518  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0518\n",
            "02/09 12:27:32 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][140/166]  lr: 2.0000e-04  eta: 0:04:07  time: 0.2869  data_time: 0.0166  memory: 5737  grad_norm: 1.3561  loss: 0.0907  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.0907\n",
            "02/09 12:27:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][160/166]  lr: 2.0000e-04  eta: 0:04:02  time: 0.2854  data_time: 0.0158  memory: 5737  grad_norm: 1.4442  loss: 0.0850  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.0850\n",
            "02/09 12:27:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:27:39 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [145][166/166]  lr: 2.0000e-04  eta: 0:04:00  time: 0.2823  data_time: 0.0146  memory: 5737  grad_norm: 1.5666  loss: 0.0892  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0892\n",
            "02/09 12:27:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [145][20/21]    eta: 0:00:00  time: 0.1405  data_time: 0.0550  memory: 991  \n",
            "02/09 12:27:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [145][21/21]    acc/top1: 0.7651  acc/top5: 1.0000  acc/mean1: 0.7596  data_time: 0.0503  time: 0.1335\n",
            "02/09 12:27:49 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][ 20/166]  lr: 2.0000e-04  eta: 0:03:54  time: 0.3232  data_time: 0.0499  memory: 5737  grad_norm: 1.3408  loss: 0.0809  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.0809\n",
            "02/09 12:27:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][ 40/166]  lr: 2.0000e-04  eta: 0:03:48  time: 0.2846  data_time: 0.0150  memory: 5737  grad_norm: 1.8768  loss: 0.1142  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1142\n",
            "02/09 12:28:00 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][ 60/166]  lr: 2.0000e-04  eta: 0:03:42  time: 0.2877  data_time: 0.0174  memory: 5737  grad_norm: 1.6070  loss: 0.0814  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0814\n",
            "02/09 12:28:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][ 80/166]  lr: 2.0000e-04  eta: 0:03:37  time: 0.2854  data_time: 0.0152  memory: 5737  grad_norm: 1.3842  loss: 0.0803  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0803\n",
            "02/09 12:28:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][100/166]  lr: 2.0000e-04  eta: 0:03:31  time: 0.2869  data_time: 0.0165  memory: 5737  grad_norm: 1.5378  loss: 0.0867  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0867\n",
            "02/09 12:28:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][120/166]  lr: 2.0000e-04  eta: 0:03:25  time: 0.2856  data_time: 0.0158  memory: 5737  grad_norm: 1.5597  loss: 0.0928  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0928\n",
            "02/09 12:28:23 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][140/166]  lr: 2.0000e-04  eta: 0:03:19  time: 0.2878  data_time: 0.0171  memory: 5737  grad_norm: 1.4321  loss: 0.0831  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0831\n",
            "02/09 12:28:29 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][160/166]  lr: 2.0000e-04  eta: 0:03:13  time: 0.2840  data_time: 0.0146  memory: 5737  grad_norm: 1.5844  loss: 0.0850  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0850\n",
            "02/09 12:28:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:28:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [146][166/166]  lr: 2.0000e-04  eta: 0:03:12  time: 0.2820  data_time: 0.0143  memory: 5737  grad_norm: 1.6804  loss: 0.0839  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0839\n",
            "02/09 12:28:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][ 20/166]  lr: 2.0000e-04  eta: 0:03:06  time: 0.3168  data_time: 0.0444  memory: 5737  grad_norm: 1.4611  loss: 0.0811  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0811\n",
            "02/09 12:28:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][ 40/166]  lr: 2.0000e-04  eta: 0:03:00  time: 0.2857  data_time: 0.0156  memory: 5737  grad_norm: 1.4637  loss: 0.0948  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0948\n",
            "02/09 12:28:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][ 60/166]  lr: 2.0000e-04  eta: 0:02:54  time: 0.2867  data_time: 0.0162  memory: 5737  grad_norm: 1.4960  loss: 0.0937  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0937\n",
            "02/09 12:28:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][ 80/166]  lr: 2.0000e-04  eta: 0:02:49  time: 0.2856  data_time: 0.0154  memory: 5737  grad_norm: 1.5459  loss: 0.0835  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0835\n",
            "02/09 12:28:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][100/166]  lr: 2.0000e-04  eta: 0:02:43  time: 0.2870  data_time: 0.0165  memory: 5737  grad_norm: 1.6807  loss: 0.1079  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1079\n",
            "02/09 12:29:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][120/166]  lr: 2.0000e-04  eta: 0:02:37  time: 0.2867  data_time: 0.0160  memory: 5737  grad_norm: 1.8707  loss: 0.1159  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1159\n",
            "02/09 12:29:11 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][140/166]  lr: 2.0000e-04  eta: 0:02:31  time: 0.2867  data_time: 0.0166  memory: 5737  grad_norm: 1.5003  loss: 0.0849  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0849\n",
            "02/09 12:29:17 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][160/166]  lr: 2.0000e-04  eta: 0:02:25  time: 0.2840  data_time: 0.0143  memory: 5737  grad_norm: 1.2454  loss: 0.0712  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0712\n",
            "02/09 12:29:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:29:18 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [147][166/166]  lr: 2.0000e-04  eta: 0:02:24  time: 0.2823  data_time: 0.0142  memory: 5737  grad_norm: 1.3275  loss: 0.0784  top1_acc: 0.9286  top5_acc: 1.0000  loss_cls: 0.0784\n",
            "02/09 12:29:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][ 20/166]  lr: 2.0000e-04  eta: 0:02:18  time: 0.3158  data_time: 0.0440  memory: 5737  grad_norm: 1.7627  loss: 0.1107  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1107\n",
            "02/09 12:29:30 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][ 40/166]  lr: 2.0000e-04  eta: 0:02:12  time: 0.2866  data_time: 0.0163  memory: 5737  grad_norm: 1.7849  loss: 0.1251  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1251\n",
            "02/09 12:29:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][ 60/166]  lr: 2.0000e-04  eta: 0:02:06  time: 0.2872  data_time: 0.0164  memory: 5737  grad_norm: 1.3521  loss: 0.0691  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0691\n",
            "02/09 12:29:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][ 80/166]  lr: 2.0000e-04  eta: 0:02:01  time: 0.2866  data_time: 0.0165  memory: 5737  grad_norm: 1.5901  loss: 0.0853  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0853\n",
            "02/09 12:29:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][100/166]  lr: 2.0000e-04  eta: 0:01:55  time: 0.2872  data_time: 0.0166  memory: 5737  grad_norm: 1.4814  loss: 0.0743  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0743\n",
            "02/09 12:29:53 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][120/166]  lr: 2.0000e-04  eta: 0:01:49  time: 0.2855  data_time: 0.0154  memory: 5737  grad_norm: 1.8360  loss: 0.1208  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1208\n",
            "02/09 12:29:59 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][140/166]  lr: 2.0000e-04  eta: 0:01:43  time: 0.2864  data_time: 0.0161  memory: 5737  grad_norm: 1.9311  loss: 0.1134  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1134\n",
            "02/09 12:30:05 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][160/166]  lr: 2.0000e-04  eta: 0:01:37  time: 0.2847  data_time: 0.0150  memory: 5737  grad_norm: 2.1640  loss: 0.1258  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1258\n",
            "02/09 12:30:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:30:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [148][166/166]  lr: 2.0000e-04  eta: 0:01:36  time: 0.2819  data_time: 0.0141  memory: 5737  grad_norm: 1.8764  loss: 0.0923  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0923\n",
            "02/09 12:30:06 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 148 epochs\n",
            "02/09 12:30:14 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][ 20/166]  lr: 2.0000e-04  eta: 0:01:30  time: 0.3209  data_time: 0.0498  memory: 5737  grad_norm: 1.4834  loss: 0.0775  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0775\n",
            "02/09 12:30:20 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][ 40/166]  lr: 2.0000e-04  eta: 0:01:24  time: 0.2865  data_time: 0.0166  memory: 5737  grad_norm: 1.5948  loss: 0.0922  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0922\n",
            "02/09 12:30:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][ 60/166]  lr: 2.0000e-04  eta: 0:01:18  time: 0.2870  data_time: 0.0171  memory: 5737  grad_norm: 1.2658  loss: 0.0801  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0801\n",
            "02/09 12:30:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][ 80/166]  lr: 2.0000e-04  eta: 0:01:12  time: 0.2863  data_time: 0.0162  memory: 5737  grad_norm: 1.8518  loss: 0.1114  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1114\n",
            "02/09 12:30:37 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][100/166]  lr: 2.0000e-04  eta: 0:01:07  time: 0.2878  data_time: 0.0173  memory: 5737  grad_norm: 2.2944  loss: 0.1312  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1312\n",
            "02/09 12:30:43 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][120/166]  lr: 2.0000e-04  eta: 0:01:01  time: 0.2857  data_time: 0.0157  memory: 5737  grad_norm: 1.2930  loss: 0.0819  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0819\n",
            "02/09 12:30:48 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][140/166]  lr: 2.0000e-04  eta: 0:00:55  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 1.6575  loss: 0.0789  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0789\n",
            "02/09 12:30:54 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][160/166]  lr: 2.0000e-04  eta: 0:00:49  time: 0.2851  data_time: 0.0153  memory: 5737  grad_norm: 2.4387  loss: 0.1257  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1257\n",
            "02/09 12:30:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:30:56 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [149][166/166]  lr: 2.0000e-04  eta: 0:00:48  time: 0.2829  data_time: 0.0149  memory: 5737  grad_norm: 2.2208  loss: 0.1248  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1248\n",
            "02/09 12:31:02 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][ 20/166]  lr: 2.0000e-04  eta: 0:00:42  time: 0.3187  data_time: 0.0474  memory: 5737  grad_norm: 1.3236  loss: 0.0706  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0706\n",
            "02/09 12:31:08 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][ 40/166]  lr: 2.0000e-04  eta: 0:00:36  time: 0.2860  data_time: 0.0159  memory: 5737  grad_norm: 1.9552  loss: 0.1007  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1007\n",
            "02/09 12:31:13 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][ 60/166]  lr: 2.0000e-04  eta: 0:00:30  time: 0.2862  data_time: 0.0158  memory: 5737  grad_norm: 1.5657  loss: 0.0859  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.0859\n",
            "02/09 12:31:19 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][ 80/166]  lr: 2.0000e-04  eta: 0:00:24  time: 0.2857  data_time: 0.0154  memory: 5737  grad_norm: 2.1967  loss: 0.1196  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1196\n",
            "02/09 12:31:25 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][100/166]  lr: 2.0000e-04  eta: 0:00:19  time: 0.2870  data_time: 0.0168  memory: 5737  grad_norm: 1.6383  loss: 0.1114  top1_acc: 0.9375  top5_acc: 1.0000  loss_cls: 0.1114\n",
            "02/09 12:31:31 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][120/166]  lr: 2.0000e-04  eta: 0:00:13  time: 0.2856  data_time: 0.0156  memory: 5737  grad_norm: 1.6085  loss: 0.0844  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0844\n",
            "02/09 12:31:36 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][140/166]  lr: 2.0000e-04  eta: 0:00:07  time: 0.2862  data_time: 0.0160  memory: 5737  grad_norm: 1.3163  loss: 0.0738  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.0738\n",
            "02/09 12:31:42 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][160/166]  lr: 2.0000e-04  eta: 0:00:01  time: 0.2853  data_time: 0.0156  memory: 5737  grad_norm: 1.8659  loss: 0.1189  top1_acc: 0.8750  top5_acc: 1.0000  loss_cls: 0.1189\n",
            "02/09 12:31:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Exp name: no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb_20240209_102917\n",
            "02/09 12:31:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(train) [150][166/166]  lr: 2.0000e-04  eta: 0:00:00  time: 0.2829  data_time: 0.0150  memory: 5737  grad_norm: 1.9848  loss: 0.1247  top1_acc: 1.0000  top5_acc: 1.0000  loss_cls: 0.1247\n",
            "02/09 12:31:44 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Saving checkpoint at 150 epochs\n",
            "02/09 12:31:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [150][20/21]    eta: 0:00:00  time: 0.1403  data_time: 0.0548  memory: 991  \n",
            "02/09 12:31:47 - mmengine - \u001b[4m\u001b[97mINFO\u001b[0m - Epoch(val) [150][21/21]    acc/top1: 0.7560  acc/top5: 1.0000  acc/mean1: 0.7479  data_time: 0.0501  time: 0.1333\n"
          ]
        }
      ],
      "source": [
        "!python ./tools/train.py ./cuny/configs/slowonly/no_pretrain_slowonly_imagenet-pretrained-r50_8xb16-4x16x1-steplr-150e_kinetics400-rgb.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "TsVCPys7dO1d"
      },
      "outputs": [],
      "source": [
        "!cp -r work_dirs /content/drive/MyDrive/cuny_dataset/"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ykj0I2v7v5ao"
      },
      "execution_count": 5,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "gpuType": "V100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}